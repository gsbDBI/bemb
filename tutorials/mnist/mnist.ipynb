{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTORCH_ENABLE_MPS_FALLBACK=1\n"
     ]
    }
   ],
   "source": [
    "%env PYTORCH_ENABLE_MPS_FALLBACK=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tianyudu/miniforge3/envs/ml/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, torchvision\n",
    "\n",
    "from torch_choice.data import ChoiceDataset\n",
    "from bemb.model import LitBEMBFlex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using BEMB Model on the MNIST Dataset\n",
    "Even though BEMB was designed for factorizing matrices, it works on more traditional classification tasks such as the MNIST dataset.\n",
    "\n",
    "## Step 1. Download the MNIST Dataset\n",
    "The `torchvision` module provides an easy way to access the MNIST dataset of hand-written digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "mnist_test = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_train.data.shape=torch.Size([60000, 28, 28])\n",
      "mnist_train.targets.shape=torch.Size([60000])\n",
      "mnist_test.data.shape=torch.Size([10000, 28, 28])\n",
      "mnist_test.targets.shape=torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "print(f'{mnist_train.data.shape=:}')\n",
    "print(f'{mnist_train.targets.shape=:}')\n",
    "print(f'{mnist_test.data.shape=:}')\n",
    "print(f'{mnist_test.targets.shape=:}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.cat([mnist_train.data.reshape(60000, -1), mnist_test.data.reshape(10000, -1)], dim=0)\n",
    "y = torch.cat([mnist_train.targets, mnist_test.targets], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define all features as user features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = torch.arange(60000)\n",
    "test_index = torch.arange(60000, 60000 + 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = 60000\n",
    "N_test = 10000\n",
    "N = N_train + N_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'mps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No `session_index` is provided, assume each choice instance is in its own session.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ChoiceDataset(label=[], item_index=[60000], user_index=[60000], session_index=[60000], item_availability=[], user_obs=[70000, 784], device=cpu),\n",
       " ChoiceDataset(label=[], item_index=[10000], user_index=[10000], session_index=[10000], item_availability=[], user_obs=[70000, 784], device=cpu),\n",
       " ChoiceDataset(label=[], item_index=[10000], user_index=[10000], session_index=[10000], item_availability=[], user_obs=[70000, 784], device=cpu)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = ChoiceDataset(user_index=torch.arange(N), item_index=y, user_obs=X)\n",
    "# dataset = ChoiceDataset(user_index=torch.zeros(N), session_index=torch.arange(N), item_index=y, session_obs=X).to(DEVICE)\n",
    "# we don't have a validation set.\n",
    "dataset_list = [dataset[train_index], dataset[test_index], dataset[test_index]]\n",
    "dataset_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the BEMB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEMB: utility formula parsed:\n",
      "[{'coefficient': ['alpha_item'], 'observable': None},\n",
      " {'coefficient': ['beta_item'], 'observable': 'user_obs'}]\n"
     ]
    }
   ],
   "source": [
    "bemb = LitBEMBFlex(\n",
    "    learning_rate=0.01,  # set the learning rate, feel free to play with different levels.\n",
    "    pred_item=True,  # let the model predict item_index, don't change this one.\n",
    "    num_seeds=4,  # number of Monte Carlo samples for estimating the ELBO.\n",
    "    utility_formula='alpha_item + beta_item * user_obs',  # the utility formula.\n",
    "    num_users=N,\n",
    "    num_items=10,\n",
    "    # num_user_obs=dataset.user_obs.shape[1],\n",
    "    obs2prior_dict={'alpha_item': False, 'beta_item': False},\n",
    "    # the dimension of latents, since the utility is an inner product of theta and alpha, they should have\n",
    "    # the same dimension.\n",
    "    coef_dim_dict={'alpha_item': 1, 'beta_item': 28**2},\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the BEMB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /Users/tianyudu/Development/bemb/tutorials/mnist/lightning_logs\n",
      "\n",
      "  | Name  | Type     | Params\n",
      "-----------------------------------\n",
      "0 | model | BEMBFlex | 15.7 K\n",
      "-----------------------------------\n",
      "15.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.7 K    Total params\n",
      "0.063     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== model received ====================\n",
      "Bayesian EMBedding Model with U[user, item, session] = alpha_item + beta_item * user_obs\n",
      "Total number of parameters: 15700.\n",
      "With the following coefficients:\n",
      "ModuleDict(\n",
      "  (alpha_item): BayesianCoefficient(num_classes=10, dimension=1, prior=N(0, I))\n",
      "  (beta_item): BayesianCoefficient(num_classes=10, dimension=784, prior=N(0, I))\n",
      ")\n",
      "[]\n",
      "==================== data set received ====================\n",
      "[Training dataset] ChoiceDataset(label=[], item_index=[60000], user_index=[60000], session_index=[60000], item_availability=[], user_obs=[70000, 784], device=cpu)\n",
      "[Validation dataset] ChoiceDataset(label=[], item_index=[10000], user_index=[10000], session_index=[10000], item_availability=[], user_obs=[70000, 784], device=cpu)\n",
      "[Testing dataset] ChoiceDataset(label=[], item_index=[10000], user_index=[10000], session_index=[10000], item_availability=[], user_obs=[70000, 784], device=cpu)\n",
      "==================== train the model ====================\n",
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tianyudu/miniforge3/envs/ml/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/tianyudu/miniforge3/envs/ml/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 21/21 [00:03<00:00,  5.81it/s, loss=1.24e+06, v_num=0, val_acc=0.914, val_ll=-2.95]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tianyudu/miniforge3/envs/ml/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "time taken: 187.7522497177124\n",
      "==================== test performance ====================\n",
      "Testing DataLoader 0: 100%|██████████| 29/29 [00:00<00:00, 121.75it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc                   0.914\n",
      "         test_ll            -2.949439179197525\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "bemb = bemb.fit_model(dataset_list, batch_size=len(dataset) // 20, num_epochs=50, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5859d33511df864b0b7226a715510a0165ef032ed4b83eb4ae2c092f0788759c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
