{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for Bayesian Embedding (BEMB) with Educational Data\n",
    "Author: Tianyu Du\n",
    "\n",
    "Date: May. 7, 2022\n",
    "\n",
    "This tutorial helps lab members to deploy the BEMB model on educational question-answering (QA) datasets. We will be using the 17Zuoye data, which is available on Sherlock, throughout this tutorial.\n",
    "\n",
    "However, this tutorial generalizes to any QA datasets in which each row of the dataset corresponds to a triple (student, question, label). Equivalently, each row of these QA datasets is about a student answering a question correctly/incorrectly.\n",
    "\n",
    "You can find the executable Jupyter notebook for this tutorial [here](https://github.com/gsbDBI/deepchoice/blob/main/tutorials/education_data/education_data.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from bemb.model import LitBEMBFlex\n",
    "from bemb.utils.run_helper import run\n",
    "from sklearn import preprocessing\n",
    "from torch_choice.data import ChoiceDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build some helper functions especially for the Zuoye data for demonstration, you can skip this part if you have your own data ready.\n",
    "Please see below for the formats data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_unique_fields(column, field = 'id'):\n",
    "    unique_fields = set()\n",
    "    for tag_list in column:\n",
    "        for entry in tag_list:\n",
    "            unique_fields.add(entry[field])\n",
    "    return list(unique_fields)\n",
    "\n",
    "def convert_tag_list_into_binary_vector(tag_list, encoder, vec_len):\n",
    "    index = encoder.transform([x['id'] for x in tag_list])\n",
    "    out = torch.zeros([vec_len], dtype = torch.float64)\n",
    "    out[index] = 1\n",
    "    return out\n",
    "\n",
    "def convert_column_to_binary_vectors(column):\n",
    "    all_elements = get_all_unique_fields(column)\n",
    "    my_encoder = preprocessing.LabelEncoder()\n",
    "    my_encoder.fit(all_elements)\n",
    "    out = column.apply(lambda x: convert_tag_list_into_binary_vector(x, my_encoder, len(all_elements)))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to try this tutorial on the 17Zuoye dataset, which is located at `data_path` on Sherlock.\n",
    "Please make sure the `data_path` is correct if you are running on your local machine.\n",
    "\n",
    "Henry prepared these datasets in the `feather` format.\n",
    "Feather is a portable file format for storing Arrow tables or data frames (from languages like Python or R) that utilizes the Arrow IPC format internally. Feather was created early in the Arrow project as a proof of concept for fast, language-agnostic data frame storage for Python (pandas) and R (see [here](https://arrow.apache.org/docs/python/feather.html) for more information about Feather data format).\n",
    "You can easily load the data using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/oak/stanford/groups/athey/17Zuoye/bayesian_measurement_17zy/bayes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response_path = os.path.join(data_path, 'exam_response_with_attrib.feather')\n",
    "attribute_path = os.path.join(data_path, 'exam_response_ques_attrib.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The User-Item and Label Dataset (i.e., The **Response** Dataset)\n",
    "For the student response use case, the **response** dataset contains at least three columns: `{user_id, item_id, label}`.\n",
    "\n",
    "Where `user_id` is typically the student's ID, `item_id` is the question's ID, and `label` is the student's response to the question, which is a binary variable indicating whether the student answered the question correctly.\n",
    "\n",
    "In the `df_resp` dataset loaded below, the `student_id` column corresponds to the `user_id`, the `question_id` column corresponds to the `item_id`, and the `correct` column corresponds to the `label`.\n",
    "\n",
    "The length of the `df_resp` dataset is the total number of times students answer questions, this corresponds to the number of **purchasing records** following our terminology in the data management tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of student-question response pairs: 8621720\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>correct</th>\n",
       "      <th>subject</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90368</td>\n",
       "      <td>409</td>\n",
       "      <td>0</td>\n",
       "      <td>CHINESE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90368</td>\n",
       "      <td>409</td>\n",
       "      <td>0</td>\n",
       "      <td>CHINESE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90368</td>\n",
       "      <td>409</td>\n",
       "      <td>0</td>\n",
       "      <td>CHINESE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93193</td>\n",
       "      <td>409</td>\n",
       "      <td>0</td>\n",
       "      <td>CHINESE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93193</td>\n",
       "      <td>409</td>\n",
       "      <td>0</td>\n",
       "      <td>CHINESE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8621715</th>\n",
       "      <td>115131</td>\n",
       "      <td>2080</td>\n",
       "      <td>0</td>\n",
       "      <td>MATH</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8621716</th>\n",
       "      <td>83680</td>\n",
       "      <td>2561</td>\n",
       "      <td>1</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8621717</th>\n",
       "      <td>83680</td>\n",
       "      <td>2564</td>\n",
       "      <td>1</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8621718</th>\n",
       "      <td>83680</td>\n",
       "      <td>2563</td>\n",
       "      <td>1</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8621719</th>\n",
       "      <td>83680</td>\n",
       "      <td>2562</td>\n",
       "      <td>1</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8621720 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         student_id  question_id  correct  subject  grade\n",
       "0             90368          409        0  CHINESE      2\n",
       "1             90368          409        0  CHINESE      2\n",
       "2             90368          409        0  CHINESE      2\n",
       "3             93193          409        0  CHINESE      2\n",
       "4             93193          409        0  CHINESE      2\n",
       "...             ...          ...      ...      ...    ...\n",
       "8621715      115131         2080        0     MATH      2\n",
       "8621716       83680         2561        1  ENGLISH      3\n",
       "8621717       83680         2564        1  ENGLISH      3\n",
       "8621718       83680         2563        1  ENGLISH      3\n",
       "8621719       83680         2562        1  ENGLISH      3\n",
       "\n",
       "[8621720 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resp = pd.read_feather(response_path)\n",
    "print('Number of student-question response pairs:', len(df_resp))\n",
    "df_resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains `261,756` students and `3,604` questions. Student IDs are already encoded as integers ranging from  `0` to `261,755`, and question IDs are already encoded as integers ranging from `0` to `3,603`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261756\n",
      "3604\n"
     ]
    }
   ],
   "source": [
    "print(df_resp['student_id'].nunique())\n",
    "print(df_resp['question_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261755\n",
      "3603\n"
     ]
    }
   ],
   "source": [
    "print(df_resp['student_id'].max())\n",
    "print(df_resp['question_id'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Attribute Dataset\n",
    "Researchers can optionally supply a separate **attribute** dataset including observables of users (i.e., students) and items (i.e., questions).\n",
    "\n",
    "Here we load the `df_attr` dataset, which has length equal to the number of questions. Each row of `df_attr` contains attributes/observables of each question.\n",
    "\n",
    "Specifically, `df_attr` contains a column called `question_id` and several other columns of attributes.\n",
    "For each question, we have two attribute as known as `capability` and `knowledge`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>capability</th>\n",
       "      <th>knowledge</th>\n",
       "      <th>kp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 'TAG_10100001553832', 'type': 0}, {'id...</td>\n",
       "      <td>[{'id': '0101001', 'type': 0.0}, {'id': '01020...</td>\n",
       "      <td>[{'id': 'KP_10100071064944'}, {'id': 'KP_10100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'id': 'TAG_10100001553832', 'type': 0}, {'id...</td>\n",
       "      <td>[{'id': '0101001', 'type': 0.0}, {'id': '01020...</td>\n",
       "      <td>[{'id': 'KP_10100050863402'}, {'id': 'KP_10100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[{'id': 'TAG_10100001553832', 'type': 0}, {'id...</td>\n",
       "      <td>[{'id': '0101001', 'type': 0.0}, {'id': '01020...</td>\n",
       "      <td>[{'id': 'KP_10100050866393'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[{'id': 'TAG_10100001553832', 'type': 0}, {'id...</td>\n",
       "      <td>[{'id': '0101001', 'type': 0.0}, {'id': '01020...</td>\n",
       "      <td>[{'id': 'KP_10100125674593'}, {'id': 'KP_10100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[{'id': 'TAG_10100001553832', 'type': 0}, {'id...</td>\n",
       "      <td>[{'id': '0101001', 'type': 0.0}, {'id': '01020...</td>\n",
       "      <td>[{'id': 'KP_10100077305590'}, {'id': 'KP_10100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599</th>\n",
       "      <td>3599</td>\n",
       "      <td>[{'id': 'TAG_10300000827653', 'type': 0}, {'id...</td>\n",
       "      <td>[{'id': '0301001', 'type': 0.0}, {'id': '03020...</td>\n",
       "      <td>[{'id': 'KP_10300117105040'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3600</th>\n",
       "      <td>3600</td>\n",
       "      <td>[{'id': 'TAG_10300000827653', 'type': 0}, {'id...</td>\n",
       "      <td>[{'id': '0301001', 'type': 0.0}, {'id': '03020...</td>\n",
       "      <td>[{'id': 'KP_10300212870515'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3601</th>\n",
       "      <td>3601</td>\n",
       "      <td>[{'id': 'TAG_10300000827653', 'type': 0}, {'id...</td>\n",
       "      <td>[{'id': '0301001', 'type': 0.0}, {'id': '03020...</td>\n",
       "      <td>[{'id': 'KP_10300111435423'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3602</th>\n",
       "      <td>3602</td>\n",
       "      <td>[{'id': 'TAG_10300000827653', 'type': 0}, {'id...</td>\n",
       "      <td>[{'id': '0301001', 'type': 0.0}, {'id': '03020...</td>\n",
       "      <td>[{'id': 'KP_10300213265389'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3603</th>\n",
       "      <td>3603</td>\n",
       "      <td>[{'id': 'TAG_10300000827653', 'type': 0}, {'id...</td>\n",
       "      <td>[{'id': '0301001', 'type': 0.0}, {'id': '03020...</td>\n",
       "      <td>[{'id': 'KP_10300111316448'}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3604 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      question_id                                         capability  \\\n",
       "0               0  [{'id': 'TAG_10100001553832', 'type': 0}, {'id...   \n",
       "1               1  [{'id': 'TAG_10100001553832', 'type': 0}, {'id...   \n",
       "2               2  [{'id': 'TAG_10100001553832', 'type': 0}, {'id...   \n",
       "3               3  [{'id': 'TAG_10100001553832', 'type': 0}, {'id...   \n",
       "4               4  [{'id': 'TAG_10100001553832', 'type': 0}, {'id...   \n",
       "...           ...                                                ...   \n",
       "3599         3599  [{'id': 'TAG_10300000827653', 'type': 0}, {'id...   \n",
       "3600         3600  [{'id': 'TAG_10300000827653', 'type': 0}, {'id...   \n",
       "3601         3601  [{'id': 'TAG_10300000827653', 'type': 0}, {'id...   \n",
       "3602         3602  [{'id': 'TAG_10300000827653', 'type': 0}, {'id...   \n",
       "3603         3603  [{'id': 'TAG_10300000827653', 'type': 0}, {'id...   \n",
       "\n",
       "                                              knowledge  \\\n",
       "0     [{'id': '0101001', 'type': 0.0}, {'id': '01020...   \n",
       "1     [{'id': '0101001', 'type': 0.0}, {'id': '01020...   \n",
       "2     [{'id': '0101001', 'type': 0.0}, {'id': '01020...   \n",
       "3     [{'id': '0101001', 'type': 0.0}, {'id': '01020...   \n",
       "4     [{'id': '0101001', 'type': 0.0}, {'id': '01020...   \n",
       "...                                                 ...   \n",
       "3599  [{'id': '0301001', 'type': 0.0}, {'id': '03020...   \n",
       "3600  [{'id': '0301001', 'type': 0.0}, {'id': '03020...   \n",
       "3601  [{'id': '0301001', 'type': 0.0}, {'id': '03020...   \n",
       "3602  [{'id': '0301001', 'type': 0.0}, {'id': '03020...   \n",
       "3603  [{'id': '0301001', 'type': 0.0}, {'id': '03020...   \n",
       "\n",
       "                                                     kp  \n",
       "0     [{'id': 'KP_10100071064944'}, {'id': 'KP_10100...  \n",
       "1     [{'id': 'KP_10100050863402'}, {'id': 'KP_10100...  \n",
       "2                         [{'id': 'KP_10100050866393'}]  \n",
       "3     [{'id': 'KP_10100125674593'}, {'id': 'KP_10100...  \n",
       "4     [{'id': 'KP_10100077305590'}, {'id': 'KP_10100...  \n",
       "...                                                 ...  \n",
       "3599                      [{'id': 'KP_10300117105040'}]  \n",
       "3600                      [{'id': 'KP_10300212870515'}]  \n",
       "3601                      [{'id': 'KP_10300111435423'}]  \n",
       "3602                      [{'id': 'KP_10300213265389'}]  \n",
       "3603                      [{'id': 'KP_10300111316448'}]  \n",
       "\n",
       "[3604 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_attr = pd.read_feather(attribute_path).sort_values('question_id').reset_index(drop=True)\n",
    "df_attr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 90 types of capabilities and 34 types of knowledge required by different questions in ths dataset.\n",
    "We convert these attributes into two binary vectors named `capability_vec` and `knowledge_vec`.\n",
    "\n",
    "The `capability_vec` vector has shape `(number_of_questions, 90)` and the `knowledge_vec` vector has shape `(number_of_questions, 34)`.\n",
    "For example, `knowledge_vec[i, j] = 1`  indicates answering question `i` correctly requires type `j` of knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(z):\n",
    "    # extract knowledge domain.\n",
    "    return z[-1]['id']\n",
    "\n",
    "knowledge_domain = [f(x) for x in df_attr['knowledge'].values]\n",
    "\n",
    "df_attr['capability_vec'] = convert_column_to_binary_vectors(df_attr['capability'])\n",
    "df_attr['knowledge_vec'] = convert_column_to_binary_vectors(df_attr['knowledge'])\n",
    "\n",
    "capability_vec = torch.stack(df_attr['capability_vec'].to_list(), dim = 0).float()\n",
    "knowledge_vec = torch.stack(df_attr['knowledge_vec'].to_list(), dim = 0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knowledge_vec.shape=torch.Size([3604, 34])\n",
      "capability_vec.shape=torch.Size([3604, 90])\n"
     ]
    }
   ],
   "source": [
    "print(f\"{knowledge_vec.shape=:}\")\n",
    "print(f\"{capability_vec.shape=:}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we concatenate the `capability_vec` and `knowledge_vec` vectors into a single vector called `item_obs` with shape `(number_of_questions, 124)`. This vector encompasses all attributes/observables of items (i.e., questions in this context)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_obs.shape=torch.Size([3604, 124])\n"
     ]
    }
   ],
   "source": [
    "item_obs = torch.cat([capability_vec, knowledge_vec], dim=1)\n",
    "print(f\"{item_obs.shape=:}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the `ChoiceDataset` Object\n",
    "The last step is to construct the `ChoiceDataset` object. The `item_index`(`user_index`) keyword argument holds the identify of question answered (student answering the question) in each student-question response pair respectively. The `label` argument is a binary tensor indicating whether the student answered the question correctly.\n",
    "Lastly, we put the `item_obs` to capture observables of questions to the dataset.\n",
    "In this tutorial, we don't have any user observables (i.e., observables of students)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No `session_index` is provided, assume each choice instance is in its own session.\n"
     ]
    }
   ],
   "source": [
    "choice_dataset = ChoiceDataset(item_index=torch.LongTensor(df_resp['question_id'].values),\n",
    "                               user_index=torch.LongTensor(df_resp['student_id'].values),\n",
    "                               label=torch.LongTensor(df_resp['correct'].values),\n",
    "                               item_obs=item_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can print the `choice_dataset` to see information about tensors encompassed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChoiceDataset(label=[8621720], item_index=[8621720], user_index=[8621720], session_index=[8621720], item_availability=[], item_obs=[3604, 124], device=cpu)\n"
     ]
    }
   ],
   "source": [
    "print(choice_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = len(torch.unique(choice_dataset.user_index))\n",
    "num_items = len(torch.unique(choice_dataset.item_index))\n",
    "num_item_obs = choice_dataset.item_obs.shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data into Training, Validation, and Testing Sets\n",
    "To test the generalizability of the model, we split the data into training, validation, and testing sets.\n",
    "Specifically, we randomly take 80% of student-question pairs as the training set, 10% as the validation set, and the rest 10% as the testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly permutate the index ranging from (0, 1, ..., len(choice_Dataset) - 1).\n",
    "idx = np.random.permutation(len(choice_dataset))\n",
    "# take the first 80% from the random permutation as indices for the training set.\n",
    "train_size = int(0.8 * len(choice_dataset))\n",
    "val_size = int(0.1 * len(choice_dataset))\n",
    "train_idx = idx[:train_size]\n",
    "val_idx = idx[train_size: train_size + val_size]\n",
    "test_idx = idx[train_size + val_size:]\n",
    "\n",
    "# we put train/validation/test datasets into a list.\n",
    "dataset_list = [choice_dataset[train_idx], choice_dataset[val_idx], choice_dataset[test_idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training dataset] ChoiceDataset(label=[6897376], item_index=[6897376], user_index=[6897376], session_index=[6897376], item_availability=[], item_obs=[3604, 124], device=cpu)\n",
      "[Validation dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu)\n",
      "[Testing dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu)\n"
     ]
    }
   ],
   "source": [
    "print('[Training dataset]', dataset_list[0])\n",
    "print('[Validation dataset]', dataset_list[1])\n",
    "print('[Testing dataset]', dataset_list[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the Model\n",
    "### One Basic Model\n",
    "Now let's fit a basic BEMB model to the data. Recall that an `user` $u$ corresponds to a student and an `item` $i$ corresponds to question in this tutorial.\n",
    "\n",
    "The basic model we will be fitting has utility representation\n",
    "\n",
    "$$\n",
    "U_{ui} = \\lambda_i + \\theta_u^\\top \\alpha_i\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\theta_u, \\alpha_i \\in \\mathbb{R}^{10}\n",
    "$$\n",
    "\n",
    "The predicted probability for student $u$ to correctly answer question $i$ is\n",
    "\n",
    "$$\n",
    "\\frac{1}{1 + e^{-U_{ui}}}\n",
    "$$\n",
    "\n",
    "**Important**: be sure to set `pred_item=False` below since the model is predicting `choice_dataset.label` instead of `choice_dataset.item` as in traditional consumer choice modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEMB: utility formula parsed:\n",
      "[{'coefficient': ['lambda_item'], 'observable': None},\n",
      " {'coefficient': ['theta_user', 'alpha_item'], 'observable': None}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type     | Params\n",
      "-----------------------------------\n",
      "0 | model | BEMBFlex | 5.3 M \n",
      "-----------------------------------\n",
      "5.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.3 M     Total params\n",
      "21.258    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== model received ====================\n",
      "Bayesian EMBedding Model with U[user, item, session] = lambda_item + theta_user * alpha_item\n",
      "Total number of parameters: 5314408.\n",
      "With the following coefficients:\n",
      "ModuleDict(\n",
      "  (lambda_item): BayesianCoefficient(num_classes=3604, dimension=1, prior=N(0, I))\n",
      "  (theta_user): BayesianCoefficient(num_classes=261756, dimension=10, prior=N(0, I))\n",
      "  (alpha_item): BayesianCoefficient(num_classes=3604, dimension=10, prior=N(0, I))\n",
      ")\n",
      "[]\n",
      "==================== data set received ====================\n",
      "[Training dataset] ChoiceDataset(label=[6897376], item_index=[6897376], user_index=[6897376], session_index=[6897376], item_availability=[], item_obs=[3604, 124], device=cpu)\n",
      "[Validation dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu)\n",
      "[Testing dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu)\n",
      "==================== train the model ====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75eafd3f43e4443b33444ee4f35c9d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 89.43709015846252\n",
      "==================== test performance ====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6d80923b5d43d7b2140e6a5fcb7c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.8308121813280877\n",
      "         test_ll            -0.3618064307005444\n",
      "───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "obs2prior_dict = {'lambda_item': False, 'theta_user': False, 'alpha_item': False}\n",
    "LATENT_DIM = 10\n",
    "coef_dim_dict = {'lambda_item': 1, 'theta_user': LATENT_DIM, 'alpha_item': LATENT_DIM}\n",
    "\n",
    "bemb = LitBEMBFlex(\n",
    "    learning_rate=0.1,\n",
    "    pred_item=False,\n",
    "    num_seeds=4,\n",
    "    utility_formula='lambda_item + theta_user * alpha_item',\n",
    "    num_users=num_users,\n",
    "    num_items=num_items,\n",
    "    obs2prior_dict=obs2prior_dict,\n",
    "    coef_dim_dict=coef_dim_dict,\n",
    "    trace_log_q=True,\n",
    "    num_item_obs=num_item_obs,\n",
    "    prior_variance=1\n",
    ")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    bemb = bemb.to('cuda')\n",
    "\n",
    "bemb = run(bemb, dataset_list, batch_size=len(choice_dataset) // 20, num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leveraging More Complex Utility Representations\n",
    "Let's add the item-observable measuring capacities and knowledge required by answering each question to the utility representation.\n",
    "\n",
    "$$\n",
    "U_{ui} = \\lambda_i + \\theta_u^\\top \\alpha_i + \\eta_u^\\top X^{(item\\_obs)}_i\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\theta_u, \\alpha_i \\in \\mathbb{R}^{10}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\eta_u, X^{(item\\_obs)}_i \\in \\mathbb{R}^{124}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEMB: utility formula parsed:\n",
      "[{'coefficient': ['lambda_item'], 'observable': None},\n",
      " {'coefficient': ['theta_user', 'alpha_item'], 'observable': None},\n",
      " {'coefficient': ['eta_user'], 'observable': 'item_obs'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type     | Params\n",
      "-----------------------------------\n",
      "0 | model | BEMBFlex | 70.2 M\n",
      "-----------------------------------\n",
      "70.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "70.2 M    Total params\n",
      "280.920   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== model received ====================\n",
      "Bayesian EMBedding Model with U[user, item, session] = lambda_item + theta_user * alpha_item + eta_user * item_obs\n",
      "Total number of parameters: 70229896.\n",
      "With the following coefficients:\n",
      "ModuleDict(\n",
      "  (lambda_item): BayesianCoefficient(num_classes=3604, dimension=1, prior=N(0, I))\n",
      "  (theta_user): BayesianCoefficient(num_classes=261756, dimension=10, prior=N(0, I))\n",
      "  (alpha_item): BayesianCoefficient(num_classes=3604, dimension=10, prior=N(0, I))\n",
      "  (eta_user): BayesianCoefficient(num_classes=261756, dimension=124, prior=N(0, I))\n",
      ")\n",
      "[]\n",
      "==================== data set received ====================\n",
      "[Training dataset] ChoiceDataset(label=[6897376], item_index=[6897376], user_index=[6897376], session_index=[6897376], item_availability=[], item_obs=[3604, 124], device=cpu)\n",
      "[Validation dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu)\n",
      "[Testing dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu)\n",
      "==================== train the model ====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14da1143f846463eb8c7d79c61f9ff95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 185.29189801216125\n",
      "==================== test performance ====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "266ac17669274d958cebc45871e39677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc             0.852068960717815\n",
      "         test_ll            -0.3408827750695644\n",
      "───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "obs2prior_dict = {'lambda_item': False, 'theta_user': False, 'alpha_item': False, 'eta_user': False}\n",
    "LATENT_DIM = 10\n",
    "coef_dim_dict = {'lambda_item': 1, 'theta_user': LATENT_DIM, 'alpha_item': LATENT_DIM, 'eta_user': num_item_obs}\n",
    "\n",
    "bemb = LitBEMBFlex(\n",
    "    # trainings args.\n",
    "    learning_rate=0.1,\n",
    "    pred_item=False,\n",
    "    num_seeds=4,\n",
    "    # model args, will be passed to BEMB constructor.\n",
    "    utility_formula='lambda_item + theta_user * alpha_item + eta_user * item_obs',\n",
    "    num_users=num_users,\n",
    "    num_items=num_items,\n",
    "    obs2prior_dict=obs2prior_dict,\n",
    "    coef_dim_dict=coef_dim_dict,\n",
    "    trace_log_q=True,\n",
    "    num_item_obs=num_item_obs,\n",
    "    prior_variance=1\n",
    ")\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    bemb = bemb.to('cuda')\n",
    "\n",
    "bemb = run(bemb, dataset_list, batch_size=len(choice_dataset) // 20, num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leveraging `obs2prior`\n",
    "In both examples above, the prior of all coefficients were standard Gaussian distributions.\n",
    "\n",
    "We can improve the model by incorporating the `obs2prior` option and let the mean of prior distribution of item-specific coefficients (i.e., $\\lambda_i$ and $\\alpha_i$) depend on item observables.\n",
    "\n",
    "One can turn on the `obs2prior` option easily by setting `obs2prior_dict['lambda_item'] = True` and `obs2prior_dict['alpha_item'] = True`.\n",
    "\n",
    "**Important**: we recommend to set a small `prior_variance` to make `obs2prior` more effective. For example, if one set `prior_variance=`$\\infty$, prior distributions do not matter at all to the optimization, and the `obs2prior` will be ineffectively as a result.\n",
    "\n",
    "$$\n",
    "U_{ui} = \\lambda_i + \\theta_u^\\top \\alpha_i\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\theta_u, \\alpha_i \\in \\mathbb{R}^{10}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEMB: utility formula parsed:\n",
      "[{'coefficient': ['lambda_item'], 'observable': None},\n",
      " {'coefficient': ['theta_user', 'alpha_item'], 'observable': None},\n",
      " {'coefficient': ['eta_user'], 'observable': 'item_obs'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type     | Params\n",
      "-----------------------------------\n",
      "0 | model | BEMBFlex | 70.2 M\n",
      "-----------------------------------\n",
      "70.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "70.2 M    Total params\n",
      "280.930   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== model received ====================\n",
      "Bayesian EMBedding Model with U[user, item, session] = lambda_item + theta_user * alpha_item + eta_user * item_obs\n",
      "Total number of parameters: 70232624.\n",
      "With the following coefficients:\n",
      "ModuleDict(\n",
      "  (lambda_item): BayesianCoefficient(num_classes=3604, dimension=1, prior=N(H*X_obs(H shape=torch.Size([1, 124]), X_obs shape=124), Ix0.01))\n",
      "  (theta_user): BayesianCoefficient(num_classes=261756, dimension=10, prior=N(0, I))\n",
      "  (alpha_item): BayesianCoefficient(num_classes=3604, dimension=10, prior=N(H*X_obs(H shape=torch.Size([10, 124]), X_obs shape=124), Ix0.01))\n",
      "  (eta_user): BayesianCoefficient(num_classes=261756, dimension=124, prior=N(0, I))\n",
      ")\n",
      "[]\n",
      "==================== data set received ====================\n",
      "[Training dataset] ChoiceDataset(label=[6897376], item_index=[6897376], user_index=[6897376], session_index=[6897376], item_availability=[], item_obs=[3604, 124], device=cpu)\n",
      "[Validation dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu)\n",
      "[Testing dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu)\n",
      "==================== train the model ====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b77ec30c5a4219bfaff58ab3255be1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tianyudu/anaconda3/envs/ml/lib/python3.8/multiprocessing/queues.py\", line 235, in _feed\n",
      "    close()\n",
      "  File \"/home/tianyudu/anaconda3/envs/ml/lib/python3.8/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/home/tianyudu/anaconda3/envs/ml/lib/python3.8/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tianyudu/anaconda3/envs/ml/lib/python3.8/multiprocessing/queues.py\", line 235, in _feed\n",
      "    close()\n",
      "  File \"/home/tianyudu/anaconda3/envs/ml/lib/python3.8/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/home/tianyudu/anaconda3/envs/ml/lib/python3.8/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "  File \"/home/tianyudu/anaconda3/envs/ml/lib/python3.8/multiprocessing/queues.py\", line 235, in _feed\n",
      "    close()\n",
      "  File \"/home/tianyudu/anaconda3/envs/ml/lib/python3.8/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/home/tianyudu/anaconda3/envs/ml/lib/python3.8/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 941.1486117839813\n",
      "==================== test performance ====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bbfc3f7925a4f719faa197f4f2fc7b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.8209313222883601\n",
      "         test_ll            -0.3934649652798017\n",
      "───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "obs2prior_dict = {'lambda_item': True, 'theta_user': False, 'alpha_item': True, 'eta_user': False}\n",
    "LATENT_DIM = 10\n",
    "coef_dim_dict = {'lambda_user': 1, 'lambda_item': 1, 'theta_user': LATENT_DIM, 'alpha_item': LATENT_DIM, 'eta_user': num_item_obs}\n",
    "\n",
    "bemb = LitBEMBFlex(\n",
    "    # trainings args.\n",
    "    learning_rate=0.1,\n",
    "    pred_item=False,\n",
    "    num_seeds=4,\n",
    "    # model args, will be passed to BEMB constructor.\n",
    "    utility_formula='lambda_item + theta_user * alpha_item + eta_user * item_obs',\n",
    "    num_users=num_users,\n",
    "    num_items=num_items,\n",
    "    obs2prior_dict=obs2prior_dict,\n",
    "    coef_dim_dict=coef_dim_dict,\n",
    "    trace_log_q=True,\n",
    "    num_item_obs=num_item_obs,\n",
    "    prior_variance=0.01\n",
    ")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    bemb = bemb.to('cuda')\n",
    "   \n",
    "bemb = run(bemb, dataset_list, batch_size=len(choice_dataset) // 20, num_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the Model\n",
    "There are tons of parameters in models above, for example, we choose `LATENT_DIM = 10` based on our own experience. However, these choices of hyper-parameters can be sub-optimal.\n",
    "\n",
    "We recommend researchers to try out different combinations of hyper-parameters before sticking with a particular hyper-parameter configuration.\n",
    "\n",
    "We will be providing a script for effectively parameter tuning though the `learning-tool-competition` project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07dd84f3285103b45d36665747e055dbb0ef78c9d17293fd1b33b99205a40b05"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
