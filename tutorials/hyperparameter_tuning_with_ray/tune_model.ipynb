{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameter Tuning with Ray-Tune Tutorial\n",
    "This tutorial helps you tune hyper-parameters (e.g., learning rate, batch size, number of latent dimensions, etc) in BEMB.\n",
    "\n",
    "We will be using the `ray` library, which enables parallelization, to tune hyper-parameters.\n",
    "\n",
    "For more details regarding using Ray to tune hyper-parameters of models (especially PyTorch lightning models), please refer to this [tutorial](https://docs.ray.io/en/latest/ray-core/examples/using-ray-with-pytorch-lightning.html).\n",
    "\n",
    "Author: Tianyu Du\n",
    "Date: July. 27, 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tianyudu/miniforge3/envs/ml/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_choice.data import ChoiceDataset\n",
    "from bemb.model import LitBEMBFlex\n",
    "from bemb.utils.run_helper import run\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from bemb.model import LitBEMBFlex\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.integration.pytorch_lightning import TuneReportCallback\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea behind tuning hyper-parameters is to find the best configuration of the model among a space of hyper-parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate Datasets\n",
    "\n",
    "I use the simulated datasets from the *simulation* tutorial (refer to the `tutorials/simulation/simulation.ipynb` notebook).\n",
    "\n",
    "The `simulate_dataset` method returns a list of three `ChoiceDataset` corresponding to the train/validation/test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No `session_index` is provided, assume each choice instance is in its own session.\n"
     ]
    }
   ],
   "source": [
    "# def simulate_dataset() -> List[ChoiceDataset]:\n",
    "num_users = 1500\n",
    "num_items = 50\n",
    "data_size = 1000\n",
    "user_index = torch.LongTensor(np.random.choice(num_users, size=data_size))\n",
    "Us = np.arange(num_users)\n",
    "Is = np.sin(np.arange(num_users) / num_users * 4 * np.pi)\n",
    "Is = (Is + 1) / 2 * num_items\n",
    "Is = Is.astype(int)\n",
    "\n",
    "PREFERENCE = dict((u, i) for (u, i) in zip(Us, Is))\n",
    "\n",
    "item_index = torch.LongTensor(np.random.choice(num_items, size=data_size))\n",
    "\n",
    "for idx in range(data_size):\n",
    "    if np.random.rand() <= 0.5:\n",
    "        item_index[idx] = PREFERENCE[int(user_index[idx])]\n",
    "\n",
    "# df = pd.DataFrame(data={'item': item_index, 'user': user_index}).groupby(['item', 'user']).size().rename('size').reset_index()\n",
    "# df = df.pivot('item', 'user', 'size').fillna(0.0)\n",
    "\n",
    "user_obs = torch.zeros(num_users, num_items)\n",
    "user_obs[torch.arange(num_users), Is] = 1\n",
    "\n",
    "item_obs = torch.eye(num_items)\n",
    "\n",
    "dataset = ChoiceDataset(user_index=user_index, item_index=item_index, user_obs=user_obs, item_obs=item_obs)\n",
    "\n",
    "idx = np.random.permutation(len(dataset))\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "train_idx = idx[:train_size]\n",
    "val_idx = idx[train_size: train_size + val_size]\n",
    "test_idx = idx[train_size + val_size:]\n",
    "\n",
    "dataset_list = [dataset[train_idx], dataset[val_idx], dataset[test_idx]]\n",
    "    # return dataset_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChoiceDataset(label=[], item_index=[800], user_index=[800], session_index=[800], item_availability=[], user_obs=[1500, 50], item_obs=[50, 50], device=cpu),\n",
       " ChoiceDataset(label=[], item_index=[100], user_index=[100], session_index=[100], item_availability=[], user_obs=[1500, 50], item_obs=[50, 50], device=cpu),\n",
       " ChoiceDataset(label=[], item_index=[100], user_index=[100], session_index=[100], item_availability=[], user_obs=[1500, 50], item_obs=[50, 50], device=cpu)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset_list = simulate_dataset()\n",
    "dataset_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 3\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TuneReportCallback({'val_loss': 'val_loss', 'val_acc': 'val_acc'}, on='validation_end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tune(hparams):\n",
    "    bemb = LitBEMBFlex(\n",
    "        learning_rate=0.03,  # set the learning rate, feel free to play with different levels.\n",
    "        pred_item=True,  # let the model predict item_index, don't change this one.\n",
    "        num_seeds=32,  # number of Monte Carlo samples for estimating the ELBO.\n",
    "        utility_formula='theta_user * alpha_item',  # the utility formula.\n",
    "        num_users=num_users,\n",
    "        num_items=num_items,\n",
    "        num_user_obs=dataset.user_obs.shape[1],\n",
    "        num_item_obs=dataset.item_obs.shape[1],\n",
    "        # whether to turn on obs2prior for each parameter.\n",
    "        obs2prior_dict={'theta_user': hparams['obs2prior'], 'alpha_item': hparams['obs2prior']},\n",
    "        # the dimension of latents, since the utility is an inner product of theta and alpha, they should have\n",
    "        # the same dimension.\n",
    "        coef_dim_dict={'theta_user': hparams['latent_dim'], 'alpha_item': hparams['latent_dim']}\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=1,\n",
    "        check_val_every_n_epoch=1,\n",
    "        log_every_n_steps=1,\n",
    "        gpus=0,\n",
    "        progress_bar_refresh_rate=0,\n",
    "        auto_lr_find=False,\n",
    "        logger=TensorBoardLogger(save_dir='./', name='', version='.'),\n",
    "        callbacks=[callback, EarlyStopping(monitor='val_loss', patience=30, mode='min')])\n",
    "\n",
    "    # find an appropriate learning rate.\n",
    "    trainer.tune(bemb,\n",
    "                 train_dataloaders=DataLoader(dataset_list[0]),\n",
    "                 val_dataloaders=dataset_list[1],\n",
    "                 test_dataloaders=dataset_list[2])\n",
    "    # trainer.fit(bemb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 01:04:14,741\tERROR services.py:1488 -- Failed to start the dashboard: Failed to start the dashboard, return code 1\n",
      "Failed to read dashboard log: [Errno 2] No such file or directory: '/tmp/ray/session_2022-07-27_01-04-13_590765_58763/logs/dashboard.log'\n",
      "2022-07-27 01:04:14,742\tERROR services.py:1489 -- Failed to start the dashboard, return code 1\n",
      "Failed to read dashboard log: [Errno 2] No such file or directory: '/tmp/ray/session_2022-07-27_01-04-13_590765_58763/logs/dashboard.log'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tianyudu/miniforge3/envs/ml/lib/python3.9/site-packages/ray/_private/services.py\", line 1451, in start_dashboard\n",
      "    with open(dashboard_log, \"rb\") as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/tmp/ray/session_2022-07-27_01-04-13_590765_58763/logs/dashboard.log'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tianyudu/miniforge3/envs/ml/lib/python3.9/site-packages/ray/_private/services.py\", line 1462, in start_dashboard\n",
      "    raise Exception(err_msg + f\"\\nFailed to read dashboard log: {e}\")\n",
      "Exception: Failed to start the dashboard, return code 1\n",
      "Failed to read dashboard log: [Errno 2] No such file or directory: '/tmp/ray/session_2022-07-27_01-04-13_590765_58763/logs/dashboard.log'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'learning_rate': tune.choice([0.01, 0.03, 0.1, 0.3]),\n",
    "    'latent_dim': tune.choice([10, 20, 50, 100]),\n",
    "    'obs2prior': tune.choice([True, False])\n",
    "}\n",
    "\n",
    "# scheduler = ASHAScheduler(max_t=num_epochs, grace_period=1, reduction_factor=2)\n",
    "scheduler = None\n",
    "\n",
    "reporter = CLIReporter(parameter_columns=list(config.keys()),\n",
    "                        metric_columns=list(callback._metrics.keys()))\n",
    "\n",
    "analysis = tune.run(\n",
    "    tune.with_parameters(train_tune, epochs=num_epochs),\n",
    "    metric='val_loss',\n",
    "    mode='min',\n",
    "    resources_per_trial={'cpu': 4, 'gpu': 0},\n",
    "    config=config,\n",
    "    num_samples=num_samples,\n",
    "    scheduler=scheduler,\n",
    "    progress_reporter=reporter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5859d33511df864b0b7226a715510a0165ef032ed4b83eb4ae2c092f0788759c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
