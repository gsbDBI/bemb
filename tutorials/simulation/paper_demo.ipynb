{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEMB Paper Code Demonstration\n",
    "This file contains code demonstrated in our BEMB paper, readers can run the code in this file to reproduce the results in our paper or modify the code to fit their own needs.\n",
    "\n",
    "Readers can refer to the `torch-choice` paper or `torch-choice` documentation website for more details about the `ChoiceDataset` data structure.\n",
    "\n",
    "Code for simulation studies is in another separate notebook.\n",
    "\n",
    "> Author: Tianyu Du\n",
    ">\n",
    "> Date: Sept. 12, 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_choice\n",
    "from torch_choice.data import ChoiceDataset\n",
    "\n",
    "import bemb\n",
    "from bemb.model import LitBEMBFlex\n",
    "from bemb.utils.run_helper import run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.__version__=2.0.1\n",
      "torch.cuda.is_available()=False\n",
      "torch_choice.__version__=1.0.4a\n",
      "bemb.__version__=0.1.6\n"
     ]
    }
   ],
   "source": [
    "print(f\"{torch.__version__=:}\")\n",
    "print(f\"{torch.cuda.is_available()=:}\")\n",
    "print(f\"{torch_choice.__version__=:}\")\n",
    "print(f\"{bemb.__version__=:}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x115985190>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for reproducibility, fix random seeds.\n",
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "torch.random.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "else:\n",
    "    DEVICE = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Random Information for Demonstration\n",
    "Here we will use randomly generated information to illustrate the usage of `ChoiceDataset`. Observable tensors are classified by how they vary by user, item, and session. The package is expecting particular shapes of these observable tensors based on their types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to modify it as you want.\n",
    "num_users = 10  # $U$\n",
    "num_items = 4  # $I$\n",
    "num_sessions = 500  # $S$\n",
    "\n",
    "length_of_dataset = 10000  # $N$\n",
    "# create observables/features, the number of parameters are arbitrarily chosen.\n",
    "# generate 128 features for each user, e.g., race, gender.\n",
    "# these variables should have shape (num_users, *)\n",
    "user_obs = torch.randn(num_users, 128)\n",
    "# generate 64 features for each user, e.g., quality.\n",
    "item_obs = torch.randn(num_items, 64)\n",
    "# generate 10 features for each session, e.g., weekday indicator. \n",
    "session_obs = torch.randn(num_sessions, 10)\n",
    "# generate 12 features for each session user pair, e.g., the budget of that user at the shopping day.\n",
    "itemsession_obs = torch.randn(num_sessions, num_items, 12)\n",
    "# generate 12 features for each user item pair, e.g., the user's preference on that item.\n",
    "useritem_obs = torch.randn(num_users, num_items, 12)\n",
    "# generate 10 user-session specific observables, e.g., the historical spending amount of that user at that session.\n",
    "usersession_obs = torch.randn(num_users, num_sessions, 10)\n",
    "# generate 8 features for each user session item triple, e.g., the user's preference on that item at that session.\n",
    "# since `U*S*I` is potentially huge and may cause identifiability issues, we rarely use this kind of observable in practice.\n",
    "usersessionitem_obs = torch.randn(num_users, num_sessions, num_items, 8)\n",
    "\n",
    "# generate the array of item[n].\n",
    "item_index = torch.LongTensor(np.random.choice(num_items, size=length_of_dataset))\n",
    "# generate the array of user[n].\n",
    "user_index = torch.LongTensor(np.random.choice(num_users, size=length_of_dataset))\n",
    "# generate the array of session[n].\n",
    "session_index = torch.LongTensor(np.random.choice(num_sessions, size=length_of_dataset))\n",
    "\n",
    "# assume all items are available in all sessions.\n",
    "item_availability = torch.ones(num_sessions, num_items).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ChoiceDataset(\n",
    "    # pre-specified keywords of __init__\n",
    "    item_index=item_index,  # required.\n",
    "    num_items=num_items,\n",
    "    # optional:\n",
    "    user_index=user_index,\n",
    "    num_users=num_users,\n",
    "    session_index=session_index,\n",
    "    item_availability=item_availability,\n",
    "    # additional keywords of __init__\n",
    "    user_obs=user_obs,\n",
    "    item_obs=item_obs,\n",
    "    session_obs=session_obs,\n",
    "    itemsession_obs=itemsession_obs,\n",
    "    useritem_obs=useritem_obs,\n",
    "    usersession_obs=usersession_obs,\n",
    "    usersessionitem_obs=usersessionitem_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_obs: torch.Size([10000, 4, 128])\n",
      "item_obs: torch.Size([10000, 4, 64])\n",
      "session_obs: torch.Size([10000, 4, 10])\n",
      "itemsession_obs: torch.Size([10000, 4, 12])\n",
      "useritem_obs: torch.Size([10000, 4, 12])\n",
      "usersession_obs: torch.Size([10000, 4, 10])\n",
      "usersessionitem_obs: torch.Size([10000, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "def print_dict(d):\n",
    "    for k, v in d.items():\n",
    "        if torch.is_tensor(v):\n",
    "            print(f\"{k}: {v.shape}\")\n",
    "print_dict(dataset.x_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can subset the dataset by conventional python indexing.\n",
    "dataset_train = dataset[:8000].to(DEVICE)\n",
    "dataset_val = dataset[8000:9000].to(DEVICE)\n",
    "dataset_test = dataset[9000:].to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conduct the ELBO Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type     | Params\n",
      "-----------------------------------\n",
      "0 | model | BEMBFlex | 34.3 K\n",
      "-----------------------------------\n",
      "34.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "34.3 K    Total params\n",
      "0.137     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEMB: utility formula parsed:\n",
      "[{'coefficient': ['alpha_item'], 'observable': None},\n",
      " {'coefficient': ['beta_user', 'gamma_item'], 'observable': None},\n",
      " {'coefficient': ['delta_user'], 'observable': 'item_obs'},\n",
      " {'coefficient': ['eta_item', 'pi_user'], 'observable': 'session_obs'}]\n",
      "==================== model received ====================\n",
      "Bayesian EMBedding Model with U[user, item, session] = alpha_item + beta_user * gamma_item + delta_user * item_obs + eta_item * pi_user * session_obs\n",
      "Total number of parameters: 34280.\n",
      "With the following coefficients:\n",
      "ModuleDict(\n",
      "  (alpha_item): BayesianCoefficient(num_classes=4, dimension=1, prior=N(H*X_obs(H shape=torch.Size([1, 64]), X_obs shape=64), Ix1.0))\n",
      "  (beta_user): BayesianCoefficient(num_classes=10, dimension=10, prior=N(H*X_obs(H shape=torch.Size([10, 128]), X_obs shape=128), Ix1.0))\n",
      "  (gamma_item): BayesianCoefficient(num_classes=4, dimension=10, prior=N(H*X_obs(H shape=torch.Size([10, 64]), X_obs shape=64), Ix1.0))\n",
      "  (delta_user): BayesianCoefficient(num_classes=10, dimension=64, prior=N(H*X_obs(H shape=torch.Size([64, 128]), X_obs shape=128), Ix1.0))\n",
      "  (eta_item): BayesianCoefficient(num_classes=4, dimension=30, prior=N(H*X_obs(H shape=torch.Size([30, 64]), X_obs shape=64), Ix1.0))\n",
      "  (pi_user): BayesianCoefficient(num_classes=10, dimension=30, prior=N(H*X_obs(H shape=torch.Size([30, 128]), X_obs shape=128), Ix1.0))\n",
      ")\n",
      "[]\n",
      "Optimizer: Adam, Learning rate: 0.1\n",
      "==================== data set received ====================\n",
      "[Training dataset] ChoiceDataset(label=[], item_index=[8000], user_index=[8000], session_index=[8000], item_availability=[500, 4], user_obs=[10, 128], item_obs=[4, 64], session_obs=[500, 10], itemsession_obs=[500, 4, 12], useritem_obs=[10, 4, 12], usersession_obs=[10, 500, 10], usersessionitem_obs=[10, 500, 4, 8], device=cpu)\n",
      "[Validation dataset] ChoiceDataset(label=[], item_index=[1000], user_index=[1000], session_index=[1000], item_availability=[500, 4], user_obs=[10, 128], item_obs=[4, 64], session_obs=[500, 10], itemsession_obs=[500, 4, 12], useritem_obs=[10, 4, 12], usersession_obs=[10, 500, 10], usersessionitem_obs=[10, 500, 4, 8], device=cpu)\n",
      "[Testing dataset] ChoiceDataset(label=[], item_index=[1000], user_index=[1000], session_index=[1000], item_availability=[500, 4], user_obs=[10, 128], item_obs=[4, 64], session_obs=[500, 10], itemsession_obs=[500, 4, 12], useritem_obs=[10, 4, 12], usersession_obs=[10, 500, 10], usersessionitem_obs=[10, 500, 4, 8], device=cpu)\n",
      "==================== train the model ====================\n",
      "Epoch 2: 100%|██████████| 71/71 [00:02<00:00, 33.29it/s, loss=3.44e+03, v_num=45, val_acc=0.248, val_ll=-1.99]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 71/71 [00:02<00:00, 33.17it/s, loss=3.44e+03, v_num=45, val_acc=0.248, val_ll=-1.99]\n",
      "time taken: 6.626070022583008\n",
      "==================== test performance ====================\n",
      "Testing DataLoader 0: 100%|██████████| 84/84 [00:00<00:00, 182.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           0.249           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_ll          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    -1.9957098799463049    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          0.249          \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_ll         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   -1.9957098799463049   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bemb = LitBEMBFlex(\n",
    "    learning_rate=0.1,  # set the learning rate, feel free to play with different levels.\n",
    "    pred_item=True,  # let the model predict item_index, don't change this one.\n",
    "    num_seeds=32,  # number of Monte Carlo samples for estimating the ELBO.\n",
    "    utility_formula=\"alpha_item + beta_user * gamma_item + delta_user * item_obs + eta_item * pi_user * session_obs\",  # the utility formula.\n",
    "    num_users=num_users,\n",
    "    num_items=num_items,\n",
    "    num_sessions=num_sessions,\n",
    "    num_user_obs=dataset.user_obs.shape[1],\n",
    "    num_item_obs=dataset.item_obs.shape[1],\n",
    "    # we use obs2prior on all coefficients, simply change them to False if you want to disable the obs2prior for a particular coefficient.\n",
    "    obs2prior_dict={\"alpha_item\": True, \n",
    "                    \"beta_user\": True,\n",
    "                    \"gamma_item\": True,\n",
    "                    \"delta_user\": True,\n",
    "                    \"eta_item\": True,\n",
    "                    \"pi_user\": True},\n",
    "    # the dimension of latents, since the utility is an inner product of theta and alpha, they should have\n",
    "    # the same dimension.\n",
    "    coef_dim_dict={\"alpha_item\": 1,  # fix effect should always have dimension of 1.\n",
    "                   # the matrix decomposition term beta_user * gamma_item indicates that beta_user and gamma_item should have the same dimension.\n",
    "                   # we choose the latent dimension to 10 here.\n",
    "                   \"beta_user\": 10,\n",
    "                   \"gamma_item\": 10,\n",
    "                   # delta_user * item_obs term indicates that delta_user and item_obs should have the same dimension.\n",
    "                   # and we generated 64 item features above.\n",
    "                   \"delta_user\": 64,\n",
    "                   # eta_item * pi_user* session_obs suggests that both of eta_item and pi_user should have the same dimension.\n",
    "                   # the dimension of them should be the dimension of session_obs (which is 10) multiplied by the latent dimension.\n",
    "                   # we choose the latent dimension to be 3 here.\n",
    "                   \"eta_item\": 10*3,\n",
    "                   \"pi_user\": 10*3},\n",
    ")\n",
    "\n",
    "# move the model to the computing device (e.g., GPU if available).\n",
    "bemb = bemb.to(DEVICE)\n",
    "\n",
    "# estimate the model for 3 epochs.\n",
    "bemb = bemb.fit_model([dataset_train, dataset_val, dataset_test],\n",
    "                      batch_size=128, num_epochs=3, num_workers=0, device=DEVICE, enable_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The paper demon notebook has run successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"The paper demon notebook has run successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
