{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1c2c5e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "import torch\n",
    "import yaml\n",
    "from deepchoice.data import ChoiceDataset\n",
    "from deepchoice.data.utils import create_data_loader\n",
    "from deepchoice.model.bemb_flex_lightning import LitBEMBFlex\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from termcolor import cprint\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from deepchoice.model import BEMBFlex\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.integration.pytorch_lightning import TuneReportCallback\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch\n",
    "import yaml\n",
    "from deepchoice.data import ChoiceDataset\n",
    "from deepchoice.data.utils import create_data_loader\n",
    "from deepchoice.model.bemb_flex_lightning import LitBEMBFlex\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from termcolor import cprint\n",
    "\n",
    "from deepchoice.model import BEMBFlex\n",
    "\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc303dcb",
   "metadata": {},
   "source": [
    "# The Simulation Study for Quick Checks on the Correctness of Algorithm: Define the data-generating-process (DGP)\n",
    "\n",
    "$$\n",
    "U_{uit} = \\theta_i^\\top \\beta_u P\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\theta_i \\sim \\mathcal{N}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\beta_u \\sim \\mathcal{N}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8afd2be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_USERS = 5\n",
    "NUM_ITEMS = 20\n",
    "NUM_SESSIONS = 10\n",
    "K = 5\n",
    "N = 1000\n",
    "NUM_P_DIM = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1d67f944",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mean = torch.randn((NUM_USERS, K * NUM_P_DIM))\n",
    "item_mean = - torch.randn((NUM_ITEMS, K * NUM_P_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9178b83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_dist = MultivariateNormal(loc=item_mean, covariance_matrix=torch.eye(K * NUM_P_DIM))\n",
    "theta = theta_dist.sample()\n",
    "theta = theta.reshape(NUM_ITEMS, K, NUM_P_DIM)\n",
    "\n",
    "beta_dist = MultivariateNormal(loc=user_mean, covariance_matrix=torch.eye(K * NUM_P_DIM))\n",
    "beta = beta_dist.sample()\n",
    "beta = beta.reshape(NUM_USERS, K, NUM_P_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "69058965",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_index = torch.LongTensor(np.random.choice(range(NUM_USERS), size=N, replace=True))\n",
    "session_index = torch.LongTensor(np.random.choice(range(NUM_SESSIONS), size=N, replace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b88b0728",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = torch.randn(size=(NUM_SESSIONS, NUM_ITEMS, NUM_P_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c32c0bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f40edbfb790>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(user_mean.reshape(-1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ff9618",
   "metadata": {},
   "source": [
    "## Compute Utilities and Generate Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b77fa73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 4366.91it/s]\n"
     ]
    }
   ],
   "source": [
    "utility_array = list()\n",
    "for row in tqdm(range(N)):\n",
    "    u = user_index[row]\n",
    "    t = session_index[row]\n",
    "    utility = torch.zeros(NUM_ITEMS)\n",
    "    for i in range(NUM_ITEMS):\n",
    "        theta_i = theta[i]\n",
    "        beta_u = beta[u]\n",
    "        coef = (theta_i * beta_u).sum(dim=0)\n",
    "        price = P[t, i, :]\n",
    "        utility[i] = (coef * price).sum()\n",
    "    utility_array.append(utility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f21ac32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "U = torch.stack(utility_array)\n",
    "label = torch.argmax(U, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8ecda0",
   "metadata": {},
   "source": [
    "# Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5013021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = np.arange(0, int(0.7*N))\n",
    "val_mask = np.arange(int(0.7*N), int(0.85*N))\n",
    "test_mask = np.arange(int(0.85*N), N)\n",
    "\n",
    "dataset_list = list()\n",
    "for mask in (train_mask, val_mask, test_mask):\n",
    "    d = ChoiceDataset(label=label[mask],\n",
    "                      user_index=user_index[mask],\n",
    "                      session_index=session_index[mask],\n",
    "                      item_availability=None,\n",
    "                      price_obs=P)\n",
    "    dataset_list.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "08154130",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitBEMBFlex(pl.LightningModule):\n",
    "    def __init__(self, **kwargs):\n",
    "        # use kwargs to pass parameter to BEMB Torch.\n",
    "        super().__init__()\n",
    "        self.model = BEMBFlex(**kwargs)\n",
    "        self.num_needs = 4\n",
    "        self.learning_rate = 0.03\n",
    "        self.batch_size = 500\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return str(self.model)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        elbo = self.model.elbo(batch, num_seeds=self.num_needs)\n",
    "        self.log('train_elbo', elbo)\n",
    "        loss = - elbo\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        LL = self.model.forward(\n",
    "            batch, return_logit=False, all_items=False).mean()\n",
    "        self.log('val_log_likelihood', LL, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        LL = self.model.forward(\n",
    "            batch, return_logit=False, all_items=False).mean()\n",
    "        self.log('test_log_likelihood', LL)\n",
    "\n",
    "        pred = self.model(batch)\n",
    "        performance = self.model.get_within_category_accuracy(\n",
    "            pred, batch.label)\n",
    "        for key, val in performance.items():\n",
    "            self.log('test_' + key, val, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return create_data_loader(dataset_list[0], batch_size=self.batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return create_data_loader(dataset_list[1], batch_size=self.batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        # use smaller batch size for test, which takes more memory.\n",
    "        return create_data_loader(dataset_list[2], batch_size=10000, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1a3aaf20",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type     | Params\n",
      "-----------------------------------\n",
      "0 | model | BEMBFlex | 7.5 K \n",
      "-----------------------------------\n",
      "7.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.5 K     Total params\n",
      "0.030     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mYou are using BEMB Flex v3 (rc)\u001b[0m\n",
      "BEMB: utility formula parsed:\n",
      "[{'coefficient': ['theta_item', 'beta_user'], 'observable': 'price_obs'}]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7d9737f61864348b1d4b11fb42fa93e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_latents = 50\n",
    "\n",
    "model = LitBEMBFlex(utility_formula='theta_item * beta_user * price_obs',\n",
    "                    num_users=NUM_USERS,\n",
    "                    num_items=NUM_ITEMS,\n",
    "                    num_sessions=NUM_SESSIONS,\n",
    "                    obs2prior_dict={'theta_item': False, 'beta_user': False},\n",
    "                    coef_dim_dict={'theta_item': num_latents * NUM_P_DIM, 'beta_user': num_latents * NUM_P_DIM},\n",
    "                    num_price_obs=NUM_P_DIM)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    check_val_every_n_epoch=1,\n",
    "    log_every_n_steps=1,\n",
    "    gpus=1)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "52d4d6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ef41db3b0be416da9032e3ace830482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_accuracy': 0.7866666913032532,\n",
      " 'test_f1score': 0.7876542210578918,\n",
      " 'test_log_likelihood': -1.9390641450881958,\n",
      " 'test_precision': 0.8188446760177612,\n",
      " 'test_recall': 0.758752703666687}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_log_likelihood': -1.9390641450881958,\n",
       "  'test_accuracy': 0.7866666913032532,\n",
       "  'test_precision': 0.8188446760177612,\n",
       "  'test_recall': 0.758752703666687,\n",
       "  'test_f1score': 0.7876542210578918}]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8419207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "callback = TuneReportCallback({'val_log_likelihood': 'val_log_likelihood'}, on='validation_end')\n",
    "\n",
    "def train_tune(hparams, epochs=10, gpus=1):\n",
    "    model = LitBEMBFlex(utility_formula='theta_item * beta_user * price_obs',\n",
    "                    num_users=NUM_USERS,\n",
    "                    num_items=NUM_ITEMS,\n",
    "                    num_sessions=NUM_SESSIONS,\n",
    "                    obs2prior_dict={'theta_item': False, 'beta_user': False},\n",
    "                    coef_dim_dict={'theta_item': hparams['num_latents'] * NUM_P_DIM, 'beta_user': hparams['num_latents'] * NUM_P_DIM},\n",
    "                    num_price_obs=NUM_P_DIM)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=epochs,\n",
    "        check_val_every_n_epoch=1,\n",
    "        log_every_n_steps=1,\n",
    "        gpus=gpus,\n",
    "        progress_bar_refresh_rate=0,\n",
    "        logger=TensorBoardLogger(save_dir=tune.get_trial_dir(), name='', version='.'),\n",
    "        callbacks=[callback])\n",
    "    trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dec2d94",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 8.4/125.5 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 0/16 CPUs, 0/1 GPUs, 0.0/73.6 GiB heap, 0.0/35.54 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/tianyudu/ray_results/train_tune_2021-10-11_18-19-59\n",
      "Number of trials: 17/20 (17 PENDING)\n",
      "+------------------------+----------+-------+---------------+\n",
      "| Trial name             | status   | loc   |   num_latents |\n",
      "|------------------------+----------+-------+---------------|\n",
      "| train_tune_84be5_00000 | PENDING  |       |            10 |\n",
      "| train_tune_84be5_00001 | PENDING  |       |           100 |\n",
      "| train_tune_84be5_00002 | PENDING  |       |             3 |\n",
      "| train_tune_84be5_00003 | PENDING  |       |             4 |\n",
      "| train_tune_84be5_00004 | PENDING  |       |            10 |\n",
      "| train_tune_84be5_00005 | PENDING  |       |            10 |\n",
      "| train_tune_84be5_00006 | PENDING  |       |            20 |\n",
      "| train_tune_84be5_00007 | PENDING  |       |            10 |\n",
      "| train_tune_84be5_00008 | PENDING  |       |             2 |\n",
      "| train_tune_84be5_00009 | PENDING  |       |          1000 |\n",
      "| train_tune_84be5_00010 | PENDING  |       |             5 |\n",
      "| train_tune_84be5_00011 | PENDING  |       |             3 |\n",
      "| train_tune_84be5_00012 | PENDING  |       |           300 |\n",
      "| train_tune_84be5_00013 | PENDING  |       |             2 |\n",
      "| train_tune_84be5_00014 | PENDING  |       |             4 |\n",
      "| train_tune_84be5_00015 | PENDING  |       |             1 |\n",
      "| train_tune_84be5_00016 | PENDING  |       |            10 |\n",
      "+------------------------+----------+-------+---------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=1039943)\u001b[0m \u001b[31mYou are using BEMB Flex v3 (rc)\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=1039943)\u001b[0m BEMB: utility formula parsed:\n",
      "\u001b[2m\u001b[36m(pid=1039943)\u001b[0m [{'coefficient': ['theta_item', 'beta_user'], 'observable': 'price_obs'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1039943)\u001b[0m GPU available: True, used: True\n",
      "\u001b[2m\u001b[36m(pid=1039943)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1039943)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(pid=1039943)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[2m\u001b[36m(pid=1039943)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1039943)\u001b[0m   | Name  | Type     | Params\n",
      "\u001b[2m\u001b[36m(pid=1039943)\u001b[0m -----------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1039943)\u001b[0m 0 | model | BEMBFlex | 1.5 K \n",
      "\u001b[2m\u001b[36m(pid=1039943)\u001b[0m -----------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1039943)\u001b[0m 1.5 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1039943)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1039943)\u001b[0m 1.5 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1039943)\u001b[0m 0.006     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1039943)\u001b[0m /home/tianyudu/anaconda3/envs/ml/lib/python3.8/site-packages/pytorch_lightning/trainer/deprecated_api.py:25: LightningDeprecationWarning: `Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\n",
      "\u001b[2m\u001b[36m(pid=1039943)\u001b[0m   rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 12.3/125.5 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 16.0/16 CPUs, 1.0/1 GPUs, 0.0/73.6 GiB heap, 0.0/35.54 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/tianyudu/ray_results/train_tune_2021-10-11_18-19-59\n",
      "Number of trials: 18/20 (17 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+-------+---------------+\n",
      "| Trial name             | status   | loc   |   num_latents |\n",
      "|------------------------+----------+-------+---------------|\n",
      "| train_tune_84be5_00000 | RUNNING  |       |            10 |\n",
      "| train_tune_84be5_00001 | PENDING  |       |           100 |\n",
      "| train_tune_84be5_00002 | PENDING  |       |             3 |\n",
      "| train_tune_84be5_00003 | PENDING  |       |             4 |\n",
      "| train_tune_84be5_00004 | PENDING  |       |            10 |\n",
      "| train_tune_84be5_00005 | PENDING  |       |            10 |\n",
      "| train_tune_84be5_00006 | PENDING  |       |            20 |\n",
      "| train_tune_84be5_00007 | PENDING  |       |            10 |\n",
      "| train_tune_84be5_00008 | PENDING  |       |             2 |\n",
      "| train_tune_84be5_00009 | PENDING  |       |          1000 |\n",
      "| train_tune_84be5_00010 | PENDING  |       |             5 |\n",
      "| train_tune_84be5_00011 | PENDING  |       |             3 |\n",
      "| train_tune_84be5_00012 | PENDING  |       |           300 |\n",
      "| train_tune_84be5_00013 | PENDING  |       |             2 |\n",
      "| train_tune_84be5_00014 | PENDING  |       |             4 |\n",
      "| train_tune_84be5_00015 | PENDING  |       |             1 |\n",
      "| train_tune_84be5_00016 | PENDING  |       |            10 |\n",
      "| train_tune_84be5_00017 | PENDING  |       |             2 |\n",
      "+------------------------+----------+-------+---------------+\n",
      "\n",
      "\n",
      "Result for train_tune_84be5_00000:\n",
      "  date: 2021-10-11_18-20-05\n",
      "  done: false\n",
      "  experiment_id: 3ad9de640ef443238105c5e2caa5de50\n",
      "  hostname: aurora\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.0.158\n",
      "  pid: 1039943\n",
      "  time_since_restore: 4.017311334609985\n",
      "  time_this_iter_s: 4.017311334609985\n",
      "  time_total_s: 4.017311334609985\n",
      "  timestamp: 1634001605\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 84be5_00000\n",
      "  val_log_likelihood: -7.3631062507629395\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 12.4/125.5 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: -4.776825904846191 | Iter 2.000: -6.445621013641357 | Iter 1.000: -7.3631062507629395\n",
      "Resources requested: 16.0/16 CPUs, 1.0/1 GPUs, 0.0/73.6 GiB heap, 0.0/35.54 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Current best trial: 84be5_00000 with val_log_likelihood=-2.9988136291503906 and parameters={'num_latents': 10}\n",
      "Result logdir: /home/tianyudu/ray_results/train_tune_2021-10-11_18-19-59\n",
      "Number of trials: 18/20 (17 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+-----------------------+---------------+----------------------+\n",
      "| Trial name             | status   | loc                   |   num_latents |   val_log_likelihood |\n",
      "|------------------------+----------+-----------------------+---------------+----------------------|\n",
      "| train_tune_84be5_00000 | RUNNING  | 192.168.0.158:1039943 |            10 |             -2.99881 |\n",
      "| train_tune_84be5_00001 | PENDING  |                       |           100 |                      |\n",
      "| train_tune_84be5_00002 | PENDING  |                       |             3 |                      |\n",
      "| train_tune_84be5_00003 | PENDING  |                       |             4 |                      |\n",
      "| train_tune_84be5_00004 | PENDING  |                       |            10 |                      |\n",
      "| train_tune_84be5_00005 | PENDING  |                       |            10 |                      |\n",
      "| train_tune_84be5_00006 | PENDING  |                       |            20 |                      |\n",
      "| train_tune_84be5_00007 | PENDING  |                       |            10 |                      |\n",
      "| train_tune_84be5_00008 | PENDING  |                       |             2 |                      |\n",
      "| train_tune_84be5_00009 | PENDING  |                       |          1000 |                      |\n",
      "| train_tune_84be5_00010 | PENDING  |                       |             5 |                      |\n",
      "| train_tune_84be5_00011 | PENDING  |                       |             3 |                      |\n",
      "| train_tune_84be5_00012 | PENDING  |                       |           300 |                      |\n",
      "| train_tune_84be5_00013 | PENDING  |                       |             2 |                      |\n",
      "| train_tune_84be5_00014 | PENDING  |                       |             4 |                      |\n",
      "| train_tune_84be5_00015 | PENDING  |                       |             1 |                      |\n",
      "| train_tune_84be5_00016 | PENDING  |                       |            10 |                      |\n",
      "| train_tune_84be5_00017 | PENDING  |                       |             2 |                      |\n",
      "+------------------------+----------+-----------------------+---------------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_tune_84be5_00000:\n",
      "  date: 2021-10-11_18-20-10\n",
      "  done: false\n",
      "  experiment_id: 3ad9de640ef443238105c5e2caa5de50\n",
      "  hostname: aurora\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.0.158\n",
      "  pid: 1039943\n",
      "  time_since_restore: 9.581341981887817\n",
      "  time_this_iter_s: 0.6658051013946533\n",
      "  time_total_s: 9.581341981887817\n",
      "  timestamp: 1634001610\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 9\n",
      "  trial_id: 84be5_00000\n",
      "  val_log_likelihood: -2.212611436843872\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 12.2/125.5 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -1.0825423002243042 | Iter 8.000: -2.5817272663116455 | Iter 4.000: -4.776825904846191 | Iter 2.000: -6.445621013641357 | Iter 1.000: -7.3631062507629395\n",
      "Resources requested: 16.0/16 CPUs, 1.0/1 GPUs, 0.0/73.6 GiB heap, 0.0/35.54 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Current best trial: 84be5_00000 with val_log_likelihood=-1.0825423002243042 and parameters={'num_latents': 10}\n",
      "Result logdir: /home/tianyudu/ray_results/train_tune_2021-10-11_18-19-59\n",
      "Number of trials: 18/20 (17 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+-----------------------+---------------+----------------------+\n",
      "| Trial name             | status   | loc                   |   num_latents |   val_log_likelihood |\n",
      "|------------------------+----------+-----------------------+---------------+----------------------|\n",
      "| train_tune_84be5_00000 | RUNNING  | 192.168.0.158:1039943 |            10 |             -1.08254 |\n",
      "| train_tune_84be5_00001 | PENDING  |                       |           100 |                      |\n",
      "| train_tune_84be5_00002 | PENDING  |                       |             3 |                      |\n",
      "| train_tune_84be5_00003 | PENDING  |                       |             4 |                      |\n",
      "| train_tune_84be5_00004 | PENDING  |                       |            10 |                      |\n",
      "| train_tune_84be5_00005 | PENDING  |                       |            10 |                      |\n",
      "| train_tune_84be5_00006 | PENDING  |                       |            20 |                      |\n",
      "| train_tune_84be5_00007 | PENDING  |                       |            10 |                      |\n",
      "| train_tune_84be5_00008 | PENDING  |                       |             2 |                      |\n",
      "| train_tune_84be5_00009 | PENDING  |                       |          1000 |                      |\n",
      "| train_tune_84be5_00010 | PENDING  |                       |             5 |                      |\n",
      "| train_tune_84be5_00011 | PENDING  |                       |             3 |                      |\n",
      "| train_tune_84be5_00012 | PENDING  |                       |           300 |                      |\n",
      "| train_tune_84be5_00013 | PENDING  |                       |             2 |                      |\n",
      "| train_tune_84be5_00014 | PENDING  |                       |             4 |                      |\n",
      "| train_tune_84be5_00015 | PENDING  |                       |             1 |                      |\n",
      "| train_tune_84be5_00016 | PENDING  |                       |            10 |                      |\n",
      "| train_tune_84be5_00017 | PENDING  |                       |             2 |                      |\n",
      "+------------------------+----------+-----------------------+---------------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_tune_84be5_00000:\n",
      "  date: 2021-10-11_18-20-16\n",
      "  done: false\n",
      "  experiment_id: 3ad9de640ef443238105c5e2caa5de50\n",
      "  hostname: aurora\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.0.158\n",
      "  pid: 1039943\n",
      "  time_since_restore: 15.065951347351074\n",
      "  time_this_iter_s: 0.6839993000030518\n",
      "  time_total_s: 15.065951347351074\n",
      "  timestamp: 1634001616\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 17\n",
      "  trial_id: 84be5_00000\n",
      "  val_log_likelihood: -1.0132337808609009\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 12.2/125.5 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -1.0825423002243042 | Iter 8.000: -2.5817272663116455 | Iter 4.000: -4.776825904846191 | Iter 2.000: -6.445621013641357 | Iter 1.000: -7.3631062507629395\n",
      "Resources requested: 16.0/16 CPUs, 1.0/1 GPUs, 0.0/73.6 GiB heap, 0.0/35.54 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Current best trial: 84be5_00000 with val_log_likelihood=-0.5969322919845581 and parameters={'num_latents': 10}\n",
      "Result logdir: /home/tianyudu/ray_results/train_tune_2021-10-11_18-19-59\n",
      "Number of trials: 18/20 (17 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+-----------------------+---------------+----------------------+\n",
      "| Trial name             | status   | loc                   |   num_latents |   val_log_likelihood |\n",
      "|------------------------+----------+-----------------------+---------------+----------------------|\n",
      "| train_tune_84be5_00000 | RUNNING  | 192.168.0.158:1039943 |            10 |            -0.596932 |\n",
      "| train_tune_84be5_00001 | PENDING  |                       |           100 |                      |\n",
      "| train_tune_84be5_00002 | PENDING  |                       |             3 |                      |\n",
      "| train_tune_84be5_00003 | PENDING  |                       |             4 |                      |\n",
      "| train_tune_84be5_00004 | PENDING  |                       |            10 |                      |\n",
      "| train_tune_84be5_00005 | PENDING  |                       |            10 |                      |\n",
      "| train_tune_84be5_00006 | PENDING  |                       |            20 |                      |\n",
      "| train_tune_84be5_00007 | PENDING  |                       |            10 |                      |\n",
      "| train_tune_84be5_00008 | PENDING  |                       |             2 |                      |\n",
      "| train_tune_84be5_00009 | PENDING  |                       |          1000 |                      |\n",
      "| train_tune_84be5_00010 | PENDING  |                       |             5 |                      |\n",
      "| train_tune_84be5_00011 | PENDING  |                       |             3 |                      |\n",
      "| train_tune_84be5_00012 | PENDING  |                       |           300 |                      |\n",
      "| train_tune_84be5_00013 | PENDING  |                       |             2 |                      |\n",
      "| train_tune_84be5_00014 | PENDING  |                       |             4 |                      |\n",
      "| train_tune_84be5_00015 | PENDING  |                       |             1 |                      |\n",
      "| train_tune_84be5_00016 | PENDING  |                       |            10 |                      |\n",
      "| train_tune_84be5_00017 | PENDING  |                       |             2 |                      |\n",
      "+------------------------+----------+-----------------------+---------------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_tune_84be5_00000:\n",
      "  date: 2021-10-11_18-20-21\n",
      "  done: false\n",
      "  experiment_id: 3ad9de640ef443238105c5e2caa5de50\n",
      "  hostname: aurora\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.0.158\n",
      "  pid: 1039943\n",
      "  time_since_restore: 20.60879421234131\n",
      "  time_this_iter_s: 0.6698012351989746\n",
      "  time_total_s: 20.60879421234131\n",
      "  timestamp: 1634001621\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 25\n",
      "  trial_id: 84be5_00000\n",
      "  val_log_likelihood: -0.5492780208587646\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 12.2/125.5 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 32.000: -0.281253457069397 | Iter 16.000: -1.0825423002243042 | Iter 8.000: -2.5817272663116455 | Iter 4.000: -4.776825904846191 | Iter 2.000: -6.445621013641357 | Iter 1.000: -7.3631062507629395\n",
      "Resources requested: 16.0/16 CPUs, 1.0/1 GPUs, 0.0/73.6 GiB heap, 0.0/35.54 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Current best trial: 84be5_00000 with val_log_likelihood=-0.281253457069397 and parameters={'num_latents': 10}\n",
      "Result logdir: /home/tianyudu/ray_results/train_tune_2021-10-11_18-19-59\n",
      "Number of trials: 18/20 (17 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+-----------------------+---------------+----------------------+\n",
      "| Trial name             | status   | loc                   |   num_latents |   val_log_likelihood |\n",
      "|------------------------+----------+-----------------------+---------------+----------------------|\n",
      "| train_tune_84be5_00000 | RUNNING  | 192.168.0.158:1039943 |            10 |            -0.281253 |\n",
      "| train_tune_84be5_00001 | PENDING  |                       |           100 |                      |\n",
      "| train_tune_84be5_00002 | PENDING  |                       |             3 |                      |\n",
      "| train_tune_84be5_00003 | PENDING  |                       |             4 |                      |\n",
      "| train_tune_84be5_00004 | PENDING  |                       |            10 |                      |\n",
      "| train_tune_84be5_00005 | PENDING  |                       |            10 |                      |\n",
      "| train_tune_84be5_00006 | PENDING  |                       |            20 |                      |\n",
      "| train_tune_84be5_00007 | PENDING  |                       |            10 |                      |\n",
      "| train_tune_84be5_00008 | PENDING  |                       |             2 |                      |\n",
      "| train_tune_84be5_00009 | PENDING  |                       |          1000 |                      |\n",
      "| train_tune_84be5_00010 | PENDING  |                       |             5 |                      |\n",
      "| train_tune_84be5_00011 | PENDING  |                       |             3 |                      |\n",
      "| train_tune_84be5_00012 | PENDING  |                       |           300 |                      |\n",
      "| train_tune_84be5_00013 | PENDING  |                       |             2 |                      |\n",
      "| train_tune_84be5_00014 | PENDING  |                       |             4 |                      |\n",
      "| train_tune_84be5_00015 | PENDING  |                       |             1 |                      |\n",
      "| train_tune_84be5_00016 | PENDING  |                       |            10 |                      |\n",
      "| train_tune_84be5_00017 | PENDING  |                       |             2 |                      |\n",
      "+------------------------+----------+-----------------------+---------------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_tune_84be5_00000:\n",
      "  date: 2021-10-11_18-20-27\n",
      "  done: false\n",
      "  experiment_id: 3ad9de640ef443238105c5e2caa5de50\n",
      "  hostname: aurora\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.0.158\n",
      "  pid: 1039943\n",
      "  time_since_restore: 26.066145181655884\n",
      "  time_this_iter_s: 0.6690382957458496\n",
      "  time_total_s: 26.066145181655884\n",
      "  timestamp: 1634001627\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 33\n",
      "  trial_id: 84be5_00000\n",
      "  val_log_likelihood: -0.24883194267749786\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 12.2/125.5 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 32.000: -0.281253457069397 | Iter 16.000: -1.0825423002243042 | Iter 8.000: -2.5817272663116455 | Iter 4.000: -4.776825904846191 | Iter 2.000: -6.445621013641357 | Iter 1.000: -7.3631062507629395\n",
      "Resources requested: 16.0/16 CPUs, 1.0/1 GPUs, 0.0/73.6 GiB heap, 0.0/35.54 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Current best trial: 84be5_00000 with val_log_likelihood=-0.1233576089143753 and parameters={'num_latents': 10}\n",
      "Result logdir: /home/tianyudu/ray_results/train_tune_2021-10-11_18-19-59\n",
      "Number of trials: 18/20 (17 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+-----------------------+---------------+----------------------+\n",
      "| Trial name             | status   | loc                   |   num_latents |   val_log_likelihood |\n",
      "|------------------------+----------+-----------------------+---------------+----------------------|\n",
      "| train_tune_84be5_00000 | RUNNING  | 192.168.0.158:1039943 |            10 |            -0.123358 |\n",
      "| train_tune_84be5_00001 | PENDING  |                       |           100 |                      |\n",
      "| train_tune_84be5_00002 | PENDING  |                       |             3 |                      |\n",
      "| train_tune_84be5_00003 | PENDING  |                       |             4 |                      |\n",
      "| train_tune_84be5_00004 | PENDING  |                       |            10 |                      |\n",
      "| train_tune_84be5_00005 | PENDING  |                       |            10 |                      |\n",
      "| train_tune_84be5_00006 | PENDING  |                       |            20 |                      |\n",
      "| train_tune_84be5_00007 | PENDING  |                       |            10 |                      |\n",
      "| train_tune_84be5_00008 | PENDING  |                       |             2 |                      |\n",
      "| train_tune_84be5_00009 | PENDING  |                       |          1000 |                      |\n",
      "| train_tune_84be5_00010 | PENDING  |                       |             5 |                      |\n",
      "| train_tune_84be5_00011 | PENDING  |                       |             3 |                      |\n",
      "| train_tune_84be5_00012 | PENDING  |                       |           300 |                      |\n",
      "| train_tune_84be5_00013 | PENDING  |                       |             2 |                      |\n",
      "| train_tune_84be5_00014 | PENDING  |                       |             4 |                      |\n",
      "| train_tune_84be5_00015 | PENDING  |                       |             1 |                      |\n",
      "| train_tune_84be5_00016 | PENDING  |                       |            10 |                      |\n",
      "| train_tune_84be5_00017 | PENDING  |                       |             2 |                      |\n",
      "+------------------------+----------+-----------------------+---------------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_tune_84be5_00000:\n",
      "  date: 2021-10-11_18-20-32\n",
      "  done: false\n",
      "  experiment_id: 3ad9de640ef443238105c5e2caa5de50\n",
      "  hostname: aurora\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 192.168.0.158\n",
      "  pid: 1039943\n",
      "  time_since_restore: 31.647354125976562\n",
      "  time_this_iter_s: 0.6802787780761719\n",
      "  time_total_s: 31.647354125976562\n",
      "  timestamp: 1634001632\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 41\n",
      "  trial_id: 84be5_00000\n",
      "  val_log_likelihood: -0.10934583097696304\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 12.2/125.5 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 32.000: -0.281253457069397 | Iter 16.000: -1.0825423002243042 | Iter 8.000: -2.5817272663116455 | Iter 4.000: -4.776825904846191 | Iter 2.000: -6.445621013641357 | Iter 1.000: -7.3631062507629395\n",
      "Resources requested: 16.0/16 CPUs, 1.0/1 GPUs, 0.0/73.6 GiB heap, 0.0/35.54 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Current best trial: 84be5_00000 with val_log_likelihood=-0.023121792823076248 and parameters={'num_latents': 10}\n",
      "Result logdir: /home/tianyudu/ray_results/train_tune_2021-10-11_18-19-59\n",
      "Number of trials: 18/20 (17 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+-----------------------+---------------+----------------------+\n",
      "| Trial name             | status   | loc                   |   num_latents |   val_log_likelihood |\n",
      "|------------------------+----------+-----------------------+---------------+----------------------|\n",
      "| train_tune_84be5_00000 | RUNNING  | 192.168.0.158:1039943 |            10 |           -0.0231218 |\n",
      "| train_tune_84be5_00001 | PENDING  |                       |           100 |                      |\n",
      "| train_tune_84be5_00002 | PENDING  |                       |             3 |                      |\n",
      "| train_tune_84be5_00003 | PENDING  |                       |             4 |                      |\n",
      "| train_tune_84be5_00004 | PENDING  |                       |            10 |                      |\n",
      "| train_tune_84be5_00005 | PENDING  |                       |            10 |                      |\n",
      "| train_tune_84be5_00006 | PENDING  |                       |            20 |                      |\n",
      "| train_tune_84be5_00007 | PENDING  |                       |            10 |                      |\n",
      "| train_tune_84be5_00008 | PENDING  |                       |             2 |                      |\n",
      "| train_tune_84be5_00009 | PENDING  |                       |          1000 |                      |\n",
      "| train_tune_84be5_00010 | PENDING  |                       |             5 |                      |\n",
      "| train_tune_84be5_00011 | PENDING  |                       |             3 |                      |\n",
      "| train_tune_84be5_00012 | PENDING  |                       |           300 |                      |\n",
      "| train_tune_84be5_00013 | PENDING  |                       |             2 |                      |\n",
      "| train_tune_84be5_00014 | PENDING  |                       |             4 |                      |\n",
      "| train_tune_84be5_00015 | PENDING  |                       |             1 |                      |\n",
      "| train_tune_84be5_00016 | PENDING  |                       |            10 |                      |\n",
      "| train_tune_84be5_00017 | PENDING  |                       |             2 |                      |\n",
      "+------------------------+----------+-----------------------+---------------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_tune_84be5_00000:\n",
      "  date: 2021-10-11_18-20-38\n",
      "  done: false\n",
      "  experiment_id: 3ad9de640ef443238105c5e2caa5de50\n",
      "  hostname: aurora\n",
      "  iterations_since_restore: 49\n",
      "  node_ip: 192.168.0.158\n",
      "  pid: 1039943\n",
      "  time_since_restore: 37.08507561683655\n",
      "  time_this_iter_s: 0.6671164035797119\n",
      "  time_total_s: 37.08507561683655\n",
      "  timestamp: 1634001638\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 49\n",
      "  trial_id: 84be5_00000\n",
      "  val_log_likelihood: -0.01784338243305683\n",
      "  \n",
      "Result for train_tune_84be5_00000:\n",
      "  date: 2021-10-11_18-20-39\n",
      "  done: true\n",
      "  experiment_id: 3ad9de640ef443238105c5e2caa5de50\n",
      "  hostname: aurora\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 192.168.0.158\n",
      "  pid: 1039943\n",
      "  time_since_restore: 37.76810836791992\n",
      "  time_this_iter_s: 0.683032751083374\n",
      "  time_total_s: 37.76810836791992\n",
      "  timestamp: 1634001639\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 50\n",
      "  trial_id: 84be5_00000\n",
      "  val_log_likelihood: -0.013439194299280643\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1054171)\u001b[0m GPU available: True, used: True\n",
      "\u001b[2m\u001b[36m(pid=1054171)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1054171)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(pid=1054171)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1054171)\u001b[0m \u001b[31mYou are using BEMB Flex v3 (rc)\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=1054171)\u001b[0m BEMB: utility formula parsed:\n",
      "\u001b[2m\u001b[36m(pid=1054171)\u001b[0m [{'coefficient': ['theta_item', 'beta_user'], 'observable': 'price_obs'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1054171)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1054171)\u001b[0m   | Name  | Type     | Params\n",
      "\u001b[2m\u001b[36m(pid=1054171)\u001b[0m -----------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1054171)\u001b[0m 0 | model | BEMBFlex | 15.0 K\n",
      "\u001b[2m\u001b[36m(pid=1054171)\u001b[0m -----------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1054171)\u001b[0m 15.0 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1054171)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1054171)\u001b[0m 15.0 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=1054171)\u001b[0m 0.060     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 11.4/125.5 GiB\n",
      "Using AsyncHyperBand: num_stopped=1\n",
      "Bracket: Iter 32.000: -0.281253457069397 | Iter 16.000: -1.0825423002243042 | Iter 8.000: -2.5817272663116455 | Iter 4.000: -4.776825904846191 | Iter 2.000: -6.445621013641357 | Iter 1.000: -7.3631062507629395\n",
      "Resources requested: 16.0/16 CPUs, 1.0/1 GPUs, 0.0/73.6 GiB heap, 0.0/35.54 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Current best trial: 84be5_00000 with val_log_likelihood=-0.013439194299280643 and parameters={'num_latents': 10}\n",
      "Result logdir: /home/tianyudu/ray_results/train_tune_2021-10-11_18-19-59\n",
      "Number of trials: 19/20 (17 PENDING, 1 RUNNING, 1 TERMINATED)\n",
      "+------------------------+------------+-------+---------------+----------------------+\n",
      "| Trial name             | status     | loc   |   num_latents |   val_log_likelihood |\n",
      "|------------------------+------------+-------+---------------+----------------------|\n",
      "| train_tune_84be5_00001 | RUNNING    |       |           100 |                      |\n",
      "| train_tune_84be5_00002 | PENDING    |       |             3 |                      |\n",
      "| train_tune_84be5_00003 | PENDING    |       |             4 |                      |\n",
      "| train_tune_84be5_00004 | PENDING    |       |            10 |                      |\n",
      "| train_tune_84be5_00005 | PENDING    |       |            10 |                      |\n",
      "| train_tune_84be5_00006 | PENDING    |       |            20 |                      |\n",
      "| train_tune_84be5_00007 | PENDING    |       |            10 |                      |\n",
      "| train_tune_84be5_00008 | PENDING    |       |             2 |                      |\n",
      "| train_tune_84be5_00009 | PENDING    |       |          1000 |                      |\n",
      "| train_tune_84be5_00010 | PENDING    |       |             5 |                      |\n",
      "| train_tune_84be5_00011 | PENDING    |       |             3 |                      |\n",
      "| train_tune_84be5_00012 | PENDING    |       |           300 |                      |\n",
      "| train_tune_84be5_00013 | PENDING    |       |             2 |                      |\n",
      "| train_tune_84be5_00014 | PENDING    |       |             4 |                      |\n",
      "| train_tune_84be5_00015 | PENDING    |       |             1 |                      |\n",
      "| train_tune_84be5_00016 | PENDING    |       |            10 |                      |\n",
      "| train_tune_84be5_00017 | PENDING    |       |             2 |                      |\n",
      "| train_tune_84be5_00018 | PENDING    |       |            10 |                      |\n",
      "| train_tune_84be5_00000 | TERMINATED |       |            10 |           -0.0134392 |\n",
      "+------------------------+------------+-------+---------------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1054171)\u001b[0m /home/tianyudu/anaconda3/envs/ml/lib/python3.8/site-packages/pytorch_lightning/trainer/deprecated_api.py:25: LightningDeprecationWarning: `Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\n",
      "\u001b[2m\u001b[36m(pid=1054171)\u001b[0m   rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_tune_84be5_00001:\n",
      "  date: 2021-10-11_18-20-44\n",
      "  done: true\n",
      "  experiment_id: 90a0c1712fd3444a981d6a0dae6daee9\n",
      "  hostname: aurora\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.0.158\n",
      "  pid: 1054171\n",
      "  time_since_restore: 4.085261106491089\n",
      "  time_this_iter_s: 4.085261106491089\n",
      "  time_total_s: 4.085261106491089\n",
      "  timestamp: 1634001644\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 84be5_00001\n",
      "  val_log_likelihood: -25.585140228271484\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=1054643)\u001b[0m \u001b[31mYou are using BEMB Flex v3 (rc)\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=1054643)\u001b[0m BEMB: utility formula parsed:\n",
      "\u001b[2m\u001b[36m(pid=1054643)\u001b[0m [{'coefficient': ['theta_item', 'beta_user'], 'observable': 'price_obs'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1054643)\u001b[0m GPU available: True, used: True\n",
      "\u001b[2m\u001b[36m(pid=1054643)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1054643)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(pid=1054643)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 11.1/125.5 GiB\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 32.000: -0.281253457069397 | Iter 16.000: -1.0825423002243042 | Iter 8.000: -2.5817272663116455 | Iter 4.000: -4.776825904846191 | Iter 2.000: -6.445621013641357 | Iter 1.000: -16.474123239517212\n",
      "Resources requested: 16.0/16 CPUs, 1.0/1 GPUs, 0.0/73.6 GiB heap, 0.0/35.54 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Current best trial: 84be5_00000 with val_log_likelihood=-0.013439194299280643 and parameters={'num_latents': 10}\n",
      "Result logdir: /home/tianyudu/ray_results/train_tune_2021-10-11_18-19-59\n",
      "Number of trials: 20/20 (17 PENDING, 1 RUNNING, 2 TERMINATED)\n",
      "+------------------------+------------+-------+---------------+----------------------+\n",
      "| Trial name             | status     | loc   |   num_latents |   val_log_likelihood |\n",
      "|------------------------+------------+-------+---------------+----------------------|\n",
      "| train_tune_84be5_00002 | RUNNING    |       |             3 |                      |\n",
      "| train_tune_84be5_00003 | PENDING    |       |             4 |                      |\n",
      "| train_tune_84be5_00004 | PENDING    |       |            10 |                      |\n",
      "| train_tune_84be5_00005 | PENDING    |       |            10 |                      |\n",
      "| train_tune_84be5_00006 | PENDING    |       |            20 |                      |\n",
      "| train_tune_84be5_00007 | PENDING    |       |            10 |                      |\n",
      "| train_tune_84be5_00008 | PENDING    |       |             2 |                      |\n",
      "| train_tune_84be5_00009 | PENDING    |       |          1000 |                      |\n",
      "| train_tune_84be5_00010 | PENDING    |       |             5 |                      |\n",
      "| train_tune_84be5_00011 | PENDING    |       |             3 |                      |\n",
      "| train_tune_84be5_00012 | PENDING    |       |           300 |                      |\n",
      "| train_tune_84be5_00013 | PENDING    |       |             2 |                      |\n",
      "| train_tune_84be5_00014 | PENDING    |       |             4 |                      |\n",
      "| train_tune_84be5_00015 | PENDING    |       |             1 |                      |\n",
      "| train_tune_84be5_00016 | PENDING    |       |            10 |                      |\n",
      "| train_tune_84be5_00017 | PENDING    |       |             2 |                      |\n",
      "| train_tune_84be5_00018 | PENDING    |       |            10 |                      |\n",
      "| train_tune_84be5_00019 | PENDING    |       |             7 |                      |\n",
      "| train_tune_84be5_00000 | TERMINATED |       |            10 |           -0.0134392 |\n",
      "| train_tune_84be5_00001 | TERMINATED |       |           100 |          -25.5851    |\n",
      "+------------------------+------------+-------+---------------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1054643)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1054643)\u001b[0m   | Name  | Type     | Params\n",
      "\u001b[2m\u001b[36m(pid=1054643)\u001b[0m -----------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1054643)\u001b[0m 0 | model | BEMBFlex | 450   \n",
      "\u001b[2m\u001b[36m(pid=1054643)\u001b[0m -----------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1054643)\u001b[0m 450       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1054643)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1054643)\u001b[0m 450       Total params\n",
      "\u001b[2m\u001b[36m(pid=1054643)\u001b[0m 0.002     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1054643)\u001b[0m /home/tianyudu/anaconda3/envs/ml/lib/python3.8/site-packages/pytorch_lightning/trainer/deprecated_api.py:25: LightningDeprecationWarning: `Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\n",
      "\u001b[2m\u001b[36m(pid=1054643)\u001b[0m   rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_tune_84be5_00002:\n",
      "  date: 2021-10-11_18-20-49\n",
      "  done: false\n",
      "  experiment_id: acb3c244d748411cbf7f6380bf429d4f\n",
      "  hostname: aurora\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.0.158\n",
      "  pid: 1054643\n",
      "  time_since_restore: 4.056497573852539\n",
      "  time_this_iter_s: 4.056497573852539\n",
      "  time_total_s: 4.056497573852539\n",
      "  timestamp: 1634001649\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 84be5_00002\n",
      "  val_log_likelihood: -5.045517921447754\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 12.2/125.5 GiB\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 32.000: -0.281253457069397 | Iter 16.000: -1.0825423002243042 | Iter 8.000: -2.5817272663116455 | Iter 4.000: -4.431471824645996 | Iter 2.000: -5.569539785385132 | Iter 1.000: -7.3631062507629395\n",
      "Resources requested: 16.0/16 CPUs, 1.0/1 GPUs, 0.0/73.6 GiB heap, 0.0/35.54 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Current best trial: 84be5_00000 with val_log_likelihood=-0.013439194299280643 and parameters={'num_latents': 10}\n",
      "Result logdir: /home/tianyudu/ray_results/train_tune_2021-10-11_18-19-59\n",
      "Number of trials: 20/20 (17 PENDING, 1 RUNNING, 2 TERMINATED)\n",
      "+------------------------+------------+-----------------------+---------------+----------------------+\n",
      "| Trial name             | status     | loc                   |   num_latents |   val_log_likelihood |\n",
      "|------------------------+------------+-----------------------+---------------+----------------------|\n",
      "| train_tune_84be5_00002 | RUNNING    | 192.168.0.158:1054643 |             3 |           -3.83604   |\n",
      "| train_tune_84be5_00003 | PENDING    |                       |             4 |                      |\n",
      "| train_tune_84be5_00004 | PENDING    |                       |            10 |                      |\n",
      "| train_tune_84be5_00005 | PENDING    |                       |            10 |                      |\n",
      "| train_tune_84be5_00006 | PENDING    |                       |            20 |                      |\n",
      "| train_tune_84be5_00007 | PENDING    |                       |            10 |                      |\n",
      "| train_tune_84be5_00008 | PENDING    |                       |             2 |                      |\n",
      "| train_tune_84be5_00009 | PENDING    |                       |          1000 |                      |\n",
      "| train_tune_84be5_00010 | PENDING    |                       |             5 |                      |\n",
      "| train_tune_84be5_00011 | PENDING    |                       |             3 |                      |\n",
      "| train_tune_84be5_00012 | PENDING    |                       |           300 |                      |\n",
      "| train_tune_84be5_00013 | PENDING    |                       |             2 |                      |\n",
      "| train_tune_84be5_00014 | PENDING    |                       |             4 |                      |\n",
      "| train_tune_84be5_00015 | PENDING    |                       |             1 |                      |\n",
      "| train_tune_84be5_00016 | PENDING    |                       |            10 |                      |\n",
      "| train_tune_84be5_00017 | PENDING    |                       |             2 |                      |\n",
      "| train_tune_84be5_00018 | PENDING    |                       |            10 |                      |\n",
      "| train_tune_84be5_00019 | PENDING    |                       |             7 |                      |\n",
      "| train_tune_84be5_00000 | TERMINATED |                       |            10 |           -0.0134392 |\n",
      "| train_tune_84be5_00001 | TERMINATED |                       |           100 |          -25.5851    |\n",
      "+------------------------+------------+-----------------------+---------------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_tune_84be5_00002:\n",
      "  date: 2021-10-11_18-20-54\n",
      "  done: true\n",
      "  experiment_id: acb3c244d748411cbf7f6380bf429d4f\n",
      "  hostname: aurora\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.0.158\n",
      "  pid: 1054643\n",
      "  time_since_restore: 8.89798092842102\n",
      "  time_this_iter_s: 0.7371094226837158\n",
      "  time_total_s: 8.89798092842102\n",
      "  timestamp: 1634001654\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 8\n",
      "  trial_id: 84be5_00002\n",
      "  val_log_likelihood: -3.2677206993103027\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=1057077)\u001b[0m \u001b[31mYou are using BEMB Flex v3 (rc)\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=1057077)\u001b[0m BEMB: utility formula parsed:\n",
      "\u001b[2m\u001b[36m(pid=1057077)\u001b[0m [{'coefficient': ['theta_item', 'beta_user'], 'observable': 'price_obs'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1057077)\u001b[0m GPU available: True, used: True\n",
      "\u001b[2m\u001b[36m(pid=1057077)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1057077)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(pid=1057077)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[2m\u001b[36m(pid=1057077)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1057077)\u001b[0m   | Name  | Type     | Params\n",
      "\u001b[2m\u001b[36m(pid=1057077)\u001b[0m -----------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1057077)\u001b[0m 0 | model | BEMBFlex | 600   \n",
      "\u001b[2m\u001b[36m(pid=1057077)\u001b[0m -----------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1057077)\u001b[0m 600       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1057077)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1057077)\u001b[0m 600       Total params\n",
      "\u001b[2m\u001b[36m(pid=1057077)\u001b[0m 0.002     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1057077)\u001b[0m /home/tianyudu/anaconda3/envs/ml/lib/python3.8/site-packages/pytorch_lightning/trainer/deprecated_api.py:25: LightningDeprecationWarning: `Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\n",
      "\u001b[2m\u001b[36m(pid=1057077)\u001b[0m   rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_tune_84be5_00003:\n",
      "  date: 2021-10-11_18-20-59\n",
      "  done: false\n",
      "  experiment_id: 002c57cbe52341d2844c1b9b495dac08\n",
      "  hostname: aurora\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.0.158\n",
      "  pid: 1057077\n",
      "  time_since_restore: 4.06821084022522\n",
      "  time_this_iter_s: 4.06821084022522\n",
      "  time_total_s: 4.06821084022522\n",
      "  timestamp: 1634001659\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 84be5_00003\n",
      "  val_log_likelihood: -6.108400821685791\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 12.2/125.5 GiB\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 32.000: -0.281253457069397 | Iter 16.000: -1.0825423002243042 | Iter 8.000: -2.924723982810974 | Iter 4.000: -4.431471824645996 | Iter 2.000: -5.569539785385132 | Iter 1.000: -6.735753536224365\n",
      "Resources requested: 16.0/16 CPUs, 1.0/1 GPUs, 0.0/73.6 GiB heap, 0.0/35.54 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Current best trial: 84be5_00000 with val_log_likelihood=-0.013439194299280643 and parameters={'num_latents': 10}\n",
      "Result logdir: /home/tianyudu/ray_results/train_tune_2021-10-11_18-19-59\n",
      "Number of trials: 20/20 (16 PENDING, 1 RUNNING, 3 TERMINATED)\n",
      "+------------------------+------------+-----------------------+---------------+----------------------+\n",
      "| Trial name             | status     | loc                   |   num_latents |   val_log_likelihood |\n",
      "|------------------------+------------+-----------------------+---------------+----------------------|\n",
      "| train_tune_84be5_00003 | RUNNING    | 192.168.0.158:1057077 |             4 |           -6.1084    |\n",
      "| train_tune_84be5_00004 | PENDING    |                       |            10 |                      |\n",
      "| train_tune_84be5_00005 | PENDING    |                       |            10 |                      |\n",
      "| train_tune_84be5_00006 | PENDING    |                       |            20 |                      |\n",
      "| train_tune_84be5_00007 | PENDING    |                       |            10 |                      |\n",
      "| train_tune_84be5_00008 | PENDING    |                       |             2 |                      |\n",
      "| train_tune_84be5_00009 | PENDING    |                       |          1000 |                      |\n",
      "| train_tune_84be5_00010 | PENDING    |                       |             5 |                      |\n",
      "| train_tune_84be5_00011 | PENDING    |                       |             3 |                      |\n",
      "| train_tune_84be5_00012 | PENDING    |                       |           300 |                      |\n",
      "| train_tune_84be5_00013 | PENDING    |                       |             2 |                      |\n",
      "| train_tune_84be5_00014 | PENDING    |                       |             4 |                      |\n",
      "| train_tune_84be5_00015 | PENDING    |                       |             1 |                      |\n",
      "| train_tune_84be5_00016 | PENDING    |                       |            10 |                      |\n",
      "| train_tune_84be5_00017 | PENDING    |                       |             2 |                      |\n",
      "| train_tune_84be5_00018 | PENDING    |                       |            10 |                      |\n",
      "| train_tune_84be5_00019 | PENDING    |                       |             7 |                      |\n",
      "| train_tune_84be5_00000 | TERMINATED |                       |            10 |           -0.0134392 |\n",
      "| train_tune_84be5_00001 | TERMINATED |                       |           100 |          -25.5851    |\n",
      "| train_tune_84be5_00002 | TERMINATED |                       |             3 |           -3.26772   |\n",
      "+------------------------+------------+-----------------------+---------------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_tune_84be5_00003:\n",
      "  date: 2021-10-11_18-21-00\n",
      "  done: true\n",
      "  experiment_id: 002c57cbe52341d2844c1b9b495dac08\n",
      "  hostname: aurora\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.0.158\n",
      "  pid: 1057077\n",
      "  time_since_restore: 4.793136119842529\n",
      "  time_this_iter_s: 0.7249252796173096\n",
      "  time_total_s: 4.793136119842529\n",
      "  timestamp: 1634001660\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: 84be5_00003\n",
      "  val_log_likelihood: -5.584064483642578\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=1057829)\u001b[0m \u001b[31mYou are using BEMB Flex v3 (rc)\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=1057829)\u001b[0m BEMB: utility formula parsed:\n",
      "\u001b[2m\u001b[36m(pid=1057829)\u001b[0m [{'coefficient': ['theta_item', 'beta_user'], 'observable': 'price_obs'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1057829)\u001b[0m GPU available: True, used: True\n",
      "\u001b[2m\u001b[36m(pid=1057829)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1057829)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(pid=1057829)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[2m\u001b[36m(pid=1057829)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1057829)\u001b[0m   | Name  | Type     | Params\n",
      "\u001b[2m\u001b[36m(pid=1057829)\u001b[0m -----------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1057829)\u001b[0m 0 | model | BEMBFlex | 1.5 K \n",
      "\u001b[2m\u001b[36m(pid=1057829)\u001b[0m -----------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1057829)\u001b[0m 1.5 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1057829)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1057829)\u001b[0m 1.5 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1057829)\u001b[0m 0.006     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1057829)\u001b[0m /home/tianyudu/anaconda3/envs/ml/lib/python3.8/site-packages/pytorch_lightning/trainer/deprecated_api.py:25: LightningDeprecationWarning: `Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\n",
      "\u001b[2m\u001b[36m(pid=1057829)\u001b[0m   rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_tune_84be5_00004:\n",
      "  date: 2021-10-11_18-21-05\n",
      "  done: true\n",
      "  experiment_id: aec8cbf0c9e14f599b83b13f59cf058d\n",
      "  hostname: aurora\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.0.158\n",
      "  pid: 1057829\n",
      "  time_since_restore: 3.997380256652832\n",
      "  time_this_iter_s: 3.997380256652832\n",
      "  time_total_s: 3.997380256652832\n",
      "  timestamp: 1634001665\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 84be5_00004\n",
      "  val_log_likelihood: -9.618912696838379\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 12.1/125.5 GiB\n",
      "Using AsyncHyperBand: num_stopped=5\n",
      "Bracket: Iter 32.000: -0.281253457069397 | Iter 16.000: -1.0825423002243042 | Iter 8.000: -2.924723982810974 | Iter 4.000: -4.431471824645996 | Iter 2.000: -5.584064483642578 | Iter 1.000: -7.3631062507629395\n",
      "Resources requested: 0/16 CPUs, 0/1 GPUs, 0.0/73.6 GiB heap, 0.0/35.54 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Current best trial: 84be5_00000 with val_log_likelihood=-0.013439194299280643 and parameters={'num_latents': 10}\n",
      "Result logdir: /home/tianyudu/ray_results/train_tune_2021-10-11_18-19-59\n",
      "Number of trials: 20/20 (15 PENDING, 5 TERMINATED)\n",
      "+------------------------+------------+-------+---------------+----------------------+\n",
      "| Trial name             | status     | loc   |   num_latents |   val_log_likelihood |\n",
      "|------------------------+------------+-------+---------------+----------------------|\n",
      "| train_tune_84be5_00005 | PENDING    |       |            10 |                      |\n",
      "| train_tune_84be5_00006 | PENDING    |       |            20 |                      |\n",
      "| train_tune_84be5_00007 | PENDING    |       |            10 |                      |\n",
      "| train_tune_84be5_00008 | PENDING    |       |             2 |                      |\n",
      "| train_tune_84be5_00009 | PENDING    |       |          1000 |                      |\n",
      "| train_tune_84be5_00010 | PENDING    |       |             5 |                      |\n",
      "| train_tune_84be5_00011 | PENDING    |       |             3 |                      |\n",
      "| train_tune_84be5_00012 | PENDING    |       |           300 |                      |\n",
      "| train_tune_84be5_00013 | PENDING    |       |             2 |                      |\n",
      "| train_tune_84be5_00014 | PENDING    |       |             4 |                      |\n",
      "| train_tune_84be5_00015 | PENDING    |       |             1 |                      |\n",
      "| train_tune_84be5_00016 | PENDING    |       |            10 |                      |\n",
      "| train_tune_84be5_00017 | PENDING    |       |             2 |                      |\n",
      "| train_tune_84be5_00018 | PENDING    |       |            10 |                      |\n",
      "| train_tune_84be5_00019 | PENDING    |       |             7 |                      |\n",
      "| train_tune_84be5_00000 | TERMINATED |       |            10 |           -0.0134392 |\n",
      "| train_tune_84be5_00001 | TERMINATED |       |           100 |          -25.5851    |\n",
      "| train_tune_84be5_00002 | TERMINATED |       |             3 |           -3.26772   |\n",
      "| train_tune_84be5_00003 | TERMINATED |       |             4 |           -5.58406   |\n",
      "| train_tune_84be5_00004 | TERMINATED |       |            10 |           -9.61891   |\n",
      "+------------------------+------------+-------+---------------+----------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=1058295)\u001b[0m \u001b[31mYou are using BEMB Flex v3 (rc)\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=1058295)\u001b[0m BEMB: utility formula parsed:\n",
      "\u001b[2m\u001b[36m(pid=1058295)\u001b[0m [{'coefficient': ['theta_item', 'beta_user'], 'observable': 'price_obs'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1058295)\u001b[0m GPU available: True, used: True\n",
      "\u001b[2m\u001b[36m(pid=1058295)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1058295)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(pid=1058295)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[2m\u001b[36m(pid=1058295)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1058295)\u001b[0m   | Name  | Type     | Params\n",
      "\u001b[2m\u001b[36m(pid=1058295)\u001b[0m -----------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1058295)\u001b[0m 0 | model | BEMBFlex | 1.5 K \n",
      "\u001b[2m\u001b[36m(pid=1058295)\u001b[0m -----------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1058295)\u001b[0m 1.5 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1058295)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1058295)\u001b[0m 1.5 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1058295)\u001b[0m 0.006     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1058295)\u001b[0m /home/tianyudu/anaconda3/envs/ml/lib/python3.8/site-packages/pytorch_lightning/trainer/deprecated_api.py:25: LightningDeprecationWarning: `Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\n",
      "\u001b[2m\u001b[36m(pid=1058295)\u001b[0m   rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_tune_84be5_00005:\n",
      "  date: 2021-10-11_18-21-10\n",
      "  done: true\n",
      "  experiment_id: 3ae2408d48924af7a6c1db8fef04fb2b\n",
      "  hostname: aurora\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.0.158\n",
      "  pid: 1058295\n",
      "  time_since_restore: 3.992957830429077\n",
      "  time_this_iter_s: 3.992957830429077\n",
      "  time_total_s: 3.992957830429077\n",
      "  timestamp: 1634001670\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 84be5_00005\n",
      "  val_log_likelihood: -8.894775390625\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 12.1/125.5 GiB\n",
      "Using AsyncHyperBand: num_stopped=6\n",
      "Bracket: Iter 32.000: -0.281253457069397 | Iter 16.000: -1.0825423002243042 | Iter 8.000: -2.924723982810974 | Iter 4.000: -4.431471824645996 | Iter 2.000: -5.584064483642578 | Iter 1.000: -8.12894082069397\n",
      "Resources requested: 0/16 CPUs, 0/1 GPUs, 0.0/73.6 GiB heap, 0.0/35.54 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Current best trial: 84be5_00000 with val_log_likelihood=-0.013439194299280643 and parameters={'num_latents': 10}\n",
      "Result logdir: /home/tianyudu/ray_results/train_tune_2021-10-11_18-19-59\n",
      "Number of trials: 20/20 (14 PENDING, 6 TERMINATED)\n",
      "+------------------------+------------+-------+---------------+----------------------+\n",
      "| Trial name             | status     | loc   |   num_latents |   val_log_likelihood |\n",
      "|------------------------+------------+-------+---------------+----------------------|\n",
      "| train_tune_84be5_00006 | PENDING    |       |            20 |                      |\n",
      "| train_tune_84be5_00007 | PENDING    |       |            10 |                      |\n",
      "| train_tune_84be5_00008 | PENDING    |       |             2 |                      |\n",
      "| train_tune_84be5_00009 | PENDING    |       |          1000 |                      |\n",
      "| train_tune_84be5_00010 | PENDING    |       |             5 |                      |\n",
      "| train_tune_84be5_00011 | PENDING    |       |             3 |                      |\n",
      "| train_tune_84be5_00012 | PENDING    |       |           300 |                      |\n",
      "| train_tune_84be5_00013 | PENDING    |       |             2 |                      |\n",
      "| train_tune_84be5_00014 | PENDING    |       |             4 |                      |\n",
      "| train_tune_84be5_00015 | PENDING    |       |             1 |                      |\n",
      "| train_tune_84be5_00016 | PENDING    |       |            10 |                      |\n",
      "| train_tune_84be5_00017 | PENDING    |       |             2 |                      |\n",
      "| train_tune_84be5_00018 | PENDING    |       |            10 |                      |\n",
      "| train_tune_84be5_00019 | PENDING    |       |             7 |                      |\n",
      "| train_tune_84be5_00000 | TERMINATED |       |            10 |           -0.0134392 |\n",
      "| train_tune_84be5_00001 | TERMINATED |       |           100 |          -25.5851    |\n",
      "| train_tune_84be5_00002 | TERMINATED |       |             3 |           -3.26772   |\n",
      "| train_tune_84be5_00003 | TERMINATED |       |             4 |           -5.58406   |\n",
      "| train_tune_84be5_00004 | TERMINATED |       |            10 |           -9.61891   |\n",
      "| train_tune_84be5_00005 | TERMINATED |       |            10 |           -8.89478   |\n",
      "+------------------------+------------+-------+---------------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1058767)\u001b[0m GPU available: True, used: True\n",
      "\u001b[2m\u001b[36m(pid=1058767)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1058767)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(pid=1058767)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1058767)\u001b[0m \u001b[31mYou are using BEMB Flex v3 (rc)\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=1058767)\u001b[0m BEMB: utility formula parsed:\n",
      "\u001b[2m\u001b[36m(pid=1058767)\u001b[0m [{'coefficient': ['theta_item', 'beta_user'], 'observable': 'price_obs'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1058767)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1058767)\u001b[0m   | Name  | Type     | Params\n",
      "\u001b[2m\u001b[36m(pid=1058767)\u001b[0m -----------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1058767)\u001b[0m 0 | model | BEMBFlex | 3.0 K \n",
      "\u001b[2m\u001b[36m(pid=1058767)\u001b[0m -----------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1058767)\u001b[0m 3.0 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1058767)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1058767)\u001b[0m 3.0 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1058767)\u001b[0m 0.012     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1058767)\u001b[0m /home/tianyudu/anaconda3/envs/ml/lib/python3.8/site-packages/pytorch_lightning/trainer/deprecated_api.py:25: LightningDeprecationWarning: `Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\n",
      "\u001b[2m\u001b[36m(pid=1058767)\u001b[0m   rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_tune_84be5_00006:\n",
      "  date: 2021-10-11_18-21-16\n",
      "  done: true\n",
      "  experiment_id: ca664ce6b61c45399fd866fd4af99e31\n",
      "  hostname: aurora\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.0.158\n",
      "  pid: 1058767\n",
      "  time_since_restore: 4.009984731674194\n",
      "  time_this_iter_s: 4.009984731674194\n",
      "  time_total_s: 4.009984731674194\n",
      "  timestamp: 1634001676\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 84be5_00006\n",
      "  val_log_likelihood: -15.803245544433594\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 12.2/125.5 GiB\n",
      "Using AsyncHyperBand: num_stopped=7\n",
      "Bracket: Iter 32.000: -0.281253457069397 | Iter 16.000: -1.0825423002243042 | Iter 8.000: -2.924723982810974 | Iter 4.000: -4.431471824645996 | Iter 2.000: -5.584064483642578 | Iter 1.000: -8.894775390625\n",
      "Resources requested: 0/16 CPUs, 0/1 GPUs, 0.0/73.6 GiB heap, 0.0/35.54 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Current best trial: 84be5_00000 with val_log_likelihood=-0.013439194299280643 and parameters={'num_latents': 10}\n",
      "Result logdir: /home/tianyudu/ray_results/train_tune_2021-10-11_18-19-59\n",
      "Number of trials: 20/20 (13 PENDING, 7 TERMINATED)\n",
      "+------------------------+------------+-------+---------------+----------------------+\n",
      "| Trial name             | status     | loc   |   num_latents |   val_log_likelihood |\n",
      "|------------------------+------------+-------+---------------+----------------------|\n",
      "| train_tune_84be5_00007 | PENDING    |       |            10 |                      |\n",
      "| train_tune_84be5_00008 | PENDING    |       |             2 |                      |\n",
      "| train_tune_84be5_00009 | PENDING    |       |          1000 |                      |\n",
      "| train_tune_84be5_00010 | PENDING    |       |             5 |                      |\n",
      "| train_tune_84be5_00011 | PENDING    |       |             3 |                      |\n",
      "| train_tune_84be5_00012 | PENDING    |       |           300 |                      |\n",
      "| train_tune_84be5_00013 | PENDING    |       |             2 |                      |\n",
      "| train_tune_84be5_00014 | PENDING    |       |             4 |                      |\n",
      "| train_tune_84be5_00015 | PENDING    |       |             1 |                      |\n",
      "| train_tune_84be5_00016 | PENDING    |       |            10 |                      |\n",
      "| train_tune_84be5_00017 | PENDING    |       |             2 |                      |\n",
      "| train_tune_84be5_00018 | PENDING    |       |            10 |                      |\n",
      "| train_tune_84be5_00019 | PENDING    |       |             7 |                      |\n",
      "| train_tune_84be5_00000 | TERMINATED |       |            10 |           -0.0134392 |\n",
      "| train_tune_84be5_00001 | TERMINATED |       |           100 |          -25.5851    |\n",
      "| train_tune_84be5_00002 | TERMINATED |       |             3 |           -3.26772   |\n",
      "| train_tune_84be5_00003 | TERMINATED |       |             4 |           -5.58406   |\n",
      "| train_tune_84be5_00004 | TERMINATED |       |            10 |           -9.61891   |\n",
      "| train_tune_84be5_00005 | TERMINATED |       |            10 |           -8.89478   |\n",
      "| train_tune_84be5_00006 | TERMINATED |       |            20 |          -15.8032    |\n",
      "+------------------------+------------+-------+---------------+----------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=1059236)\u001b[0m \u001b[31mYou are using BEMB Flex v3 (rc)\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=1059236)\u001b[0m BEMB: utility formula parsed:\n",
      "\u001b[2m\u001b[36m(pid=1059236)\u001b[0m [{'coefficient': ['theta_item', 'beta_user'], 'observable': 'price_obs'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1059236)\u001b[0m GPU available: True, used: True\n",
      "\u001b[2m\u001b[36m(pid=1059236)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1059236)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(pid=1059236)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[2m\u001b[36m(pid=1059236)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1059236)\u001b[0m   | Name  | Type     | Params\n",
      "\u001b[2m\u001b[36m(pid=1059236)\u001b[0m -----------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1059236)\u001b[0m 0 | model | BEMBFlex | 1.5 K \n",
      "\u001b[2m\u001b[36m(pid=1059236)\u001b[0m -----------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1059236)\u001b[0m 1.5 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1059236)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1059236)\u001b[0m 1.5 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1059236)\u001b[0m 0.006     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1059236)\u001b[0m /home/tianyudu/anaconda3/envs/ml/lib/python3.8/site-packages/pytorch_lightning/trainer/deprecated_api.py:25: LightningDeprecationWarning: `Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\n",
      "\u001b[2m\u001b[36m(pid=1059236)\u001b[0m   rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_tune_84be5_00007:\n",
      "  date: 2021-10-11_18-21-21\n",
      "  done: true\n",
      "  experiment_id: 2acc937ce5054373b8068f0477b61bc1\n",
      "  hostname: aurora\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.0.158\n",
      "  pid: 1059236\n",
      "  time_since_restore: 3.995650053024292\n",
      "  time_this_iter_s: 3.995650053024292\n",
      "  time_total_s: 3.995650053024292\n",
      "  timestamp: 1634001681\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 84be5_00007\n",
      "  val_log_likelihood: -10.072299003601074\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 12.2/125.5 GiB\n",
      "Using AsyncHyperBand: num_stopped=8\n",
      "Bracket: Iter 32.000: -0.281253457069397 | Iter 16.000: -1.0825423002243042 | Iter 8.000: -2.924723982810974 | Iter 4.000: -4.431471824645996 | Iter 2.000: -5.584064483642578 | Iter 1.000: -9.25684404373169\n",
      "Resources requested: 0/16 CPUs, 0/1 GPUs, 0.0/73.6 GiB heap, 0.0/35.54 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Current best trial: 84be5_00000 with val_log_likelihood=-0.013439194299280643 and parameters={'num_latents': 10}\n",
      "Result logdir: /home/tianyudu/ray_results/train_tune_2021-10-11_18-19-59\n",
      "Number of trials: 20/20 (12 PENDING, 8 TERMINATED)\n",
      "+------------------------+------------+-------+---------------+----------------------+\n",
      "| Trial name             | status     | loc   |   num_latents |   val_log_likelihood |\n",
      "|------------------------+------------+-------+---------------+----------------------|\n",
      "| train_tune_84be5_00008 | PENDING    |       |             2 |                      |\n",
      "| train_tune_84be5_00009 | PENDING    |       |          1000 |                      |\n",
      "| train_tune_84be5_00010 | PENDING    |       |             5 |                      |\n",
      "| train_tune_84be5_00011 | PENDING    |       |             3 |                      |\n",
      "| train_tune_84be5_00012 | PENDING    |       |           300 |                      |\n",
      "| train_tune_84be5_00013 | PENDING    |       |             2 |                      |\n",
      "| train_tune_84be5_00014 | PENDING    |       |             4 |                      |\n",
      "| train_tune_84be5_00015 | PENDING    |       |             1 |                      |\n",
      "| train_tune_84be5_00016 | PENDING    |       |            10 |                      |\n",
      "| train_tune_84be5_00017 | PENDING    |       |             2 |                      |\n",
      "| train_tune_84be5_00018 | PENDING    |       |            10 |                      |\n",
      "| train_tune_84be5_00019 | PENDING    |       |             7 |                      |\n",
      "| train_tune_84be5_00000 | TERMINATED |       |            10 |           -0.0134392 |\n",
      "| train_tune_84be5_00001 | TERMINATED |       |           100 |          -25.5851    |\n",
      "| train_tune_84be5_00002 | TERMINATED |       |             3 |           -3.26772   |\n",
      "| train_tune_84be5_00003 | TERMINATED |       |             4 |           -5.58406   |\n",
      "| train_tune_84be5_00004 | TERMINATED |       |            10 |           -9.61891   |\n",
      "| train_tune_84be5_00005 | TERMINATED |       |            10 |           -8.89478   |\n",
      "| train_tune_84be5_00006 | TERMINATED |       |            20 |          -15.8032    |\n",
      "| train_tune_84be5_00007 | TERMINATED |       |            10 |          -10.0723    |\n",
      "+------------------------+------------+-------+---------------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1059715)\u001b[0m GPU available: True, used: True\n",
      "\u001b[2m\u001b[36m(pid=1059715)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1059715)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(pid=1059715)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1059715)\u001b[0m \u001b[31mYou are using BEMB Flex v3 (rc)\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=1059715)\u001b[0m BEMB: utility formula parsed:\n",
      "\u001b[2m\u001b[36m(pid=1059715)\u001b[0m [{'coefficient': ['theta_item', 'beta_user'], 'observable': 'price_obs'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1059715)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1059715)\u001b[0m   | Name  | Type     | Params\n",
      "\u001b[2m\u001b[36m(pid=1059715)\u001b[0m -----------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1059715)\u001b[0m 0 | model | BEMBFlex | 300   \n",
      "\u001b[2m\u001b[36m(pid=1059715)\u001b[0m -----------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1059715)\u001b[0m 300       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1059715)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1059715)\u001b[0m 300       Total params\n",
      "\u001b[2m\u001b[36m(pid=1059715)\u001b[0m 0.001     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1059715)\u001b[0m /home/tianyudu/anaconda3/envs/ml/lib/python3.8/site-packages/pytorch_lightning/trainer/deprecated_api.py:25: LightningDeprecationWarning: `Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\n",
      "\u001b[2m\u001b[36m(pid=1059715)\u001b[0m   rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_tune_84be5_00008:\n",
      "  date: 2021-10-11_18-21-26\n",
      "  done: false\n",
      "  experiment_id: 7addb37cbad849de9ecb8b6350df19c0\n",
      "  hostname: aurora\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.0.158\n",
      "  pid: 1059715\n",
      "  time_since_restore: 4.011392116546631\n",
      "  time_this_iter_s: 4.011392116546631\n",
      "  time_total_s: 4.011392116546631\n",
      "  timestamp: 1634001686\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 84be5_00008\n",
      "  val_log_likelihood: -5.595610618591309\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 12.2/125.5 GiB\n",
      "Using AsyncHyperBand: num_stopped=8\n",
      "Bracket: Iter 32.000: -0.281253457069397 | Iter 16.000: -1.0825423002243042 | Iter 8.000: -2.924723982810974 | Iter 4.000: -4.431471824645996 | Iter 2.000: -5.584064483642578 | Iter 1.000: -8.894775390625\n",
      "Resources requested: 16.0/16 CPUs, 1.0/1 GPUs, 0.0/73.6 GiB heap, 0.0/35.54 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Current best trial: 84be5_00000 with val_log_likelihood=-0.013439194299280643 and parameters={'num_latents': 10}\n",
      "Result logdir: /home/tianyudu/ray_results/train_tune_2021-10-11_18-19-59\n",
      "Number of trials: 20/20 (11 PENDING, 1 RUNNING, 8 TERMINATED)\n",
      "+------------------------+------------+-----------------------+---------------+----------------------+\n",
      "| Trial name             | status     | loc                   |   num_latents |   val_log_likelihood |\n",
      "|------------------------+------------+-----------------------+---------------+----------------------|\n",
      "| train_tune_84be5_00008 | RUNNING    | 192.168.0.158:1059715 |             2 |           -5.59561   |\n",
      "| train_tune_84be5_00009 | PENDING    |                       |          1000 |                      |\n",
      "| train_tune_84be5_00010 | PENDING    |                       |             5 |                      |\n",
      "| train_tune_84be5_00011 | PENDING    |                       |             3 |                      |\n",
      "| train_tune_84be5_00012 | PENDING    |                       |           300 |                      |\n",
      "| train_tune_84be5_00013 | PENDING    |                       |             2 |                      |\n",
      "| train_tune_84be5_00014 | PENDING    |                       |             4 |                      |\n",
      "| train_tune_84be5_00015 | PENDING    |                       |             1 |                      |\n",
      "| train_tune_84be5_00016 | PENDING    |                       |            10 |                      |\n",
      "| train_tune_84be5_00017 | PENDING    |                       |             2 |                      |\n",
      "| train_tune_84be5_00018 | PENDING    |                       |            10 |                      |\n",
      "| train_tune_84be5_00019 | PENDING    |                       |             7 |                      |\n",
      "| train_tune_84be5_00000 | TERMINATED |                       |            10 |           -0.0134392 |\n",
      "| train_tune_84be5_00001 | TERMINATED |                       |           100 |          -25.5851    |\n",
      "| train_tune_84be5_00002 | TERMINATED |                       |             3 |           -3.26772   |\n",
      "| train_tune_84be5_00003 | TERMINATED |                       |             4 |           -5.58406   |\n",
      "| train_tune_84be5_00004 | TERMINATED |                       |            10 |           -9.61891   |\n",
      "| train_tune_84be5_00005 | TERMINATED |                       |            10 |           -8.89478   |\n",
      "| train_tune_84be5_00006 | TERMINATED |                       |            20 |          -15.8032    |\n",
      "| train_tune_84be5_00007 | TERMINATED |                       |            10 |          -10.0723    |\n",
      "+------------------------+------------+-----------------------+---------------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_tune_84be5_00008:\n",
      "  date: 2021-10-11_18-21-28\n",
      "  done: true\n",
      "  experiment_id: 7addb37cbad849de9ecb8b6350df19c0\n",
      "  hostname: aurora\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.0.158\n",
      "  pid: 1059715\n",
      "  time_since_restore: 6.176767826080322\n",
      "  time_this_iter_s: 0.755084753036499\n",
      "  time_total_s: 6.176767826080322\n",
      "  timestamp: 1634001688\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 4\n",
      "  trial_id: 84be5_00008\n",
      "  val_log_likelihood: -4.577444076538086\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1061022)\u001b[0m GPU available: True, used: True\n",
      "\u001b[2m\u001b[36m(pid=1061022)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1061022)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(pid=1061022)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1061022)\u001b[0m \u001b[31mYou are using BEMB Flex v3 (rc)\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=1061022)\u001b[0m BEMB: utility formula parsed:\n",
      "\u001b[2m\u001b[36m(pid=1061022)\u001b[0m [{'coefficient': ['theta_item', 'beta_user'], 'observable': 'price_obs'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1061022)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1061022)\u001b[0m   | Name  | Type     | Params\n",
      "\u001b[2m\u001b[36m(pid=1061022)\u001b[0m -----------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1061022)\u001b[0m 0 | model | BEMBFlex | 150 K \n",
      "\u001b[2m\u001b[36m(pid=1061022)\u001b[0m -----------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1061022)\u001b[0m 150 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1061022)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1061022)\u001b[0m 150 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1061022)\u001b[0m 0.600     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1061022)\u001b[0m /home/tianyudu/anaconda3/envs/ml/lib/python3.8/site-packages/pytorch_lightning/trainer/deprecated_api.py:25: LightningDeprecationWarning: `Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\n",
      "\u001b[2m\u001b[36m(pid=1061022)\u001b[0m   rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_tune_84be5_00009:\n",
      "  date: 2021-10-11_18-21-33\n",
      "  done: true\n",
      "  experiment_id: 65c6c75d0fde418b8b58043359b9aca1\n",
      "  hostname: aurora\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.0.158\n",
      "  pid: 1061022\n",
      "  time_since_restore: 3.9928383827209473\n",
      "  time_this_iter_s: 3.9928383827209473\n",
      "  time_total_s: 3.9928383827209473\n",
      "  timestamp: 1634001693\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 84be5_00009\n",
      "  val_log_likelihood: -22.585466384887695\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 12.2/125.5 GiB\n",
      "Using AsyncHyperBand: num_stopped=10\n",
      "Bracket: Iter 32.000: -0.281253457069397 | Iter 16.000: -1.0825423002243042 | Iter 8.000: -2.924723982810974 | Iter 4.000: -4.577444076538086 | Iter 2.000: -5.404385805130005 | Iter 1.000: -9.25684404373169\n",
      "Resources requested: 0/16 CPUs, 0/1 GPUs, 0.0/73.6 GiB heap, 0.0/35.54 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Current best trial: 84be5_00000 with val_log_likelihood=-0.013439194299280643 and parameters={'num_latents': 10}\n",
      "Result logdir: /home/tianyudu/ray_results/train_tune_2021-10-11_18-19-59\n",
      "Number of trials: 20/20 (10 PENDING, 10 TERMINATED)\n",
      "+------------------------+------------+-------+---------------+----------------------+\n",
      "| Trial name             | status     | loc   |   num_latents |   val_log_likelihood |\n",
      "|------------------------+------------+-------+---------------+----------------------|\n",
      "| train_tune_84be5_00010 | PENDING    |       |             5 |                      |\n",
      "| train_tune_84be5_00011 | PENDING    |       |             3 |                      |\n",
      "| train_tune_84be5_00012 | PENDING    |       |           300 |                      |\n",
      "| train_tune_84be5_00013 | PENDING    |       |             2 |                      |\n",
      "| train_tune_84be5_00014 | PENDING    |       |             4 |                      |\n",
      "| train_tune_84be5_00015 | PENDING    |       |             1 |                      |\n",
      "| train_tune_84be5_00016 | PENDING    |       |            10 |                      |\n",
      "| train_tune_84be5_00017 | PENDING    |       |             2 |                      |\n",
      "| train_tune_84be5_00018 | PENDING    |       |            10 |                      |\n",
      "| train_tune_84be5_00019 | PENDING    |       |             7 |                      |\n",
      "| train_tune_84be5_00000 | TERMINATED |       |            10 |           -0.0134392 |\n",
      "| train_tune_84be5_00001 | TERMINATED |       |           100 |          -25.5851    |\n",
      "| train_tune_84be5_00002 | TERMINATED |       |             3 |           -3.26772   |\n",
      "| train_tune_84be5_00003 | TERMINATED |       |             4 |           -5.58406   |\n",
      "| train_tune_84be5_00004 | TERMINATED |       |            10 |           -9.61891   |\n",
      "| train_tune_84be5_00005 | TERMINATED |       |            10 |           -8.89478   |\n",
      "| train_tune_84be5_00006 | TERMINATED |       |            20 |          -15.8032    |\n",
      "| train_tune_84be5_00007 | TERMINATED |       |            10 |          -10.0723    |\n",
      "| train_tune_84be5_00008 | TERMINATED |       |             2 |           -4.57744   |\n",
      "| train_tune_84be5_00009 | TERMINATED |       |          1000 |          -22.5855    |\n",
      "+------------------------+------------+-------+---------------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1061495)\u001b[0m GPU available: True, used: True\n",
      "\u001b[2m\u001b[36m(pid=1061495)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1061495)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(pid=1061495)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1061495)\u001b[0m \u001b[31mYou are using BEMB Flex v3 (rc)\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=1061495)\u001b[0m BEMB: utility formula parsed:\n",
      "\u001b[2m\u001b[36m(pid=1061495)\u001b[0m [{'coefficient': ['theta_item', 'beta_user'], 'observable': 'price_obs'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1061495)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1061495)\u001b[0m   | Name  | Type     | Params\n",
      "\u001b[2m\u001b[36m(pid=1061495)\u001b[0m -----------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1061495)\u001b[0m 0 | model | BEMBFlex | 750   \n",
      "\u001b[2m\u001b[36m(pid=1061495)\u001b[0m -----------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1061495)\u001b[0m 750       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1061495)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1061495)\u001b[0m 750       Total params\n",
      "\u001b[2m\u001b[36m(pid=1061495)\u001b[0m 0.003     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1061495)\u001b[0m /home/tianyudu/anaconda3/envs/ml/lib/python3.8/site-packages/pytorch_lightning/trainer/deprecated_api.py:25: LightningDeprecationWarning: `Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\n",
      "\u001b[2m\u001b[36m(pid=1061495)\u001b[0m   rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_tune_84be5_00010:\n",
      "  date: 2021-10-11_18-21-39\n",
      "  done: false\n",
      "  experiment_id: 2d54c9546e4b4c56bf2430cf598e62c7\n",
      "  hostname: aurora\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.0.158\n",
      "  pid: 1061495\n",
      "  time_since_restore: 4.024066209793091\n",
      "  time_this_iter_s: 4.024066209793091\n",
      "  time_total_s: 4.024066209793091\n",
      "  timestamp: 1634001699\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 84be5_00010\n",
      "  val_log_likelihood: -4.8438191413879395\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 12.2/125.5 GiB\n",
      "Using AsyncHyperBand: num_stopped=10\n",
      "Bracket: Iter 32.000: -0.281253457069397 | Iter 16.000: -1.0825423002243042 | Iter 8.000: -2.924723982810974 | Iter 4.000: -4.577444076538086 | Iter 2.000: -5.404385805130005 | Iter 1.000: -8.894775390625\n",
      "Resources requested: 16.0/16 CPUs, 1.0/1 GPUs, 0.0/73.6 GiB heap, 0.0/35.54 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Current best trial: 84be5_00000 with val_log_likelihood=-0.013439194299280643 and parameters={'num_latents': 10}\n",
      "Result logdir: /home/tianyudu/ray_results/train_tune_2021-10-11_18-19-59\n",
      "Number of trials: 20/20 (9 PENDING, 1 RUNNING, 10 TERMINATED)\n",
      "+------------------------+------------+-----------------------+---------------+----------------------+\n",
      "| Trial name             | status     | loc                   |   num_latents |   val_log_likelihood |\n",
      "|------------------------+------------+-----------------------+---------------+----------------------|\n",
      "| train_tune_84be5_00010 | RUNNING    | 192.168.0.158:1061495 |             5 |           -4.84382   |\n",
      "| train_tune_84be5_00011 | PENDING    |                       |             3 |                      |\n",
      "| train_tune_84be5_00012 | PENDING    |                       |           300 |                      |\n",
      "| train_tune_84be5_00013 | PENDING    |                       |             2 |                      |\n",
      "| train_tune_84be5_00014 | PENDING    |                       |             4 |                      |\n",
      "| train_tune_84be5_00015 | PENDING    |                       |             1 |                      |\n",
      "| train_tune_84be5_00016 | PENDING    |                       |            10 |                      |\n",
      "| train_tune_84be5_00017 | PENDING    |                       |             2 |                      |\n",
      "| train_tune_84be5_00018 | PENDING    |                       |            10 |                      |\n",
      "| train_tune_84be5_00019 | PENDING    |                       |             7 |                      |\n",
      "| train_tune_84be5_00000 | TERMINATED |                       |            10 |           -0.0134392 |\n",
      "| train_tune_84be5_00001 | TERMINATED |                       |           100 |          -25.5851    |\n",
      "| train_tune_84be5_00002 | TERMINATED |                       |             3 |           -3.26772   |\n",
      "| train_tune_84be5_00003 | TERMINATED |                       |             4 |           -5.58406   |\n",
      "| train_tune_84be5_00004 | TERMINATED |                       |            10 |           -9.61891   |\n",
      "| train_tune_84be5_00005 | TERMINATED |                       |            10 |           -8.89478   |\n",
      "| train_tune_84be5_00006 | TERMINATED |                       |            20 |          -15.8032    |\n",
      "| train_tune_84be5_00007 | TERMINATED |                       |            10 |          -10.0723    |\n",
      "| train_tune_84be5_00008 | TERMINATED |                       |             2 |           -4.57744   |\n",
      "| train_tune_84be5_00009 | TERMINATED |                       |          1000 |          -22.5855    |\n",
      "+------------------------+------------+-----------------------+---------------+----------------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_samples = 20\n",
    "\n",
    "config = {\n",
    "    'num_latents': tune.choice([1, 2, 3, 4, 5, 7, 10, 20, 50, 100, 300, 1000])\n",
    "}\n",
    "\n",
    "scheduler = ASHAScheduler(max_t=num_epochs, grace_period=1, reduction_factor=2)\n",
    "\n",
    "reporter = CLIReporter(parameter_columns=list(config.keys()),\n",
    "                       metric_columns=list(callback._metrics.keys()))\n",
    "\n",
    "analysis = tune.run(\n",
    "    tune.with_parameters(train_tune, epochs=num_epochs, gpus=1),\n",
    "    metric='val_log_likelihood',\n",
    "    mode='max',\n",
    "    resources_per_trial={'cpu': 16, 'gpu': 1},\n",
    "    config=config,\n",
    "    num_samples=num_samples,\n",
    "    scheduler=scheduler,\n",
    "    progress_reporter=reporter)\n",
    "\n",
    "print(\"Best hyperparameters found were: \", analysis.best_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40d10ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
