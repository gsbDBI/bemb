
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://example.com/api_torch_choice/">
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.3.0, mkdocs-material-8.2.13">
    
    
      
        <title>API Reference Torch-Choice - Deep Choice</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.e411adfe.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.cc9b2e1e.min.css">
        
      
    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="none" data-md-color-accent="none">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#api-reference-torch-choice" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Deep Choice" class="md-header__button md-logo" aria-label="Deep Choice" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Deep Choice
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              API Reference Torch-Choice
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Deep Choice" class="md-nav__button md-logo" aria-label="Deep Choice" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Deep Choice
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../intro/" class="md-nav__link">
        About
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../install/" class="md-nav__link">
        Get Started
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../data_management/" class="md-nav__link">
        Tutorial for  Data Management
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../conditional_logit_model_mode_canada/" class="md-nav__link">
        Tutorial for Conditional Logit Model
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../nested_logit_model_house_cooling/" class="md-nav__link">
        Tutorial for Nested Logit Model
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../bemb/" class="md-nav__link">
        Tutorial for Bayesian Embedding (BEMB)
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../projects/" class="md-nav__link">
        Related Projects
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../test/" class="md-nav__link">
        Compability Tests
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          API Reference Torch-Choice
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        API Reference Torch-Choice
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#torch_choice" class="md-nav__link">
    torch_choice
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torch_choice.data" class="md-nav__link">
    data
  </a>
  
    <nav class="md-nav" aria-label="data">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.choice_dataset" class="md-nav__link">
    choice_dataset
  </a>
  
    <nav class="md-nav" aria-label="choice_dataset">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.choice_dataset.ChoiceDataset" class="md-nav__link">
    ChoiceDataset
  </a>
  
    <nav class="md-nav" aria-label="ChoiceDataset">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.choice_dataset.ChoiceDataset.device" class="md-nav__link">
    device
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.choice_dataset.ChoiceDataset.num_items" class="md-nav__link">
    num_items
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.choice_dataset.ChoiceDataset.num_sessions" class="md-nav__link">
    num_sessions
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.choice_dataset.ChoiceDataset.num_users" class="md-nav__link">
    num_users
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.choice_dataset.ChoiceDataset.x_dict" class="md-nav__link">
    x_dict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.choice_dataset.ChoiceDataset.__getitem__" class="md-nav__link">
    __getitem__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.choice_dataset.ChoiceDataset.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.choice_dataset.ChoiceDataset.__len__" class="md-nav__link">
    __len__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.choice_dataset.ChoiceDataset.__repr__" class="md-nav__link">
    __repr__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.choice_dataset.ChoiceDataset.apply_tensor" class="md-nav__link">
    apply_tensor()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.choice_dataset.ChoiceDataset.clone" class="md-nav__link">
    clone()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.choice_dataset.ChoiceDataset.to" class="md-nav__link">
    to()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.joint_dataset" class="md-nav__link">
    joint_dataset
  </a>
  
    <nav class="md-nav" aria-label="joint_dataset">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.joint_dataset.JointDataset" class="md-nav__link">
    JointDataset
  </a>
  
    <nav class="md-nav" aria-label="JointDataset">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.joint_dataset.JointDataset.device" class="md-nav__link">
    device
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.joint_dataset.JointDataset.__getitem__" class="md-nav__link">
    __getitem__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.joint_dataset.JointDataset.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.joint_dataset.JointDataset.__len__" class="md-nav__link">
    __len__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.joint_dataset.JointDataset.__repr__" class="md-nav__link">
    __repr__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.joint_dataset.JointDataset.to" class="md-nav__link">
    to()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.utils" class="md-nav__link">
    utils
  </a>
  
    <nav class="md-nav" aria-label="utils">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.utils.pivot3d" class="md-nav__link">
    pivot3d()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torch_choice.model" class="md-nav__link">
    model
  </a>
  
    <nav class="md-nav" aria-label="model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.coefficient" class="md-nav__link">
    coefficient
  </a>
  
    <nav class="md-nav" aria-label="coefficient">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.coefficient.Coefficient" class="md-nav__link">
    Coefficient
  </a>
  
    <nav class="md-nav" aria-label="Coefficient">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.coefficient.Coefficient.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.coefficient.Coefficient.__repr__" class="md-nav__link">
    __repr__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.coefficient.Coefficient.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.conditional_logit_model" class="md-nav__link">
    conditional_logit_model
  </a>
  
    <nav class="md-nav" aria-label="conditional_logit_model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.conditional_logit_model.ConditionalLogitModel" class="md-nav__link">
    ConditionalLogitModel
  </a>
  
    <nav class="md-nav" aria-label="ConditionalLogitModel">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.conditional_logit_model.ConditionalLogitModel.num_params" class="md-nav__link">
    num_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.conditional_logit_model.ConditionalLogitModel.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.conditional_logit_model.ConditionalLogitModel.__repr__" class="md-nav__link">
    __repr__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.conditional_logit_model.ConditionalLogitModel.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.conditional_logit_model.ConditionalLogitModel.negative_log_likelihood" class="md-nav__link">
    negative_log_likelihood()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.conditional_logit_model.ConditionalLogitModel.summary" class="md-nav__link">
    summary()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.nested_logit_model" class="md-nav__link">
    nested_logit_model
  </a>
  
    <nav class="md-nav" aria-label="nested_logit_model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.nested_logit_model.NestedLogitModel" class="md-nav__link">
    NestedLogitModel
  </a>
  
    <nav class="md-nav" aria-label="NestedLogitModel">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.nested_logit_model.NestedLogitModel.num_params" class="md-nav__link">
    num_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.nested_logit_model.NestedLogitModel.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.nested_logit_model.NestedLogitModel.forward" class="md-nav__link">
    forward()
  </a>
  
    <nav class="md-nav" aria-label="forward()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.nested_logit_model.NestedLogitModel.forward--todo-the-conditionalogitmodel-returns-predicted-utility-the-nestedlogitmodel-behaves-the-same" class="md-nav__link">
    TODO: the ConditionaLogitModel returns predicted utility, the NestedLogitModel behaves the same?
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.nested_logit_model.NestedLogitModel.log_likelihood" class="md-nav__link">
    log_likelihood()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.nested_logit_model.NestedLogitModel.negative_log_likelihood" class="md-nav__link">
    negative_log_likelihood()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../api_bemb/" class="md-nav__link">
        API Reference BEMB
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#torch_choice" class="md-nav__link">
    torch_choice
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torch_choice.data" class="md-nav__link">
    data
  </a>
  
    <nav class="md-nav" aria-label="data">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.choice_dataset" class="md-nav__link">
    choice_dataset
  </a>
  
    <nav class="md-nav" aria-label="choice_dataset">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.choice_dataset.ChoiceDataset" class="md-nav__link">
    ChoiceDataset
  </a>
  
    <nav class="md-nav" aria-label="ChoiceDataset">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.choice_dataset.ChoiceDataset.device" class="md-nav__link">
    device
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.choice_dataset.ChoiceDataset.num_items" class="md-nav__link">
    num_items
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.choice_dataset.ChoiceDataset.num_sessions" class="md-nav__link">
    num_sessions
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.choice_dataset.ChoiceDataset.num_users" class="md-nav__link">
    num_users
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.choice_dataset.ChoiceDataset.x_dict" class="md-nav__link">
    x_dict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.choice_dataset.ChoiceDataset.__getitem__" class="md-nav__link">
    __getitem__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.choice_dataset.ChoiceDataset.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.choice_dataset.ChoiceDataset.__len__" class="md-nav__link">
    __len__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.choice_dataset.ChoiceDataset.__repr__" class="md-nav__link">
    __repr__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.choice_dataset.ChoiceDataset.apply_tensor" class="md-nav__link">
    apply_tensor()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.choice_dataset.ChoiceDataset.clone" class="md-nav__link">
    clone()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.choice_dataset.ChoiceDataset.to" class="md-nav__link">
    to()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.joint_dataset" class="md-nav__link">
    joint_dataset
  </a>
  
    <nav class="md-nav" aria-label="joint_dataset">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.joint_dataset.JointDataset" class="md-nav__link">
    JointDataset
  </a>
  
    <nav class="md-nav" aria-label="JointDataset">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.joint_dataset.JointDataset.device" class="md-nav__link">
    device
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.joint_dataset.JointDataset.__getitem__" class="md-nav__link">
    __getitem__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.joint_dataset.JointDataset.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.joint_dataset.JointDataset.__len__" class="md-nav__link">
    __len__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.joint_dataset.JointDataset.__repr__" class="md-nav__link">
    __repr__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.joint_dataset.JointDataset.to" class="md-nav__link">
    to()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.utils" class="md-nav__link">
    utils
  </a>
  
    <nav class="md-nav" aria-label="utils">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torch_choice.data.utils.pivot3d" class="md-nav__link">
    pivot3d()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torch_choice.model" class="md-nav__link">
    model
  </a>
  
    <nav class="md-nav" aria-label="model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.coefficient" class="md-nav__link">
    coefficient
  </a>
  
    <nav class="md-nav" aria-label="coefficient">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.coefficient.Coefficient" class="md-nav__link">
    Coefficient
  </a>
  
    <nav class="md-nav" aria-label="Coefficient">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.coefficient.Coefficient.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.coefficient.Coefficient.__repr__" class="md-nav__link">
    __repr__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.coefficient.Coefficient.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.conditional_logit_model" class="md-nav__link">
    conditional_logit_model
  </a>
  
    <nav class="md-nav" aria-label="conditional_logit_model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.conditional_logit_model.ConditionalLogitModel" class="md-nav__link">
    ConditionalLogitModel
  </a>
  
    <nav class="md-nav" aria-label="ConditionalLogitModel">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.conditional_logit_model.ConditionalLogitModel.num_params" class="md-nav__link">
    num_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.conditional_logit_model.ConditionalLogitModel.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.conditional_logit_model.ConditionalLogitModel.__repr__" class="md-nav__link">
    __repr__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.conditional_logit_model.ConditionalLogitModel.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.conditional_logit_model.ConditionalLogitModel.negative_log_likelihood" class="md-nav__link">
    negative_log_likelihood()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.conditional_logit_model.ConditionalLogitModel.summary" class="md-nav__link">
    summary()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.nested_logit_model" class="md-nav__link">
    nested_logit_model
  </a>
  
    <nav class="md-nav" aria-label="nested_logit_model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.nested_logit_model.NestedLogitModel" class="md-nav__link">
    NestedLogitModel
  </a>
  
    <nav class="md-nav" aria-label="NestedLogitModel">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.nested_logit_model.NestedLogitModel.num_params" class="md-nav__link">
    num_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.nested_logit_model.NestedLogitModel.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.nested_logit_model.NestedLogitModel.forward" class="md-nav__link">
    forward()
  </a>
  
    <nav class="md-nav" aria-label="forward()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.nested_logit_model.NestedLogitModel.forward--todo-the-conditionalogitmodel-returns-predicted-utility-the-nestedlogitmodel-behaves-the-same" class="md-nav__link">
    TODO: the ConditionaLogitModel returns predicted utility, the NestedLogitModel behaves the same?
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.nested_logit_model.NestedLogitModel.log_likelihood" class="md-nav__link">
    log_likelihood()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torch_choice.model.nested_logit_model.NestedLogitModel.negative_log_likelihood" class="md-nav__link">
    negative_log_likelihood()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                


<h1 id="api-reference-torch-choice">API Reference: Torch Choice</h1>


  <div class="doc doc-object doc-module">

<a id="torch_choice"></a>
    <div class="doc doc-contents first">




  <div class="doc doc-children">










  <div class="doc doc-object doc-module">



<h2 id="torch_choice.data" class="doc doc-heading">
        <code>data</code>


  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h2>

    <div class="doc doc-contents ">




  <div class="doc doc-children">










  <div class="doc doc-object doc-module">



<h3 id="torch_choice.data.choice_dataset" class="doc doc-heading">
        <code>choice_dataset</code>



</h3>

    <div class="doc doc-contents ">

      <p>The dataset object for management large scale consumer choice datasets.
Please refer to the documentation and tutorials for more details on using <code>ChoiceDataset</code>.</p>
<p>Author: Tianyu Du
Update: Apr. 27, 2022</p>



  <div class="doc doc-children">







  <div class="doc doc-object doc-class">



<h4 id="torch_choice.data.choice_dataset.ChoiceDataset" class="doc doc-heading">
        <code>
ChoiceDataset            (<span title="torch.utils.data.dataset.Dataset">Dataset</span>)
        </code>



</h4>

    <div class="doc doc-contents ">


        <details class="quote">
          <summary>Source code in <code>torch_choice/data/choice_dataset.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">ChoiceDataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">item_index</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">,</span>
                 <span class="n">label</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">user_index</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">session_index</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">item_availability</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">BoolTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialization methods for the dataset object, researchers should supply all information about the dataset</span>
<span class="sd">        using this initialization method.</span>

<span class="sd">        The number of choice instances are called `batch_size` in the documentation. The `batch_size` corresponds to the</span>
<span class="sd">        file length in wide-format dataset, and often denoted using `N`. We call it `batch_size` to follow the convention</span>
<span class="sd">        in machine learning literature.</span>
<span class="sd">        A `choice instance` is a row of the dataset, so there are `batch_size` choice instances in each `ChoiceDataset`.</span>

<span class="sd">        The dataset consists of:</span>
<span class="sd">        (1) a collection of `batch_size` tuples (item_id, user_id, session_id, label), where each tuple is a choice instance.</span>
<span class="sd">        (2) a collection of `observables` associated with item, user, session, etc.</span>

<span class="sd">        Args:</span>
<span class="sd">            item_index (torch.LongTensor): a tensor of shape (batch_size) indicating the relevant item in each row</span>
<span class="sd">                of the dataset, the relevant item can be:</span>
<span class="sd">                (1) the item bought in this choice instance,</span>
<span class="sd">                (2) or the item reviewed by the user. In the later case, we need the `label` tensor to specify the rating score.</span>
<span class="sd">                NOTE: The support for second case is under-development, currently, we are only supporting binary label.</span>

<span class="sd">            label (Optional[torch.LongTensor], optional): a tensor of shape (batch_size) indicating the label for prediction in</span>
<span class="sd">                each choice instance. While you want to predict the item bought, you can leave the `label` argument</span>
<span class="sd">                as `None` in the initialization method, and the model will use `item_index` as the object to be predicted.</span>
<span class="sd">                But if you are, for example, predicting the rating an user gave an item, label must be provided.</span>
<span class="sd">                Defaults to None.</span>

<span class="sd">            user_index (Optional[torch.LongTensor], optional): a tensor of shape num_purchases (batch_size) indicating</span>
<span class="sd">                the ID of the user who was involved in each choice instance. If `None` user index is provided, it&#39;s assumed</span>
<span class="sd">                that the choice instances are from the same user.</span>
<span class="sd">                `user_index` is required if and only if there are multiple users in the dataset, for example:</span>
<span class="sd">                    (1) user-observables is involved in the utility form,</span>
<span class="sd">                    (2) and/or the coefficient is user-specific.</span>
<span class="sd">                This tensor is used to select the corresponding user observables and coefficients assigned to the</span>
<span class="sd">                user (like theta_user) for making prediction for that purchase.</span>
<span class="sd">                Defaults to None.</span>

<span class="sd">            session_index (Optional[torch.LongTensor], optional): a tensor of shape num_purchases (batch_size) indicating</span>
<span class="sd">                the ID of the session when that choice instance occurred. This tensor is used to select the correct</span>
<span class="sd">                session observables or price observables for making prediction for that choice instance. Therefore, if</span>
<span class="sd">                there is no session/price observables, you can leave this argument as `None`. In this case, the `ChoiceDataset`</span>
<span class="sd">                object will assume each choice instance to be in its own session.</span>
<span class="sd">                Defaults to None.</span>

<span class="sd">            item_availability (Optional[torch.BoolTensor], optional): A boolean tensor of shape (num_sessions, num_items)</span>
<span class="sd">                indicating the availability of each item in each session. Utilities of unavailable items would be set to -infinite,</span>
<span class="sd">                and hence these unavailable items will be set to 0 while making prediction.</span>
<span class="sd">                We assume all items are available if set to None.</span>
<span class="sd">                Defaults to None.</span>

<span class="sd">        Other Kwargs (Observables):</span>
<span class="sd">            One can specify the following types of observables, where * in shape denotes any positive</span>
<span class="sd">                integer. Typically * represents the number of observables.</span>
<span class="sd">            Please refer to the documentation for a detailed guide to use observables.</span>
<span class="sd">            1. user observables must start with &#39;user_&#39; and have shape (num_users, *)</span>
<span class="sd">            2. item observables must start with &#39;item_&#39; and have shape (num_items, *)</span>
<span class="sd">            3. session observables must start with &#39;session_&#39; and have shape (num_sessions, *)</span>
<span class="sd">            4. taste observables (those vary by user and item) must start with `taste_` and have shape</span>
<span class="sd">                (num_users, num_items, *).</span>
<span class="sd">            NOTE: we don&#39;t recommend using taste observables, because num_users * num_items is potentially large.</span>
<span class="sd">            5. price observables (those vary by session and item) must start with `price_` and have</span>
<span class="sd">                shape (num_sessions, num_items, *)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># ENHANCEMENT(Tianyu): add item_names for summary.</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ChoiceDataset</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label</span> <span class="o">=</span> <span class="n">label</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">item_index</span> <span class="o">=</span> <span class="n">item_index</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">user_index</span> <span class="o">=</span> <span class="n">user_index</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">session_index</span> <span class="o">=</span> <span class="n">session_index</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">session_index</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># if any([x.startswith(&#39;session_&#39;) or x.startswith(&#39;price_&#39;) for x in kwargs.keys()]):</span>
            <span class="c1"># if any session sensitive observable is provided, but session index is not,</span>
            <span class="c1"># infer each row in the dataset to be a session.</span>
            <span class="c1"># TODO: (design choice) should we assign unique session index to each choice instance or the same session index.</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;No `session_index` is provided, assume each choice instance is in its own session.&#39;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">session_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">item_index</span><span class="p">))</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">item_availability</span> <span class="o">=</span> <span class="n">item_availability</span>

        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">item</span><span class="p">)</span>

        <span class="c1"># TODO: add a validation procedure to check the consistency of the dataset.</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="s2">&quot;ChoiceDataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Retrieves samples corresponding to the provided index or list of indices.</span>

<span class="sd">        Args:</span>
<span class="sd">            indices (Union[int, torch.LongTensor]): a single integer index or a tensor of indices.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ChoiceDataset: a subset of the dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="c1"># convert single integer index to an array of indices.</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="n">indices</span><span class="p">])</span>
        <span class="n">new_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="n">new_dict</span><span class="p">[</span><span class="s1">&#39;item_index&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_index</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

        <span class="c1"># copy optional attributes.</span>
        <span class="n">new_dict</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">label</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">label</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="n">new_dict</span><span class="p">[</span><span class="s1">&#39;user_index&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">user_index</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">user_index</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="n">new_dict</span><span class="p">[</span><span class="s1">&#39;session_index&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">session_index</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">session_index</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="c1"># item_availability has shape (num_sessions, num_items), no need to re-index it.</span>
        <span class="n">new_dict</span><span class="p">[</span><span class="s1">&#39;item_availability&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_availability</span>

        <span class="c1"># copy other attributes.</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">new_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">val</span><span class="p">):</span>
                    <span class="n">new_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">new_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_from_dict</span><span class="p">(</span><span class="n">new_dict</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns number of samples in this dataset.</span>

<span class="sd">        Returns:</span>
<span class="sd">            int: length of the dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">item_index</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__contains__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns the device of the dataset.</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: the device of the dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">attr</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">attr</span><span class="o">.</span><span class="n">device</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">num_users</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns number of users involved in this dataset, returns 1 if there is no user identity.</span>

<span class="sd">        Returns:</span>
<span class="sd">            int: the number of users involved in this dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># query from user_index</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">user_index</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">user_index</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">1</span>

        <span class="c1"># for key, val in self.__dict__.items():</span>
        <span class="c1">#     if torch.is_tensor(val):</span>
        <span class="c1">#         if self._is_user_attribute(key) or self._is_taste_attribute(key):</span>
        <span class="c1">#             return val.shape[0]</span>
        <span class="c1"># return 1</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">num_items</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns the number of items involved in this dataset.</span>

<span class="sd">        Returns:</span>
<span class="sd">            int: the number of items involved in this dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">item_index</span><span class="p">))</span>

        <span class="c1"># for key, val in self.__dict__.items():</span>
        <span class="c1">#     if torch.is_tensor(val):</span>
        <span class="c1">#         if self._is_item_attribute(key):</span>
        <span class="c1">#             return val.shape[0]</span>
        <span class="c1">#         elif self._is_taste_attribute(key) or self._is_price_attribute(key):</span>
        <span class="c1">#             return val.shape[1]</span>
        <span class="c1"># return 1</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">num_sessions</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns the number of sessions involved in this dataset.</span>

<span class="sd">        Returns:</span>
<span class="sd">            int: the number of sessions involved in this dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">session_index</span><span class="p">))</span>

        <span class="c1"># if self.session_index is None:</span>
        <span class="c1">#     return 1</span>

        <span class="c1"># for key, val in self.__dict__.items():</span>
        <span class="c1">#     if torch.is_tensor(val):</span>
        <span class="c1">#         if self._is_session_attribute(key) or self._is_price_attribute(key):</span>
        <span class="c1">#             return val.shape[0]</span>
        <span class="c1"># return 1</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">x_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">object</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Formats attributes of in this dataset into shape (num_sessions, num_items, num_params) and returns in a dictionary format.</span>
<span class="sd">        Models in this package are expecting this dictionary based data format.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dict[object, torch.Tensor]: a dictionary with attribute names in the dataset as keys, and reshaped attribute</span>
<span class="sd">                tensors as values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">out</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_attribute</span><span class="p">(</span><span class="n">key</span><span class="p">):</span>  <span class="c1"># only include attributes.</span>
                <span class="n">out</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_expand_tensor</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>  <span class="c1"># reshape to (num_sessions, num_items, num_params).</span>
        <span class="k">return</span> <span class="n">out</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">_from_dict</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="s2">&quot;ChoiceDataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Creates an instance of ChoiceDataset from a dictionary of arguments.</span>

<span class="sd">        Args:</span>
<span class="sd">            dictionary (Dict[str, torch.tensor]): a dictionary with keys as argument names and values as arguments.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ChoiceDataset: the created copy of dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="o">**</span><span class="n">dictionary</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">item</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">dataset</span>

    <span class="k">def</span> <span class="nf">apply_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">func</span><span class="p">:</span> <span class="n">callable</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;ChoiceDataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;This s a helper method to apply the provided function to all tensors and tensor values of all dictionaries.</span>

<span class="sd">        Args:</span>
<span class="sd">            func (callable): a callable function to be applied on tensors and tensor-values of dictionaries.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ChoiceDataset: the modified dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">item</span><span class="p">):</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">func</span><span class="p">(</span><span class="n">item</span><span class="p">))</span>
            <span class="c1"># boardcast func to dictionary of tensors as well.</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">),</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">obj_key</span><span class="p">,</span> <span class="n">obj_item</span> <span class="ow">in</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">obj_item</span><span class="p">):</span>
                        <span class="nb">setattr</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">),</span> <span class="n">obj_key</span><span class="p">,</span> <span class="n">func</span><span class="p">(</span><span class="n">obj_item</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="s2">&quot;ChoiceDataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Moves all tensors in this dataset to the specified PyTorch device.</span>

<span class="sd">        Args:</span>
<span class="sd">            device (Union[str, torch.device]): the destination device.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ChoiceDataset: the modified dataset on the new device.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">apply_tensor</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">clone</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;ChoiceDataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Creates a copy of self.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ChoiceDataset: a copy of self.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dictionary</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
                <span class="n">dictionary</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">dictionary</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="n">_from_dict</span><span class="p">(</span><span class="n">dictionary</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_check_device_consistency</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Checks if all tensors in this dataset are on the same device.</span>

<span class="sd">        Raises:</span>
<span class="sd">            Exception: an exception is raised if not all tensors are on the same device.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># assert all tensors are on the same device.</span>
        <span class="n">devices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">val</span><span class="p">):</span>
                <span class="n">devices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">devices</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Found tensors on different devices: </span><span class="si">{</span><span class="nb">set</span><span class="p">(</span><span class="n">devices</span><span class="p">)</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">,</span>
                            <span class="s1">&#39;Use dataset.to() method to align devices.&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_size_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="nb">object</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;A helper method to get the string-representation of object sizes, this is helpful while constructing the</span>
<span class="sd">        string representation of the dataset.</span>

<span class="sd">        Args:</span>
<span class="sd">            value (object): an object to examine its size.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List[int]: list of integers representing the size of the object, length of the list is equal to dimension of `value`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
            <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">)]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;A method to get a string representation of the dataset.</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: the string representation of the dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">info</span> <span class="o">=</span> <span class="p">[</span>
            <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1">=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_size_repr</span><span class="p">(</span><span class="n">item</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">()]</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(</span><span class="si">{</span><span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">info</span><span class="p">)</span><span class="si">}</span><span class="s2">, device=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2">)&quot;</span>

    <span class="c1"># ==================================================================================================================</span>
    <span class="c1"># methods for checking attribute categories.</span>
    <span class="c1"># ==================================================================================================================</span>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_is_item_attribute</span><span class="p">(</span><span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;item_&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">key</span> <span class="o">!=</span> <span class="s1">&#39;item_availability&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">key</span> <span class="o">!=</span> <span class="s1">&#39;item_index&#39;</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_is_user_attribute</span><span class="p">(</span><span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;user_&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">key</span> <span class="o">!=</span> <span class="s1">&#39;user_index&#39;</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_is_session_attribute</span><span class="p">(</span><span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;session_&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">key</span> <span class="o">!=</span> <span class="s1">&#39;session_index&#39;</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_is_taste_attribute</span><span class="p">(</span><span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;taste_&#39;</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_is_price_attribute</span><span class="p">(</span><span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;price_&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_is_attribute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_item_attribute</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> \
            <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_user_attribute</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> \
            <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_session_attribute</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> \
            <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_taste_attribute</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> \
            <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_price_attribute</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_expand_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">val</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Expands attribute tensor to (num_sessions, num_items, num_params) shape for prediction tasks, this method</span>
<span class="sd">        won&#39;t reshape the tensor at all if the `key` (i.e., name of the tensor) suggests its not an attribute of any kind.</span>

<span class="sd">        Args:</span>
<span class="sd">            key (str): name of the attribute used to determine the raw shape of the tensor. For example, &#39;item_obs&#39; means</span>
<span class="sd">                the raw tensor is in shape (num_items, num_params).</span>
<span class="sd">            val (torch.Tensor): the attribute tensor to be reshaped.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: the reshaped tensor with shape (num_sessions, num_items, num_params).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_attribute</span><span class="p">(</span><span class="n">key</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Warning: the input key </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1"> is not an attribute of the dataset, will NOT modify the provided tensor.&#39;</span><span class="p">)</span>
            <span class="c1"># don&#39;t expand non-attribute tensors, if any.</span>
            <span class="k">return</span> <span class="n">val</span>

        <span class="n">num_params</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_user_attribute</span><span class="p">(</span><span class="n">key</span><span class="p">):</span>
            <span class="c1"># user_attribute (num_users, *)</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">val</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">user_index</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_params</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_item_attribute</span><span class="p">(</span><span class="n">key</span><span class="p">):</span>
            <span class="c1"># item_attribute (num_items, *)</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">,</span> <span class="n">num_params</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_session_attribute</span><span class="p">(</span><span class="n">key</span><span class="p">):</span>
            <span class="c1"># session_attribute (num_sessions, *)</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">val</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">session_index</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_params</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_taste_attribute</span><span class="p">(</span><span class="n">key</span><span class="p">):</span>
            <span class="c1"># taste_attribute (num_users, num_items, *)</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">val</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">user_index</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_price_attribute</span><span class="p">(</span><span class="n">key</span><span class="p">):</span>
            <span class="c1"># price_attribute (num_sessions, num_items, *)</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">val</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">session_index</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>

        <span class="k">assert</span> <span class="n">out</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">,</span> <span class="n">num_params</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">






  <div class="doc doc-object doc-attribute">



<h5 id="torch_choice.data.choice_dataset.ChoiceDataset.device" class="doc doc-heading">
<code class="highlight language-python"><span class="n">device</span><span class="p">:</span> <span class="nb">str</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

</h5>

    <div class="doc doc-contents ">

      <p>Returns the device of the dataset.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>str</code></td>
      <td><p>the device of the dataset.</p></td>
    </tr>
  </tbody>
</table>    </div>

  </div>



  <div class="doc doc-object doc-attribute">



<h5 id="torch_choice.data.choice_dataset.ChoiceDataset.num_items" class="doc doc-heading">
<code class="highlight language-python"><span class="n">num_items</span><span class="p">:</span> <span class="nb">int</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

</h5>

    <div class="doc doc-contents ">

      <p>Returns the number of items involved in this dataset.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>int</code></td>
      <td><p>the number of items involved in this dataset.</p></td>
    </tr>
  </tbody>
</table>    </div>

  </div>



  <div class="doc doc-object doc-attribute">



<h5 id="torch_choice.data.choice_dataset.ChoiceDataset.num_sessions" class="doc doc-heading">
<code class="highlight language-python"><span class="n">num_sessions</span><span class="p">:</span> <span class="nb">int</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

</h5>

    <div class="doc doc-contents ">

      <p>Returns the number of sessions involved in this dataset.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>int</code></td>
      <td><p>the number of sessions involved in this dataset.</p></td>
    </tr>
  </tbody>
</table>    </div>

  </div>



  <div class="doc doc-object doc-attribute">



<h5 id="torch_choice.data.choice_dataset.ChoiceDataset.num_users" class="doc doc-heading">
<code class="highlight language-python"><span class="n">num_users</span><span class="p">:</span> <span class="nb">int</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

</h5>

    <div class="doc doc-contents ">

      <p>Returns number of users involved in this dataset, returns 1 if there is no user identity.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>int</code></td>
      <td><p>the number of users involved in this dataset.</p></td>
    </tr>
  </tbody>
</table>    </div>

  </div>



  <div class="doc doc-object doc-attribute">



<h5 id="torch_choice.data.choice_dataset.ChoiceDataset.x_dict" class="doc doc-heading">
<code class="highlight language-python"><span class="n">x_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">object</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

</h5>

    <div class="doc doc-contents ">

      <p>Formats attributes of in this dataset into shape (num_sessions, num_items, num_params) and returns in a dictionary format.
Models in this package are expecting this dictionary based data format.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Dict[object, torch.Tensor]</code></td>
      <td><p>a dictionary with attribute names in the dataset as keys, and reshaped attribute
    tensors as values.</p></td>
    </tr>
  </tbody>
</table>    </div>

  </div>







  <div class="doc doc-object doc-method">



<h5 id="torch_choice.data.choice_dataset.ChoiceDataset.__getitem__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h5>

    <div class="doc doc-contents ">

      <p>Retrieves samples corresponding to the provided index or list of indices.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>indices</code></td>
        <td><code>Union[int, torch.LongTensor]</code></td>
        <td><p>a single integer index or a tensor of indices.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>ChoiceDataset</code></td>
      <td><p>a subset of the dataset.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>torch_choice/data/choice_dataset.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="s2">&quot;ChoiceDataset&quot;</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Retrieves samples corresponding to the provided index or list of indices.</span>

<span class="sd">    Args:</span>
<span class="sd">        indices (Union[int, torch.LongTensor]): a single integer index or a tensor of indices.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ChoiceDataset: a subset of the dataset.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="c1"># convert single integer index to an array of indices.</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="n">indices</span><span class="p">])</span>
    <span class="n">new_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="n">new_dict</span><span class="p">[</span><span class="s1">&#39;item_index&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_index</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

    <span class="c1"># copy optional attributes.</span>
    <span class="n">new_dict</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">label</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">label</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
    <span class="n">new_dict</span><span class="p">[</span><span class="s1">&#39;user_index&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">user_index</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">user_index</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
    <span class="n">new_dict</span><span class="p">[</span><span class="s1">&#39;session_index&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">session_index</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">session_index</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
    <span class="c1"># item_availability has shape (num_sessions, num_items), no need to re-index it.</span>
    <span class="n">new_dict</span><span class="p">[</span><span class="s1">&#39;item_availability&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_availability</span>

    <span class="c1"># copy other attributes.</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">new_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">val</span><span class="p">):</span>
                <span class="n">new_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">new_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_from_dict</span><span class="p">(</span><span class="n">new_dict</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="torch_choice.data.choice_dataset.ChoiceDataset.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item_index</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">user_index</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">session_index</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">item_availability</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h5>

    <div class="doc doc-contents ">

      <p>Initialization methods for the dataset object, researchers should supply all information about the dataset
using this initialization method.</p>
<p>The number of choice instances are called <code>batch_size</code> in the documentation. The <code>batch_size</code> corresponds to the
file length in wide-format dataset, and often denoted using <code>N</code>. We call it <code>batch_size</code> to follow the convention
in machine learning literature.
A <code>choice instance</code> is a row of the dataset, so there are <code>batch_size</code> choice instances in each <code>ChoiceDataset</code>.</p>
<p>The dataset consists of:
(1) a collection of <code>batch_size</code> tuples (item_id, user_id, session_id, label), where each tuple is a choice instance.
(2) a collection of <code>observables</code> associated with item, user, session, etc.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>item_index</code></td>
        <td><code>torch.LongTensor</code></td>
        <td><p>a tensor of shape (batch_size) indicating the relevant item in each row
of the dataset, the relevant item can be:
(1) the item bought in this choice instance,
(2) or the item reviewed by the user. In the later case, we need the <code>label</code> tensor to specify the rating score.
NOTE: The support for second case is under-development, currently, we are only supporting binary label.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>label</code></td>
        <td><code>Optional[torch.LongTensor]</code></td>
        <td><p>a tensor of shape (batch_size) indicating the label for prediction in
each choice instance. While you want to predict the item bought, you can leave the <code>label</code> argument
as <code>None</code> in the initialization method, and the model will use <code>item_index</code> as the object to be predicted.
But if you are, for example, predicting the rating an user gave an item, label must be provided.
Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>user_index</code></td>
        <td><code>Optional[torch.LongTensor]</code></td>
        <td><p>a tensor of shape num_purchases (batch_size) indicating
the ID of the user who was involved in each choice instance. If <code>None</code> user index is provided, it's assumed
that the choice instances are from the same user.
<code>user_index</code> is required if and only if there are multiple users in the dataset, for example:
    (1) user-observables is involved in the utility form,
    (2) and/or the coefficient is user-specific.
This tensor is used to select the corresponding user observables and coefficients assigned to the
user (like theta_user) for making prediction for that purchase.
Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>session_index</code></td>
        <td><code>Optional[torch.LongTensor]</code></td>
        <td><p>a tensor of shape num_purchases (batch_size) indicating
the ID of the session when that choice instance occurred. This tensor is used to select the correct
session observables or price observables for making prediction for that choice instance. Therefore, if
there is no session/price observables, you can leave this argument as <code>None</code>. In this case, the <code>ChoiceDataset</code>
object will assume each choice instance to be in its own session.
Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>item_availability</code></td>
        <td><code>Optional[torch.BoolTensor]</code></td>
        <td><p>A boolean tensor of shape (num_sessions, num_items)
indicating the availability of each item in each session. Utilities of unavailable items would be set to -infinite,
and hence these unavailable items will be set to 0 while making prediction.
We assume all items are available if set to None.
Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>      <p>Other Kwargs (Observables):
    One can specify the following types of observables, where * in shape denotes any positive
        integer. Typically * represents the number of observables.
    Please refer to the documentation for a detailed guide to use observables.
    1. user observables must start with 'user_' and have shape (num_users, <em>)
    2. item observables must start with 'item_' and have shape (num_items, </em>)
    3. session observables must start with 'session_' and have shape (num_sessions, <em>)
    4. taste observables (those vary by user and item) must start with <code>taste_</code> and have shape
        (num_users, num_items, </em>).
    NOTE: we don't recommend using taste observables, because num_users * num_items is potentially large.
    5. price observables (those vary by session and item) must start with <code>price_</code> and have
        shape (num_sessions, num_items, *)</p>

        <details class="quote">
          <summary>Source code in <code>torch_choice/data/choice_dataset.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
             <span class="n">item_index</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">,</span>
             <span class="n">label</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
             <span class="n">user_index</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
             <span class="n">session_index</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
             <span class="n">item_availability</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">BoolTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
             <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initialization methods for the dataset object, researchers should supply all information about the dataset</span>
<span class="sd">    using this initialization method.</span>

<span class="sd">    The number of choice instances are called `batch_size` in the documentation. The `batch_size` corresponds to the</span>
<span class="sd">    file length in wide-format dataset, and often denoted using `N`. We call it `batch_size` to follow the convention</span>
<span class="sd">    in machine learning literature.</span>
<span class="sd">    A `choice instance` is a row of the dataset, so there are `batch_size` choice instances in each `ChoiceDataset`.</span>

<span class="sd">    The dataset consists of:</span>
<span class="sd">    (1) a collection of `batch_size` tuples (item_id, user_id, session_id, label), where each tuple is a choice instance.</span>
<span class="sd">    (2) a collection of `observables` associated with item, user, session, etc.</span>

<span class="sd">    Args:</span>
<span class="sd">        item_index (torch.LongTensor): a tensor of shape (batch_size) indicating the relevant item in each row</span>
<span class="sd">            of the dataset, the relevant item can be:</span>
<span class="sd">            (1) the item bought in this choice instance,</span>
<span class="sd">            (2) or the item reviewed by the user. In the later case, we need the `label` tensor to specify the rating score.</span>
<span class="sd">            NOTE: The support for second case is under-development, currently, we are only supporting binary label.</span>

<span class="sd">        label (Optional[torch.LongTensor], optional): a tensor of shape (batch_size) indicating the label for prediction in</span>
<span class="sd">            each choice instance. While you want to predict the item bought, you can leave the `label` argument</span>
<span class="sd">            as `None` in the initialization method, and the model will use `item_index` as the object to be predicted.</span>
<span class="sd">            But if you are, for example, predicting the rating an user gave an item, label must be provided.</span>
<span class="sd">            Defaults to None.</span>

<span class="sd">        user_index (Optional[torch.LongTensor], optional): a tensor of shape num_purchases (batch_size) indicating</span>
<span class="sd">            the ID of the user who was involved in each choice instance. If `None` user index is provided, it&#39;s assumed</span>
<span class="sd">            that the choice instances are from the same user.</span>
<span class="sd">            `user_index` is required if and only if there are multiple users in the dataset, for example:</span>
<span class="sd">                (1) user-observables is involved in the utility form,</span>
<span class="sd">                (2) and/or the coefficient is user-specific.</span>
<span class="sd">            This tensor is used to select the corresponding user observables and coefficients assigned to the</span>
<span class="sd">            user (like theta_user) for making prediction for that purchase.</span>
<span class="sd">            Defaults to None.</span>

<span class="sd">        session_index (Optional[torch.LongTensor], optional): a tensor of shape num_purchases (batch_size) indicating</span>
<span class="sd">            the ID of the session when that choice instance occurred. This tensor is used to select the correct</span>
<span class="sd">            session observables or price observables for making prediction for that choice instance. Therefore, if</span>
<span class="sd">            there is no session/price observables, you can leave this argument as `None`. In this case, the `ChoiceDataset`</span>
<span class="sd">            object will assume each choice instance to be in its own session.</span>
<span class="sd">            Defaults to None.</span>

<span class="sd">        item_availability (Optional[torch.BoolTensor], optional): A boolean tensor of shape (num_sessions, num_items)</span>
<span class="sd">            indicating the availability of each item in each session. Utilities of unavailable items would be set to -infinite,</span>
<span class="sd">            and hence these unavailable items will be set to 0 while making prediction.</span>
<span class="sd">            We assume all items are available if set to None.</span>
<span class="sd">            Defaults to None.</span>

<span class="sd">    Other Kwargs (Observables):</span>
<span class="sd">        One can specify the following types of observables, where * in shape denotes any positive</span>
<span class="sd">            integer. Typically * represents the number of observables.</span>
<span class="sd">        Please refer to the documentation for a detailed guide to use observables.</span>
<span class="sd">        1. user observables must start with &#39;user_&#39; and have shape (num_users, *)</span>
<span class="sd">        2. item observables must start with &#39;item_&#39; and have shape (num_items, *)</span>
<span class="sd">        3. session observables must start with &#39;session_&#39; and have shape (num_sessions, *)</span>
<span class="sd">        4. taste observables (those vary by user and item) must start with `taste_` and have shape</span>
<span class="sd">            (num_users, num_items, *).</span>
<span class="sd">        NOTE: we don&#39;t recommend using taste observables, because num_users * num_items is potentially large.</span>
<span class="sd">        5. price observables (those vary by session and item) must start with `price_` and have</span>
<span class="sd">            shape (num_sessions, num_items, *)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># ENHANCEMENT(Tianyu): add item_names for summary.</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">ChoiceDataset</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">label</span> <span class="o">=</span> <span class="n">label</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">item_index</span> <span class="o">=</span> <span class="n">item_index</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">user_index</span> <span class="o">=</span> <span class="n">user_index</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">session_index</span> <span class="o">=</span> <span class="n">session_index</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">session_index</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># if any([x.startswith(&#39;session_&#39;) or x.startswith(&#39;price_&#39;) for x in kwargs.keys()]):</span>
        <span class="c1"># if any session sensitive observable is provided, but session index is not,</span>
        <span class="c1"># infer each row in the dataset to be a session.</span>
        <span class="c1"># TODO: (design choice) should we assign unique session index to each choice instance or the same session index.</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;No `session_index` is provided, assume each choice instance is in its own session.&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">session_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">item_index</span><span class="p">))</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">item_availability</span> <span class="o">=</span> <span class="n">item_availability</span>

    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">item</span><span class="p">)</span>

    <span class="c1"># TODO: add a validation procedure to check the consistency of the dataset.</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="torch_choice.data.choice_dataset.ChoiceDataset.__len__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h5>

    <div class="doc doc-contents ">

      <p>Returns number of samples in this dataset.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>int</code></td>
      <td><p>length of the dataset.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>torch_choice/data/choice_dataset.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Returns number of samples in this dataset.</span>

<span class="sd">    Returns:</span>
<span class="sd">        int: length of the dataset.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">item_index</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="torch_choice.data.choice_dataset.ChoiceDataset.__repr__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h5>

    <div class="doc doc-contents ">

      <p>A method to get a string representation of the dataset.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>str</code></td>
      <td><p>the string representation of the dataset.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>torch_choice/data/choice_dataset.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;A method to get a string representation of the dataset.</span>

<span class="sd">    Returns:</span>
<span class="sd">        str: the string representation of the dataset.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">info</span> <span class="o">=</span> <span class="p">[</span>
        <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1">=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_size_repr</span><span class="p">(</span><span class="n">item</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">()]</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(</span><span class="si">{</span><span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">info</span><span class="p">)</span><span class="si">}</span><span class="s2">, device=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2">)&quot;</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="torch_choice.data.choice_dataset.ChoiceDataset.apply_tensor" class="doc doc-heading">
<code class="highlight language-python"><span class="n">apply_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">func</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>This s a helper method to apply the provided function to all tensors and tensor values of all dictionaries.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>func</code></td>
        <td><code>callable</code></td>
        <td><p>a callable function to be applied on tensors and tensor-values of dictionaries.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>ChoiceDataset</code></td>
      <td><p>the modified dataset.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>torch_choice/data/choice_dataset.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">apply_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">func</span><span class="p">:</span> <span class="n">callable</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;ChoiceDataset&quot;</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;This s a helper method to apply the provided function to all tensors and tensor values of all dictionaries.</span>

<span class="sd">    Args:</span>
<span class="sd">        func (callable): a callable function to be applied on tensors and tensor-values of dictionaries.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ChoiceDataset: the modified dataset.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">item</span><span class="p">):</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">func</span><span class="p">(</span><span class="n">item</span><span class="p">))</span>
        <span class="c1"># boardcast func to dictionary of tensors as well.</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">),</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">obj_key</span><span class="p">,</span> <span class="n">obj_item</span> <span class="ow">in</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">obj_item</span><span class="p">):</span>
                    <span class="nb">setattr</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">),</span> <span class="n">obj_key</span><span class="p">,</span> <span class="n">func</span><span class="p">(</span><span class="n">obj_item</span><span class="p">))</span>
    <span class="k">return</span> <span class="bp">self</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="torch_choice.data.choice_dataset.ChoiceDataset.clone" class="doc doc-heading">
<code class="highlight language-python"><span class="n">clone</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>Creates a copy of self.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>ChoiceDataset</code></td>
      <td><p>a copy of self.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>torch_choice/data/choice_dataset.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">clone</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;ChoiceDataset&quot;</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Creates a copy of self.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ChoiceDataset: a copy of self.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dictionary</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
            <span class="n">dictionary</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dictionary</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="n">_from_dict</span><span class="p">(</span><span class="n">dictionary</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="torch_choice.data.choice_dataset.ChoiceDataset.to" class="doc doc-heading">
<code class="highlight language-python"><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>Moves all tensors in this dataset to the specified PyTorch device.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>device</code></td>
        <td><code>Union[str, torch.device]</code></td>
        <td><p>the destination device.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>ChoiceDataset</code></td>
      <td><p>the modified dataset on the new device.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>torch_choice/data/choice_dataset.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="s2">&quot;ChoiceDataset&quot;</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Moves all tensors in this dataset to the specified PyTorch device.</span>

<span class="sd">    Args:</span>
<span class="sd">        device (Union[str, torch.device]): the destination device.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ChoiceDataset: the modified dataset on the new device.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">apply_tensor</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>







  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h3 id="torch_choice.data.joint_dataset" class="doc doc-heading">
        <code>joint_dataset</code>



</h3>

    <div class="doc doc-contents ">

      <p>The JointDataset class is a wrapper for the torch.utils.data.ChoiceDataset class, it is particularly useful when we
need to make prediction from multiple datasets. For example, you have data on consumer purchase records in a fast food
store, and suppose every customer will purchase exactly a single main food and a single drink. In this case, you have
two separate datasets: FoodDataset and DrinkDataset. You may want to use PyTorch sampler to sample them in a dependent
manner: you want to take the i-th sample from both datasets, so that you know what (food, drink) combo the i-th customer
purchased. You can do this by using the JointDataset class.</p>
<p>Author: Tianyu Du
Update: Apr. 28, 2022</p>



  <div class="doc doc-children">







  <div class="doc doc-object doc-class">



<h4 id="torch_choice.data.joint_dataset.JointDataset" class="doc doc-heading">
        <code>
JointDataset            (<span title="torch.utils.data.dataset.Dataset">Dataset</span>)
        </code>



</h4>

    <div class="doc doc-contents ">

      <p>A helper class for joining several pytorch datasets, using JointDataset
and pytorch data loader allows for sampling the same batch index from several
datasets.</p>
<p>The JointDataset class is a wrapper for the torch.utils.data.ChoiceDataset class, it is particularly useful when we
need to make prediction from multiple datasets. For example, you have data on consumer purchase records in a fast food
store, and suppose every customer will purchase exactly a single main food and a single drink. In this case, you have
two separate datasets: FoodDataset and DrinkDataset. You may want to use PyTorch sampler to sample them in a dependent
manner: you want to take the i-th sample from both datasets, so that you know what (food, drink) combo the i-th customer
purchased. You can do this by using the JointDataset class.</p>

        <details class="quote">
          <summary>Source code in <code>torch_choice/data/joint_dataset.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">JointDataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A helper class for joining several pytorch datasets, using JointDataset</span>
<span class="sd">    and pytorch data loader allows for sampling the same batch index from several</span>
<span class="sd">    datasets.</span>

<span class="sd">    The JointDataset class is a wrapper for the torch.utils.data.ChoiceDataset class, it is particularly useful when we</span>
<span class="sd">    need to make prediction from multiple datasets. For example, you have data on consumer purchase records in a fast food</span>
<span class="sd">    store, and suppose every customer will purchase exactly a single main food and a single drink. In this case, you have</span>
<span class="sd">    two separate datasets: FoodDataset and DrinkDataset. You may want to use PyTorch sampler to sample them in a dependent</span>
<span class="sd">    manner: you want to take the i-th sample from both datasets, so that you know what (food, drink) combo the i-th customer</span>
<span class="sd">    purchased. You can do this by using the JointDataset class.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">datasets</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;The initialize methods.</span>

<span class="sd">        Args:</span>
<span class="sd">            Arbitrarily many datasets with arbitrary names as keys. In the example above, you can construct</span>
<span class="sd">            ```</span>
<span class="sd">            dataset = JointDataset(food=FoodDataset, drink=DrinkDataset)</span>
<span class="sd">            ```</span>
<span class="sd">            All datasets should have the same length.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">JointDataset</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span> <span class="o">=</span> <span class="n">datasets</span>
        <span class="c1"># check the length of sub-datasets are the same.</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">d</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">values</span><span class="p">()]))</span> <span class="o">==</span> <span class="mi">1</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Get the number of samples in the joint dataset.</span>

<span class="sd">        Returns:</span>
<span class="sd">            int: the number of samples in the joint dataset, which is the same as the number of samples in each dataset contained.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ChoiceDataset</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Queries samples from the dataset by index.</span>

<span class="sd">        Args:</span>
<span class="sd">            indices (Union[int, torch.LongTensor]): an integer or a 1D tensor of multiple indices.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dict[str, ChoiceDataset]: the subset of the dataset. Keys of the dictionary will be names of each dataset</span>
<span class="sd">                contained (the same as the keys of the ``datasets`` argument in the constructor). Values will be subsets</span>
<span class="sd">                of contained datasets, sliced using the provided indices.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">((</span><span class="n">name</span><span class="p">,</span> <span class="n">d</span><span class="p">[</span><span class="n">indices</span><span class="p">])</span> <span class="k">for</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;A method to get a string representation of the dataset.</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: the string representation of the dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">out</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;JointDataset with </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">)</span><span class="si">}</span><span class="s1"> sub-datasets: (&#39;</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\t</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;)&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns the device of datasets contained in the joint dataset.</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: the device of the dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="k">return</span> <span class="n">d</span><span class="o">.</span><span class="n">device</span>

    <span class="k">def</span> <span class="nf">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="s2">&quot;JointDataset&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Moves all datasets in this dataset to the specified PyTorch device.</span>

<span class="sd">        Args:</span>
<span class="sd">            device (Union[str, torch.device]): the destination device.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ChoiceDataset: the modified dataset on the new device.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="n">d</span> <span class="o">=</span> <span class="n">d</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">






  <div class="doc doc-object doc-attribute">



<h5 id="torch_choice.data.joint_dataset.JointDataset.device" class="doc doc-heading">
<code class="highlight language-python"><span class="n">device</span><span class="p">:</span> <span class="nb">str</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

</h5>

    <div class="doc doc-contents ">

      <p>Returns the device of datasets contained in the joint dataset.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>str</code></td>
      <td><p>the device of the dataset.</p></td>
    </tr>
  </tbody>
</table>    </div>

  </div>






  <div class="doc doc-object doc-method">



<h5 id="torch_choice.data.joint_dataset.JointDataset.__getitem__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h5>

    <div class="doc doc-contents ">

      <p>Queries samples from the dataset by index.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>indices</code></td>
        <td><code>Union[int, torch.LongTensor]</code></td>
        <td><p>an integer or a 1D tensor of multiple indices.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Dict[str, ChoiceDataset]</code></td>
      <td><p>the subset of the dataset. Keys of the dictionary will be names of each dataset
    contained (the same as the keys of the <code>datasets</code> argument in the constructor). Values will be subsets
    of contained datasets, sliced using the provided indices.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>torch_choice/data/joint_dataset.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ChoiceDataset</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;Queries samples from the dataset by index.</span>

<span class="sd">    Args:</span>
<span class="sd">        indices (Union[int, torch.LongTensor]): an integer or a 1D tensor of multiple indices.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dict[str, ChoiceDataset]: the subset of the dataset. Keys of the dictionary will be names of each dataset</span>
<span class="sd">            contained (the same as the keys of the ``datasets`` argument in the constructor). Values will be subsets</span>
<span class="sd">            of contained datasets, sliced using the provided indices.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">dict</span><span class="p">((</span><span class="n">name</span><span class="p">,</span> <span class="n">d</span><span class="p">[</span><span class="n">indices</span><span class="p">])</span> <span class="k">for</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="torch_choice.data.joint_dataset.JointDataset.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">datasets</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h5>

    <div class="doc doc-contents ">

      <p>The initialize methods.</p>

        <details class="quote">
          <summary>Source code in <code>torch_choice/data/joint_dataset.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">datasets</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;The initialize methods.</span>

<span class="sd">    Args:</span>
<span class="sd">        Arbitrarily many datasets with arbitrary names as keys. In the example above, you can construct</span>
<span class="sd">        ```</span>
<span class="sd">        dataset = JointDataset(food=FoodDataset, drink=DrinkDataset)</span>
<span class="sd">        ```</span>
<span class="sd">        All datasets should have the same length.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">JointDataset</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span> <span class="o">=</span> <span class="n">datasets</span>
    <span class="c1"># check the length of sub-datasets are the same.</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">d</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">values</span><span class="p">()]))</span> <span class="o">==</span> <span class="mi">1</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="torch_choice.data.joint_dataset.JointDataset.__len__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h5>

    <div class="doc doc-contents ">

      <p>Get the number of samples in the joint dataset.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>int</code></td>
      <td><p>the number of samples in the joint dataset, which is the same as the number of samples in each dataset contained.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>torch_choice/data/joint_dataset.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Get the number of samples in the joint dataset.</span>

<span class="sd">    Returns:</span>
<span class="sd">        int: the number of samples in the joint dataset, which is the same as the number of samples in each dataset contained.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="torch_choice.data.joint_dataset.JointDataset.__repr__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h5>

    <div class="doc doc-contents ">

      <p>A method to get a string representation of the dataset.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>str</code></td>
      <td><p>the string representation of the dataset.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>torch_choice/data/joint_dataset.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;A method to get a string representation of the dataset.</span>

<span class="sd">    Returns:</span>
<span class="sd">        str: the string representation of the dataset.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">out</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;JointDataset with </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">)</span><span class="si">}</span><span class="s1"> sub-datasets: (&#39;</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\t</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;)&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="torch_choice.data.joint_dataset.JointDataset.to" class="doc doc-heading">
<code class="highlight language-python"><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>Moves all datasets in this dataset to the specified PyTorch device.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>device</code></td>
        <td><code>Union[str, torch.device]</code></td>
        <td><p>the destination device.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>ChoiceDataset</code></td>
      <td><p>the modified dataset on the new device.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>torch_choice/data/joint_dataset.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="s2">&quot;JointDataset&quot;</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Moves all datasets in this dataset to the specified PyTorch device.</span>

<span class="sd">    Args:</span>
<span class="sd">        device (Union[str, torch.device]): the destination device.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ChoiceDataset: the modified dataset on the new device.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
        <span class="n">d</span> <span class="o">=</span> <span class="n">d</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>







  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h3 id="torch_choice.data.utils" class="doc doc-heading">
        <code>utils</code>



</h3>

    <div class="doc doc-contents ">




  <div class="doc doc-children">









  <div class="doc doc-object doc-function">



<h4 id="torch_choice.data.utils.pivot3d" class="doc doc-heading">
<code class="highlight language-python"><span class="n">pivot3d</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">dim0</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span></code>


</h4>

    <div class="doc doc-contents ">

      <p>Creates a tensor of shape (df[dim0].nunique(), df[dim1].nunique(), len(values)) from the
provided data frame.</p>
<p>Example, if dim0 is the column of session ID, dim1 is the column of alternative names, then
    out[t, i, k] is the feature values[k] of item i in session t. The returned tensor
    has shape (num_sessions, num_items, num_params), which fits the purpose of conditioanl
    logit models.</p>

        <details class="quote">
          <summary>Source code in <code>torch_choice/data/utils.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">pivot3d</span><span class="p">(</span><span class="n">df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">dim0</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">dim1</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">values</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Creates a tensor of shape (df[dim0].nunique(), df[dim1].nunique(), len(values)) from the</span>
<span class="sd">    provided data frame.</span>

<span class="sd">    Example, if dim0 is the column of session ID, dim1 is the column of alternative names, then</span>
<span class="sd">        out[t, i, k] is the feature values[k] of item i in session t. The returned tensor</span>
<span class="sd">        has shape (num_sessions, num_items, num_params), which fits the purpose of conditioanl</span>
<span class="sd">        logit models.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">values</span> <span class="o">=</span> <span class="p">[</span><span class="n">values</span><span class="p">]</span>

    <span class="n">dim1_list</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">dim1</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>

    <span class="n">tensor_slice</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">values</span><span class="p">:</span>
        <span class="n">layer</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">pivot</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">dim0</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">dim1</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>
        <span class="n">tensor_slice</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">layer</span><span class="p">[</span><span class="n">dim1_list</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">))</span>

    <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">tensor_slice</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">dim0</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">(),</span> <span class="n">df</span><span class="p">[</span><span class="n">dim1</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">(),</span> <span class="nb">len</span><span class="p">(</span><span class="n">values</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">tensor</span>
</code></pre></div>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>




  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="torch_choice.model" class="doc doc-heading">
        <code>model</code>


  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h2>

    <div class="doc doc-contents ">




  <div class="doc doc-children">










  <div class="doc doc-object doc-module">



<h3 id="torch_choice.model.coefficient" class="doc doc-heading">
        <code>coefficient</code>



</h3>

    <div class="doc doc-contents ">

      <p>The general class of learnable coefficients in various models, this class serves as the building blocks for models in this package.
The weights (i.e., learnable parameters) in the Coefficient class are implemented using PyTorch and can be trained
directly using optimizers from PyTorch.</p>
<p>NOTE: torch-choice package users don't interact with classes in this file directly, please use conditional_logit_model.py
and nested_logit_model.py instead.</p>
<p>Author: Tianyu Du
Update: Apr. 28, 2022</p>



  <div class="doc doc-children">







  <div class="doc doc-object doc-class">



<h4 id="torch_choice.model.coefficient.Coefficient" class="doc doc-heading">
        <code>
Coefficient            (<span title="torch.nn.modules.module.Module">Module</span>)
        </code>



</h4>

    <div class="doc doc-contents ">


        <details class="quote">
          <summary>Source code in <code>torch_choice/model/coefficient.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">Coefficient</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">variation</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
                 <span class="n">num_params</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                 <span class="n">num_items</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">num_users</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span>
                 <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;A generic coefficient object storing trainable parameters. This class corresponds to those variables typically</span>
<span class="sd">        in Greek letters in the model&#39;s utility representation.</span>

<span class="sd">        Args:</span>
<span class="sd">            variation (str): the degree of variation of this coefficient. For example, the coefficient can vary by users or items.</span>
<span class="sd">                Currently, we support variations &#39;constant&#39;, &#39;item&#39;, &#39;item-full&#39;, &#39;user&#39;, &#39;user-item&#39;, &#39;user-item-full&#39;.</span>
<span class="sd">                For detailed explanation of these variations, please refer to the documentation of ConditionalLogitModel.</span>
<span class="sd">            num_params (int): number of parameters in this coefficient. Note that this number is the number of parameters</span>
<span class="sd">                per class, not the total number of parameters. For example, suppose we have U users and you want to initiate</span>
<span class="sd">                an user-specific coefficient called `theta_user`. The coefficient enters the utility form while being multiplied</span>
<span class="sd">                with some K-dimension observables. Then, for each user, there are K parameters to be multiplied with the K-dimensional</span>
<span class="sd">                observable. However, the total number of parameters is K * U (K for each of U users). In this case, `num_params` should</span>
<span class="sd">                be set to `K`, NOT `K*U`.</span>
<span class="sd">            num_items (int): the number of items in the prediction problem, this is required to reshape the parameter correctly.</span>
<span class="sd">            num_users (Optional[int], optional): number of users, this is only necessary if the coefficient varies by users.</span>
<span class="sd">                Defaults to None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Coefficient</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">variation</span> <span class="o">=</span> <span class="n">variation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span> <span class="o">=</span> <span class="n">num_items</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_users</span> <span class="o">=</span> <span class="n">num_users</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_params</span> <span class="o">=</span> <span class="n">num_params</span>

        <span class="c1"># construct the trainable.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">variation</span> <span class="o">==</span> <span class="s1">&#39;constant&#39;</span><span class="p">:</span>
            <span class="c1"># constant for all users and items.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coef</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">num_params</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">variation</span> <span class="o">==</span> <span class="s1">&#39;item&#39;</span><span class="p">:</span>
            <span class="c1"># coef depends on item j but not on user i.</span>
            <span class="c1"># force coefficients for the first item class to be zero.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coef</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_items</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_params</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">variation</span> <span class="o">==</span> <span class="s1">&#39;item-full&#39;</span><span class="p">:</span>
            <span class="c1"># coef depends on item j but not on user i.</span>
            <span class="c1"># model coefficient for every item.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coef</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_items</span><span class="p">,</span> <span class="n">num_params</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">variation</span> <span class="o">==</span> <span class="s1">&#39;user&#39;</span><span class="p">:</span>
            <span class="c1"># coef depends on the user.</span>
            <span class="c1"># we always model coefficient for all users.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coef</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_users</span><span class="p">,</span> <span class="n">num_params</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">variation</span> <span class="o">==</span> <span class="s1">&#39;user-item&#39;</span><span class="p">:</span>
            <span class="c1"># coefficients of the first item is forced to be zero, model coefficients for N - 1 items only.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coef</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_users</span><span class="p">,</span> <span class="n">num_items</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_params</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">variation</span> <span class="o">==</span> <span class="s1">&#39;user-item-full&#39;</span><span class="p">:</span>
            <span class="c1"># construct coefficients for every items.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coef</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_users</span><span class="p">,</span> <span class="n">num_items</span><span class="p">,</span> <span class="n">num_params</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Unsupported type of variation: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">variation</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns a string representation of the coefficient.</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: the string representation of the coefficient.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s1">&#39;Coefficient(variation=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">variation</span><span class="si">}</span><span class="s1">, num_items=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="si">}</span><span class="s1">,&#39;</span> \
               <span class="o">+</span> <span class="sa">f</span><span class="s1">&#39; num_users=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_users</span><span class="si">}</span><span class="s1">, num_params=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_params</span><span class="si">}</span><span class="s1">,&#39;</span> \
               <span class="o">+</span> <span class="sa">f</span><span class="s1">&#39; </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">coef</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span><span class="si">}</span><span class="s1"> trainable parameters in total).&#39;</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                <span class="n">user_index</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">manual_coef_value</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span>
                <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The forward function of the coefficient, which computes the utility from purchasing each item in each session.</span>
<span class="sd">        The output shape will be (num_sessions, num_items).</span>

<span class="sd">        Args:</span>
<span class="sd">            x (torch.Tensor): a tensor of shape (num_sessions, num_items, num_params). Please note that the Coefficient</span>
<span class="sd">                class will NOT reshape input tensors itself, this reshaping needs to be done in the model class.</span>
<span class="sd">            user_index (Optional[torch.Tensor], optional): a tensor of shape (num_sessions,)</span>
<span class="sd">                contain IDs of the user involved in that session. If set to None, assume the same</span>
<span class="sd">                user is making all decisions.</span>
<span class="sd">                Defaults to None.</span>
<span class="sd">            manual_coef_value (Optional[torch.Tensor], optional): a tensor with the same number of</span>
<span class="sd">                entries as self.coef. If provided, the forward function uses provided values</span>
<span class="sd">                as coefficient and return the predicted utility, this feature is useful when</span>
<span class="sd">                the researcher wishes to manually specify values for coefficients and examine prediction</span>
<span class="sd">                with specified coefficient values. If not provided, forward function is executed</span>
<span class="sd">                using values from self.coef.</span>
<span class="sd">                Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: a tensor of shape (num_sessions, num_items) whose (t, i) entry represents</span>
<span class="sd">                the utility of purchasing item i in session t.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">manual_coef_value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">manual_coef_value</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
            <span class="c1"># plugin the provided coefficient values, coef is a tensor.</span>
            <span class="n">coef</span> <span class="o">=</span> <span class="n">manual_coef_value</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">coef</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># use the learned coefficient values, coef is a nn.Parameter.</span>
            <span class="n">coef</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef</span>

        <span class="n">num_trips</span><span class="p">,</span> <span class="n">num_items</span><span class="p">,</span> <span class="n">num_feats</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_params</span> <span class="o">==</span> <span class="n">num_feats</span>

        <span class="c1"># cast coefficient tensor to (num_trips, num_items, self.num_params).</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">variation</span> <span class="o">==</span> <span class="s1">&#39;constant&#39;</span><span class="p">:</span>
            <span class="n">coef</span> <span class="o">=</span> <span class="n">coef</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_params</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">num_trips</span><span class="p">,</span> <span class="n">num_items</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">variation</span> <span class="o">==</span> <span class="s1">&#39;item&#39;</span><span class="p">:</span>
            <span class="c1"># coef has shape (num_items-1, num_params)</span>
            <span class="c1"># force coefficient for the first item to be zero.</span>
            <span class="n">zeros</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_params</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">coef</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">coef</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">zeros</span><span class="p">,</span> <span class="n">coef</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># (num_items, num_params)</span>
            <span class="n">coef</span> <span class="o">=</span> <span class="n">coef</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_params</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">num_trips</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">variation</span> <span class="o">==</span> <span class="s1">&#39;item-full&#39;</span><span class="p">:</span>
            <span class="c1"># coef has shape (num_items, num_params)</span>
            <span class="n">coef</span> <span class="o">=</span> <span class="n">coef</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_params</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">num_trips</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">variation</span> <span class="o">==</span> <span class="s1">&#39;user&#39;</span><span class="p">:</span>
            <span class="c1"># coef has shape (num_users, num_params)</span>
            <span class="n">coef</span> <span class="o">=</span> <span class="n">coef</span><span class="p">[</span><span class="n">user_index</span><span class="p">,</span> <span class="p">:]</span>  <span class="c1"># (num_trips, num_params) user-specific coefficients.</span>
            <span class="n">coef</span> <span class="o">=</span> <span class="n">coef</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">num_trips</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_params</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_items</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">variation</span> <span class="o">==</span> <span class="s1">&#39;user-item&#39;</span><span class="p">:</span>
            <span class="c1"># (num_trips,) long tensor of user ID.</span>
            <span class="c1"># originally, coef has shape (num_users, num_items-1, num_params)</span>
            <span class="c1"># transform to (num_trips, num_items - 1, num_params), user-specific.</span>
            <span class="n">coef</span> <span class="o">=</span> <span class="n">coef</span><span class="p">[</span><span class="n">user_index</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
            <span class="c1"># coefs for the first item for all users are enforced to 0.</span>
            <span class="n">zeros</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_trips</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_params</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">coef</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">coef</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">zeros</span><span class="p">,</span> <span class="n">coef</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (num_trips, num_items, num_params)</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">variation</span> <span class="o">==</span> <span class="s1">&#39;user-item-full&#39;</span><span class="p">:</span>
            <span class="c1"># originally, coef has shape (num_users, num_items, num_params)</span>
            <span class="n">coef</span> <span class="o">=</span> <span class="n">coef</span><span class="p">[</span><span class="n">user_index</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>  <span class="c1"># (num_trips, num_items, num_params)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Unsupported type of variation: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">variation</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span>

        <span class="k">assert</span> <span class="n">coef</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_trips</span><span class="p">,</span> <span class="n">num_items</span><span class="p">,</span> <span class="n">num_feats</span><span class="p">)</span> <span class="o">==</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>

        <span class="c1"># compute the utility of each item in each trip, take summation along the feature dimension, the same as taking</span>
        <span class="c1"># the inner product.</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">coef</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">









  <div class="doc doc-object doc-method">



<h5 id="torch_choice.model.coefficient.Coefficient.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variation</span><span class="p">,</span> <span class="n">num_params</span><span class="p">,</span> <span class="n">num_items</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_users</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h5>

    <div class="doc doc-contents ">

      <p>A generic coefficient object storing trainable parameters. This class corresponds to those variables typically
in Greek letters in the model's utility representation.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>variation</code></td>
        <td><code>str</code></td>
        <td><p>the degree of variation of this coefficient. For example, the coefficient can vary by users or items.
Currently, we support variations 'constant', 'item', 'item-full', 'user', 'user-item', 'user-item-full'.
For detailed explanation of these variations, please refer to the documentation of ConditionalLogitModel.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>num_params</code></td>
        <td><code>int</code></td>
        <td><p>number of parameters in this coefficient. Note that this number is the number of parameters
per class, not the total number of parameters. For example, suppose we have U users and you want to initiate
an user-specific coefficient called <code>theta_user</code>. The coefficient enters the utility form while being multiplied
with some K-dimension observables. Then, for each user, there are K parameters to be multiplied with the K-dimensional
observable. However, the total number of parameters is K * U (K for each of U users). In this case, <code>num_params</code> should
be set to <code>K</code>, NOT <code>K*U</code>.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>num_items</code></td>
        <td><code>int</code></td>
        <td><p>the number of items in the prediction problem, this is required to reshape the parameter correctly.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>num_users</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>number of users, this is only necessary if the coefficient varies by users.
Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>torch_choice/model/coefficient.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
             <span class="n">variation</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
             <span class="n">num_params</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
             <span class="n">num_items</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
             <span class="n">num_users</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span>
             <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;A generic coefficient object storing trainable parameters. This class corresponds to those variables typically</span>
<span class="sd">    in Greek letters in the model&#39;s utility representation.</span>

<span class="sd">    Args:</span>
<span class="sd">        variation (str): the degree of variation of this coefficient. For example, the coefficient can vary by users or items.</span>
<span class="sd">            Currently, we support variations &#39;constant&#39;, &#39;item&#39;, &#39;item-full&#39;, &#39;user&#39;, &#39;user-item&#39;, &#39;user-item-full&#39;.</span>
<span class="sd">            For detailed explanation of these variations, please refer to the documentation of ConditionalLogitModel.</span>
<span class="sd">        num_params (int): number of parameters in this coefficient. Note that this number is the number of parameters</span>
<span class="sd">            per class, not the total number of parameters. For example, suppose we have U users and you want to initiate</span>
<span class="sd">            an user-specific coefficient called `theta_user`. The coefficient enters the utility form while being multiplied</span>
<span class="sd">            with some K-dimension observables. Then, for each user, there are K parameters to be multiplied with the K-dimensional</span>
<span class="sd">            observable. However, the total number of parameters is K * U (K for each of U users). In this case, `num_params` should</span>
<span class="sd">            be set to `K`, NOT `K*U`.</span>
<span class="sd">        num_items (int): the number of items in the prediction problem, this is required to reshape the parameter correctly.</span>
<span class="sd">        num_users (Optional[int], optional): number of users, this is only necessary if the coefficient varies by users.</span>
<span class="sd">            Defaults to None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Coefficient</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">variation</span> <span class="o">=</span> <span class="n">variation</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span> <span class="o">=</span> <span class="n">num_items</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_users</span> <span class="o">=</span> <span class="n">num_users</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_params</span> <span class="o">=</span> <span class="n">num_params</span>

    <span class="c1"># construct the trainable.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">variation</span> <span class="o">==</span> <span class="s1">&#39;constant&#39;</span><span class="p">:</span>
        <span class="c1"># constant for all users and items.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coef</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">num_params</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">variation</span> <span class="o">==</span> <span class="s1">&#39;item&#39;</span><span class="p">:</span>
        <span class="c1"># coef depends on item j but not on user i.</span>
        <span class="c1"># force coefficients for the first item class to be zero.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coef</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_items</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_params</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">variation</span> <span class="o">==</span> <span class="s1">&#39;item-full&#39;</span><span class="p">:</span>
        <span class="c1"># coef depends on item j but not on user i.</span>
        <span class="c1"># model coefficient for every item.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coef</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_items</span><span class="p">,</span> <span class="n">num_params</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">variation</span> <span class="o">==</span> <span class="s1">&#39;user&#39;</span><span class="p">:</span>
        <span class="c1"># coef depends on the user.</span>
        <span class="c1"># we always model coefficient for all users.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coef</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_users</span><span class="p">,</span> <span class="n">num_params</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">variation</span> <span class="o">==</span> <span class="s1">&#39;user-item&#39;</span><span class="p">:</span>
        <span class="c1"># coefficients of the first item is forced to be zero, model coefficients for N - 1 items only.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coef</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_users</span><span class="p">,</span> <span class="n">num_items</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_params</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">variation</span> <span class="o">==</span> <span class="s1">&#39;user-item-full&#39;</span><span class="p">:</span>
        <span class="c1"># construct coefficients for every items.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coef</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_users</span><span class="p">,</span> <span class="n">num_items</span><span class="p">,</span> <span class="n">num_params</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Unsupported type of variation: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">variation</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="torch_choice.model.coefficient.Coefficient.__repr__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h5>

    <div class="doc doc-contents ">

      <p>Returns a string representation of the coefficient.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>str</code></td>
      <td><p>the string representation of the coefficient.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>torch_choice/model/coefficient.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Returns a string representation of the coefficient.</span>

<span class="sd">    Returns:</span>
<span class="sd">        str: the string representation of the coefficient.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s1">&#39;Coefficient(variation=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">variation</span><span class="si">}</span><span class="s1">, num_items=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="si">}</span><span class="s1">,&#39;</span> \
           <span class="o">+</span> <span class="sa">f</span><span class="s1">&#39; num_users=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_users</span><span class="si">}</span><span class="s1">, num_params=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_params</span><span class="si">}</span><span class="s1">,&#39;</span> \
           <span class="o">+</span> <span class="sa">f</span><span class="s1">&#39; </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">coef</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span><span class="si">}</span><span class="s1"> trainable parameters in total).&#39;</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="torch_choice.model.coefficient.Coefficient.forward" class="doc doc-heading">
<code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">user_index</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">manual_coef_value</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>The forward function of the coefficient, which computes the utility from purchasing each item in each session.
The output shape will be (num_sessions, num_items).</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>x</code></td>
        <td><code>torch.Tensor</code></td>
        <td><p>a tensor of shape (num_sessions, num_items, num_params). Please note that the Coefficient
class will NOT reshape input tensors itself, this reshaping needs to be done in the model class.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>user_index</code></td>
        <td><code>Optional[torch.Tensor]</code></td>
        <td><p>a tensor of shape (num_sessions,)
contain IDs of the user involved in that session. If set to None, assume the same
user is making all decisions.
Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>manual_coef_value</code></td>
        <td><code>Optional[torch.Tensor]</code></td>
        <td><p>a tensor with the same number of
entries as self.coef. If provided, the forward function uses provided values
as coefficient and return the predicted utility, this feature is useful when
the researcher wishes to manually specify values for coefficients and examine prediction
with specified coefficient values. If not provided, forward function is executed
using values from self.coef.
Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>torch.Tensor</code></td>
      <td><p>a tensor of shape (num_sessions, num_items) whose (t, i) entry represents
    the utility of purchasing item i in session t.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>torch_choice/model/coefficient.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
            <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
            <span class="n">user_index</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">manual_coef_value</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span>
            <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The forward function of the coefficient, which computes the utility from purchasing each item in each session.</span>
<span class="sd">    The output shape will be (num_sessions, num_items).</span>

<span class="sd">    Args:</span>
<span class="sd">        x (torch.Tensor): a tensor of shape (num_sessions, num_items, num_params). Please note that the Coefficient</span>
<span class="sd">            class will NOT reshape input tensors itself, this reshaping needs to be done in the model class.</span>
<span class="sd">        user_index (Optional[torch.Tensor], optional): a tensor of shape (num_sessions,)</span>
<span class="sd">            contain IDs of the user involved in that session. If set to None, assume the same</span>
<span class="sd">            user is making all decisions.</span>
<span class="sd">            Defaults to None.</span>
<span class="sd">        manual_coef_value (Optional[torch.Tensor], optional): a tensor with the same number of</span>
<span class="sd">            entries as self.coef. If provided, the forward function uses provided values</span>
<span class="sd">            as coefficient and return the predicted utility, this feature is useful when</span>
<span class="sd">            the researcher wishes to manually specify values for coefficients and examine prediction</span>
<span class="sd">            with specified coefficient values. If not provided, forward function is executed</span>
<span class="sd">            using values from self.coef.</span>
<span class="sd">            Defaults to None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: a tensor of shape (num_sessions, num_items) whose (t, i) entry represents</span>
<span class="sd">            the utility of purchasing item i in session t.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">manual_coef_value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">manual_coef_value</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
        <span class="c1"># plugin the provided coefficient values, coef is a tensor.</span>
        <span class="n">coef</span> <span class="o">=</span> <span class="n">manual_coef_value</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">coef</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># use the learned coefficient values, coef is a nn.Parameter.</span>
        <span class="n">coef</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef</span>

    <span class="n">num_trips</span><span class="p">,</span> <span class="n">num_items</span><span class="p">,</span> <span class="n">num_feats</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_params</span> <span class="o">==</span> <span class="n">num_feats</span>

    <span class="c1"># cast coefficient tensor to (num_trips, num_items, self.num_params).</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">variation</span> <span class="o">==</span> <span class="s1">&#39;constant&#39;</span><span class="p">:</span>
        <span class="n">coef</span> <span class="o">=</span> <span class="n">coef</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_params</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">num_trips</span><span class="p">,</span> <span class="n">num_items</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">variation</span> <span class="o">==</span> <span class="s1">&#39;item&#39;</span><span class="p">:</span>
        <span class="c1"># coef has shape (num_items-1, num_params)</span>
        <span class="c1"># force coefficient for the first item to be zero.</span>
        <span class="n">zeros</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_params</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">coef</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">coef</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">zeros</span><span class="p">,</span> <span class="n">coef</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># (num_items, num_params)</span>
        <span class="n">coef</span> <span class="o">=</span> <span class="n">coef</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_params</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">num_trips</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">variation</span> <span class="o">==</span> <span class="s1">&#39;item-full&#39;</span><span class="p">:</span>
        <span class="c1"># coef has shape (num_items, num_params)</span>
        <span class="n">coef</span> <span class="o">=</span> <span class="n">coef</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_params</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">num_trips</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">variation</span> <span class="o">==</span> <span class="s1">&#39;user&#39;</span><span class="p">:</span>
        <span class="c1"># coef has shape (num_users, num_params)</span>
        <span class="n">coef</span> <span class="o">=</span> <span class="n">coef</span><span class="p">[</span><span class="n">user_index</span><span class="p">,</span> <span class="p">:]</span>  <span class="c1"># (num_trips, num_params) user-specific coefficients.</span>
        <span class="n">coef</span> <span class="o">=</span> <span class="n">coef</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">num_trips</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_params</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_items</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">variation</span> <span class="o">==</span> <span class="s1">&#39;user-item&#39;</span><span class="p">:</span>
        <span class="c1"># (num_trips,) long tensor of user ID.</span>
        <span class="c1"># originally, coef has shape (num_users, num_items-1, num_params)</span>
        <span class="c1"># transform to (num_trips, num_items - 1, num_params), user-specific.</span>
        <span class="n">coef</span> <span class="o">=</span> <span class="n">coef</span><span class="p">[</span><span class="n">user_index</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
        <span class="c1"># coefs for the first item for all users are enforced to 0.</span>
        <span class="n">zeros</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_trips</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_params</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">coef</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">coef</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">zeros</span><span class="p">,</span> <span class="n">coef</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (num_trips, num_items, num_params)</span>

    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">variation</span> <span class="o">==</span> <span class="s1">&#39;user-item-full&#39;</span><span class="p">:</span>
        <span class="c1"># originally, coef has shape (num_users, num_items, num_params)</span>
        <span class="n">coef</span> <span class="o">=</span> <span class="n">coef</span><span class="p">[</span><span class="n">user_index</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>  <span class="c1"># (num_trips, num_items, num_params)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Unsupported type of variation: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">variation</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span>

    <span class="k">assert</span> <span class="n">coef</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_trips</span><span class="p">,</span> <span class="n">num_items</span><span class="p">,</span> <span class="n">num_feats</span><span class="p">)</span> <span class="o">==</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>

    <span class="c1"># compute the utility of each item in each trip, take summation along the feature dimension, the same as taking</span>
    <span class="c1"># the inner product.</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">coef</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>







  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h3 id="torch_choice.model.conditional_logit_model" class="doc doc-heading">
        <code>conditional_logit_model</code>



</h3>

    <div class="doc doc-contents ">

      <p>Conditional Logit Model.</p>
<p>Author: Tianyu Du
Date: Aug. 8, 2021
Update: Apr. 28, 2022</p>



  <div class="doc doc-children">







  <div class="doc doc-object doc-class">



<h4 id="torch_choice.model.conditional_logit_model.ConditionalLogitModel" class="doc doc-heading">
        <code>
ConditionalLogitModel            (<span title="torch.nn.modules.module.Module">Module</span>)
        </code>



</h4>

    <div class="doc doc-contents ">

      <p>The more generalized version of conditional logit model, the model allows for research specific
variable types(groups) and different levels of variations for coefficient.</p>
<p>The model allows for the following levels for variable variations:
!!! note "unless the <code>-full</code> flag is specified (which means we want to explicitly model coefficients"
    for all items), for all variation levels related to item (item specific and user-item specific),
    the model force coefficients for the first item to be zero. This design follows standard
    econometric practice.</p>
<ul>
<li>
<p>constant: constant over all users and items,</p>
</li>
<li>
<p>user: user-specific parameters but constant across all items,</p>
</li>
<li>
<p>item: item-specific parameters but constant across all users, parameters for the first item are
    forced to be zero.</p>
</li>
<li>
<p>item-full: item-specific parameters but constant across all users, explicitly model for all items.</p>
</li>
<li>
<p>user-item: parameters that are specific to both user and item, parameter for the first item
    for all users are forced to be zero.</p>
</li>
<li>user-item-full: parameters that are specific to both user and item, explicitly model for all items.</li>
</ul>

        <details class="quote">
          <summary>Source code in <code>torch_choice/model/conditional_logit_model.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">ConditionalLogitModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The more generalized version of conditional logit model, the model allows for research specific</span>
<span class="sd">    variable types(groups) and different levels of variations for coefficient.</span>

<span class="sd">    The model allows for the following levels for variable variations:</span>
<span class="sd">    NOTE: unless the `-full` flag is specified (which means we want to explicitly model coefficients</span>
<span class="sd">        for all items), for all variation levels related to item (item specific and user-item specific),</span>
<span class="sd">        the model force coefficients for the first item to be zero. This design follows standard</span>
<span class="sd">        econometric practice.</span>

<span class="sd">    - constant: constant over all users and items,</span>

<span class="sd">    - user: user-specific parameters but constant across all items,</span>

<span class="sd">    - item: item-specific parameters but constant across all users, parameters for the first item are</span>
<span class="sd">        forced to be zero.</span>
<span class="sd">    - item-full: item-specific parameters but constant across all users, explicitly model for all items.</span>

<span class="sd">    - user-item: parameters that are specific to both user and item, parameter for the first item</span>
<span class="sd">        for all users are forced to be zero.</span>
<span class="sd">    - user-item-full: parameters that are specific to both user and item, explicitly model for all items.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">coef_variation_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span>
                 <span class="n">num_param_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
                 <span class="n">num_items</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">num_users</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span>
                 <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            num_items (int): number of items in the dataset.</span>
<span class="sd">            num_users (int): number of users in the dataset.</span>
<span class="sd">            coef_variation_dict (Dict[str, str]): variable type to variation level dictionary. Keys of this dictionary</span>
<span class="sd">                should be variable names in the dataset (i.e., these starting with `price_`, `user_`, etc), or `intercept`</span>
<span class="sd">                if the researcher requires an intercept term.</span>
<span class="sd">                For each variable name X_var (e.g., `user_income`) or `intercept`, the corresponding dictionary key should</span>
<span class="sd">                be one of the following values, this value specifies the &quot;level of variation&quot; of the coefficient.</span>

<span class="sd">                - `constant`: the coefficient constant over all users and items: $X \beta$.</span>

<span class="sd">                - `user`: user-specific parameters but constant across all items: $X \beta_{u}$.</span>

<span class="sd">                - `item`: item-specific parameters but constant across all users, $X \beta_{i}$.</span>
<span class="sd">                    Note that the coefficients for the first item are forced to be zero following the standard practice</span>
<span class="sd">                    in econometrics.</span>

<span class="sd">                - `item-full`: the same configuration as `item`, but does not force the coefficients of the first item to</span>
<span class="sd">                    be zeros.</span>

<span class="sd">                The following configurations are supported by the package, but we don&#39;t recommend using them due to the</span>
<span class="sd">                    large number of parameters.</span>
<span class="sd">                - `user-item`: parameters that are specific to both user and item, parameter for the first item</span>
<span class="sd">                    for all users are forced to be zero.</span>

<span class="sd">                - `user-item-full`: parameters that are specific to both user and item, explicitly model for all items.</span>

<span class="sd">            num_param_dict (Dict[str, int]): variable type to number of parameters dictionary with keys exactly the same</span>
<span class="sd">                as the `coef_variation_dict`. Values of `num_param_dict` records numbers of features in each kind of variable.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ConditionalLogitModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="k">assert</span> <span class="n">coef_variation_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="o">==</span> <span class="n">num_param_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">variable_types</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">num_param_dict</span><span class="p">)</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">coef_variation_dict</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">coef_variation_dict</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_param_dict</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">num_param_dict</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span> <span class="o">=</span> <span class="n">num_items</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_users</span> <span class="o">=</span> <span class="n">num_users</span>

        <span class="c1"># check number of parameters specified are all positive.</span>
        <span class="k">for</span> <span class="n">var_type</span><span class="p">,</span> <span class="n">num_params</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_param_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">assert</span> <span class="n">num_params</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;num_params needs to be positive, got: </span><span class="si">{</span><span class="n">num_params</span><span class="si">}</span><span class="s1">.&#39;</span>

        <span class="c1"># infer the number of parameters for intercept if the researcher forgets.</span>
        <span class="k">if</span> <span class="s1">&#39;intercept&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_variation_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="ow">and</span> <span class="s1">&#39;intercept&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_param_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;&#39;intercept&#39; key found in coef_variation_dict but not in num_param_dict, num_param_dict[&#39;intercept&#39;] has been set to 1.&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_param_dict</span><span class="p">[</span><span class="s1">&#39;intercept&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="c1"># construct trainable parameters.</span>
        <span class="n">coef_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">var_type</span><span class="p">,</span> <span class="n">variation</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_variation_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">coef_dict</span><span class="p">[</span><span class="n">var_type</span><span class="p">]</span> <span class="o">=</span> <span class="n">Coefficient</span><span class="p">(</span><span class="n">variation</span><span class="o">=</span><span class="n">variation</span><span class="p">,</span>
                                              <span class="n">num_items</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">,</span>
                                              <span class="n">num_users</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_users</span><span class="p">,</span>
                                              <span class="n">num_params</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_param_dict</span><span class="p">[</span><span class="n">var_type</span><span class="p">])</span>
        <span class="c1"># A ModuleDict is required to properly register all trainable parameters.</span>
        <span class="c1"># self.parameter() will fail if a python dictionary is used instead.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coef_dict</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleDict</span><span class="p">(</span><span class="n">coef_dict</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return a string representation of the model.</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: the string representation of the model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">out_str_lst</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Conditional logistic discrete choice model, expects input features:</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">var_type</span><span class="p">,</span> <span class="n">num_params</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_param_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">out_str_lst</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;X[</span><span class="si">{</span><span class="n">var_type</span><span class="si">}</span><span class="s1">] with </span><span class="si">{</span><span class="n">num_params</span><span class="si">}</span><span class="s1"> parameters, with </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">coef_variation_dict</span><span class="p">[</span><span class="n">var_type</span><span class="p">]</span><span class="si">}</span><span class="s1"> level variation.&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__repr__</span><span class="p">()</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">out_str_lst</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">num_params</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Get the total number of parameters. For example, if there is only an user-specific coefficient to be multiplied</span>
<span class="sd">        with the K-dimensional observable, then the total number of parameters would be K x number of users, assuming no</span>
<span class="sd">        intercept is involved.</span>

<span class="sd">        Returns:</span>
<span class="sd">            int: the total number of learnable parameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">summary</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Print out the current model parameter.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">var_type</span><span class="p">,</span> <span class="n">coefficient</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">coefficient</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Variable Type: &#39;</span><span class="p">,</span> <span class="n">var_type</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">coefficient</span><span class="o">.</span><span class="n">coef</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                <span class="n">batch</span><span class="p">:</span> <span class="n">ChoiceDataset</span><span class="p">,</span>
                <span class="n">manual_coef_value_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward pass of the model.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch: a `ChoiceDataset` object.</span>

<span class="sd">            manual_coef_value_dict (Optional[Dict[str, torch.Tensor]], optional): a dictionary with</span>
<span class="sd">                keys in {&#39;u&#39;, &#39;i&#39;} etc and tensors as values. If provided, the model will force</span>
<span class="sd">                coefficient to be the provided values and compute utility conditioned on the provided</span>
<span class="sd">                coefficient values. This feature is useful when the research wishes to plug in particular</span>
<span class="sd">                values of coefficients and examine the utility values. If not provided, the model will</span>
<span class="sd">                use the learned coefficient values in self.coef_dict.</span>
<span class="sd">                Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: a tensor of shape (num_trips, num_items) whose (t, i) entry represents</span>
<span class="sd">                the utility from item i in trip t for the user involved in that trip.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x_dict</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">x_dict</span>

        <span class="k">if</span> <span class="s1">&#39;intercept&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_variation_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="c1"># intercept term has no input tensor, which has only 1 feature.</span>
            <span class="n">x_dict</span><span class="p">[</span><span class="s1">&#39;intercept&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">batch</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># compute the utility from each item in each choice session.</span>
        <span class="n">total_utility</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">batch</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="c1"># for each type of variables, apply the corresponding coefficient to input x.</span>

        <span class="k">for</span> <span class="n">var_type</span><span class="p">,</span> <span class="n">coef</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">total_utility</span> <span class="o">+=</span> <span class="n">coef</span><span class="p">(</span>
                <span class="n">x_dict</span><span class="p">[</span><span class="n">var_type</span><span class="p">],</span> <span class="n">batch</span><span class="o">.</span><span class="n">user_index</span><span class="p">,</span>
                <span class="n">manual_coef_value</span><span class="o">=</span><span class="kc">None</span> <span class="k">if</span> <span class="n">manual_coef_value_dict</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">manual_coef_value_dict</span><span class="p">[</span><span class="n">var_type</span><span class="p">])</span>

        <span class="k">assert</span> <span class="n">total_utility</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">batch</span><span class="o">.</span><span class="n">item_availability</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># mask out unavilable items.</span>
            <span class="n">total_utility</span><span class="p">[</span><span class="o">~</span><span class="n">batch</span><span class="o">.</span><span class="n">item_availability</span><span class="p">[</span><span class="n">batch</span><span class="o">.</span><span class="n">session_index</span><span class="p">,</span> <span class="p">:]]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">total_utility</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">min</span> <span class="o">/</span> <span class="mi">2</span>
        <span class="k">return</span> <span class="n">total_utility</span>


    <span class="k">def</span> <span class="nf">negative_log_likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">ChoiceDataset</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">is_train</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Computes the log-likelihood for the batch and label.</span>
<span class="sd">        TODO: consider remove y, change to label.</span>
<span class="sd">        TODO: consider move this method outside the model, the role of the model is to compute the utility.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch (ChoiceDataset): a ChoiceDataset object containing the data.</span>
<span class="sd">            y (torch.Tensor): the label.</span>
<span class="sd">            is_train (bool, optional): whether to trace the gradient. Defaults to True.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: the negative log-likelihood.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">is_train</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="c1"># (num_trips, num_items)</span>
        <span class="n">total_utility</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        <span class="n">logP</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">total_utility</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">nll</span> <span class="o">=</span> <span class="o">-</span> <span class="n">logP</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)),</span> <span class="n">y</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">nll</span>


    <span class="c1"># NOTE: the method for computing Hessian and standard deviation has been moved to std.py.</span>
    <span class="c1"># @staticmethod</span>
    <span class="c1"># def flatten_coef_dict(coef_dict: Dict[str, Union[torch.Tensor, torch.nn.Parameter]]) -&gt; Tuple[torch.Tensor, dict]:</span>
    <span class="c1">#     &quot;&quot;&quot;Flattens the coef_dict into a 1-dimension tensor, used for hessian computation.</span>

    <span class="c1">#     Args:</span>
    <span class="c1">#         coef_dict (Dict[str, Union[torch.Tensor, torch.nn.Parameter]]): a dictionary holding learnable parameters.</span>

    <span class="c1">#     Returns:</span>
    <span class="c1">#         Tuple[torch.Tensor, dict]: 1. the flattened tensors with shape (num_params,), 2. an indexing dictionary</span>
    <span class="c1">#             used for reconstructing the original coef_dict from the flatten tensor.</span>
    <span class="c1">#     &quot;&quot;&quot;</span>
    <span class="c1">#     type2idx = dict()</span>
    <span class="c1">#     param_list = list()</span>
    <span class="c1">#     start = 0</span>

    <span class="c1">#     for var_type in coef_dict.keys():</span>
    <span class="c1">#         num_params = coef_dict[var_type].coef.numel()</span>
    <span class="c1">#         # track which portion of all_param tensor belongs to this variable type.</span>
    <span class="c1">#         type2idx[var_type] = (start, start + num_params)</span>
    <span class="c1">#         start += num_params</span>
    <span class="c1">#         # use reshape instead of view to make a copy.</span>
    <span class="c1">#         param_list.append(coef_dict[var_type].coef.clone().reshape(-1,))</span>

    <span class="c1">#     all_param = torch.cat(param_list)  # (self.num_params(), )</span>
    <span class="c1">#     return all_param, type2idx</span>

    <span class="c1"># @staticmethod</span>
    <span class="c1"># def unwrap_coef_dict(param: torch.Tensor, type2idx: Dict[str, Tuple[int, int]]) -&gt; Dict[str, torch.Tensor]:</span>
    <span class="c1">#     &quot;&quot;&quot;Rebuilds coef_dict from output of self.flatten_coef_dict method.</span>

    <span class="c1">#     Args:</span>
    <span class="c1">#         param (torch.Tensor): the flattened coef_dict from self.flatten_coef_dict.</span>
    <span class="c1">#         type2idx (Dict[str, Tuple[int, int]]): the indexing dictionary from self.flatten_coef_dict.</span>

    <span class="c1">#     Returns:</span>
    <span class="c1">#         Dict[str, torch.Tensor]: the re-constructed coefficient dictionary.</span>
    <span class="c1">#     &quot;&quot;&quot;</span>
    <span class="c1">#     coef_dict = dict()</span>
    <span class="c1">#     for var_type in type2idx.keys():</span>
    <span class="c1">#         start, end = type2idx[var_type]</span>
    <span class="c1">#         # no need to reshape here, Coefficient handles it.</span>
    <span class="c1">#         coef_dict[var_type] = param[start:end]</span>
    <span class="c1">#     return coef_dict</span>

    <span class="c1"># def compute_hessian(self, x_dict, availability, user_index, y) -&gt; torch.Tensor:</span>
    <span class="c1">#     &quot;&quot;&quot;Computes the Hessian of negative log-likelihood (total cross-entropy loss) with respect</span>
    <span class="c1">#     to all parameters in this model. The Hessian can be later used for constructing the standard deviation of</span>
    <span class="c1">#     parameters.</span>

    <span class="c1">#     Args:</span>
    <span class="c1">#         x_dict ,availability, user_index: see definitions in self.forward method.</span>
    <span class="c1">#         y (torch.LongTensor): a tensor with shape (num_trips,) of IDs of items actually purchased.</span>

    <span class="c1">#     Returns:</span>
    <span class="c1">#         torch.Tensor: a (self.num_params, self.num_params) tensor of the Hessian matrix.</span>
    <span class="c1">#     &quot;&quot;&quot;</span>
    <span class="c1">#     all_coefs, type2idx = self.flatten_coef_dict(self.coef_dict)</span>

    <span class="c1">#     def compute_nll(P: torch.Tensor) -&gt; float:</span>
    <span class="c1">#         coef_dict = self.unwrap_coef_dict(P, type2idx)</span>
    <span class="c1">#         y_pred = self._forward(x_dict=x_dict,</span>
    <span class="c1">#                                availability=availability,</span>
    <span class="c1">#                                user_index=user_index,</span>
    <span class="c1">#                                manual_coef_value_dict=coef_dict)</span>
    <span class="c1">#         # the reduction needs to be &#39;sum&#39; to obtain NLL.</span>
    <span class="c1">#         loss = F.cross_entropy(y_pred, y, reduction=&#39;sum&#39;)</span>
    <span class="c1">#         return loss</span>

    <span class="c1">#     H = torch.autograd.functional.hessian(compute_nll, all_coefs)</span>
    <span class="c1">#     assert H.shape == (self.num_params, self.num_params)</span>
    <span class="c1">#     return H</span>

    <span class="c1"># def compute_std(self, x_dict, availability, user_index, y) -&gt; Dict[str, torch.Tensor]:</span>
    <span class="c1">#     &quot;&quot;&quot;Computes</span>

    <span class="c1">#     Args:f</span>
    <span class="c1">#         See definitions in self.compute_hessian.</span>

    <span class="c1">#     Returns:</span>
    <span class="c1">#         Dict[str, torch.Tensor]: a dictionary whose keys are the same as self.coef_dict.keys()</span>
    <span class="c1">#         the values are standard errors of coefficients in each coefficient group.</span>
    <span class="c1">#     &quot;&quot;&quot;</span>
    <span class="c1">#     _, type2idx = self.flatten_coef_dict(self.coef_dict)</span>
    <span class="c1">#     H = self.compute_hessian(x_dict, availability, user_index, y)</span>
    <span class="c1">#     std_all = torch.sqrt(torch.diag(torch.inverse(H)))</span>
    <span class="c1">#     std_dict = dict()</span>
    <span class="c1">#     for var_type in type2idx.keys():</span>
    <span class="c1">#         # get std of variables belonging to each type.</span>
    <span class="c1">#         start, end = type2idx[var_type]</span>
    <span class="c1">#         std_dict[var_type] = std_all[start:end]</span>
    <span class="c1">#     return std_dict</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">






  <div class="doc doc-object doc-attribute">



<h5 id="torch_choice.model.conditional_logit_model.ConditionalLogitModel.num_params" class="doc doc-heading">
<code class="highlight language-python"><span class="n">num_params</span><span class="p">:</span> <span class="nb">int</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

</h5>

    <div class="doc doc-contents ">

      <p>Get the total number of parameters. For example, if there is only an user-specific coefficient to be multiplied
with the K-dimensional observable, then the total number of parameters would be K x number of users, assuming no
intercept is involved.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>int</code></td>
      <td><p>the total number of learnable parameters.</p></td>
    </tr>
  </tbody>
</table>    </div>

  </div>






  <div class="doc doc-object doc-method">



<h5 id="torch_choice.model.conditional_logit_model.ConditionalLogitModel.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coef_variation_dict</span><span class="p">,</span> <span class="n">num_param_dict</span><span class="p">,</span> <span class="n">num_items</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_users</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h5>

    <div class="doc doc-contents ">


<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>num_items</code></td>
        <td><code>int</code></td>
        <td><p>number of items in the dataset.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>num_users</code></td>
        <td><code>int</code></td>
        <td><p>number of users in the dataset.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>coef_variation_dict</code></td>
        <td><code>Dict[str, str]</code></td>
        <td><p>variable type to variation level dictionary. Keys of this dictionary
should be variable names in the dataset (i.e., these starting with <code>price_</code>, <code>user_</code>, etc), or <code>intercept</code>
if the researcher requires an intercept term.
For each variable name X_var (e.g., <code>user_income</code>) or <code>intercept</code>, the corresponding dictionary key should
be one of the following values, this value specifies the "level of variation" of the coefficient.</p>
<ul>
<li>
<p><code>constant</code>: the coefficient constant over all users and items: <span class="arithmatex">\(X eta\)</span>.</p>
</li>
<li>
<p><code>user</code>: user-specific parameters but constant across all items: <span class="arithmatex">\(X eta_{u}\)</span>.</p>
</li>
<li>
<p><code>item</code>: item-specific parameters but constant across all users, <span class="arithmatex">\(X eta_{i}\)</span>.
    Note that the coefficients for the first item are forced to be zero following the standard practice
    in econometrics.</p>
</li>
<li>
<p><code>item-full</code>: the same configuration as <code>item</code>, but does not force the coefficients of the first item to
    be zeros.</p>
</li>
</ul>
<p>The following configurations are supported by the package, but we don't recommend using them due to the
    large number of parameters.
- <code>user-item</code>: parameters that are specific to both user and item, parameter for the first item
    for all users are forced to be zero.</p>
<ul>
<li><code>user-item-full</code>: parameters that are specific to both user and item, explicitly model for all items.</li>
</ul></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>num_param_dict</code></td>
        <td><code>Dict[str, int]</code></td>
        <td><p>variable type to number of parameters dictionary with keys exactly the same
as the <code>coef_variation_dict</code>. Values of <code>num_param_dict</code> records numbers of features in each kind of variable.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>torch_choice/model/conditional_logit_model.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
             <span class="n">coef_variation_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span>
             <span class="n">num_param_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
             <span class="n">num_items</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
             <span class="n">num_users</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span>
             <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Args:</span>
<span class="sd">        num_items (int): number of items in the dataset.</span>
<span class="sd">        num_users (int): number of users in the dataset.</span>
<span class="sd">        coef_variation_dict (Dict[str, str]): variable type to variation level dictionary. Keys of this dictionary</span>
<span class="sd">            should be variable names in the dataset (i.e., these starting with `price_`, `user_`, etc), or `intercept`</span>
<span class="sd">            if the researcher requires an intercept term.</span>
<span class="sd">            For each variable name X_var (e.g., `user_income`) or `intercept`, the corresponding dictionary key should</span>
<span class="sd">            be one of the following values, this value specifies the &quot;level of variation&quot; of the coefficient.</span>

<span class="sd">            - `constant`: the coefficient constant over all users and items: $X \beta$.</span>

<span class="sd">            - `user`: user-specific parameters but constant across all items: $X \beta_{u}$.</span>

<span class="sd">            - `item`: item-specific parameters but constant across all users, $X \beta_{i}$.</span>
<span class="sd">                Note that the coefficients for the first item are forced to be zero following the standard practice</span>
<span class="sd">                in econometrics.</span>

<span class="sd">            - `item-full`: the same configuration as `item`, but does not force the coefficients of the first item to</span>
<span class="sd">                be zeros.</span>

<span class="sd">            The following configurations are supported by the package, but we don&#39;t recommend using them due to the</span>
<span class="sd">                large number of parameters.</span>
<span class="sd">            - `user-item`: parameters that are specific to both user and item, parameter for the first item</span>
<span class="sd">                for all users are forced to be zero.</span>

<span class="sd">            - `user-item-full`: parameters that are specific to both user and item, explicitly model for all items.</span>

<span class="sd">        num_param_dict (Dict[str, int]): variable type to number of parameters dictionary with keys exactly the same</span>
<span class="sd">            as the `coef_variation_dict`. Values of `num_param_dict` records numbers of features in each kind of variable.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">ConditionalLogitModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">assert</span> <span class="n">coef_variation_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="o">==</span> <span class="n">num_param_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">variable_types</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">num_param_dict</span><span class="p">)</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">coef_variation_dict</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">coef_variation_dict</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_param_dict</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">num_param_dict</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span> <span class="o">=</span> <span class="n">num_items</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_users</span> <span class="o">=</span> <span class="n">num_users</span>

    <span class="c1"># check number of parameters specified are all positive.</span>
    <span class="k">for</span> <span class="n">var_type</span><span class="p">,</span> <span class="n">num_params</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_param_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">assert</span> <span class="n">num_params</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;num_params needs to be positive, got: </span><span class="si">{</span><span class="n">num_params</span><span class="si">}</span><span class="s1">.&#39;</span>

    <span class="c1"># infer the number of parameters for intercept if the researcher forgets.</span>
    <span class="k">if</span> <span class="s1">&#39;intercept&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_variation_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="ow">and</span> <span class="s1">&#39;intercept&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_param_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;&#39;intercept&#39; key found in coef_variation_dict but not in num_param_dict, num_param_dict[&#39;intercept&#39;] has been set to 1.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_param_dict</span><span class="p">[</span><span class="s1">&#39;intercept&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="c1"># construct trainable parameters.</span>
    <span class="n">coef_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">var_type</span><span class="p">,</span> <span class="n">variation</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_variation_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">coef_dict</span><span class="p">[</span><span class="n">var_type</span><span class="p">]</span> <span class="o">=</span> <span class="n">Coefficient</span><span class="p">(</span><span class="n">variation</span><span class="o">=</span><span class="n">variation</span><span class="p">,</span>
                                          <span class="n">num_items</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">,</span>
                                          <span class="n">num_users</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_users</span><span class="p">,</span>
                                          <span class="n">num_params</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_param_dict</span><span class="p">[</span><span class="n">var_type</span><span class="p">])</span>
    <span class="c1"># A ModuleDict is required to properly register all trainable parameters.</span>
    <span class="c1"># self.parameter() will fail if a python dictionary is used instead.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">coef_dict</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleDict</span><span class="p">(</span><span class="n">coef_dict</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="torch_choice.model.conditional_logit_model.ConditionalLogitModel.__repr__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h5>

    <div class="doc doc-contents ">

      <p>Return a string representation of the model.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>str</code></td>
      <td><p>the string representation of the model.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>torch_choice/model/conditional_logit_model.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Return a string representation of the model.</span>

<span class="sd">    Returns:</span>
<span class="sd">        str: the string representation of the model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">out_str_lst</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Conditional logistic discrete choice model, expects input features:</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">var_type</span><span class="p">,</span> <span class="n">num_params</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_param_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">out_str_lst</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;X[</span><span class="si">{</span><span class="n">var_type</span><span class="si">}</span><span class="s1">] with </span><span class="si">{</span><span class="n">num_params</span><span class="si">}</span><span class="s1"> parameters, with </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">coef_variation_dict</span><span class="p">[</span><span class="n">var_type</span><span class="p">]</span><span class="si">}</span><span class="s1"> level variation.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__repr__</span><span class="p">()</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">out_str_lst</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="torch_choice.model.conditional_logit_model.ConditionalLogitModel.forward" class="doc doc-heading">
<code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">manual_coef_value_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>Forward pass of the model.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>batch</code></td>
        <td><code>ChoiceDataset</code></td>
        <td><p>a <code>ChoiceDataset</code> object.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>manual_coef_value_dict</code></td>
        <td><code>Optional[Dict[str, torch.Tensor]]</code></td>
        <td><p>a dictionary with
keys in {'u', 'i'} etc and tensors as values. If provided, the model will force
coefficient to be the provided values and compute utility conditioned on the provided
coefficient values. This feature is useful when the research wishes to plug in particular
values of coefficients and examine the utility values. If not provided, the model will
use the learned coefficient values in self.coef_dict.
Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>torch.Tensor</code></td>
      <td><p>a tensor of shape (num_trips, num_items) whose (t, i) entry represents
    the utility from item i in trip t for the user involved in that trip.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>torch_choice/model/conditional_logit_model.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
            <span class="n">batch</span><span class="p">:</span> <span class="n">ChoiceDataset</span><span class="p">,</span>
            <span class="n">manual_coef_value_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Forward pass of the model.</span>

<span class="sd">    Args:</span>
<span class="sd">        batch: a `ChoiceDataset` object.</span>

<span class="sd">        manual_coef_value_dict (Optional[Dict[str, torch.Tensor]], optional): a dictionary with</span>
<span class="sd">            keys in {&#39;u&#39;, &#39;i&#39;} etc and tensors as values. If provided, the model will force</span>
<span class="sd">            coefficient to be the provided values and compute utility conditioned on the provided</span>
<span class="sd">            coefficient values. This feature is useful when the research wishes to plug in particular</span>
<span class="sd">            values of coefficients and examine the utility values. If not provided, the model will</span>
<span class="sd">            use the learned coefficient values in self.coef_dict.</span>
<span class="sd">            Defaults to None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: a tensor of shape (num_trips, num_items) whose (t, i) entry represents</span>
<span class="sd">            the utility from item i in trip t for the user involved in that trip.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x_dict</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">x_dict</span>

    <span class="k">if</span> <span class="s1">&#39;intercept&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_variation_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="c1"># intercept term has no input tensor, which has only 1 feature.</span>
        <span class="n">x_dict</span><span class="p">[</span><span class="s1">&#39;intercept&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">batch</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># compute the utility from each item in each choice session.</span>
    <span class="n">total_utility</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">batch</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="c1"># for each type of variables, apply the corresponding coefficient to input x.</span>

    <span class="k">for</span> <span class="n">var_type</span><span class="p">,</span> <span class="n">coef</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">total_utility</span> <span class="o">+=</span> <span class="n">coef</span><span class="p">(</span>
            <span class="n">x_dict</span><span class="p">[</span><span class="n">var_type</span><span class="p">],</span> <span class="n">batch</span><span class="o">.</span><span class="n">user_index</span><span class="p">,</span>
            <span class="n">manual_coef_value</span><span class="o">=</span><span class="kc">None</span> <span class="k">if</span> <span class="n">manual_coef_value_dict</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">manual_coef_value_dict</span><span class="p">[</span><span class="n">var_type</span><span class="p">])</span>

    <span class="k">assert</span> <span class="n">total_utility</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">batch</span><span class="o">.</span><span class="n">item_availability</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># mask out unavilable items.</span>
        <span class="n">total_utility</span><span class="p">[</span><span class="o">~</span><span class="n">batch</span><span class="o">.</span><span class="n">item_availability</span><span class="p">[</span><span class="n">batch</span><span class="o">.</span><span class="n">session_index</span><span class="p">,</span> <span class="p">:]]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">total_utility</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">min</span> <span class="o">/</span> <span class="mi">2</span>
    <span class="k">return</span> <span class="n">total_utility</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="torch_choice.model.conditional_logit_model.ConditionalLogitModel.negative_log_likelihood" class="doc doc-heading">
<code class="highlight language-python"><span class="n">negative_log_likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">is_train</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>Computes the log-likelihood for the batch and label.
TODO: consider remove y, change to label.
TODO: consider move this method outside the model, the role of the model is to compute the utility.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>batch</code></td>
        <td><code>ChoiceDataset</code></td>
        <td><p>a ChoiceDataset object containing the data.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>y</code></td>
        <td><code>torch.Tensor</code></td>
        <td><p>the label.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>is_train</code></td>
        <td><code>bool</code></td>
        <td><p>whether to trace the gradient. Defaults to True.</p></td>
        <td><code>True</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>torch.Tensor</code></td>
      <td><p>the negative log-likelihood.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>torch_choice/model/conditional_logit_model.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">negative_log_likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">ChoiceDataset</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">is_train</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Computes the log-likelihood for the batch and label.</span>
<span class="sd">    TODO: consider remove y, change to label.</span>
<span class="sd">    TODO: consider move this method outside the model, the role of the model is to compute the utility.</span>

<span class="sd">    Args:</span>
<span class="sd">        batch (ChoiceDataset): a ChoiceDataset object containing the data.</span>
<span class="sd">        y (torch.Tensor): the label.</span>
<span class="sd">        is_train (bool, optional): whether to trace the gradient. Defaults to True.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: the negative log-likelihood.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">is_train</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="c1"># (num_trips, num_items)</span>
    <span class="n">total_utility</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
    <span class="n">logP</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">total_utility</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">nll</span> <span class="o">=</span> <span class="o">-</span> <span class="n">logP</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)),</span> <span class="n">y</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">nll</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="torch_choice.model.conditional_logit_model.ConditionalLogitModel.summary" class="doc doc-heading">
<code class="highlight language-python"><span class="n">summary</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>Print out the current model parameter.</p>

        <details class="quote">
          <summary>Source code in <code>torch_choice/model/conditional_logit_model.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">summary</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Print out the current model parameter.&quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">var_type</span><span class="p">,</span> <span class="n">coefficient</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">coefficient</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Variable Type: &#39;</span><span class="p">,</span> <span class="n">var_type</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">coefficient</span><span class="o">.</span><span class="n">coef</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>







  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h3 id="torch_choice.model.nested_logit_model" class="doc doc-heading">
        <code>nested_logit_model</code>



</h3>

    <div class="doc doc-contents ">

      <p>Implementation of the nested logit model, see page 86 of the book
"discrete choice methods with simulation" by Train. for more details.</p>
<p>Author: Tianyu Du
Update; Apr. 28, 2022</p>



  <div class="doc doc-children">







  <div class="doc doc-object doc-class">



<h4 id="torch_choice.model.nested_logit_model.NestedLogitModel" class="doc doc-heading">
        <code>
NestedLogitModel            (<span title="torch.nn.modules.module.Module">Module</span>)
        </code>



</h4>

    <div class="doc doc-contents ">


        <details class="quote">
          <summary>Source code in <code>torch_choice/model/nested_logit_model.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">NestedLogitModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">category_to_item</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">object</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]],</span>
                 <span class="n">category_coef_variation_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span>
                 <span class="n">category_num_param_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
                 <span class="n">item_coef_variation_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span>
                 <span class="n">item_num_param_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
                 <span class="n">num_users</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">shared_lambda</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">False</span>
                 <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Initialization method of the nested logit model.</span>

<span class="sd">        Args:</span>
<span class="sd">            category_to_item (Dict[object, List[int]]): a dictionary maps a category ID to a list</span>
<span class="sd">                of items IDs of the queried category.</span>

<span class="sd">            category_coef_variation_dict (Dict[str, str]): a dictionary maps a variable type</span>
<span class="sd">                (i.e., variable group) to the level of variation for the coefficient of this type</span>
<span class="sd">                of variables.</span>
<span class="sd">            category_num_param_dict (Dict[str, int]): a dictionary maps a variable type name to</span>
<span class="sd">                the number of parameters in this variable group.</span>

<span class="sd">            item_coef_variation_dict (Dict[str, str]): the same as category_coef_variation_dict but</span>
<span class="sd">                for item features.</span>
<span class="sd">            item_num_param_dict (Dict[str, int]): the same as category_num_param_dict but for item</span>
<span class="sd">                features.</span>

<span class="sd">            num_users (Optional[int], optional): number of users to be modelled, this is only</span>
<span class="sd">                required if any of variable type requires user-specific variations.</span>
<span class="sd">                Defaults to None.</span>

<span class="sd">            shared_lambda (bool): a boolean indicating whether to enforce the elasticity lambda, which</span>
<span class="sd">                is the coefficient for inclusive values, to be constant for all categories.</span>
<span class="sd">                The lambda enters the category-level selection as the following</span>
<span class="sd">                Utility of choosing category k = lambda * inclusive value of category k</span>
<span class="sd">                                               + linear combination of some other category level features</span>
<span class="sd">                If set to True, a single lambda will be learned for all categories, otherwise, the</span>
<span class="sd">                model learns an individual lambda for each category.</span>
<span class="sd">                Defaults to False.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">NestedLogitModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">category_to_item</span> <span class="o">=</span> <span class="n">category_to_item</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">category_coef_variation_dict</span> <span class="o">=</span> <span class="n">category_coef_variation_dict</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">category_num_param_dict</span> <span class="o">=</span> <span class="n">category_num_param_dict</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">item_coef_variation_dict</span> <span class="o">=</span> <span class="n">item_coef_variation_dict</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">item_num_param_dict</span> <span class="o">=</span> <span class="n">item_num_param_dict</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_users</span> <span class="o">=</span> <span class="n">num_users</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">categories</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">category_to_item</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_categories</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">categories</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">items</span><span class="p">)</span> <span class="k">for</span> <span class="n">items</span> <span class="ow">in</span> <span class="n">category_to_item</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

        <span class="c1"># category coefficients.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">category_coef_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_coef_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">category_coef_variation_dict</span><span class="p">,</span>
                                                        <span class="bp">self</span><span class="o">.</span><span class="n">category_num_param_dict</span><span class="p">,</span>
                                                        <span class="bp">self</span><span class="o">.</span><span class="n">num_categories</span><span class="p">)</span>

        <span class="c1"># item coefficients.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">item_coef_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_coef_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">item_coef_variation_dict</span><span class="p">,</span>
                                                    <span class="bp">self</span><span class="o">.</span><span class="n">item_num_param_dict</span><span class="p">,</span>
                                                    <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">shared_lambda</span> <span class="o">=</span> <span class="n">shared_lambda</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">shared_lambda</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lambda_weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lambda_weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_categories</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># breakpoint()</span>
        <span class="c1"># self.iv_weights = nn.Parameter(torch.ones(1), requires_grad=True)</span>
        <span class="c1"># used to warn users if forgot to call clamp.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_clamp_called_flag</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">num_params</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Get the total number of parameters. For example, if there is only an user-specific coefficient to be multiplied</span>
<span class="sd">        with the K-dimensional observable, then the total number of parameters would be K x number of users, assuming no</span>
<span class="sd">        intercept is involved.</span>

<span class="sd">        Returns:</span>
<span class="sd">            int: the total number of learnable parameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">_build_coef_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                         <span class="n">coef_variation_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span>
                         <span class="n">num_param_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
                         <span class="n">num_items</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleDict</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Builds a coefficient dictionary containing all trainable components of the model, mapping coefficient names</span>
<span class="sd">            to the corresponding Coefficient Module.</span>
<span class="sd">            num_items could be the actual number of items or the number of categories depends on the use case.</span>
<span class="sd">            NOTE: torch-choice users don&#39;t directly interact with this method.</span>

<span class="sd">        Args:</span>
<span class="sd">            coef_variation_dict (Dict[str, str]): a dictionary mapping coefficient names (e.g., theta_user) to the level</span>
<span class="sd">                of variation (e.g., &#39;user&#39;).</span>
<span class="sd">            num_param_dict (Dict[str, int]): a dictionary mapping coefficient names to the number of parameters in this</span>
<span class="sd">                coefficient. Be aware that, for example, if there is one K-dimensional coefficient for every user, then</span>
<span class="sd">                the `num_param` should be K instead of K x number of users.</span>
<span class="sd">            num_items (int): the total number of items in the prediction problem. `num_items` should be the number of</span>
<span class="sd">                categories if _build_coef_dict() is used for category-level prediction.</span>

<span class="sd">        Returns:</span>
<span class="sd">            nn.ModuleDict: a PyTorch ModuleDict object mapping from coefficient names to training Coefficient.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">coef_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">var_type</span><span class="p">,</span> <span class="n">variation</span> <span class="ow">in</span> <span class="n">coef_variation_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">num_params</span> <span class="o">=</span> <span class="n">num_param_dict</span><span class="p">[</span><span class="n">var_type</span><span class="p">]</span>
            <span class="n">coef_dict</span><span class="p">[</span><span class="n">var_type</span><span class="p">]</span> <span class="o">=</span> <span class="n">Coefficient</span><span class="p">(</span><span class="n">variation</span><span class="o">=</span><span class="n">variation</span><span class="p">,</span>
                                              <span class="n">num_items</span><span class="o">=</span><span class="n">num_items</span><span class="p">,</span>
                                              <span class="n">num_users</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_users</span><span class="p">,</span>
                                              <span class="n">num_params</span><span class="o">=</span><span class="n">num_params</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleDict</span><span class="p">(</span><span class="n">coef_dict</span><span class="p">)</span>

    <span class="c1"># def _check_input_shapes(self, category_x_dict, item_x_dict, user_index, item_availability) -&gt; None:</span>
    <span class="c1">#     T = list(category_x_dict.values())[0].shape[0]  # batch size.</span>
    <span class="c1">#     for var_type, x_category in category_x_dict.items():</span>
    <span class="c1">#         x_item = item_x_dict[var_type]</span>
    <span class="c1">#         assert len(x_item.shape) == len(x_item.shape) == 3</span>
    <span class="c1">#         assert x_category.shape[0] == x_item.shape[0]</span>
    <span class="c1">#         assert x_category.shape == (T, self.num_categories, self.category_num_param_dict[var_type])</span>
    <span class="c1">#         assert x_item.shape == (T, self.num_items, self.item_num_param_dict[var_type])</span>

    <span class="c1">#     if (user_index is not None) and (self.num_users is not None):</span>
    <span class="c1">#         assert user_index.shape == (T,)</span>

    <span class="c1">#     if item_availability is not None:</span>
    <span class="c1">#         assert item_availability.shape == (T, self.num_items)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">ChoiceDataset</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;An standard forward method for the model, the user feeds a ChoiceDataset batch and the model returns the</span>
<span class="sd">            predicted log-likelihood tensor. The main forward passing happens in the _forward() method, but we provide</span>
<span class="sd">            this wrapper forward() method for a cleaner API, as forward() only requires a single batch argument.</span>
<span class="sd">            For more details about the forward passing, please refer to the _forward() method.</span>

<span class="sd">        # TODO: the ConditionaLogitModel returns predicted utility, the NestedLogitModel behaves the same?</span>

<span class="sd">        Args:</span>
<span class="sd">            batch (ChoiceDataset): a ChoiceDataset object containing the data batch.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: a tensor of shape (num_trips, num_items) including the log probability</span>
<span class="sd">            of choosing item i in trip t.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s1">&#39;category&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">x_dict</span><span class="p">,</span>
                             <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;item&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">x_dict</span><span class="p">,</span>
                             <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;item&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">user_index</span><span class="p">,</span>
                             <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;item&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">item_availability</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">category_x_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
                 <span class="n">item_x_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
                 <span class="n">user_index</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">item_availability</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">BoolTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
                 <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;&quot;Computes log P[t, i] = the log probability for the user involved in trip t to choose item i.</span>
<span class="sd">        Let n denote the ID of the user involved in trip t, then P[t, i] = P_{ni} on page 86 of the</span>
<span class="sd">        book &quot;discrete choice methods with simulation&quot; by Train.</span>

<span class="sd">        Args:</span>
<span class="sd">            x_category (torch.Tensor): a tensor with shape (num_trips, num_categories, *) including</span>
<span class="sd">                features of all categories in each trip.</span>
<span class="sd">            x_item (torch.Tensor): a tensor with shape (num_trips, num_items, *) including features</span>
<span class="sd">                of all items in each trip.</span>
<span class="sd">            user_index (torch.LongTensor): a tensor of shape (num_trips,) indicating which user is</span>
<span class="sd">                making decision in each trip. Setting user_index = None assumes the same user is</span>
<span class="sd">                making decisions in all trips.</span>
<span class="sd">            item_availability (torch.BoolTensor): a boolean tensor with shape (num_trips, num_items)</span>
<span class="sd">                indicating the aviliability of items in each trip. If item_availability[t, i] = False,</span>
<span class="sd">                the utility of choosing item i in trip t, V[t, i], will be set to -inf.</span>
<span class="sd">                Given the decomposition V[t, i] = W[t, k(i)] + Y[t, i] + eps, V[t, i] is set to -inf</span>
<span class="sd">                by setting Y[t, i] = -inf for unavilable items.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: a tensor of shape (num_trips, num_items) including the log probability</span>
<span class="sd">            of choosing item i in trip t.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">shared_lambda</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lambdas</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lambda_weight</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_categories</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lambdas</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lambda_weight</span>

        <span class="c1"># if not self._clamp_called_flag:</span>
        <span class="c1">#     warnings.warn(&#39;Did you forget to call clamp_lambdas() after optimizer.step()?&#39;)</span>

        <span class="c1"># The overall utility of item can be decomposed into V[item] = W[category] + Y[item] + eps.</span>
        <span class="n">T</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">item_x_dict</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">device</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">item_x_dict</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span>
        <span class="c1"># compute category-specific utility with shape (T, num_categories).</span>
        <span class="n">W</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_categories</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="k">if</span> <span class="s1">&#39;intercept&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">category_coef_variation_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">category_x_dict</span><span class="p">[</span><span class="s1">&#39;intercept&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">T</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_categories</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">var_type</span><span class="p">,</span> <span class="n">coef</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">category_coef_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">W</span> <span class="o">+=</span> <span class="n">coef</span><span class="p">(</span><span class="n">category_x_dict</span><span class="p">[</span><span class="n">var_type</span><span class="p">],</span> <span class="n">user_index</span><span class="p">)</span>

        <span class="c1"># compute item-specific utility (T, num_items).</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">var_type</span><span class="p">,</span> <span class="n">coef</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_coef_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">Y</span> <span class="o">+=</span> <span class="n">coef</span><span class="p">(</span><span class="n">item_x_dict</span><span class="p">[</span><span class="n">var_type</span><span class="p">],</span> <span class="n">user_index</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">item_availability</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">Y</span><span class="p">[</span><span class="o">~</span><span class="n">item_availability</span><span class="p">]</span> <span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">min</span> <span class="o">/</span> <span class="mi">2</span>

        <span class="c1"># =============================================================================</span>
        <span class="c1"># compute the inclusive value of each category.</span>
        <span class="n">inclusive_value</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">Bk</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">category_to_item</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="c1"># for nest k, divide the Y of all items in Bk by lambda_k.</span>
            <span class="n">Y</span><span class="p">[:,</span> <span class="n">Bk</span><span class="p">]</span> <span class="o">/=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lambdas</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
            <span class="c1"># compute inclusive value for category k.</span>
            <span class="c1"># mask out unavilable items.</span>
            <span class="n">inclusive_value</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">logsumexp</span><span class="p">(</span><span class="n">Y</span><span class="p">[:,</span> <span class="n">Bk</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># (T,)</span>
        <span class="c1"># boardcast inclusive value from (T, num_categories) to (T, num_items).</span>
        <span class="c1"># for trip t, I[t, i] is the inclusive value of the category item i belongs to.</span>
        <span class="n">I</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">Bk</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">category_to_item</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">I</span><span class="p">[:,</span> <span class="n">Bk</span><span class="p">]</span> <span class="o">=</span> <span class="n">inclusive_value</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># (T, |Bk|)</span>

        <span class="c1"># logP_item[t, i] = log P(ni|Bk), where Bk is the category item i is in, n is the user in trip t.</span>
        <span class="n">logP_item</span> <span class="o">=</span> <span class="n">Y</span> <span class="o">-</span> <span class="n">I</span>  <span class="c1"># (T, num_items)</span>

        <span class="c1"># =============================================================================</span>
        <span class="c1"># logP_category[t, i] = log P(Bk), for item i in trip t, the probability of choosing the nest/bucket</span>
        <span class="c1"># item i belongs to. logP_category has shape (T, num_items)</span>
        <span class="c1"># logit[t, i] = W[n, k] + lambda[k] I[n, k], where n is the user involved in trip t, k is</span>
        <span class="c1"># the category item i belongs to.</span>
        <span class="n">logit</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">Bk</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">category_to_item</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">logit</span><span class="p">[:,</span> <span class="n">Bk</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">W</span><span class="p">[:,</span> <span class="n">k</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">lambdas</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">inclusive_value</span><span class="p">[</span><span class="n">k</span><span class="p">])</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># (T, |Bk|)</span>
        <span class="c1"># only count each category once in the logsumexp within the category level model.</span>
        <span class="n">cols</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">category_to_item</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
        <span class="n">logP_category</span> <span class="o">=</span> <span class="n">logit</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">logsumexp</span><span class="p">(</span><span class="n">logit</span><span class="p">[:,</span> <span class="n">cols</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># =============================================================================</span>
        <span class="c1"># compute the joint log P_{ni} as in the textbook.</span>
        <span class="n">logP</span> <span class="o">=</span> <span class="n">logP_item</span> <span class="o">+</span> <span class="n">logP_category</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_clamp_called_flag</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="n">logP</span>

    <span class="k">def</span> <span class="nf">log_likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Computes the log likelihood of the model, please refer to the negative_log_likelihood() method.</span>

<span class="sd">        Returns:</span>
<span class="sd">            _type_: the log likelihood of the model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">negative_log_likelihood</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">negative_log_likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                                <span class="n">batch</span><span class="p">:</span> <span class="n">ChoiceDataset</span><span class="p">,</span>
                                <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">,</span>
                                <span class="n">is_train</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">scalar_tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Computes the negative log likelihood of the model. Please note the log-likelihood is summed over all samples</span>
<span class="sd">            in batch instead of the average.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch (ChoiceDataset): the ChoiceDataset object containing the data.</span>
<span class="sd">            y (torch.LongTensor): the label.</span>
<span class="sd">            is_train (bool, optional): which mode of the model to be used for the forward passing, if we need Hessian</span>
<span class="sd">                of the NLL through auto-grad, `is_train` should be set to True. If we merely need a performance metric,</span>
<span class="sd">                then `is_train` can be set to False for better performance.</span>
<span class="sd">                Defaults to True.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.scalar_tensor: the negative log likelihood of the model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># compute the negative log-likelihood loss directly.</span>
        <span class="k">if</span> <span class="n">is_train</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="c1"># (num_trips, num_items)</span>
        <span class="n">logP</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        <span class="n">nll</span> <span class="o">=</span> <span class="o">-</span> <span class="n">logP</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)),</span> <span class="n">y</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">nll</span>

    <span class="c1"># def clamp_lambdas(self):</span>
    <span class="c1">#     &quot;&quot;&quot;</span>
    <span class="c1">#     Restrict values of lambdas to 0 &lt; lambda &lt;= 1 to guarantee the utility maximization property</span>
    <span class="c1">#     of the model.</span>
    <span class="c1">#     This method should be called everytime after optimizer.step().</span>
    <span class="c1">#     We add a self_clamp_called_flag to remind researchers if this method is not called.</span>
    <span class="c1">#     &quot;&quot;&quot;</span>
    <span class="c1">#     for k in range(len(self.lambdas)):</span>
    <span class="c1">#         self.lambdas[k] = torch.clamp(self.lambdas[k], 1e-5, 1)</span>
    <span class="c1">#     self._clam_called_flag = True</span>

    <span class="c1"># @staticmethod</span>
    <span class="c1"># def add_constant(x: torch.Tensor, where: str=&#39;prepend&#39;) -&gt; torch.Tensor:</span>
    <span class="c1">#     &quot;&quot;&quot;A helper function used to add constant to feature tensor,</span>
    <span class="c1">#     x has shape (batch_size, num_classes, num_parameters),</span>
    <span class="c1">#     returns a tensor of shape (*, num_parameters+1).</span>
    <span class="c1">#     &quot;&quot;&quot;</span>
    <span class="c1">#     batch_size, num_classes, num_parameters = x.shape</span>
    <span class="c1">#     ones = torch.ones((batch_size, num_classes, 1))</span>
    <span class="c1">#     if where == &#39;prepend&#39;:</span>
    <span class="c1">#         new = torch.cat((ones, x), dim=-1)</span>
    <span class="c1">#     elif where == &#39;append&#39;:</span>
    <span class="c1">#         new = torch.cat((x, ones), dim=-1)</span>
    <span class="c1">#     else:</span>
    <span class="c1">#         raise Exception</span>
    <span class="c1">#     return new</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">






  <div class="doc doc-object doc-attribute">



<h5 id="torch_choice.model.nested_logit_model.NestedLogitModel.num_params" class="doc doc-heading">
<code class="highlight language-python"><span class="n">num_params</span><span class="p">:</span> <span class="nb">int</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

</h5>

    <div class="doc doc-contents ">

      <p>Get the total number of parameters. For example, if there is only an user-specific coefficient to be multiplied
with the K-dimensional observable, then the total number of parameters would be K x number of users, assuming no
intercept is involved.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>int</code></td>
      <td><p>the total number of learnable parameters.</p></td>
    </tr>
  </tbody>
</table>    </div>

  </div>






  <div class="doc doc-object doc-method">



<h5 id="torch_choice.model.nested_logit_model.NestedLogitModel.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">category_to_item</span><span class="p">,</span> <span class="n">category_coef_variation_dict</span><span class="p">,</span> <span class="n">category_num_param_dict</span><span class="p">,</span> <span class="n">item_coef_variation_dict</span><span class="p">,</span> <span class="n">item_num_param_dict</span><span class="p">,</span> <span class="n">num_users</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">shared_lambda</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h5>

    <div class="doc doc-contents ">

      <p>Initialization method of the nested logit model.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>category_to_item</code></td>
        <td><code>Dict[object, List[int]]</code></td>
        <td><p>a dictionary maps a category ID to a list
of items IDs of the queried category.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>category_coef_variation_dict</code></td>
        <td><code>Dict[str, str]</code></td>
        <td><p>a dictionary maps a variable type
(i.e., variable group) to the level of variation for the coefficient of this type
of variables.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>category_num_param_dict</code></td>
        <td><code>Dict[str, int]</code></td>
        <td><p>a dictionary maps a variable type name to
the number of parameters in this variable group.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>item_coef_variation_dict</code></td>
        <td><code>Dict[str, str]</code></td>
        <td><p>the same as category_coef_variation_dict but
for item features.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>item_num_param_dict</code></td>
        <td><code>Dict[str, int]</code></td>
        <td><p>the same as category_num_param_dict but for item
features.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>num_users</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>number of users to be modelled, this is only
required if any of variable type requires user-specific variations.
Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>shared_lambda</code></td>
        <td><code>bool</code></td>
        <td><p>a boolean indicating whether to enforce the elasticity lambda, which
is the coefficient for inclusive values, to be constant for all categories.
The lambda enters the category-level selection as the following
Utility of choosing category k = lambda * inclusive value of category k
                               + linear combination of some other category level features
If set to True, a single lambda will be learned for all categories, otherwise, the
model learns an individual lambda for each category.
Defaults to False.</p></td>
        <td><code>False</code></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>torch_choice/model/nested_logit_model.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
             <span class="n">category_to_item</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">object</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]],</span>
             <span class="n">category_coef_variation_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span>
             <span class="n">category_num_param_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
             <span class="n">item_coef_variation_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span>
             <span class="n">item_num_param_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
             <span class="n">num_users</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
             <span class="n">shared_lambda</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">False</span>
             <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Initialization method of the nested logit model.</span>

<span class="sd">    Args:</span>
<span class="sd">        category_to_item (Dict[object, List[int]]): a dictionary maps a category ID to a list</span>
<span class="sd">            of items IDs of the queried category.</span>

<span class="sd">        category_coef_variation_dict (Dict[str, str]): a dictionary maps a variable type</span>
<span class="sd">            (i.e., variable group) to the level of variation for the coefficient of this type</span>
<span class="sd">            of variables.</span>
<span class="sd">        category_num_param_dict (Dict[str, int]): a dictionary maps a variable type name to</span>
<span class="sd">            the number of parameters in this variable group.</span>

<span class="sd">        item_coef_variation_dict (Dict[str, str]): the same as category_coef_variation_dict but</span>
<span class="sd">            for item features.</span>
<span class="sd">        item_num_param_dict (Dict[str, int]): the same as category_num_param_dict but for item</span>
<span class="sd">            features.</span>

<span class="sd">        num_users (Optional[int], optional): number of users to be modelled, this is only</span>
<span class="sd">            required if any of variable type requires user-specific variations.</span>
<span class="sd">            Defaults to None.</span>

<span class="sd">        shared_lambda (bool): a boolean indicating whether to enforce the elasticity lambda, which</span>
<span class="sd">            is the coefficient for inclusive values, to be constant for all categories.</span>
<span class="sd">            The lambda enters the category-level selection as the following</span>
<span class="sd">            Utility of choosing category k = lambda * inclusive value of category k</span>
<span class="sd">                                           + linear combination of some other category level features</span>
<span class="sd">            If set to True, a single lambda will be learned for all categories, otherwise, the</span>
<span class="sd">            model learns an individual lambda for each category.</span>
<span class="sd">            Defaults to False.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">NestedLogitModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">category_to_item</span> <span class="o">=</span> <span class="n">category_to_item</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">category_coef_variation_dict</span> <span class="o">=</span> <span class="n">category_coef_variation_dict</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">category_num_param_dict</span> <span class="o">=</span> <span class="n">category_num_param_dict</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">item_coef_variation_dict</span> <span class="o">=</span> <span class="n">item_coef_variation_dict</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">item_num_param_dict</span> <span class="o">=</span> <span class="n">item_num_param_dict</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_users</span> <span class="o">=</span> <span class="n">num_users</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">categories</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">category_to_item</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_categories</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">categories</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">items</span><span class="p">)</span> <span class="k">for</span> <span class="n">items</span> <span class="ow">in</span> <span class="n">category_to_item</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

    <span class="c1"># category coefficients.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">category_coef_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_coef_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">category_coef_variation_dict</span><span class="p">,</span>
                                                    <span class="bp">self</span><span class="o">.</span><span class="n">category_num_param_dict</span><span class="p">,</span>
                                                    <span class="bp">self</span><span class="o">.</span><span class="n">num_categories</span><span class="p">)</span>

    <span class="c1"># item coefficients.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">item_coef_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_coef_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">item_coef_variation_dict</span><span class="p">,</span>
                                                <span class="bp">self</span><span class="o">.</span><span class="n">item_num_param_dict</span><span class="p">,</span>
                                                <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">shared_lambda</span> <span class="o">=</span> <span class="n">shared_lambda</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">shared_lambda</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lambda_weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lambda_weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_categories</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="c1"># breakpoint()</span>
    <span class="c1"># self.iv_weights = nn.Parameter(torch.ones(1), requires_grad=True)</span>
    <span class="c1"># used to warn users if forgot to call clamp.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_clamp_called_flag</span> <span class="o">=</span> <span class="kc">True</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="torch_choice.model.nested_logit_model.NestedLogitModel.forward" class="doc doc-heading">
<code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>An standard forward method for the model, the user feeds a ChoiceDataset batch and the model returns the
    predicted log-likelihood tensor. The main forward passing happens in the _forward() method, but we provide
    this wrapper forward() method for a cleaner API, as forward() only requires a single batch argument.
    For more details about the forward passing, please refer to the _forward() method.</p>
<h6 id="torch_choice.model.nested_logit_model.NestedLogitModel.forward--todo-the-conditionalogitmodel-returns-predicted-utility-the-nestedlogitmodel-behaves-the-same">TODO: the ConditionaLogitModel returns predicted utility, the NestedLogitModel behaves the same?</h6>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>batch</code></td>
        <td><code>ChoiceDataset</code></td>
        <td><p>a ChoiceDataset object containing the data batch.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>torch.Tensor</code></td>
      <td><p>a tensor of shape (num_trips, num_items) including the log probability
of choosing item i in trip t.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>torch_choice/model/nested_logit_model.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">ChoiceDataset</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;An standard forward method for the model, the user feeds a ChoiceDataset batch and the model returns the</span>
<span class="sd">        predicted log-likelihood tensor. The main forward passing happens in the _forward() method, but we provide</span>
<span class="sd">        this wrapper forward() method for a cleaner API, as forward() only requires a single batch argument.</span>
<span class="sd">        For more details about the forward passing, please refer to the _forward() method.</span>

<span class="sd">    # TODO: the ConditionaLogitModel returns predicted utility, the NestedLogitModel behaves the same?</span>

<span class="sd">    Args:</span>
<span class="sd">        batch (ChoiceDataset): a ChoiceDataset object containing the data batch.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: a tensor of shape (num_trips, num_items) including the log probability</span>
<span class="sd">        of choosing item i in trip t.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s1">&#39;category&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">x_dict</span><span class="p">,</span>
                         <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;item&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">x_dict</span><span class="p">,</span>
                         <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;item&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">user_index</span><span class="p">,</span>
                         <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;item&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">item_availability</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="torch_choice.model.nested_logit_model.NestedLogitModel.log_likelihood" class="doc doc-heading">
<code class="highlight language-python"><span class="n">log_likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>Computes the log likelihood of the model, please refer to the negative_log_likelihood() method.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>_type_</code></td>
      <td><p>the log likelihood of the model.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>torch_choice/model/nested_logit_model.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">log_likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Computes the log likelihood of the model, please refer to the negative_log_likelihood() method.</span>

<span class="sd">    Returns:</span>
<span class="sd">        _type_: the log likelihood of the model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">negative_log_likelihood</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="torch_choice.model.nested_logit_model.NestedLogitModel.negative_log_likelihood" class="doc doc-heading">
<code class="highlight language-python"><span class="n">negative_log_likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">is_train</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>Computes the negative log likelihood of the model. Please note the log-likelihood is summed over all samples
    in batch instead of the average.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>batch</code></td>
        <td><code>ChoiceDataset</code></td>
        <td><p>the ChoiceDataset object containing the data.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>y</code></td>
        <td><code>torch.LongTensor</code></td>
        <td><p>the label.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>is_train</code></td>
        <td><code>bool</code></td>
        <td><p>which mode of the model to be used for the forward passing, if we need Hessian
of the NLL through auto-grad, <code>is_train</code> should be set to True. If we merely need a performance metric,
then <code>is_train</code> can be set to False for better performance.
Defaults to True.</p></td>
        <td><code>True</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>torch.scalar_tensor</code></td>
      <td><p>the negative log likelihood of the model.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>torch_choice/model/nested_logit_model.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">negative_log_likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                            <span class="n">batch</span><span class="p">:</span> <span class="n">ChoiceDataset</span><span class="p">,</span>
                            <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">,</span>
                            <span class="n">is_train</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">scalar_tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Computes the negative log likelihood of the model. Please note the log-likelihood is summed over all samples</span>
<span class="sd">        in batch instead of the average.</span>

<span class="sd">    Args:</span>
<span class="sd">        batch (ChoiceDataset): the ChoiceDataset object containing the data.</span>
<span class="sd">        y (torch.LongTensor): the label.</span>
<span class="sd">        is_train (bool, optional): which mode of the model to be used for the forward passing, if we need Hessian</span>
<span class="sd">            of the NLL through auto-grad, `is_train` should be set to True. If we merely need a performance metric,</span>
<span class="sd">            then `is_train` can be set to False for better performance.</span>
<span class="sd">            Defaults to True.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.scalar_tensor: the negative log likelihood of the model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># compute the negative log-likelihood loss directly.</span>
    <span class="k">if</span> <span class="n">is_train</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="c1"># (num_trips, num_items)</span>
    <span class="n">logP</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
    <span class="n">nll</span> <span class="o">=</span> <span class="o">-</span> <span class="n">logP</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)),</span> <span class="n">y</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">nll</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>







  </div>

    </div>

  </div>




  </div>

    </div>

  </div>




  </div>

    </div>

  </div>

              
            </article>
          </div>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        
        <a href="../test/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Compability Tests" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Compability Tests
            </div>
          </div>
        </a>
      
      
        
        <a href="../api_bemb/" class="md-footer__link md-footer__link--next" aria-label="Next: API Reference BEMB" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              API Reference BEMB
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.2a1c317c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.ed9748b7.min.js"></script>
      
        <script src="../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>