{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to torch-choice's documentation! Authors: Tianyu Du and Ayush Kanodia; PI: Susan Athey; Contact: tianyudu@stanford.edu What's this package? This is a fast and flexible PyTorch package to model choices, which offers an efficient data management and choice models accelerated by graphic processor units (GPUs). Why use torch-choice? With the growing size of choice datasets available, existing implementations of consumer choice modelling does not easily scale up modern datasets of millions of records. Our objective is to provide a versatile interface for managing choice dataset, a range of baseline models (the torch_choice part), and a Bayesian Embedding (i.e., BEMB) models for choice modeling that handle large-scale consumer choice datasets in modern research projects. What's in the package? The package includes a data management tool based on PyTorch 's dataset called ChoiceDataset . Our dataset implementation allows users to easily move data between CPU and GPU. Unlike traditional long or wide formats, the ChoiceDataset offers a memory-efficient way to manage observables. The package provides a (1) conditional logit model for consumer choice modeling, (2) a nested logit model for consumer choice modeling, and (3) a Bayesian Embedding (also known as probabilistic matrix factorization) model that builds latents for customers and items. The package leverage GPU acceleration using PyTorch and easily scale to large dataset of millions of choice records. All models are trained using state-of-the-art optimizers by in PyTorch. These optimization algorithms are tested to be scalable by modern machine learning practitioners. However, you can rest assure that the package runs flawlessly when no GPU is used as well. For those without much experience in model PyTorch development, setting up optimizers and training loops can be frustrating. We provide easy-to-use PyTorch lightning wrapper of models to free researchers from the hassle from setting up PyTorch optimizers and training loops.","title":"Home"},{"location":"#welcome-to-torch-choices-documentation","text":"Authors: Tianyu Du and Ayush Kanodia; PI: Susan Athey; Contact: tianyudu@stanford.edu","title":"Welcome to torch-choice's documentation!"},{"location":"#whats-this-package","text":"This is a fast and flexible PyTorch package to model choices, which offers an efficient data management and choice models accelerated by graphic processor units (GPUs).","title":"What's this package?"},{"location":"#why-use-torch-choice","text":"With the growing size of choice datasets available, existing implementations of consumer choice modelling does not easily scale up modern datasets of millions of records. Our objective is to provide a versatile interface for managing choice dataset, a range of baseline models (the torch_choice part), and a Bayesian Embedding (i.e., BEMB) models for choice modeling that handle large-scale consumer choice datasets in modern research projects.","title":"Why use torch-choice?"},{"location":"#whats-in-the-package","text":"The package includes a data management tool based on PyTorch 's dataset called ChoiceDataset . Our dataset implementation allows users to easily move data between CPU and GPU. Unlike traditional long or wide formats, the ChoiceDataset offers a memory-efficient way to manage observables. The package provides a (1) conditional logit model for consumer choice modeling, (2) a nested logit model for consumer choice modeling, and (3) a Bayesian Embedding (also known as probabilistic matrix factorization) model that builds latents for customers and items. The package leverage GPU acceleration using PyTorch and easily scale to large dataset of millions of choice records. All models are trained using state-of-the-art optimizers by in PyTorch. These optimization algorithms are tested to be scalable by modern machine learning practitioners. However, you can rest assure that the package runs flawlessly when no GPU is used as well. For those without much experience in model PyTorch development, setting up optimizers and training loops can be frustrating. We provide easy-to-use PyTorch lightning wrapper of models to free researchers from the hassle from setting up PyTorch optimizers and training loops.","title":"What's in the package?"},{"location":"api_bemb/","text":"API Reference: BEMB model special bayesian_coefficient Bayesian Coefficient is the building block for the BEMB model. Author: Tianyu Du Update: Apr. 28, 2022 BayesianCoefficient ( Module ) Source code in bemb/model/bayesian_coefficient.py class BayesianCoefficient ( nn . Module ): def __init__ ( self , variation : str , num_classes : int , obs2prior : bool , num_obs : Optional [ int ] = None , dim : int = 1 , prior_variance : float = 1.0 ) -> None : \"\"\"The Bayesian coefficient object represents a learnable tensor mu_i in R^k, where i is from a family (e.g., user, item) so there are num_classes * num_obs learnable weights in total. The prior distribution of mu_i is N(0, I) or N(H*X_obs(H shape=num_obs, X_obs shape=dim), Ix1). The posterior(i.e., variational) distribution of mu_i is a Gaussian distribution with learnable mean mu_i and unit covariance. The mean of the variational distribution consists of two parts: 1. The fixed part, which is not learnable. This part is particularly useful when the researcher want to impose some structure on the variational distribution. For example, the research might have some variational mean learned from another model and wish to use BEMB to polish the learned mean. 2. The flexible part, which is the main learnable part of the variational mean. Args: variation (str): the variation # TODO: this will be removed in the next version, after we have a complete test pipline. num_classes (int): number of classes in the coefficient. For example, if we have user-specific coefficients, `theta_user`, the `num_classes` should be the number of users. If we have item-specific coefficients, the the `num_classes` should be the number of items. obs2prior (bool): whether the mean of coefficient prior depends on the observable or not. num_obs (int, optional): the number of observables associated with each class. For example, if the coefficient if item-specific, and we have `obs2prior` set to True, the `num_obs` should be the number of observables for each item. Defaults to None. dim (int, optional): the dimension of the coefficient. Defaults to 1. prior_variance (float): the variance of the prior distribution of coefficient. Defaults to 1.0. \"\"\" super ( BayesianCoefficient , self ) . __init__ () # do we use this at all? TODO: drop self.variation. assert variation in [ 'item' , 'user' , 'constant' ] self . variation = variation self . obs2prior = obs2prior if variation == 'constant' : assert not obs2prior self . num_classes = num_classes self . num_obs = num_obs self . dim = dim # the dimension of greek letter parameter. self . prior_variance = prior_variance assert self . prior_variance > 0 # create prior distribution. if self . obs2prior : # the mean of prior distribution depends on observables. # initiate a Bayesian Coefficient with shape (dim, num_obs) standard Gaussian. self . prior_H = BayesianCoefficient ( variation = 'constant' , num_classes = dim , obs2prior = False , dim = num_obs , prior_variance = 1.0 ) else : self . register_buffer ( 'prior_zero_mean' , torch . zeros ( num_classes , dim )) # self.prior_cov_factor = nn.Parameter(torch.zeros(num_classes, dim, 1), requires_grad=False) # self.prior_cov_diag = nn.Parameter(torch.ones(num_classes, dim), requires_grad=False) self . register_buffer ( 'prior_cov_factor' , torch . zeros ( num_classes , dim , 1 )) self . register_buffer ( 'prior_cov_diag' , torch . ones ( num_classes , dim ) * self . prior_variance ) # create variational distribution. self . variational_mean_flexible = nn . Parameter ( torch . randn ( num_classes , dim ), requires_grad = True ) self . variational_logstd = nn . Parameter ( torch . randn ( num_classes , dim ), requires_grad = True ) self . register_buffer ( 'variational_cov_factor' , torch . zeros ( num_classes , dim , 1 )) self . variational_mean_fixed = None def __repr__ ( self ) -> str : \"\"\"Constructs a string representation of the Bayesian coefficient object. Returns: str: the string representation of the Bayesian coefficient object. \"\"\" if self . obs2prior : prior_str = f 'prior=N(H*X_obs(H shape= { self . prior_H . prior_zero_mean . shape } , X_obs shape= { self . prior_H . dim } ), Ix { self . prior_variance } )' else : prior_str = f 'prior=N(0, I)' return f 'BayesianCoefficient(num_classes= { self . num_classes } , dimension= { self . dim } , { prior_str } )' def update_variational_mean_fixed ( self , new_value : torch . Tensor ) -> None : \"\"\"Updates the fixed part of the mean of the variational distribution. Args: new_value (torch.Tensor): the new value of the fixed part of the mean of the variational distribution. \"\"\" assert new_value . shape == self . variational_mean_flexible . shape del self . variational_mean_fixed self . register_buffer ( 'variational_mean_fixed' , new_value ) @property def variational_mean ( self ) -> torch . Tensor : \"\"\"Returns the mean of the variational distribution. Returns: torch.Tensor: the current mean of the variational distribution with shape (num_classes, dim). \"\"\" if self . variational_mean_fixed is None : return self . variational_mean_flexible else : return self . variational_mean_fixed + self . variational_mean_flexible def log_prior ( self , sample : torch . Tensor , H_sample : Optional [ torch . Tensor ] = None , x_obs : Optional [ torch . Tensor ] = None ) -> torch . Tensor : \"\"\" Computes the logP_{Prior}(Coefficient Sample) for provided samples of the coefficient. The prior will either be a zero-mean Gaussian (if `obs2prior` is False) or a Gaussian with a learnable mean (if `obs2prior` is True). Args: sample (torch.Tensor): Monte Carlo samples of the variable with shape (num_seeds, num_classes, dim), where sample[i, :, :] corresponds to one sample of the coefficient. # arguments required only if `obs2prior == True`: H_sample (Optional[torch.Tensor], optional): Monte Carlo samples of the weight in obs2prior term, with shape (num_seeds, dim, self.num_obs), this is required if and only if obs2prior == True. Defaults to None. x_obs (Optional[torch.Tensor], optional): observables for obs2prior with shape (num_classes, num_obs), only required if and only if obs2prior == True. Defaults to None. Returns: torch.Tensor: the log prior of the variable with shape (num_seeds, num_classes). \"\"\" # p(sample) num_seeds , num_classes , dim = sample . shape # shape (num_seeds, num_classes) if self . obs2prior : assert H_sample . shape == ( num_seeds , dim , self . num_obs ) assert x_obs . shape == ( num_classes , self . num_obs ) x_obs = x_obs . view ( 1 , num_classes , self . num_obs ) . expand ( num_seeds , - 1 , - 1 ) H_sample = torch . transpose ( H_sample , 1 , 2 ) assert H_sample . shape == ( num_seeds , self . num_obs , dim ) mu = torch . bmm ( x_obs , H_sample ) assert mu . shape == ( num_seeds , num_classes , dim ) else : mu = self . prior_zero_mean out = LowRankMultivariateNormal ( loc = mu , cov_factor = self . prior_cov_factor , cov_diag = self . prior_cov_diag ) . log_prob ( sample ) assert out . shape == ( num_seeds , num_classes ) return out def log_variational ( self , sample : torch . Tensor ) -> torch . Tensor : \"\"\"Given a set of sampled values of coefficients, with shape (num_seeds, num_classes, dim), computes the the log probability of these sampled values of coefficients under the current variational distribution. Args: sample (torch.Tensor): a tensor of shape (num_seeds, num_classes, dim) containing sampled values of coefficients, where sample[i, :, :] corresponds to one sample of the coefficient. Returns: torch.Tensor: a tensor of shape (num_seeds, num_classes) containing the log probability of provided samples under the variational distribution. The output is splitted by random seeds and classes, you can sum along the second axis (i.e., the num_classes axis) to get the total log probability. \"\"\" num_seeds , num_classes , dim = sample . shape out = self . variational_distribution . log_prob ( sample ) assert out . shape == ( num_seeds , num_classes ) return out def rsample ( self , num_seeds : int = 1 ) -> Union [ torch . Tensor , Tuple [ torch . Tensor ]]: \"\"\"Samples values of the coefficient from the variational distribution using re-parameterization trick. Args: num_seeds (int, optional): number of values to be sampled. Defaults to 1. Returns: Union[torch.Tensor, Tuple[torch.Tensor]]: if `obs2prior` is disabled, returns a tensor of shape (num_seeds, num_classes, dim) where each output[i, :, :] corresponds to one sample of the coefficient. If `obs2prior` is enabled, returns a tuple of samples: (1) a tensor of shape (num_seeds, num_classes, dim) containing sampled values of coefficient, and (2) a tensor o shape (num_seeds, dim, num_obs) containing samples of the H weight in the prior distribution. \"\"\" value_sample = self . variational_distribution . rsample ( torch . Size ([ num_seeds ])) if self . obs2prior : # sample obs2prior H as well. H_sample = self . prior_H . rsample ( num_seeds = num_seeds ) return ( value_sample , H_sample ) else : return value_sample @property def variational_distribution ( self ) -> LowRankMultivariateNormal : \"\"\"Constructs the current variational distribution of the coefficient from current variational mean and covariance. \"\"\" return LowRankMultivariateNormal ( loc = self . variational_mean , cov_factor = self . variational_cov_factor , cov_diag = torch . exp ( self . variational_logstd )) @property def device ( self ) -> torch . device : \"\"\"Returns the device of tensors contained in this module.\"\"\" return self . variational_mean . device device : device property readonly Returns the device of tensors contained in this module. variational_distribution : LowRankMultivariateNormal property readonly Constructs the current variational distribution of the coefficient from current variational mean and covariance. variational_mean : Tensor property readonly Returns the mean of the variational distribution. Returns: Type Description torch.Tensor the current mean of the variational distribution with shape (num_classes, dim). __init__ ( self , variation , num_classes , obs2prior , num_obs = None , dim = 1 , prior_variance = 1.0 ) special The Bayesian coefficient object represents a learnable tensor mu_i in R^k, where i is from a family (e.g., user, item) so there are num_classes * num_obs learnable weights in total. The prior distribution of mu_i is N(0, I) or N(H*X_obs(H shape=num_obs, X_obs shape=dim), Ix1). The posterior(i.e., variational) distribution of mu_i is a Gaussian distribution with learnable mean mu_i and unit covariance. The mean of the variational distribution consists of two parts: 1. The fixed part, which is not learnable. This part is particularly useful when the researcher want to impose some structure on the variational distribution. For example, the research might have some variational mean learned from another model and wish to use BEMB to polish the learned mean. 2. The flexible part, which is the main learnable part of the variational mean. Parameters: Name Type Description Default variation str the variation # TODO: this will be removed in the next version, after we have a complete test pipline. required num_classes int number of classes in the coefficient. For example, if we have user-specific coefficients, theta_user , the num_classes should be the number of users. If we have item-specific coefficients, the the num_classes should be the number of items. required obs2prior bool whether the mean of coefficient prior depends on the observable or not. required num_obs int the number of observables associated with each class. For example, if the coefficient if item-specific, and we have obs2prior set to True, the num_obs should be the number of observables for each item. Defaults to None. None dim int the dimension of the coefficient. Defaults to 1. 1 prior_variance float the variance of the prior distribution of coefficient. Defaults to 1.0. 1.0 Source code in bemb/model/bayesian_coefficient.py def __init__ ( self , variation : str , num_classes : int , obs2prior : bool , num_obs : Optional [ int ] = None , dim : int = 1 , prior_variance : float = 1.0 ) -> None : \"\"\"The Bayesian coefficient object represents a learnable tensor mu_i in R^k, where i is from a family (e.g., user, item) so there are num_classes * num_obs learnable weights in total. The prior distribution of mu_i is N(0, I) or N(H*X_obs(H shape=num_obs, X_obs shape=dim), Ix1). The posterior(i.e., variational) distribution of mu_i is a Gaussian distribution with learnable mean mu_i and unit covariance. The mean of the variational distribution consists of two parts: 1. The fixed part, which is not learnable. This part is particularly useful when the researcher want to impose some structure on the variational distribution. For example, the research might have some variational mean learned from another model and wish to use BEMB to polish the learned mean. 2. The flexible part, which is the main learnable part of the variational mean. Args: variation (str): the variation # TODO: this will be removed in the next version, after we have a complete test pipline. num_classes (int): number of classes in the coefficient. For example, if we have user-specific coefficients, `theta_user`, the `num_classes` should be the number of users. If we have item-specific coefficients, the the `num_classes` should be the number of items. obs2prior (bool): whether the mean of coefficient prior depends on the observable or not. num_obs (int, optional): the number of observables associated with each class. For example, if the coefficient if item-specific, and we have `obs2prior` set to True, the `num_obs` should be the number of observables for each item. Defaults to None. dim (int, optional): the dimension of the coefficient. Defaults to 1. prior_variance (float): the variance of the prior distribution of coefficient. Defaults to 1.0. \"\"\" super ( BayesianCoefficient , self ) . __init__ () # do we use this at all? TODO: drop self.variation. assert variation in [ 'item' , 'user' , 'constant' ] self . variation = variation self . obs2prior = obs2prior if variation == 'constant' : assert not obs2prior self . num_classes = num_classes self . num_obs = num_obs self . dim = dim # the dimension of greek letter parameter. self . prior_variance = prior_variance assert self . prior_variance > 0 # create prior distribution. if self . obs2prior : # the mean of prior distribution depends on observables. # initiate a Bayesian Coefficient with shape (dim, num_obs) standard Gaussian. self . prior_H = BayesianCoefficient ( variation = 'constant' , num_classes = dim , obs2prior = False , dim = num_obs , prior_variance = 1.0 ) else : self . register_buffer ( 'prior_zero_mean' , torch . zeros ( num_classes , dim )) # self.prior_cov_factor = nn.Parameter(torch.zeros(num_classes, dim, 1), requires_grad=False) # self.prior_cov_diag = nn.Parameter(torch.ones(num_classes, dim), requires_grad=False) self . register_buffer ( 'prior_cov_factor' , torch . zeros ( num_classes , dim , 1 )) self . register_buffer ( 'prior_cov_diag' , torch . ones ( num_classes , dim ) * self . prior_variance ) # create variational distribution. self . variational_mean_flexible = nn . Parameter ( torch . randn ( num_classes , dim ), requires_grad = True ) self . variational_logstd = nn . Parameter ( torch . randn ( num_classes , dim ), requires_grad = True ) self . register_buffer ( 'variational_cov_factor' , torch . zeros ( num_classes , dim , 1 )) self . variational_mean_fixed = None __repr__ ( self ) special Constructs a string representation of the Bayesian coefficient object. Returns: Type Description str the string representation of the Bayesian coefficient object. Source code in bemb/model/bayesian_coefficient.py def __repr__ ( self ) -> str : \"\"\"Constructs a string representation of the Bayesian coefficient object. Returns: str: the string representation of the Bayesian coefficient object. \"\"\" if self . obs2prior : prior_str = f 'prior=N(H*X_obs(H shape= { self . prior_H . prior_zero_mean . shape } , X_obs shape= { self . prior_H . dim } ), Ix { self . prior_variance } )' else : prior_str = f 'prior=N(0, I)' return f 'BayesianCoefficient(num_classes= { self . num_classes } , dimension= { self . dim } , { prior_str } )' log_prior ( self , sample , H_sample = None , x_obs = None ) Computes the logP_{Prior}(Coefficient Sample) for provided samples of the coefficient. The prior will either be a zero-mean Gaussian (if obs2prior is False) or a Gaussian with a learnable mean (if obs2prior is True). Parameters: Name Type Description Default sample torch.Tensor Monte Carlo samples of the variable with shape (num_seeds, num_classes, dim), where sample[i, :, :] corresponds to one sample of the coefficient. required # arguments required only if `obs2prior == True` required H_sample Optional[torch.Tensor] Monte Carlo samples of the weight in obs2prior term, with shape (num_seeds, dim, self.num_obs), this is required if and only if obs2prior == True. Defaults to None. None x_obs Optional[torch.Tensor] observables for obs2prior with shape (num_classes, num_obs), only required if and only if obs2prior == True. Defaults to None. None Returns: Type Description torch.Tensor the log prior of the variable with shape (num_seeds, num_classes). Source code in bemb/model/bayesian_coefficient.py def log_prior ( self , sample : torch . Tensor , H_sample : Optional [ torch . Tensor ] = None , x_obs : Optional [ torch . Tensor ] = None ) -> torch . Tensor : \"\"\" Computes the logP_{Prior}(Coefficient Sample) for provided samples of the coefficient. The prior will either be a zero-mean Gaussian (if `obs2prior` is False) or a Gaussian with a learnable mean (if `obs2prior` is True). Args: sample (torch.Tensor): Monte Carlo samples of the variable with shape (num_seeds, num_classes, dim), where sample[i, :, :] corresponds to one sample of the coefficient. # arguments required only if `obs2prior == True`: H_sample (Optional[torch.Tensor], optional): Monte Carlo samples of the weight in obs2prior term, with shape (num_seeds, dim, self.num_obs), this is required if and only if obs2prior == True. Defaults to None. x_obs (Optional[torch.Tensor], optional): observables for obs2prior with shape (num_classes, num_obs), only required if and only if obs2prior == True. Defaults to None. Returns: torch.Tensor: the log prior of the variable with shape (num_seeds, num_classes). \"\"\" # p(sample) num_seeds , num_classes , dim = sample . shape # shape (num_seeds, num_classes) if self . obs2prior : assert H_sample . shape == ( num_seeds , dim , self . num_obs ) assert x_obs . shape == ( num_classes , self . num_obs ) x_obs = x_obs . view ( 1 , num_classes , self . num_obs ) . expand ( num_seeds , - 1 , - 1 ) H_sample = torch . transpose ( H_sample , 1 , 2 ) assert H_sample . shape == ( num_seeds , self . num_obs , dim ) mu = torch . bmm ( x_obs , H_sample ) assert mu . shape == ( num_seeds , num_classes , dim ) else : mu = self . prior_zero_mean out = LowRankMultivariateNormal ( loc = mu , cov_factor = self . prior_cov_factor , cov_diag = self . prior_cov_diag ) . log_prob ( sample ) assert out . shape == ( num_seeds , num_classes ) return out log_variational ( self , sample ) Given a set of sampled values of coefficients, with shape (num_seeds, num_classes, dim), computes the the log probability of these sampled values of coefficients under the current variational distribution. Parameters: Name Type Description Default sample torch.Tensor a tensor of shape (num_seeds, num_classes, dim) containing sampled values of coefficients, where sample[i, :, :] corresponds to one sample of the coefficient. required Returns: Type Description torch.Tensor a tensor of shape (num_seeds, num_classes) containing the log probability of provided samples under the variational distribution. The output is splitted by random seeds and classes, you can sum along the second axis (i.e., the num_classes axis) to get the total log probability. Source code in bemb/model/bayesian_coefficient.py def log_variational ( self , sample : torch . Tensor ) -> torch . Tensor : \"\"\"Given a set of sampled values of coefficients, with shape (num_seeds, num_classes, dim), computes the the log probability of these sampled values of coefficients under the current variational distribution. Args: sample (torch.Tensor): a tensor of shape (num_seeds, num_classes, dim) containing sampled values of coefficients, where sample[i, :, :] corresponds to one sample of the coefficient. Returns: torch.Tensor: a tensor of shape (num_seeds, num_classes) containing the log probability of provided samples under the variational distribution. The output is splitted by random seeds and classes, you can sum along the second axis (i.e., the num_classes axis) to get the total log probability. \"\"\" num_seeds , num_classes , dim = sample . shape out = self . variational_distribution . log_prob ( sample ) assert out . shape == ( num_seeds , num_classes ) return out rsample ( self , num_seeds = 1 ) Samples values of the coefficient from the variational distribution using re-parameterization trick. Parameters: Name Type Description Default num_seeds int number of values to be sampled. Defaults to 1. 1 Returns: Type Description Union[torch.Tensor, Tuple[torch.Tensor]] if obs2prior is disabled, returns a tensor of shape (num_seeds, num_classes, dim) where each output[i, :, :] corresponds to one sample of the coefficient. If obs2prior is enabled, returns a tuple of samples: (1) a tensor of shape (num_seeds, num_classes, dim) containing sampled values of coefficient, and (2) a tensor o shape (num_seeds, dim, num_obs) containing samples of the H weight in the prior distribution. Source code in bemb/model/bayesian_coefficient.py def rsample ( self , num_seeds : int = 1 ) -> Union [ torch . Tensor , Tuple [ torch . Tensor ]]: \"\"\"Samples values of the coefficient from the variational distribution using re-parameterization trick. Args: num_seeds (int, optional): number of values to be sampled. Defaults to 1. Returns: Union[torch.Tensor, Tuple[torch.Tensor]]: if `obs2prior` is disabled, returns a tensor of shape (num_seeds, num_classes, dim) where each output[i, :, :] corresponds to one sample of the coefficient. If `obs2prior` is enabled, returns a tuple of samples: (1) a tensor of shape (num_seeds, num_classes, dim) containing sampled values of coefficient, and (2) a tensor o shape (num_seeds, dim, num_obs) containing samples of the H weight in the prior distribution. \"\"\" value_sample = self . variational_distribution . rsample ( torch . Size ([ num_seeds ])) if self . obs2prior : # sample obs2prior H as well. H_sample = self . prior_H . rsample ( num_seeds = num_seeds ) return ( value_sample , H_sample ) else : return value_sample update_variational_mean_fixed ( self , new_value ) Updates the fixed part of the mean of the variational distribution. Parameters: Name Type Description Default new_value torch.Tensor the new value of the fixed part of the mean of the variational distribution. required Source code in bemb/model/bayesian_coefficient.py def update_variational_mean_fixed ( self , new_value : torch . Tensor ) -> None : \"\"\"Updates the fixed part of the mean of the variational distribution. Args: new_value (torch.Tensor): the new value of the fixed part of the mean of the variational distribution. \"\"\" assert new_value . shape == self . variational_mean_flexible . shape del self . variational_mean_fixed self . register_buffer ( 'variational_mean_fixed' , new_value ) bayesian_linear Bayesian tensor object. BayesianLinear ( Module ) Source code in bemb/model/bayesian_linear.py class BayesianLinear ( nn . Module ): def __init__ ( self , in_features : int , out_features : int , bias : bool = True , W_variational_mean_fixed : Optional [ torch . Tensor ] = None , device = None , dtype = None , W_prior_variance : float = 1.0 , b_prior_variance : float = 1.0 ): \"\"\"Linear layer where weight and bias are modelled as distributions. \"\"\" super () . __init__ () if dtype is not None : raise NotImplementedError ( 'dtype is not Supported yet.' ) self . in_features = in_features # the same as number of classes before. self . out_features = out_features # the same as latent dimension before. self . bias = bias # ============================================================================================================== # prior distributions for mean and bias. # ============================================================================================================== # the prior of weights are gausssian distributions independent across in_feature dimensions. self . register_buffer ( 'W_prior_mean' , torch . zeros ( in_features , out_features )) self . register_buffer ( 'W_prior_logstd' , torch . ones ( in_features , out_features ) * np . log ( W_prior_variance )) if self . bias : self . register_buffer ( 'b_prior_mean' , torch . zeros ( in_features , out_features )) self . register_buffer ( 'b_prior_logstd' , torch . ones ( in_features , out_features ) * np . log ( b_prior_variance )) # ============================================================================================================== # variational distributions for weight and bias. # ============================================================================================================== if W_variational_mean_fixed is None : self . W_variational_mean_fixed = None else : assert W_variational_mean_fixed . shape == ( in_features , out_features ), \\ f 'W_variational_mean_fixed tensor should have shape (in_features, out_features), got { W_variational_mean_fixed . shape } ' self . register_buffer ( 'W_variational_mean_fixed' , W_variational_mean_fixed ) # TODO: optionally add customizable initialization here. self . W_variational_mean_flexible = nn . Parameter ( torch . randn ( in_features , out_features ), requires_grad = True ) self . W_variational_logstd = nn . Parameter ( torch . randn ( in_features , out_features ), requires_grad = True ) if self . bias : self . b_variational_mean = nn . Parameter ( torch . randn ( out_features ), requires_grad = True ) self . b_variational_logstd = nn . Parameter ( torch . randn ( out_features ), requires_grad = True ) if device is not None : self . to ( device ) self . W_sample = None self . b_sample = None self . num_seeds = None @property def W_variational_mean ( self ): if self . W_variational_mean_fixed is None : return self . W_variational_mean_flexible else : return self . W_variational_mean_fixed + self . W_variational_mean_flexible def rsample ( self , num_seeds : int = 1 ) -> Optional [ Tuple [ torch . Tensor , Optional [ torch . Tensor ]]]: \"\"\"sample all parameters using re-parameterization trick. \"\"\" self . num_seeds = num_seeds self . W_sample = self . W_variational_distribution . rsample ( torch . Size ([ num_seeds ])) if self . bias : self . b_sample = self . b_variational_distribution . rsample ( torch . Size ([ num_seeds ])) return self . W_sample , self . b_sample def dsample ( self ): \"\"\"Deterministic sample method, set (W, b) sample to the mean of variational distribution.\"\"\" self . num_seeds = 1 self . W_sample = self . W_variational_mean . unsqueeze ( dim = 0 ) if self . bias : self . b_sample = self . b_variational_mean . unsqueeze ( dim = 0 ) return self . W_sample , self . b_sample def forward ( self , x , mode : str = 'multiply' ): \"\"\" Forward with weight sampling. Forward does out = XW + b, for forward() method behaves like the embedding layer in PyTorch, use the lookup() method. To have determinstic results, call self.dsample() before executing. To have stochastic results, call self.rsample() before executing. mode in ['multiply', 'lookup'] output shape: (num_seeds, batch_size, out_features). \"\"\" assert self . num_seeds is not None , 'run BayesianLinear.rsample() or dsample() first to sample weight and bias.' # if determinstic, num_seeds is set to 1. # w: (num_seeds, in_features=num_classes, out_features) # b: (num_seeds, out_features) # x: (N, in_features) if multiply and (N,) if lookup. # output: (num_seeds, N, out_features) if mode == 'multiply' : x = x . view ( 1 , - 1 , self . in_features ) . expand ( self . num_seeds , - 1 , - 1 ) # (num_seeds, N, in_features) out = x . bmm ( self . W_sample ) # (num_seeds, N, out_features) elif mode == 'lookup' : out = self . W_sample [:, x , :] # (num_seeds, N, out_features) else : raise ValueError ( f 'mode= { mode } is not allowed.' ) if self . bias : out += self . b_sample . view ( self . num_seeds , 1 , self . out_features ) # (num_seeds, N, out_features) return out @property def W_variational_distribution ( self ): \"\"\"the weight variational distribution.\"\"\" return Normal ( loc = self . W_variational_mean , scale = torch . exp ( self . W_variational_logstd )) @property def b_variational_distribution ( self ): return Normal ( loc = self . b_variational_mean , scale = torch . exp ( self . b_variational_logstd )) @property def device ( self ) -> torch . device : return self . W_variational_mean . device def log_prior ( self ): \"\"\"Evaluate the likelihood of the provided samples of parameter under the current prior distribution.\"\"\" assert self . num_seeds is not None , 'run BayesianLinear.rsample() or dsample() first to sample weight and bias.' num_seeds = self . W_sample . shape [ 0 ] total_log_prob = torch . zeros ( num_seeds , device = self . device ) # log P(W_sample). shape = (num_seeds,) W_prior = Normal ( loc = self . W_prior_mean , scale = torch . exp ( self . W_prior_logstd )) total_log_prob += W_prior . log_prob ( self . W_sample ) . sum ( dim = [ 1 , 2 ]) # log P(b_sample) if applicable. if self . bias : b_prior = Normal ( loc = self . b_prior_mean , scale = torch . exp ( self . b_prior_logstd )) total_log_prob += b_prior . log_prob ( self . b_sample ) . sum ( dim = 1 ) assert total_log_prob . shape == ( num_seeds ,) return total_log_prob def log_variational ( self ): \"\"\"Evaluate the likelihood of the provided samples of parameter under the current variational distribution.\"\"\" assert self . num_seeds is not None , 'run BayesianLinear.rsample() or dsample() first to sample weight and bias.' num_seeds = self . W_sample . shape [ 0 ] total_log_prob = torch . zeros ( num_seeds , device = self . device ) total_log_prob += self . W_variational_distribution . log_prob ( self . W_sample ) . sum ( dim = [ 1 , 2 ]) if self . bias : total_log_prob += self . b_variational_distribution . log_prob ( self . b_sample ) . sum ( dim = 1 ) assert total_log_prob . shape == ( num_seeds ,) return total_log_prob def __repr__ ( self ): prior_info = f 'W_prior ~ N(mu= { self . W_prior_mean } , logstd= { self . W_prior_logstd } )' if self . bias : prior_info += f 'b_prior ~ N(mu= { self . b_prior_mean } , logstd= { self . b_prior_logstd } )' return f \"BayesianLinear(in_features= { self . in_features } , out_features= { self . out_features } , bias= { self . bias } , { prior_info } )\" W_variational_distribution property readonly the weight variational distribution. __init__ ( self , in_features , out_features , bias = True , W_variational_mean_fixed = None , device = None , dtype = None , W_prior_variance = 1.0 , b_prior_variance = 1.0 ) special Linear layer where weight and bias are modelled as distributions. Source code in bemb/model/bayesian_linear.py def __init__ ( self , in_features : int , out_features : int , bias : bool = True , W_variational_mean_fixed : Optional [ torch . Tensor ] = None , device = None , dtype = None , W_prior_variance : float = 1.0 , b_prior_variance : float = 1.0 ): \"\"\"Linear layer where weight and bias are modelled as distributions. \"\"\" super () . __init__ () if dtype is not None : raise NotImplementedError ( 'dtype is not Supported yet.' ) self . in_features = in_features # the same as number of classes before. self . out_features = out_features # the same as latent dimension before. self . bias = bias # ============================================================================================================== # prior distributions for mean and bias. # ============================================================================================================== # the prior of weights are gausssian distributions independent across in_feature dimensions. self . register_buffer ( 'W_prior_mean' , torch . zeros ( in_features , out_features )) self . register_buffer ( 'W_prior_logstd' , torch . ones ( in_features , out_features ) * np . log ( W_prior_variance )) if self . bias : self . register_buffer ( 'b_prior_mean' , torch . zeros ( in_features , out_features )) self . register_buffer ( 'b_prior_logstd' , torch . ones ( in_features , out_features ) * np . log ( b_prior_variance )) # ============================================================================================================== # variational distributions for weight and bias. # ============================================================================================================== if W_variational_mean_fixed is None : self . W_variational_mean_fixed = None else : assert W_variational_mean_fixed . shape == ( in_features , out_features ), \\ f 'W_variational_mean_fixed tensor should have shape (in_features, out_features), got { W_variational_mean_fixed . shape } ' self . register_buffer ( 'W_variational_mean_fixed' , W_variational_mean_fixed ) # TODO: optionally add customizable initialization here. self . W_variational_mean_flexible = nn . Parameter ( torch . randn ( in_features , out_features ), requires_grad = True ) self . W_variational_logstd = nn . Parameter ( torch . randn ( in_features , out_features ), requires_grad = True ) if self . bias : self . b_variational_mean = nn . Parameter ( torch . randn ( out_features ), requires_grad = True ) self . b_variational_logstd = nn . Parameter ( torch . randn ( out_features ), requires_grad = True ) if device is not None : self . to ( device ) self . W_sample = None self . b_sample = None self . num_seeds = None dsample ( self ) Deterministic sample method, set (W, b) sample to the mean of variational distribution. Source code in bemb/model/bayesian_linear.py def dsample ( self ): \"\"\"Deterministic sample method, set (W, b) sample to the mean of variational distribution.\"\"\" self . num_seeds = 1 self . W_sample = self . W_variational_mean . unsqueeze ( dim = 0 ) if self . bias : self . b_sample = self . b_variational_mean . unsqueeze ( dim = 0 ) return self . W_sample , self . b_sample forward ( self , x , mode = 'multiply' ) Forward with weight sampling. Forward does out = XW + b, for forward() method behaves like the embedding layer in PyTorch, use the lookup() method. To have determinstic results, call self.dsample() before executing. To have stochastic results, call self.rsample() before executing. mode in ['multiply', 'lookup'] output shape: (num_seeds, batch_size, out_features). Source code in bemb/model/bayesian_linear.py def forward ( self , x , mode : str = 'multiply' ): \"\"\" Forward with weight sampling. Forward does out = XW + b, for forward() method behaves like the embedding layer in PyTorch, use the lookup() method. To have determinstic results, call self.dsample() before executing. To have stochastic results, call self.rsample() before executing. mode in ['multiply', 'lookup'] output shape: (num_seeds, batch_size, out_features). \"\"\" assert self . num_seeds is not None , 'run BayesianLinear.rsample() or dsample() first to sample weight and bias.' # if determinstic, num_seeds is set to 1. # w: (num_seeds, in_features=num_classes, out_features) # b: (num_seeds, out_features) # x: (N, in_features) if multiply and (N,) if lookup. # output: (num_seeds, N, out_features) if mode == 'multiply' : x = x . view ( 1 , - 1 , self . in_features ) . expand ( self . num_seeds , - 1 , - 1 ) # (num_seeds, N, in_features) out = x . bmm ( self . W_sample ) # (num_seeds, N, out_features) elif mode == 'lookup' : out = self . W_sample [:, x , :] # (num_seeds, N, out_features) else : raise ValueError ( f 'mode= { mode } is not allowed.' ) if self . bias : out += self . b_sample . view ( self . num_seeds , 1 , self . out_features ) # (num_seeds, N, out_features) return out log_prior ( self ) Evaluate the likelihood of the provided samples of parameter under the current prior distribution. Source code in bemb/model/bayesian_linear.py def log_prior ( self ): \"\"\"Evaluate the likelihood of the provided samples of parameter under the current prior distribution.\"\"\" assert self . num_seeds is not None , 'run BayesianLinear.rsample() or dsample() first to sample weight and bias.' num_seeds = self . W_sample . shape [ 0 ] total_log_prob = torch . zeros ( num_seeds , device = self . device ) # log P(W_sample). shape = (num_seeds,) W_prior = Normal ( loc = self . W_prior_mean , scale = torch . exp ( self . W_prior_logstd )) total_log_prob += W_prior . log_prob ( self . W_sample ) . sum ( dim = [ 1 , 2 ]) # log P(b_sample) if applicable. if self . bias : b_prior = Normal ( loc = self . b_prior_mean , scale = torch . exp ( self . b_prior_logstd )) total_log_prob += b_prior . log_prob ( self . b_sample ) . sum ( dim = 1 ) assert total_log_prob . shape == ( num_seeds ,) return total_log_prob log_variational ( self ) Evaluate the likelihood of the provided samples of parameter under the current variational distribution. Source code in bemb/model/bayesian_linear.py def log_variational ( self ): \"\"\"Evaluate the likelihood of the provided samples of parameter under the current variational distribution.\"\"\" assert self . num_seeds is not None , 'run BayesianLinear.rsample() or dsample() first to sample weight and bias.' num_seeds = self . W_sample . shape [ 0 ] total_log_prob = torch . zeros ( num_seeds , device = self . device ) total_log_prob += self . W_variational_distribution . log_prob ( self . W_sample ) . sum ( dim = [ 1 , 2 ]) if self . bias : total_log_prob += self . b_variational_distribution . log_prob ( self . b_sample ) . sum ( dim = 1 ) assert total_log_prob . shape == ( num_seeds ,) return total_log_prob rsample ( self , num_seeds = 1 ) sample all parameters using re-parameterization trick. Source code in bemb/model/bayesian_linear.py def rsample ( self , num_seeds : int = 1 ) -> Optional [ Tuple [ torch . Tensor , Optional [ torch . Tensor ]]]: \"\"\"sample all parameters using re-parameterization trick. \"\"\" self . num_seeds = num_seeds self . W_sample = self . W_variational_distribution . rsample ( torch . Size ([ num_seeds ])) if self . bias : self . b_sample = self . b_variational_distribution . rsample ( torch . Size ([ num_seeds ])) return self . W_sample , self . b_sample bemb The core class of the Bayesian EMBedding (BEMB) model. Author: Tianyu Du Update: Apr. 28, 2022 BEMBFlex ( Module ) Source code in bemb/model/bemb.py class BEMBFlex ( nn . Module ): # ================================================================================================================== # core function as a PyTorch module. # ================================================================================================================== def __init__ ( self , utility_formula : str , obs2prior_dict : Dict [ str , bool ], coef_dim_dict : Dict [ str , int ], num_items : int , pred_item : bool , prior_variance : Union [ float , Dict [ str , float ]] = 1.0 , num_users : Optional [ int ] = None , num_sessions : Optional [ int ] = None , trace_log_q : bool = False , category_to_item : Dict [ int , List [ int ]] = None , # number of observables. num_user_obs : Optional [ int ] = None , num_item_obs : Optional [ int ] = None , num_session_obs : Optional [ int ] = None , num_price_obs : Optional [ int ] = None , num_taste_obs : Optional [ int ] = None , # additional modules. additional_modules : Optional [ List [ nn . Module ]] = None ) -> None : \"\"\" Args: utility_formula (str): a string representing the utility function U[user, item, session]. See documentation for more details in the documentation for the format of formula. Examples: lambda_item lambda_item + theta_user * alpha_item + zeta_user * item_obs lambda_item + theta_user * alpha_item + gamma_user * beta_item * price_obs See the doc-string of parse_utility for an example. obs2prior_dict (Dict[str, bool]): a dictionary maps coefficient name (e.g., 'lambda_item') to a boolean indicating if observable (e.g., item_obs) enters the prior of the coefficient. coef_dim_dict (Dict[str, int]): a dictionary maps coefficient name (e.g., 'lambda_item') to an integer indicating the dimension of coefficient. For standalone coefficients like U = lambda_item, the dim should be 1. For factorized coefficients like U = theta_user * alpha_item, the dim should be the latent dimension of theta and alpha. For coefficients multiplied with observables like U = zeta_user * item_obs, the dim should be the number of observables in item_obs. For factorized coefficient multiplied with observables like U = gamma_user * beta_item * price_obs, the dim should be the latent dim multiplied by number of observables in price_obs. num_items (int): number of items. pred_item (bool): there are two use cases of this model, suppose we have `user_index[i]` and `item_index[i]` for the i-th observation in the dataset. Case 1: which item among all items user `user_index[i]` is going to purchase, the prediction label is therefore `item_index[i]`. Equivalently, we can ask what's the likelihood for user `user_index[i]` to purchase `item_index[i]`. Case 2: what rating would user `user_index[i]` assign to item `item_index[i]`? In this case, the dataset object needs to contain a separate label. NOTE: for now, we only support binary labels. prior_variance (Union[float, Dict[str, float]]): the variance of prior distribution for coefficients. If a float is provided, all priors will be diagonal matrix with prior_variance along the diagonal. If a dictionary is provided, keys of prior_variance should be coefficient names, and the variance of prior of coef_name would be a diagonal matrix with prior_variance[coef_name] along the diagonal. Defaults to 1.0, which means all prior have identity matrix as the covariance matrix. num_users (int, optional): number of users, required only if coefficient or observable depending on user is in utility. Defaults to None. num_sessions (int, optional): number of sessions, required only if coefficient or observable depending on session is in utility. Defaults to None. trace_log_q (bool, optional): whether to trace the derivative of variational likelihood logQ with respect to variational parameters in the ELBO while conducting gradient update. Defaults to False. category_to_item (Dict[str, List[int]], optional): a dictionary with category id or name as keys, and category_to_item[C] contains the list of item ids belonging to category C. If None is provided, all items are assumed to be in the same category. Defaults to None. num_{user, item, session, price, taste}_obs (int, optional): number of observables of each type of features, only required if observable enters prior. NOTE: currently we only allow coefficient to depend on either user or item, thus only user and item observables can enter the prior of coefficient. Hence session, price, and taste observables are never required, we include it here for completeness. \"\"\" super ( BEMBFlex , self ) . __init__ () self . utility_formula = utility_formula self . obs2prior_dict = obs2prior_dict self . coef_dim_dict = coef_dim_dict self . prior_variance = prior_variance self . pred_item = pred_item self . num_items = num_items self . num_users = num_users self . num_sessions = num_sessions self . trace_log_q = trace_log_q self . category_to_item = category_to_item # ============================================================================================================== # Category ID to Item ID mapping. # Category ID to Category Size mapping. # Item ID to Category ID mapping. # ============================================================================================================== if self . category_to_item is None : if self . pred_item : # assign all items to the same category if predicting items. self . category_to_item = { 0 : list ( np . arange ( self . num_items ))} else : # otherwise, for the j-th observation in the dataset, the label[j] # only depends on user_index[j] and item_index[j], so we put each # item to its own category. self . category_to_item = { i : [ i ] for i in range ( self . num_items )} self . num_categories = len ( self . category_to_item ) max_category_size = max ( len ( x ) for x in self . category_to_item . values ()) category_to_item_tensor = torch . full ( ( self . num_categories , max_category_size ), - 1 ) category_to_size_tensor = torch . empty ( self . num_categories ) for c , item_in_c in self . category_to_item . items (): category_to_item_tensor [ c , : len ( item_in_c )] = torch . LongTensor ( item_in_c ) category_to_size_tensor [ c ] = torch . scalar_tensor ( len ( item_in_c )) self . register_buffer ( 'category_to_item_tensor' , category_to_item_tensor . long ()) self . register_buffer ( 'category_to_size_tensor' , category_to_size_tensor . long ()) item_to_category_tensor = torch . zeros ( self . num_items ) for c , items_in_c in self . category_to_item . items (): item_to_category_tensor [ items_in_c ] = c self . register_buffer ( 'item_to_category_tensor' , item_to_category_tensor . long ()) # ============================================================================================================== # Create Bayesian Coefficient Objects # ============================================================================================================== # model configuration. self . formula = parse_utility ( utility_formula ) print ( 'BEMB: utility formula parsed:' ) pprint ( self . formula ) self . raw_formula = utility_formula self . obs2prior_dict = obs2prior_dict # dimension of each observable, this one is used only for obs2prior. self . num_obs_dict = { 'user' : num_user_obs , 'item' : num_item_obs , 'session' : num_session_obs , 'price' : num_price_obs , 'taste' : num_taste_obs , 'constant' : 1 # not really used, for dummy variables. } # how many classes for the variational distribution. # for example, beta_item would be `num_items` 10-dimensional gaussian if latent dim = 10. variation_to_num_classes = { 'user' : self . num_users , 'item' : self . num_items , 'constant' : 1 } coef_dict = dict () for additive_term in self . formula : for coef_name in additive_term [ 'coefficient' ]: variation = coef_name . split ( '_' )[ - 1 ] s2 = self . prior_variance [ coef_name ] if isinstance ( self . prior_variance , dict ) else self . prior_variance coef_dict [ coef_name ] = BayesianCoefficient ( variation = variation , num_classes = variation_to_num_classes [ variation ], obs2prior = self . obs2prior_dict [ coef_name ], num_obs = self . num_obs_dict [ variation ], dim = self . coef_dim_dict [ coef_name ], prior_variance = s2 ) self . coef_dict = nn . ModuleDict ( coef_dict ) # ============================================================================================================== # Optional: register additional modules. # ============================================================================================================== if additional_modules is None : self . additional_modules = [] else : raise NotImplementedError ( 'Additional modules are temporarily disabled for further development.' ) self . additional_modules = nn . ModuleList ( additional_modules ) def __str__ ( self ): return f 'Bayesian EMBedding Model with U[user, item, session] = { self . raw_formula } \\n ' \\ + f 'Total number of parameters: { self . num_params } . \\n ' \\ + 'With the following coefficients: \\n ' \\ + str ( self . coef_dict ) + ' \\n ' \\ + str ( self . additional_modules ) def posterior_mean ( self , coef_name : str ) -> torch . Tensor : \"\"\"Returns the mean of estimated posterior distribution of coefficient `coef_name`. Args: coef_name (str): name of the coefficient to query. Returns: torch.Tensor: mean of the estimated posterior distribution of `coef_name`. \"\"\" if coef_name in self . coef_dict . keys (): return self . coef_dict [ coef_name ] . variational_mean else : raise KeyError ( f ' { coef_name } is not a valid coefficient name in { self . utility_formula } .' ) def forward ( self , batch : ChoiceDataset , return_type : str , return_scope : str , deterministic : bool = True , sample_dict : Optional [ Dict [ str , torch . Tensor ]] = None , num_seeds : Optional [ int ] = None ) -> torch . Tensor : \"\"\"A combined method for inference with the model. Args: batch (ChoiceDataset): batch data containing choice information. return_type (str): either 'log_prob' or 'utility'. 'log_prob': return the log-probability (by within-category log-softmax) for items 'utility': return the utility value of items. return_scope (str): either 'item_index' or 'all_items'. 'item_index': for each observation i, return log-prob/utility for the chosen item batch.item_index[i] only. 'all_items': for each observation i, return log-prob/utility for all items. deterministic (bool, optional): True: expectations of parameter variational distributions are used for inference. False: the user needs to supply a dictionary of sampled parameters for inference. Defaults to True. sample_dict (Optional[Dict[str, torch.Tensor]], optional): sampled parameters for inference task. This is not needed when `deterministic` is True. When `deterministic` is False, the user can supply a `sample_dict`. If `sample_dict` is not provided, this method will create `num_seeds` samples. Defaults to None. num_seeds (Optional[int]): the number of random samples of parameters to construct. This is only required if `deterministic` is False (i.e., stochastic mode) and `sample_dict` is not provided. Defaults to None. Returns: torch.Tensor: a tensor of log-probabilities or utilities, depending on `return_type`. The shape of the returned tensor depends on `return_scope` and `deterministic`. ------------------------------------------------------------------------- | `return_scope` | `deterministic` | Output shape | ------------------------------------------------------------------------- | 'item_index` | True | (len(batch),) | ------------------------------------------------------------------------- | 'all_items' | True | (len(batch), num_items) | ------------------------------------------------------------------------- | 'item_index' | False | (num_seeds, len(batch)) | ------------------------------------------------------------------------- | 'all_items' | False | (num_seeds, len(batch), num_items) | ------------------------------------------------------------------------- \"\"\" # ============================================================================================================== # check arguments. # ============================================================================================================== assert return_type in [ 'log_prob' , 'utility' ], \"return_type must be either 'log_prob' or 'utility'.\" assert return_scope in [ 'item_index' , 'all_items' ], \"return_scope must be either 'item_index' or 'all_items'.\" assert deterministic in [ True , False ] if ( not deterministic ) and ( sample_dict is None ): assert num_seeds >= 1 , \"A positive interger `num_seeds` is required if `deterministic` is False and no `sample_dict` is provided.\" # when pred_item is true, the model is predicting which item is bought (specified by item_index). if self . pred_item : batch . label = batch . item_index # ============================================================================================================== # get sample_dict ready. # ============================================================================================================== if deterministic : num_seeds = 1 # Use the means of variational distributions as the sole deterministic MC sample. # NOTE: here we don't need to sample the obs2prior weight H since we only compute the log-likelihood. # TODO: is this correct? sample_dict = dict () for coef_name , coef in self . coef_dict . items (): sample_dict [ coef_name ] = coef . variational_distribution . mean . unsqueeze ( dim = 0 ) # (1, num_*, dim) else : if sample_dict is None : # sample stochastic parameters. sample_dict = self . sample_coefficient_dictionary ( num_seeds ) else : # use the provided sample_dict. num_seeds = list ( sample_dict . values ())[ 0 ] . shape [ 0 ] # ============================================================================================================== # call the sampling method of additional modules. # ============================================================================================================== for module in self . additional_modules : # deterministic sample. if deterministic : module . dsample () else : module . rsample ( num_seeds = num_seeds ) # if utility is requested, don't run log-softmax, simply return logit. return_logit = ( return_type == 'utility' ) if return_scope == 'all_items' : # (num_seeds, len(batch), num_items) out = self . log_likelihood_all_items ( batch = batch , sample_dict = sample_dict , return_logit = return_logit ) elif return_scope == 'item_index' : # (num_seeds, len(batch)) out = self . log_likelihood_item_index ( batch = batch , sample_dict = sample_dict , return_logit = return_logit ) if deterministic : # drop the first dimension, which has size of `num_seeds` (equals 1 in the deterministic case). # (len(batch), num_items) or (len(batch),) return out . squeeze ( dim = 0 ) return out @property def num_params ( self ) -> int : return sum ([ p . numel () for p in self . parameters ()]) @property def device ( self ) -> torch . device : for coef in self . coef_dict . values (): return coef . device # ================================================================================================================== # helper functions. # ================================================================================================================== def sample_coefficient_dictionary ( self , num_seeds : int ) -> Dict [ str , torch . Tensor ]: \"\"\"A helper function to sample parameters from coefficients. Args: num_seeds (int): number of random samples. Returns: Dict[str, torch.Tensor]: a dictionary maps coefficient names to tensor of sampled coefficient parameters, where the first dimension of the sampled tensor has size `num_seeds`. Each sample tensor has shape (num_seeds, num_classes, dim). \"\"\" sample_dict = dict () for coef_name , coef in self . coef_dict . items (): s = coef . rsample ( num_seeds ) if coef . obs2prior : # sample both obs2prior weight and realization of variable. assert isinstance ( s , tuple ) and len ( s ) == 2 sample_dict [ coef_name ] = s [ 0 ] sample_dict [ coef_name + '.H' ] = s [ 1 ] else : # only sample the realization of variable. assert torch . is_tensor ( s ) sample_dict [ coef_name ] = s return sample_dict @torch . no_grad () def get_within_category_accuracy ( self , log_p_all_items : torch . Tensor , label : torch . LongTensor ) -> Dict [ str , float ]: \"\"\"A helper function for computing prediction accuracy (i.e., all non-differential metrics) within category. In particular, this method calculates the accuracy, precision, recall and F1 score. This method has the same functionality as the following peusodcode: for C in categories: # get sessions in which item in category C was purchased. T <- (t for t in {0,1,..., len(label)-1} if label[t] is in C) Y <- label[T] predictions = list() for t in T: # get the prediction within category for this session. y_pred = argmax_{items in C} log prob computed before. predictions.append(y_pred) accuracy = mean(Y == predictions) Similarly, this function computes precision, recall and f1score as well. Args: log_p_all_items (torch.Tensor): shape (num_sessions, num_items) the log probability of choosing each item in each session. label (torch.LongTensor): shape (num_sessions,), the IDs of items purchased in each session. Returns: [Dict[str, float]]: A dictionary containing performance metrics. \"\"\" # argmax: (num_sessions, num_categories), within category argmax. # item IDs are consecutive, thus argmax is the same as IDs of the item with highest P. _ , argmax_by_category = scatter_max ( log_p_all_items , self . item_to_category_tensor , dim =- 1 ) # category_purchased[t] = the category of item label[t]. # (num_sessions,) category_purchased = self . item_to_category_tensor [ label ] # pred[t] = the item with highest utility from the category item label[t] belongs to. # (num_sessions,) pred_from_category = argmax_by_category [ torch . arange ( len ( label )), category_purchased ] within_category_accuracy = ( pred_from_category == label ) . float () . mean () . item () # precision precision = list () recall = list () for i in range ( self . num_items ): correct_i = torch . sum ( ( torch . logical_and ( pred_from_category == i , label == i )) . float ()) precision_i = correct_i / \\ torch . sum (( pred_from_category == i ) . float ()) recall_i = correct_i / torch . sum (( label == i ) . float ()) # do not add if divided by zero. if torch . any ( pred_from_category == i ): precision . append ( precision_i . cpu () . item ()) if torch . any ( label == i ): recall . append ( recall_i . cpu () . item ()) precision = float ( np . mean ( precision )) recall = float ( np . mean ( recall )) if precision == recall == 0 : f1 = 0 else : f1 = 2 * precision * recall / ( precision + recall ) return { 'accuracy' : within_category_accuracy , 'precision' : precision , 'recall' : recall , 'f1score' : f1 } # ================================================================================================================== # Methods for terms in the ELBO: prior, likelihood, and variational. # ================================================================================================================== def log_likelihood_all_items ( self , batch : ChoiceDataset , return_logit : bool , sample_dict : Dict [ str , torch . Tensor ]) -> torch . Tensor : \"\"\" NOTE to developers: This method computes utilities for all items available, which is a relatively slow operation. For training the model, you only need the utility/log-prob for the chosen/relevant item (i.e., item_index[i] for each i-th observation). Use this method for inference only. Use self.log_likelihood_item_index() for training instead. Computes the log probability of choosing `each` item in each session based on current model parameters. This method allows for specifying {user, item}_latent_value for Monte Carlo estimation in ELBO. For actual prediction tasks, use the forward() function, which will use means of variational distributions for user and item latents. Args: batch (ChoiceDataset): a ChoiceDataset object containing relevant information. return_logit(bool): if set to True, return the log-probability, otherwise return the logit/utility. sample_dict(Dict[str, torch.Tensor]): Monte Carlo samples for model coefficients (i.e., those Greek letters). sample_dict.keys() should be the same as keys of self.obs2prior_dict, i.e., those greek letters actually enter the functional form of utility. The value of sample_dict should be tensors of shape (num_seeds, num_classes, dim) where num_classes in {num_users, num_items, 1} and dim in {latent_dim(K), num_item_obs, num_user_obs, 1}. Returns: torch.Tensor: a tensor of shape (num_seeds, len(batch), self.num_items), where out[x, y, z] is the probability of choosing item z in session y conditioned on latents to be the x-th Monte Carlo sample. \"\"\" num_seeds = next ( iter ( sample_dict . values ())) . shape [ 0 ] # avoid repeated work when user purchased several items in the same session. user_session_index = torch . stack ( [ batch . user_index , batch . session_index ]) assert user_session_index . shape == ( 2 , len ( batch )) unique_user_sess , inverse_indices = torch . unique ( user_session_index , dim = 1 , return_inverse = True ) user_index = unique_user_sess [ 0 , :] session_index = unique_user_sess [ 1 , :] assert len ( user_index ) == len ( session_index ) # short-hands for easier shape check. R = num_seeds # P = len(batch) # num_purchases. P = unique_user_sess . shape [ 1 ] S = self . num_sessions U = self . num_users I = self . num_items # ============================================================================================================== # Helper Functions for Reshaping. # ============================================================================================================== def reshape_user_coef_sample ( C ): # input shape (R, U, *) C = C . view ( R , U , 1 , - 1 ) . expand ( - 1 , - 1 , I , - 1 ) # (R, U, I, *) C = C [:, user_index , :, :] assert C . shape == ( R , P , I , positive_integer ) return C def reshape_item_coef_sample ( C ): # input shape (R, I, *) C = C . view ( R , 1 , I , - 1 ) . expand ( - 1 , P , - 1 , - 1 ) assert C . shape == ( R , P , I , positive_integer ) return C def reshape_constant_coef_sample ( C ): # input shape (R, *) C = C . view ( R , 1 , 1 , - 1 ) . expand ( - 1 , P , I , - 1 ) assert C . shape == ( R , P , I , positive_integer ) return C def reshape_coef_sample ( sample , name ): # reshape the monte carlo sample of coefficients to (R, P, I, *). if name . endswith ( '_user' ): # (R, U, *) --> (R, P, I, *) return reshape_user_coef_sample ( sample ) elif name . endswith ( '_item' ): # (R, I, *) --> (R, P, I, *) return reshape_item_coef_sample ( sample ) elif name . endswith ( '_constant' ): # (R, *) --> (R, P, I, *) return reshape_constant_coef_sample ( sample ) else : raise ValueError def reshape_observable ( obs , name ): # reshape observable to (R, P, I, *) so that it can be multiplied with monte carlo # samples of coefficients. O = obs . shape [ - 1 ] # number of observables. assert O == positive_integer if name . startswith ( 'item_' ): assert obs . shape == ( I , O ) obs = obs . view ( 1 , 1 , I , O ) . expand ( R , P , - 1 , - 1 ) elif name . startswith ( 'user_' ): assert obs . shape == ( U , O ) obs = obs [ user_index , :] # (P, O) obs = obs . view ( 1 , P , 1 , O ) . expand ( R , - 1 , I , - 1 ) elif name . startswith ( 'session_' ): assert obs . shape == ( S , O ) obs = obs [ session_index , :] # (P, O) return obs . view ( 1 , P , 1 , O ) . expand ( R , - 1 , I , - 1 ) elif name . startswith ( 'price_' ): assert obs . shape == ( S , I , O ) obs = obs [ session_index , :, :] # (P, I, O) return obs . view ( 1 , P , I , O ) . expand ( R , - 1 , - 1 , - 1 ) elif name . startswith ( 'taste_' ): assert obs . shape == ( U , I , O ) obs = obs [ user_index , :, :] # (P, I, O) return obs . view ( 1 , P , I , O ) . expand ( R , - 1 , - 1 , - 1 ) else : raise ValueError assert obs . shape == ( R , P , I , O ) return obs # ============================================================================================================== # Copmute the Utility Term by Term. # ============================================================================================================== # P is the number of unique (user, session) pairs. # (random_seeds, P, num_items). utility = torch . zeros ( R , P , I , device = self . device ) # loop over additive term to utility for term in self . formula : # Type I: single coefficient, e.g., lambda_item or lambda_user. if len ( term [ 'coefficient' ]) == 1 and term [ 'observable' ] is None : # E.g., lambda_item or lambda_user coef_name = term [ 'coefficient' ][ 0 ] coef_sample = reshape_coef_sample ( sample_dict [ coef_name ], coef_name ) assert coef_sample . shape == ( R , P , I , 1 ) additive_term = coef_sample . view ( R , P , I ) # Type II: factorized coefficient, e.g., <theta_user, lambda_item>. elif len ( term [ 'coefficient' ]) == 2 and term [ 'observable' ] is None : coef_name_0 = term [ 'coefficient' ][ 0 ] coef_name_1 = term [ 'coefficient' ][ 1 ] coef_sample_0 = reshape_coef_sample ( sample_dict [ coef_name_0 ], coef_name_0 ) coef_sample_1 = reshape_coef_sample ( sample_dict [ coef_name_1 ], coef_name_1 ) assert coef_sample_0 . shape == coef_sample_1 . shape == ( R , P , I , positive_integer ) additive_term = ( coef_sample_0 * coef_sample_1 ) . sum ( dim =- 1 ) # Type III: single coefficient multiplied by observable, e.g., theta_user * x_obs_item. elif len ( term [ 'coefficient' ]) == 1 and term [ 'observable' ] is not None : coef_name = term [ 'coefficient' ][ 0 ] coef_sample = reshape_coef_sample ( sample_dict [ coef_name ], coef_name ) assert coef_sample . shape == ( R , P , I , positive_integer ) obs_name = term [ 'observable' ] obs = reshape_observable ( getattr ( batch , obs_name ), obs_name ) assert obs . shape == ( R , P , I , positive_integer ) additive_term = ( coef_sample * obs ) . sum ( dim =- 1 ) # Type IV: factorized coefficient multiplied by observable. # e.g., gamma_user * beta_item * price_obs. elif len ( term [ 'coefficient' ]) == 2 and term [ 'observable' ] is not None : coef_name_0 , coef_name_1 = term [ 'coefficient' ][ 0 ], term [ 'coefficient' ][ 1 ] coef_sample_0 = reshape_coef_sample ( sample_dict [ coef_name_0 ], coef_name_0 ) coef_sample_1 = reshape_coef_sample ( sample_dict [ coef_name_1 ], coef_name_1 ) assert coef_sample_0 . shape == coef_sample_1 . shape == ( R , P , I , positive_integer ) num_obs_times_latent_dim = coef_sample_0 . shape [ - 1 ] obs_name = term [ 'observable' ] obs = reshape_observable ( getattr ( batch , obs_name ), obs_name ) assert obs . shape == ( R , P , I , positive_integer ) num_obs = obs . shape [ - 1 ] # number of observables. assert ( num_obs_times_latent_dim % num_obs ) == 0 latent_dim = num_obs_times_latent_dim // num_obs coef_sample_0 = coef_sample_0 . view ( R , P , I , num_obs , latent_dim ) coef_sample_1 = coef_sample_1 . view ( R , P , I , num_obs , latent_dim ) # compute the factorized coefficient with shape (R, P, I, O). coef = ( coef_sample_0 * coef_sample_1 ) . sum ( dim =- 1 ) additive_term = ( coef * obs ) . sum ( dim =- 1 ) else : raise ValueError ( f 'Undefined term type: { term } ' ) assert additive_term . shape == ( R , P , I ) utility += additive_term # ============================================================================================================== # Mask Out Unavailable Items in Each Session. # ============================================================================================================== if batch . item_availability is not None : # expand to the Monte Carlo sample dimension. # (S, I) -> (P, I) -> (1, P, I) -> (R, P, I) A = batch . item_availability [ session_index , :] . unsqueeze ( dim = 0 ) . expand ( R , - 1 , - 1 ) utility [ ~ A ] = - ( torch . finfo ( utility . dtype ) . max / 2 ) utility = utility [:, inverse_indices , :] assert utility . shape == ( R , len ( batch ), I ) for module in self . additional_modules : additive_term = module ( batch ) assert additive_term . shape == ( R , len ( batch ), 1 ) utility += additive_term . expand ( - 1 , - 1 , I ) if return_logit : # output shape: (num_seeds, len(batch), num_items) return utility else : # compute log likelihood log p(choosing item i | user, item latents) # compute log softmax separately within each category. log_p = scatter_log_softmax ( utility , self . item_to_category_tensor , dim =- 1 ) # output shape: (num_seeds, len(batch), num_items) return log_p def log_likelihood_item_index ( self , batch : ChoiceDataset , return_logit : bool , sample_dict : Dict [ str , torch . Tensor ]) -> torch . Tensor : \"\"\" NOTE for developers: This method is more efficient and only computes log-likelihood/logit(utility) for item in item_index[i] for each i-th observation. Developers should use use `log_likelihood_all_items` for inference purpose and to computes log-likelihoods/utilities for ALL items for the i-th observation. Computes the log probability of choosing item_index[i] in each session based on current model parameters. This method allows for specifying {user, item}_latent_value for Monte Carlo estimation in ELBO. For actual prediction tasks, use the forward() function, which will use means of variational distributions for user and item latents. Args: batch (ChoiceDataset): a ChoiceDataset object containing relevant information. return_logit(bool): if set to True, return the log-probability, otherwise return the logit/utility. sample_dict(Dict[str, torch.Tensor]): Monte Carlo samples for model coefficients (i.e., those Greek letters). sample_dict.keys() should be the same as keys of self.obs2prior_dict, i.e., those greek letters actually enter the functional form of utility. The value of sample_dict should be tensors of shape (num_seeds, num_classes, dim) where num_classes in {num_users, num_items, 1} and dim in {latent_dim(K), num_item_obs, num_user_obs, 1}. Returns: torch.Tensor: a tensor of shape (num_seeds, len(batch)), where out[x, y] is the probabilities of choosing item batch.item[y] in session y conditioned on latents to be the x-th Monte Carlo sample. \"\"\" num_seeds = next ( iter ( sample_dict . values ())) . shape [ 0 ] # get category id of the item bought in each row of batch. cate_index = self . item_to_category_tensor [ batch . item_index ] # get item ids of all items from the same category of each item bought. relevant_item_index = self . category_to_item_tensor [ cate_index , :] relevant_item_index = relevant_item_index . view ( - 1 ,) # index were padded with -1's, drop those dummy entries. relevant_item_index = relevant_item_index [ relevant_item_index != - 1 ] # the first repeats[0] entries in relevant_item_index are for the category of item_index[0] repeats = self . category_to_size_tensor [ cate_index ] # argwhere(reverse_indices == k) are positions in relevant_item_index for the category of item_index[k]. reverse_indices = torch . repeat_interleave ( torch . arange ( len ( batch ), device = self . device ), repeats ) # expand the user_index and session_index. user_index = torch . repeat_interleave ( batch . user_index , repeats ) session_index = torch . repeat_interleave ( batch . session_index , repeats ) # duplicate the item focused to match. item_index_expanded = torch . repeat_interleave ( batch . item_index , repeats ) # short-hands for easier shape check. R = num_seeds # total number of relevant items. total_computation = len ( session_index ) S = self . num_sessions U = self . num_users I = self . num_items # ========================================================================================== # Helper Functions for Reshaping. # ========================================================================================== def reshape_coef_sample ( sample , name ): # reshape the monte carlo sample of coefficients to (R, P, I, *). if name . endswith ( '_user' ): # (R, U, *) --> (R, total_computation, *) return sample [:, user_index , :] elif name . endswith ( '_item' ): # (R, I, *) --> (R, total_computation, *) return sample [:, relevant_item_index , :] elif name . endswith ( '_constant' ): # (R, *) --> (R, total_computation, *) return sample . view ( R , 1 , - 1 ) . expand ( - 1 , total_computation , - 1 ) else : raise ValueError def reshape_observable ( obs , name ): # reshape observable to (R, P, I, *) so that it can be multiplied with monte carlo # samples of coefficients. O = obs . shape [ - 1 ] # number of observables. assert O == positive_integer if name . startswith ( 'item_' ): assert obs . shape == ( I , O ) obs = obs [ relevant_item_index , :] elif name . startswith ( 'user_' ): assert obs . shape == ( U , O ) obs = obs [ user_index , :] elif name . startswith ( 'session_' ): assert obs . shape == ( S , O ) obs = obs [ session_index , :] elif name . startswith ( 'price_' ): assert obs . shape == ( S , I , O ) obs = obs [ session_index , relevant_item_index , :] elif name . startswith ( 'taste_' ): assert obs . shape == ( U , I , O ) obs = obs [ user_index , relevant_item_index , :] else : raise ValueError assert obs . shape == ( total_computation , O ) return obs . unsqueeze ( dim = 0 ) . expand ( R , - 1 , - 1 ) # ========================================================================================== # Compute Components related to users and items only. # ========================================================================================== utility = torch . zeros ( R , total_computation , device = self . device ) # loop over additive term to utility for term in self . formula : # Type I: single coefficient, e.g., lambda_item or lambda_user. if len ( term [ 'coefficient' ]) == 1 and term [ 'observable' ] is None : # E.g., lambda_item or lambda_user coef_name = term [ 'coefficient' ][ 0 ] coef_sample = reshape_coef_sample ( sample_dict [ coef_name ], coef_name ) assert coef_sample . shape == ( R , total_computation , 1 ) additive_term = coef_sample . view ( R , total_computation ) # Type II: factorized coefficient, e.g., <theta_user, lambda_item>. elif len ( term [ 'coefficient' ]) == 2 and term [ 'observable' ] is None : coef_name_0 = term [ 'coefficient' ][ 0 ] coef_name_1 = term [ 'coefficient' ][ 1 ] coef_sample_0 = reshape_coef_sample ( sample_dict [ coef_name_0 ], coef_name_0 ) coef_sample_1 = reshape_coef_sample ( sample_dict [ coef_name_1 ], coef_name_1 ) assert coef_sample_0 . shape == coef_sample_1 . shape == ( R , total_computation , positive_integer ) additive_term = ( coef_sample_0 * coef_sample_1 ) . sum ( dim =- 1 ) # Type III: single coefficient multiplied by observable, e.g., theta_user * x_obs_item. elif len ( term [ 'coefficient' ]) == 1 and term [ 'observable' ] is not None : coef_name = term [ 'coefficient' ][ 0 ] coef_sample = reshape_coef_sample ( sample_dict [ coef_name ], coef_name ) assert coef_sample . shape == ( R , total_computation , positive_integer ) obs_name = term [ 'observable' ] obs = reshape_observable ( getattr ( batch , obs_name ), obs_name ) assert obs . shape == ( R , total_computation , positive_integer ) additive_term = ( coef_sample * obs ) . sum ( dim =- 1 ) # Type IV: factorized coefficient multiplied by observable. # e.g., gamma_user * beta_item * price_obs. elif len ( term [ 'coefficient' ]) == 2 and term [ 'observable' ] is not None : coef_name_0 , coef_name_1 = term [ 'coefficient' ][ 0 ], term [ 'coefficient' ][ 1 ] coef_sample_0 = reshape_coef_sample ( sample_dict [ coef_name_0 ], coef_name_0 ) coef_sample_1 = reshape_coef_sample ( sample_dict [ coef_name_1 ], coef_name_1 ) assert coef_sample_0 . shape == coef_sample_1 . shape == ( R , total_computation , positive_integer ) num_obs_times_latent_dim = coef_sample_0 . shape [ - 1 ] obs_name = term [ 'observable' ] obs = reshape_observable ( getattr ( batch , obs_name ), obs_name ) assert obs . shape == ( R , total_computation , positive_integer ) num_obs = obs . shape [ - 1 ] # number of observables. assert ( num_obs_times_latent_dim % num_obs ) == 0 latent_dim = num_obs_times_latent_dim // num_obs coef_sample_0 = coef_sample_0 . view ( R , total_computation , num_obs , latent_dim ) coef_sample_1 = coef_sample_1 . view ( R , total_computation , num_obs , latent_dim ) # compute the factorized coefficient with shape (R, P, I, O). coef = ( coef_sample_0 * coef_sample_1 ) . sum ( dim =- 1 ) additive_term = ( coef * obs ) . sum ( dim =- 1 ) else : raise ValueError ( f 'Undefined term type: { term } ' ) assert additive_term . shape == ( R , total_computation ) utility += additive_term # ========================================================================================== # Mask Out Unavailable Items in Each Session. # ========================================================================================== if batch . item_availability is not None : # expand to the Monte Carlo sample dimension. A = batch . item_availability [ session_index , relevant_item_index ] . unsqueeze ( dim = 0 ) . expand ( R , - 1 ) utility [ ~ A ] = - ( torch . finfo ( utility . dtype ) . max / 2 ) for module in self . additional_modules : # current utility shape: (R, total_computation) additive_term = module ( batch ) assert additive_term . shape == ( R , len ( batch )) or additive_term . shape == ( R , len ( batch ), 1 ) if additive_term . shape == ( R , len ( batch ), 1 ): # TODO: need to make this consistent with log_likelihood_all. # be tolerant for some customized module with BayesianLinear that returns (R, len(batch), 1). additive_term = additive_term . view ( R , len ( batch )) # expand to total number of computation, query by reverse_indices. # reverse_indices has length total_computation, and reverse_indices[i] correspond to the row-id that this # computation is responsible for. additive_term = additive_term [:, reverse_indices ] assert additive_term . shape == ( R , total_computation ) # compute log likelihood log p(choosing item i | user, item latents) if return_logit : log_p = utility else : # compute the log probability from logits/utilities. log_p = scatter_log_softmax ( utility , reverse_indices , dim =- 1 ) # select the log-P of the item actually bought. log_p = log_p [:, item_index_expanded == relevant_item_index ] # output shape: (num_seeds, num_purchases, num_items) return log_p def log_prior ( self , batch : ChoiceDataset , sample_dict : Dict [ str , torch . Tensor ]) -> torch . Tensor : \"\"\"Calculates the log-likelihood of Monte Carlo samples of Bayesian coefficients under their prior distribution. This method assume coefficients are statistically independent. Args: batch (ChoiceDataset): a dataset object contains observables for computing the prior distribution if obs2prior is True. sample_dict (Dict[str, torch.Tensor]): a dictionary coefficient names to Monte Carlo samples. Raises: ValueError: [description] Returns: torch.scalar_tensor: a tensor with shape (num_seeds,) of [ log P_{prior_distribution}(param[i]) ], where param[i] is the i-th Monte Carlo sample. \"\"\" # assert sample_dict.keys() == self.coef_dict.keys() num_seeds = next ( iter ( sample_dict . values ())) . shape [ 0 ] total = torch . zeros ( num_seeds , device = self . device ) for coef_name , coef in self . coef_dict . items (): if self . obs2prior_dict [ coef_name ]: if coef_name . endswith ( '_item' ): x_obs = batch . item_obs elif coef_name . endswith ( '_user' ): x_obs = batch . user_obs else : raise ValueError ( f 'No observable found to support obs2prior for { coef_name } .' ) total += coef . log_prior ( sample = sample_dict [ coef_name ], H_sample = sample_dict [ coef_name + '.H' ], x_obs = x_obs ) . sum ( dim =- 1 ) else : # log_prob outputs (num_seeds, num_{items, users}), sum to (num_seeds). total += coef . log_prior ( sample = sample_dict [ coef_name ], H_sample = None , x_obs = None ) . sum ( dim =- 1 ) for module in self . additional_modules : raise NotImplementedError () total += module . log_prior () return total def log_variational ( self , sample_dict : Dict [ str , torch . Tensor ]) -> torch . Tensor : \"\"\"Calculate the log-likelihood of samples in sample_dict under the current variational distribution. Args: sample_dict (Dict[str, torch.Tensor]): a dictionary coefficient names to Monte Carlo samples. Returns: torch.Tensor: a tensor of shape (num_seeds) of [ log P_{variational_distribution}(param[i]) ], where param[i] is the i-th Monte Carlo sample. \"\"\" num_seeds = list ( sample_dict . values ())[ 0 ] . shape [ 0 ] total = torch . zeros ( num_seeds , device = self . device ) for coef_name , coef in self . coef_dict . items (): # log_prob outputs (num_seeds, num_{items, users}), sum to (num_seeds). total += coef . log_variational ( sample_dict [ coef_name ]) . sum ( dim =- 1 ) for module in self . additional_modules : raise NotImplementedError () # with shape (num_seeds,) total += module . log_variational () . sum () return total def elbo ( self , batch : ChoiceDataset , num_seeds : int = 1 ) -> torch . Tensor : \"\"\"A combined method to computes the current ELBO given a batch, this method is used for training the model. Args: batch (ChoiceDataset): a ChoiceDataset containing necessary information. num_seeds (int, optional): the number of Monte Carlo samples from variational distributions to evaluate the expectation in ELBO. Defaults to 1. Returns: torch.Tensor: a scalar tensor of the ELBO estimated from num_seeds Monte Carlo samples. \"\"\" # ============================================================================================================== # 1. sample latent variables from their variational distributions. # ============================================================================================================== sample_dict = self . sample_coefficient_dictionary ( num_seeds ) # ============================================================================================================== # 2. compute log p(latent) prior. # (num_seeds,) --mean--> scalar. elbo = self . log_prior ( batch , sample_dict ) . mean ( dim = 0 ) # ============================================================================================================== # ============================================================================================================== # 3. compute the log likelihood log p(obs|latent). # sum over independent purchase decision for individual observations, mean over MC seeds. # the forward() function calls module.rsample(num_seeds) for module in self.additional_modules. # ============================================================================================================== if self . pred_item : # the prediction target is item_index. elbo += self . forward ( batch , return_type = 'log_prob' , return_scope = 'item_index' , deterministic = False , sample_dict = sample_dict ) . sum ( dim = 1 ) . mean ( dim = 0 ) # (num_seeds, len(batch)) --> scalar. else : # the prediction target is binary. # TODO: update the prediction function. utility = self . forward ( batch , return_type = 'utility' , return_scope = 'item_index' , deterministic = False , sample_dict = sample_dict ) # (num_seeds, len(batch)) # compute the log-likelihood for binary label. # (num_seeds, len(batch)) y_stacked = torch . stack ([ batch . label ] * num_seeds ) . float () assert y_stacked . shape == utility . shape bce = nn . BCELoss ( reduction = 'none' ) # scalar. ll = - bce ( torch . sigmoid ( utility ), y_stacked ) . sum ( dim = 1 ) . mean ( dim = 0 ) elbo += ll # ============================================================================================================== # 4. optionally add log likelihood under variational distributions q(latent). # ============================================================================================================== if self . trace_log_q : elbo -= self . log_variational ( sample_dict ) . mean ( dim = 0 ) return elbo __init__ ( self , utility_formula , obs2prior_dict , coef_dim_dict , num_items , pred_item , prior_variance = 1.0 , num_users = None , num_sessions = None , trace_log_q = False , category_to_item = None , num_user_obs = None , num_item_obs = None , num_session_obs = None , num_price_obs = None , num_taste_obs = None , additional_modules = None ) special Parameters: Name Type Description Default utility_formula str a string representing the utility function U[user, item, session]. See documentation for more details in the documentation for the format of formula. Examples: lambda_item lambda_item + theta_user * alpha_item + zeta_user * item_obs lambda_item + theta_user * alpha_item + gamma_user * beta_item * price_obs See the doc-string of parse_utility for an example. required obs2prior_dict Dict[str, bool] a dictionary maps coefficient name (e.g., 'lambda_item') to a boolean indicating if observable (e.g., item_obs) enters the prior of the coefficient. required coef_dim_dict Dict[str, int] a dictionary maps coefficient name (e.g., 'lambda_item') to an integer indicating the dimension of coefficient. For standalone coefficients like U = lambda_item, the dim should be 1. For factorized coefficients like U = theta_user * alpha_item, the dim should be the latent dimension of theta and alpha. For coefficients multiplied with observables like U = zeta_user * item_obs, the dim should be the number of observables in item_obs. For factorized coefficient multiplied with observables like U = gamma_user * beta_item * price_obs, the dim should be the latent dim multiplied by number of observables in price_obs. required num_items int number of items. required pred_item bool there are two use cases of this model, suppose we have user_index[i] and item_index[i] for the i-th observation in the dataset. Case 1: which item among all items user user_index[i] is going to purchase, the prediction label is therefore item_index[i] . Equivalently, we can ask what's the likelihood for user user_index[i] to purchase item_index[i] . Case 2: what rating would user user_index[i] assign to item item_index[i] ? In this case, the dataset object needs to contain a separate label. NOTE: for now, we only support binary labels. required prior_variance Union[float, Dict[str, float]] the variance of prior distribution for coefficients. If a float is provided, all priors will be diagonal matrix with prior_variance along the diagonal. If a dictionary is provided, keys of prior_variance should be coefficient names, and the variance of prior of coef_name would be a diagonal matrix with prior_variance[coef_name] along the diagonal. Defaults to 1.0, which means all prior have identity matrix as the covariance matrix. 1.0 num_users int number of users, required only if coefficient or observable depending on user is in utility. Defaults to None. None num_sessions int number of sessions, required only if coefficient or observable depending on session is in utility. Defaults to None. None trace_log_q bool whether to trace the derivative of variational likelihood logQ with respect to variational parameters in the ELBO while conducting gradient update. Defaults to False. False category_to_item Dict[str, List[int]] a dictionary with category id or name as keys, and category_to_item[C] contains the list of item ids belonging to category C. If None is provided, all items are assumed to be in the same category. Defaults to None. None num_{user, item, session, price, taste}_obs (int number of observables of each type of features, only required if observable enters prior. NOTE: currently we only allow coefficient to depend on either user or item, thus only user and item observables can enter the prior of coefficient. Hence session, price, and taste observables are never required, we include it here for completeness. required Source code in bemb/model/bemb.py def __init__ ( self , utility_formula : str , obs2prior_dict : Dict [ str , bool ], coef_dim_dict : Dict [ str , int ], num_items : int , pred_item : bool , prior_variance : Union [ float , Dict [ str , float ]] = 1.0 , num_users : Optional [ int ] = None , num_sessions : Optional [ int ] = None , trace_log_q : bool = False , category_to_item : Dict [ int , List [ int ]] = None , # number of observables. num_user_obs : Optional [ int ] = None , num_item_obs : Optional [ int ] = None , num_session_obs : Optional [ int ] = None , num_price_obs : Optional [ int ] = None , num_taste_obs : Optional [ int ] = None , # additional modules. additional_modules : Optional [ List [ nn . Module ]] = None ) -> None : \"\"\" Args: utility_formula (str): a string representing the utility function U[user, item, session]. See documentation for more details in the documentation for the format of formula. Examples: lambda_item lambda_item + theta_user * alpha_item + zeta_user * item_obs lambda_item + theta_user * alpha_item + gamma_user * beta_item * price_obs See the doc-string of parse_utility for an example. obs2prior_dict (Dict[str, bool]): a dictionary maps coefficient name (e.g., 'lambda_item') to a boolean indicating if observable (e.g., item_obs) enters the prior of the coefficient. coef_dim_dict (Dict[str, int]): a dictionary maps coefficient name (e.g., 'lambda_item') to an integer indicating the dimension of coefficient. For standalone coefficients like U = lambda_item, the dim should be 1. For factorized coefficients like U = theta_user * alpha_item, the dim should be the latent dimension of theta and alpha. For coefficients multiplied with observables like U = zeta_user * item_obs, the dim should be the number of observables in item_obs. For factorized coefficient multiplied with observables like U = gamma_user * beta_item * price_obs, the dim should be the latent dim multiplied by number of observables in price_obs. num_items (int): number of items. pred_item (bool): there are two use cases of this model, suppose we have `user_index[i]` and `item_index[i]` for the i-th observation in the dataset. Case 1: which item among all items user `user_index[i]` is going to purchase, the prediction label is therefore `item_index[i]`. Equivalently, we can ask what's the likelihood for user `user_index[i]` to purchase `item_index[i]`. Case 2: what rating would user `user_index[i]` assign to item `item_index[i]`? In this case, the dataset object needs to contain a separate label. NOTE: for now, we only support binary labels. prior_variance (Union[float, Dict[str, float]]): the variance of prior distribution for coefficients. If a float is provided, all priors will be diagonal matrix with prior_variance along the diagonal. If a dictionary is provided, keys of prior_variance should be coefficient names, and the variance of prior of coef_name would be a diagonal matrix with prior_variance[coef_name] along the diagonal. Defaults to 1.0, which means all prior have identity matrix as the covariance matrix. num_users (int, optional): number of users, required only if coefficient or observable depending on user is in utility. Defaults to None. num_sessions (int, optional): number of sessions, required only if coefficient or observable depending on session is in utility. Defaults to None. trace_log_q (bool, optional): whether to trace the derivative of variational likelihood logQ with respect to variational parameters in the ELBO while conducting gradient update. Defaults to False. category_to_item (Dict[str, List[int]], optional): a dictionary with category id or name as keys, and category_to_item[C] contains the list of item ids belonging to category C. If None is provided, all items are assumed to be in the same category. Defaults to None. num_{user, item, session, price, taste}_obs (int, optional): number of observables of each type of features, only required if observable enters prior. NOTE: currently we only allow coefficient to depend on either user or item, thus only user and item observables can enter the prior of coefficient. Hence session, price, and taste observables are never required, we include it here for completeness. \"\"\" super ( BEMBFlex , self ) . __init__ () self . utility_formula = utility_formula self . obs2prior_dict = obs2prior_dict self . coef_dim_dict = coef_dim_dict self . prior_variance = prior_variance self . pred_item = pred_item self . num_items = num_items self . num_users = num_users self . num_sessions = num_sessions self . trace_log_q = trace_log_q self . category_to_item = category_to_item # ============================================================================================================== # Category ID to Item ID mapping. # Category ID to Category Size mapping. # Item ID to Category ID mapping. # ============================================================================================================== if self . category_to_item is None : if self . pred_item : # assign all items to the same category if predicting items. self . category_to_item = { 0 : list ( np . arange ( self . num_items ))} else : # otherwise, for the j-th observation in the dataset, the label[j] # only depends on user_index[j] and item_index[j], so we put each # item to its own category. self . category_to_item = { i : [ i ] for i in range ( self . num_items )} self . num_categories = len ( self . category_to_item ) max_category_size = max ( len ( x ) for x in self . category_to_item . values ()) category_to_item_tensor = torch . full ( ( self . num_categories , max_category_size ), - 1 ) category_to_size_tensor = torch . empty ( self . num_categories ) for c , item_in_c in self . category_to_item . items (): category_to_item_tensor [ c , : len ( item_in_c )] = torch . LongTensor ( item_in_c ) category_to_size_tensor [ c ] = torch . scalar_tensor ( len ( item_in_c )) self . register_buffer ( 'category_to_item_tensor' , category_to_item_tensor . long ()) self . register_buffer ( 'category_to_size_tensor' , category_to_size_tensor . long ()) item_to_category_tensor = torch . zeros ( self . num_items ) for c , items_in_c in self . category_to_item . items (): item_to_category_tensor [ items_in_c ] = c self . register_buffer ( 'item_to_category_tensor' , item_to_category_tensor . long ()) # ============================================================================================================== # Create Bayesian Coefficient Objects # ============================================================================================================== # model configuration. self . formula = parse_utility ( utility_formula ) print ( 'BEMB: utility formula parsed:' ) pprint ( self . formula ) self . raw_formula = utility_formula self . obs2prior_dict = obs2prior_dict # dimension of each observable, this one is used only for obs2prior. self . num_obs_dict = { 'user' : num_user_obs , 'item' : num_item_obs , 'session' : num_session_obs , 'price' : num_price_obs , 'taste' : num_taste_obs , 'constant' : 1 # not really used, for dummy variables. } # how many classes for the variational distribution. # for example, beta_item would be `num_items` 10-dimensional gaussian if latent dim = 10. variation_to_num_classes = { 'user' : self . num_users , 'item' : self . num_items , 'constant' : 1 } coef_dict = dict () for additive_term in self . formula : for coef_name in additive_term [ 'coefficient' ]: variation = coef_name . split ( '_' )[ - 1 ] s2 = self . prior_variance [ coef_name ] if isinstance ( self . prior_variance , dict ) else self . prior_variance coef_dict [ coef_name ] = BayesianCoefficient ( variation = variation , num_classes = variation_to_num_classes [ variation ], obs2prior = self . obs2prior_dict [ coef_name ], num_obs = self . num_obs_dict [ variation ], dim = self . coef_dim_dict [ coef_name ], prior_variance = s2 ) self . coef_dict = nn . ModuleDict ( coef_dict ) # ============================================================================================================== # Optional: register additional modules. # ============================================================================================================== if additional_modules is None : self . additional_modules = [] else : raise NotImplementedError ( 'Additional modules are temporarily disabled for further development.' ) self . additional_modules = nn . ModuleList ( additional_modules ) elbo ( self , batch , num_seeds = 1 ) A combined method to computes the current ELBO given a batch, this method is used for training the model. Parameters: Name Type Description Default batch ChoiceDataset a ChoiceDataset containing necessary information. required num_seeds int the number of Monte Carlo samples from variational distributions to evaluate the expectation in ELBO. Defaults to 1. 1 Returns: Type Description torch.Tensor a scalar tensor of the ELBO estimated from num_seeds Monte Carlo samples. Source code in bemb/model/bemb.py def elbo ( self , batch : ChoiceDataset , num_seeds : int = 1 ) -> torch . Tensor : \"\"\"A combined method to computes the current ELBO given a batch, this method is used for training the model. Args: batch (ChoiceDataset): a ChoiceDataset containing necessary information. num_seeds (int, optional): the number of Monte Carlo samples from variational distributions to evaluate the expectation in ELBO. Defaults to 1. Returns: torch.Tensor: a scalar tensor of the ELBO estimated from num_seeds Monte Carlo samples. \"\"\" # ============================================================================================================== # 1. sample latent variables from their variational distributions. # ============================================================================================================== sample_dict = self . sample_coefficient_dictionary ( num_seeds ) # ============================================================================================================== # 2. compute log p(latent) prior. # (num_seeds,) --mean--> scalar. elbo = self . log_prior ( batch , sample_dict ) . mean ( dim = 0 ) # ============================================================================================================== # ============================================================================================================== # 3. compute the log likelihood log p(obs|latent). # sum over independent purchase decision for individual observations, mean over MC seeds. # the forward() function calls module.rsample(num_seeds) for module in self.additional_modules. # ============================================================================================================== if self . pred_item : # the prediction target is item_index. elbo += self . forward ( batch , return_type = 'log_prob' , return_scope = 'item_index' , deterministic = False , sample_dict = sample_dict ) . sum ( dim = 1 ) . mean ( dim = 0 ) # (num_seeds, len(batch)) --> scalar. else : # the prediction target is binary. # TODO: update the prediction function. utility = self . forward ( batch , return_type = 'utility' , return_scope = 'item_index' , deterministic = False , sample_dict = sample_dict ) # (num_seeds, len(batch)) # compute the log-likelihood for binary label. # (num_seeds, len(batch)) y_stacked = torch . stack ([ batch . label ] * num_seeds ) . float () assert y_stacked . shape == utility . shape bce = nn . BCELoss ( reduction = 'none' ) # scalar. ll = - bce ( torch . sigmoid ( utility ), y_stacked ) . sum ( dim = 1 ) . mean ( dim = 0 ) elbo += ll # ============================================================================================================== # 4. optionally add log likelihood under variational distributions q(latent). # ============================================================================================================== if self . trace_log_q : elbo -= self . log_variational ( sample_dict ) . mean ( dim = 0 ) return elbo forward ( self , batch , return_type , return_scope , deterministic = True , sample_dict = None , num_seeds = None ) A combined method for inference with the model. Parameters: Name Type Description Default batch ChoiceDataset batch data containing choice information. required return_type str either 'log_prob' or 'utility'. 'log_prob': return the log-probability (by within-category log-softmax) for items 'utility': return the utility value of items. required return_scope str either 'item_index' or 'all_items'. 'item_index': for each observation i, return log-prob/utility for the chosen item batch.item_index[i] only. 'all_items': for each observation i, return log-prob/utility for all items. required deterministic bool True: expectations of parameter variational distributions are used for inference. False: the user needs to supply a dictionary of sampled parameters for inference. Defaults to True. True sample_dict Optional[Dict[str, torch.Tensor]] sampled parameters for inference task. This is not needed when deterministic is True. When deterministic is False, the user can supply a sample_dict . If sample_dict is not provided, this method will create num_seeds samples. Defaults to None. None num_seeds Optional[int] the number of random samples of parameters to construct. This is only required if deterministic is False (i.e., stochastic mode) and sample_dict is not provided. Defaults to None. None Returns: Type Description torch.Tensor a tensor of log-probabilities or utilities, depending on return_type . The shape of the returned tensor depends on return_scope and deterministic . ------------------------------------------------------------------------- | return_scope | deterministic | Output shape | ------------------------------------------------------------------------- | 'item_index` | True | (len(batch),) | ------------------------------------------------------------------------- | 'all_items' | True | (len(batch), num_items) | ------------------------------------------------------------------------- | 'item_index' | False | (num_seeds, len(batch)) | ------------------------------------------------------------------------- | 'all_items' | False | (num_seeds, len(batch), num_items) | ------------------------------------------------------------------------- Source code in bemb/model/bemb.py def forward ( self , batch : ChoiceDataset , return_type : str , return_scope : str , deterministic : bool = True , sample_dict : Optional [ Dict [ str , torch . Tensor ]] = None , num_seeds : Optional [ int ] = None ) -> torch . Tensor : \"\"\"A combined method for inference with the model. Args: batch (ChoiceDataset): batch data containing choice information. return_type (str): either 'log_prob' or 'utility'. 'log_prob': return the log-probability (by within-category log-softmax) for items 'utility': return the utility value of items. return_scope (str): either 'item_index' or 'all_items'. 'item_index': for each observation i, return log-prob/utility for the chosen item batch.item_index[i] only. 'all_items': for each observation i, return log-prob/utility for all items. deterministic (bool, optional): True: expectations of parameter variational distributions are used for inference. False: the user needs to supply a dictionary of sampled parameters for inference. Defaults to True. sample_dict (Optional[Dict[str, torch.Tensor]], optional): sampled parameters for inference task. This is not needed when `deterministic` is True. When `deterministic` is False, the user can supply a `sample_dict`. If `sample_dict` is not provided, this method will create `num_seeds` samples. Defaults to None. num_seeds (Optional[int]): the number of random samples of parameters to construct. This is only required if `deterministic` is False (i.e., stochastic mode) and `sample_dict` is not provided. Defaults to None. Returns: torch.Tensor: a tensor of log-probabilities or utilities, depending on `return_type`. The shape of the returned tensor depends on `return_scope` and `deterministic`. ------------------------------------------------------------------------- | `return_scope` | `deterministic` | Output shape | ------------------------------------------------------------------------- | 'item_index` | True | (len(batch),) | ------------------------------------------------------------------------- | 'all_items' | True | (len(batch), num_items) | ------------------------------------------------------------------------- | 'item_index' | False | (num_seeds, len(batch)) | ------------------------------------------------------------------------- | 'all_items' | False | (num_seeds, len(batch), num_items) | ------------------------------------------------------------------------- \"\"\" # ============================================================================================================== # check arguments. # ============================================================================================================== assert return_type in [ 'log_prob' , 'utility' ], \"return_type must be either 'log_prob' or 'utility'.\" assert return_scope in [ 'item_index' , 'all_items' ], \"return_scope must be either 'item_index' or 'all_items'.\" assert deterministic in [ True , False ] if ( not deterministic ) and ( sample_dict is None ): assert num_seeds >= 1 , \"A positive interger `num_seeds` is required if `deterministic` is False and no `sample_dict` is provided.\" # when pred_item is true, the model is predicting which item is bought (specified by item_index). if self . pred_item : batch . label = batch . item_index # ============================================================================================================== # get sample_dict ready. # ============================================================================================================== if deterministic : num_seeds = 1 # Use the means of variational distributions as the sole deterministic MC sample. # NOTE: here we don't need to sample the obs2prior weight H since we only compute the log-likelihood. # TODO: is this correct? sample_dict = dict () for coef_name , coef in self . coef_dict . items (): sample_dict [ coef_name ] = coef . variational_distribution . mean . unsqueeze ( dim = 0 ) # (1, num_*, dim) else : if sample_dict is None : # sample stochastic parameters. sample_dict = self . sample_coefficient_dictionary ( num_seeds ) else : # use the provided sample_dict. num_seeds = list ( sample_dict . values ())[ 0 ] . shape [ 0 ] # ============================================================================================================== # call the sampling method of additional modules. # ============================================================================================================== for module in self . additional_modules : # deterministic sample. if deterministic : module . dsample () else : module . rsample ( num_seeds = num_seeds ) # if utility is requested, don't run log-softmax, simply return logit. return_logit = ( return_type == 'utility' ) if return_scope == 'all_items' : # (num_seeds, len(batch), num_items) out = self . log_likelihood_all_items ( batch = batch , sample_dict = sample_dict , return_logit = return_logit ) elif return_scope == 'item_index' : # (num_seeds, len(batch)) out = self . log_likelihood_item_index ( batch = batch , sample_dict = sample_dict , return_logit = return_logit ) if deterministic : # drop the first dimension, which has size of `num_seeds` (equals 1 in the deterministic case). # (len(batch), num_items) or (len(batch),) return out . squeeze ( dim = 0 ) return out get_within_category_accuracy ( self , log_p_all_items , label ) A helper function for computing prediction accuracy (i.e., all non-differential metrics) within category. In particular, this method calculates the accuracy, precision, recall and F1 score. This method has the same functionality as the following peusodcode: for C in categories: # get sessions in which item in category C was purchased. T <- (t for t in {0,1,..., len(label)-1} if label[t] is in C) Y <- label[T] predictions = list() for t in T: # get the prediction within category for this session. y_pred = argmax_{items in C} log prob computed before. predictions.append(y_pred) accuracy = mean(Y == predictions) Similarly, this function computes precision, recall and f1score as well. Parameters: Name Type Description Default log_p_all_items torch.Tensor shape (num_sessions, num_items) the log probability of choosing each item in each session. required label torch.LongTensor shape (num_sessions,), the IDs of items purchased in each session. required Returns: Type Description [Dict[str, float]] A dictionary containing performance metrics. Source code in bemb/model/bemb.py @torch . no_grad () def get_within_category_accuracy ( self , log_p_all_items : torch . Tensor , label : torch . LongTensor ) -> Dict [ str , float ]: \"\"\"A helper function for computing prediction accuracy (i.e., all non-differential metrics) within category. In particular, this method calculates the accuracy, precision, recall and F1 score. This method has the same functionality as the following peusodcode: for C in categories: # get sessions in which item in category C was purchased. T <- (t for t in {0,1,..., len(label)-1} if label[t] is in C) Y <- label[T] predictions = list() for t in T: # get the prediction within category for this session. y_pred = argmax_{items in C} log prob computed before. predictions.append(y_pred) accuracy = mean(Y == predictions) Similarly, this function computes precision, recall and f1score as well. Args: log_p_all_items (torch.Tensor): shape (num_sessions, num_items) the log probability of choosing each item in each session. label (torch.LongTensor): shape (num_sessions,), the IDs of items purchased in each session. Returns: [Dict[str, float]]: A dictionary containing performance metrics. \"\"\" # argmax: (num_sessions, num_categories), within category argmax. # item IDs are consecutive, thus argmax is the same as IDs of the item with highest P. _ , argmax_by_category = scatter_max ( log_p_all_items , self . item_to_category_tensor , dim =- 1 ) # category_purchased[t] = the category of item label[t]. # (num_sessions,) category_purchased = self . item_to_category_tensor [ label ] # pred[t] = the item with highest utility from the category item label[t] belongs to. # (num_sessions,) pred_from_category = argmax_by_category [ torch . arange ( len ( label )), category_purchased ] within_category_accuracy = ( pred_from_category == label ) . float () . mean () . item () # precision precision = list () recall = list () for i in range ( self . num_items ): correct_i = torch . sum ( ( torch . logical_and ( pred_from_category == i , label == i )) . float ()) precision_i = correct_i / \\ torch . sum (( pred_from_category == i ) . float ()) recall_i = correct_i / torch . sum (( label == i ) . float ()) # do not add if divided by zero. if torch . any ( pred_from_category == i ): precision . append ( precision_i . cpu () . item ()) if torch . any ( label == i ): recall . append ( recall_i . cpu () . item ()) precision = float ( np . mean ( precision )) recall = float ( np . mean ( recall )) if precision == recall == 0 : f1 = 0 else : f1 = 2 * precision * recall / ( precision + recall ) return { 'accuracy' : within_category_accuracy , 'precision' : precision , 'recall' : recall , 'f1score' : f1 } log_likelihood_all_items ( self , batch , return_logit , sample_dict ) NOTE to developers: This method computes utilities for all items available, which is a relatively slow operation. For training the model, you only need the utility/log-prob for the chosen/relevant item (i.e., item_index[i] for each i-th observation). Use this method for inference only. Use self.log_likelihood_item_index() for training instead. Computes the log probability of choosing each item in each session based on current model parameters. This method allows for specifying {user, item}_latent_value for Monte Carlo estimation in ELBO. For actual prediction tasks, use the forward() function, which will use means of variational distributions for user and item latents. Parameters: Name Type Description Default batch ChoiceDataset a ChoiceDataset object containing relevant information. required return_logit(bool) if set to True, return the log-probability, otherwise return the logit/utility. required sample_dict(Dict[str, torch.Tensor] Monte Carlo samples for model coefficients (i.e., those Greek letters). sample_dict.keys() should be the same as keys of self.obs2prior_dict, i.e., those greek letters actually enter the functional form of utility. The value of sample_dict should be tensors of shape (num_seeds, num_classes, dim) where num_classes in {num_users, num_items, 1} and dim in {latent_dim(K), num_item_obs, num_user_obs, 1}. required Returns: Type Description torch.Tensor a tensor of shape (num_seeds, len(batch), self.num_items), where out[x, y, z] is the probability of choosing item z in session y conditioned on latents to be the x-th Monte Carlo sample. Source code in bemb/model/bemb.py def log_likelihood_all_items ( self , batch : ChoiceDataset , return_logit : bool , sample_dict : Dict [ str , torch . Tensor ]) -> torch . Tensor : \"\"\" NOTE to developers: This method computes utilities for all items available, which is a relatively slow operation. For training the model, you only need the utility/log-prob for the chosen/relevant item (i.e., item_index[i] for each i-th observation). Use this method for inference only. Use self.log_likelihood_item_index() for training instead. Computes the log probability of choosing `each` item in each session based on current model parameters. This method allows for specifying {user, item}_latent_value for Monte Carlo estimation in ELBO. For actual prediction tasks, use the forward() function, which will use means of variational distributions for user and item latents. Args: batch (ChoiceDataset): a ChoiceDataset object containing relevant information. return_logit(bool): if set to True, return the log-probability, otherwise return the logit/utility. sample_dict(Dict[str, torch.Tensor]): Monte Carlo samples for model coefficients (i.e., those Greek letters). sample_dict.keys() should be the same as keys of self.obs2prior_dict, i.e., those greek letters actually enter the functional form of utility. The value of sample_dict should be tensors of shape (num_seeds, num_classes, dim) where num_classes in {num_users, num_items, 1} and dim in {latent_dim(K), num_item_obs, num_user_obs, 1}. Returns: torch.Tensor: a tensor of shape (num_seeds, len(batch), self.num_items), where out[x, y, z] is the probability of choosing item z in session y conditioned on latents to be the x-th Monte Carlo sample. \"\"\" num_seeds = next ( iter ( sample_dict . values ())) . shape [ 0 ] # avoid repeated work when user purchased several items in the same session. user_session_index = torch . stack ( [ batch . user_index , batch . session_index ]) assert user_session_index . shape == ( 2 , len ( batch )) unique_user_sess , inverse_indices = torch . unique ( user_session_index , dim = 1 , return_inverse = True ) user_index = unique_user_sess [ 0 , :] session_index = unique_user_sess [ 1 , :] assert len ( user_index ) == len ( session_index ) # short-hands for easier shape check. R = num_seeds # P = len(batch) # num_purchases. P = unique_user_sess . shape [ 1 ] S = self . num_sessions U = self . num_users I = self . num_items # ============================================================================================================== # Helper Functions for Reshaping. # ============================================================================================================== def reshape_user_coef_sample ( C ): # input shape (R, U, *) C = C . view ( R , U , 1 , - 1 ) . expand ( - 1 , - 1 , I , - 1 ) # (R, U, I, *) C = C [:, user_index , :, :] assert C . shape == ( R , P , I , positive_integer ) return C def reshape_item_coef_sample ( C ): # input shape (R, I, *) C = C . view ( R , 1 , I , - 1 ) . expand ( - 1 , P , - 1 , - 1 ) assert C . shape == ( R , P , I , positive_integer ) return C def reshape_constant_coef_sample ( C ): # input shape (R, *) C = C . view ( R , 1 , 1 , - 1 ) . expand ( - 1 , P , I , - 1 ) assert C . shape == ( R , P , I , positive_integer ) return C def reshape_coef_sample ( sample , name ): # reshape the monte carlo sample of coefficients to (R, P, I, *). if name . endswith ( '_user' ): # (R, U, *) --> (R, P, I, *) return reshape_user_coef_sample ( sample ) elif name . endswith ( '_item' ): # (R, I, *) --> (R, P, I, *) return reshape_item_coef_sample ( sample ) elif name . endswith ( '_constant' ): # (R, *) --> (R, P, I, *) return reshape_constant_coef_sample ( sample ) else : raise ValueError def reshape_observable ( obs , name ): # reshape observable to (R, P, I, *) so that it can be multiplied with monte carlo # samples of coefficients. O = obs . shape [ - 1 ] # number of observables. assert O == positive_integer if name . startswith ( 'item_' ): assert obs . shape == ( I , O ) obs = obs . view ( 1 , 1 , I , O ) . expand ( R , P , - 1 , - 1 ) elif name . startswith ( 'user_' ): assert obs . shape == ( U , O ) obs = obs [ user_index , :] # (P, O) obs = obs . view ( 1 , P , 1 , O ) . expand ( R , - 1 , I , - 1 ) elif name . startswith ( 'session_' ): assert obs . shape == ( S , O ) obs = obs [ session_index , :] # (P, O) return obs . view ( 1 , P , 1 , O ) . expand ( R , - 1 , I , - 1 ) elif name . startswith ( 'price_' ): assert obs . shape == ( S , I , O ) obs = obs [ session_index , :, :] # (P, I, O) return obs . view ( 1 , P , I , O ) . expand ( R , - 1 , - 1 , - 1 ) elif name . startswith ( 'taste_' ): assert obs . shape == ( U , I , O ) obs = obs [ user_index , :, :] # (P, I, O) return obs . view ( 1 , P , I , O ) . expand ( R , - 1 , - 1 , - 1 ) else : raise ValueError assert obs . shape == ( R , P , I , O ) return obs # ============================================================================================================== # Copmute the Utility Term by Term. # ============================================================================================================== # P is the number of unique (user, session) pairs. # (random_seeds, P, num_items). utility = torch . zeros ( R , P , I , device = self . device ) # loop over additive term to utility for term in self . formula : # Type I: single coefficient, e.g., lambda_item or lambda_user. if len ( term [ 'coefficient' ]) == 1 and term [ 'observable' ] is None : # E.g., lambda_item or lambda_user coef_name = term [ 'coefficient' ][ 0 ] coef_sample = reshape_coef_sample ( sample_dict [ coef_name ], coef_name ) assert coef_sample . shape == ( R , P , I , 1 ) additive_term = coef_sample . view ( R , P , I ) # Type II: factorized coefficient, e.g., <theta_user, lambda_item>. elif len ( term [ 'coefficient' ]) == 2 and term [ 'observable' ] is None : coef_name_0 = term [ 'coefficient' ][ 0 ] coef_name_1 = term [ 'coefficient' ][ 1 ] coef_sample_0 = reshape_coef_sample ( sample_dict [ coef_name_0 ], coef_name_0 ) coef_sample_1 = reshape_coef_sample ( sample_dict [ coef_name_1 ], coef_name_1 ) assert coef_sample_0 . shape == coef_sample_1 . shape == ( R , P , I , positive_integer ) additive_term = ( coef_sample_0 * coef_sample_1 ) . sum ( dim =- 1 ) # Type III: single coefficient multiplied by observable, e.g., theta_user * x_obs_item. elif len ( term [ 'coefficient' ]) == 1 and term [ 'observable' ] is not None : coef_name = term [ 'coefficient' ][ 0 ] coef_sample = reshape_coef_sample ( sample_dict [ coef_name ], coef_name ) assert coef_sample . shape == ( R , P , I , positive_integer ) obs_name = term [ 'observable' ] obs = reshape_observable ( getattr ( batch , obs_name ), obs_name ) assert obs . shape == ( R , P , I , positive_integer ) additive_term = ( coef_sample * obs ) . sum ( dim =- 1 ) # Type IV: factorized coefficient multiplied by observable. # e.g., gamma_user * beta_item * price_obs. elif len ( term [ 'coefficient' ]) == 2 and term [ 'observable' ] is not None : coef_name_0 , coef_name_1 = term [ 'coefficient' ][ 0 ], term [ 'coefficient' ][ 1 ] coef_sample_0 = reshape_coef_sample ( sample_dict [ coef_name_0 ], coef_name_0 ) coef_sample_1 = reshape_coef_sample ( sample_dict [ coef_name_1 ], coef_name_1 ) assert coef_sample_0 . shape == coef_sample_1 . shape == ( R , P , I , positive_integer ) num_obs_times_latent_dim = coef_sample_0 . shape [ - 1 ] obs_name = term [ 'observable' ] obs = reshape_observable ( getattr ( batch , obs_name ), obs_name ) assert obs . shape == ( R , P , I , positive_integer ) num_obs = obs . shape [ - 1 ] # number of observables. assert ( num_obs_times_latent_dim % num_obs ) == 0 latent_dim = num_obs_times_latent_dim // num_obs coef_sample_0 = coef_sample_0 . view ( R , P , I , num_obs , latent_dim ) coef_sample_1 = coef_sample_1 . view ( R , P , I , num_obs , latent_dim ) # compute the factorized coefficient with shape (R, P, I, O). coef = ( coef_sample_0 * coef_sample_1 ) . sum ( dim =- 1 ) additive_term = ( coef * obs ) . sum ( dim =- 1 ) else : raise ValueError ( f 'Undefined term type: { term } ' ) assert additive_term . shape == ( R , P , I ) utility += additive_term # ============================================================================================================== # Mask Out Unavailable Items in Each Session. # ============================================================================================================== if batch . item_availability is not None : # expand to the Monte Carlo sample dimension. # (S, I) -> (P, I) -> (1, P, I) -> (R, P, I) A = batch . item_availability [ session_index , :] . unsqueeze ( dim = 0 ) . expand ( R , - 1 , - 1 ) utility [ ~ A ] = - ( torch . finfo ( utility . dtype ) . max / 2 ) utility = utility [:, inverse_indices , :] assert utility . shape == ( R , len ( batch ), I ) for module in self . additional_modules : additive_term = module ( batch ) assert additive_term . shape == ( R , len ( batch ), 1 ) utility += additive_term . expand ( - 1 , - 1 , I ) if return_logit : # output shape: (num_seeds, len(batch), num_items) return utility else : # compute log likelihood log p(choosing item i | user, item latents) # compute log softmax separately within each category. log_p = scatter_log_softmax ( utility , self . item_to_category_tensor , dim =- 1 ) # output shape: (num_seeds, len(batch), num_items) return log_p log_likelihood_item_index ( self , batch , return_logit , sample_dict ) NOTE for developers: This method is more efficient and only computes log-likelihood/logit(utility) for item in item_index[i] for each i-th observation. Developers should use use log_likelihood_all_items for inference purpose and to computes log-likelihoods/utilities for ALL items for the i-th observation. Computes the log probability of choosing item_index[i] in each session based on current model parameters. This method allows for specifying {user, item}_latent_value for Monte Carlo estimation in ELBO. For actual prediction tasks, use the forward() function, which will use means of variational distributions for user and item latents. Parameters: Name Type Description Default batch ChoiceDataset a ChoiceDataset object containing relevant information. required return_logit(bool) if set to True, return the log-probability, otherwise return the logit/utility. required sample_dict(Dict[str, torch.Tensor] Monte Carlo samples for model coefficients (i.e., those Greek letters). sample_dict.keys() should be the same as keys of self.obs2prior_dict, i.e., those greek letters actually enter the functional form of utility. The value of sample_dict should be tensors of shape (num_seeds, num_classes, dim) where num_classes in {num_users, num_items, 1} and dim in {latent_dim(K), num_item_obs, num_user_obs, 1}. required Returns: Type Description torch.Tensor a tensor of shape (num_seeds, len(batch)), where out[x, y] is the probabilities of choosing item batch.item[y] in session y conditioned on latents to be the x-th Monte Carlo sample. Source code in bemb/model/bemb.py def log_likelihood_item_index ( self , batch : ChoiceDataset , return_logit : bool , sample_dict : Dict [ str , torch . Tensor ]) -> torch . Tensor : \"\"\" NOTE for developers: This method is more efficient and only computes log-likelihood/logit(utility) for item in item_index[i] for each i-th observation. Developers should use use `log_likelihood_all_items` for inference purpose and to computes log-likelihoods/utilities for ALL items for the i-th observation. Computes the log probability of choosing item_index[i] in each session based on current model parameters. This method allows for specifying {user, item}_latent_value for Monte Carlo estimation in ELBO. For actual prediction tasks, use the forward() function, which will use means of variational distributions for user and item latents. Args: batch (ChoiceDataset): a ChoiceDataset object containing relevant information. return_logit(bool): if set to True, return the log-probability, otherwise return the logit/utility. sample_dict(Dict[str, torch.Tensor]): Monte Carlo samples for model coefficients (i.e., those Greek letters). sample_dict.keys() should be the same as keys of self.obs2prior_dict, i.e., those greek letters actually enter the functional form of utility. The value of sample_dict should be tensors of shape (num_seeds, num_classes, dim) where num_classes in {num_users, num_items, 1} and dim in {latent_dim(K), num_item_obs, num_user_obs, 1}. Returns: torch.Tensor: a tensor of shape (num_seeds, len(batch)), where out[x, y] is the probabilities of choosing item batch.item[y] in session y conditioned on latents to be the x-th Monte Carlo sample. \"\"\" num_seeds = next ( iter ( sample_dict . values ())) . shape [ 0 ] # get category id of the item bought in each row of batch. cate_index = self . item_to_category_tensor [ batch . item_index ] # get item ids of all items from the same category of each item bought. relevant_item_index = self . category_to_item_tensor [ cate_index , :] relevant_item_index = relevant_item_index . view ( - 1 ,) # index were padded with -1's, drop those dummy entries. relevant_item_index = relevant_item_index [ relevant_item_index != - 1 ] # the first repeats[0] entries in relevant_item_index are for the category of item_index[0] repeats = self . category_to_size_tensor [ cate_index ] # argwhere(reverse_indices == k) are positions in relevant_item_index for the category of item_index[k]. reverse_indices = torch . repeat_interleave ( torch . arange ( len ( batch ), device = self . device ), repeats ) # expand the user_index and session_index. user_index = torch . repeat_interleave ( batch . user_index , repeats ) session_index = torch . repeat_interleave ( batch . session_index , repeats ) # duplicate the item focused to match. item_index_expanded = torch . repeat_interleave ( batch . item_index , repeats ) # short-hands for easier shape check. R = num_seeds # total number of relevant items. total_computation = len ( session_index ) S = self . num_sessions U = self . num_users I = self . num_items # ========================================================================================== # Helper Functions for Reshaping. # ========================================================================================== def reshape_coef_sample ( sample , name ): # reshape the monte carlo sample of coefficients to (R, P, I, *). if name . endswith ( '_user' ): # (R, U, *) --> (R, total_computation, *) return sample [:, user_index , :] elif name . endswith ( '_item' ): # (R, I, *) --> (R, total_computation, *) return sample [:, relevant_item_index , :] elif name . endswith ( '_constant' ): # (R, *) --> (R, total_computation, *) return sample . view ( R , 1 , - 1 ) . expand ( - 1 , total_computation , - 1 ) else : raise ValueError def reshape_observable ( obs , name ): # reshape observable to (R, P, I, *) so that it can be multiplied with monte carlo # samples of coefficients. O = obs . shape [ - 1 ] # number of observables. assert O == positive_integer if name . startswith ( 'item_' ): assert obs . shape == ( I , O ) obs = obs [ relevant_item_index , :] elif name . startswith ( 'user_' ): assert obs . shape == ( U , O ) obs = obs [ user_index , :] elif name . startswith ( 'session_' ): assert obs . shape == ( S , O ) obs = obs [ session_index , :] elif name . startswith ( 'price_' ): assert obs . shape == ( S , I , O ) obs = obs [ session_index , relevant_item_index , :] elif name . startswith ( 'taste_' ): assert obs . shape == ( U , I , O ) obs = obs [ user_index , relevant_item_index , :] else : raise ValueError assert obs . shape == ( total_computation , O ) return obs . unsqueeze ( dim = 0 ) . expand ( R , - 1 , - 1 ) # ========================================================================================== # Compute Components related to users and items only. # ========================================================================================== utility = torch . zeros ( R , total_computation , device = self . device ) # loop over additive term to utility for term in self . formula : # Type I: single coefficient, e.g., lambda_item or lambda_user. if len ( term [ 'coefficient' ]) == 1 and term [ 'observable' ] is None : # E.g., lambda_item or lambda_user coef_name = term [ 'coefficient' ][ 0 ] coef_sample = reshape_coef_sample ( sample_dict [ coef_name ], coef_name ) assert coef_sample . shape == ( R , total_computation , 1 ) additive_term = coef_sample . view ( R , total_computation ) # Type II: factorized coefficient, e.g., <theta_user, lambda_item>. elif len ( term [ 'coefficient' ]) == 2 and term [ 'observable' ] is None : coef_name_0 = term [ 'coefficient' ][ 0 ] coef_name_1 = term [ 'coefficient' ][ 1 ] coef_sample_0 = reshape_coef_sample ( sample_dict [ coef_name_0 ], coef_name_0 ) coef_sample_1 = reshape_coef_sample ( sample_dict [ coef_name_1 ], coef_name_1 ) assert coef_sample_0 . shape == coef_sample_1 . shape == ( R , total_computation , positive_integer ) additive_term = ( coef_sample_0 * coef_sample_1 ) . sum ( dim =- 1 ) # Type III: single coefficient multiplied by observable, e.g., theta_user * x_obs_item. elif len ( term [ 'coefficient' ]) == 1 and term [ 'observable' ] is not None : coef_name = term [ 'coefficient' ][ 0 ] coef_sample = reshape_coef_sample ( sample_dict [ coef_name ], coef_name ) assert coef_sample . shape == ( R , total_computation , positive_integer ) obs_name = term [ 'observable' ] obs = reshape_observable ( getattr ( batch , obs_name ), obs_name ) assert obs . shape == ( R , total_computation , positive_integer ) additive_term = ( coef_sample * obs ) . sum ( dim =- 1 ) # Type IV: factorized coefficient multiplied by observable. # e.g., gamma_user * beta_item * price_obs. elif len ( term [ 'coefficient' ]) == 2 and term [ 'observable' ] is not None : coef_name_0 , coef_name_1 = term [ 'coefficient' ][ 0 ], term [ 'coefficient' ][ 1 ] coef_sample_0 = reshape_coef_sample ( sample_dict [ coef_name_0 ], coef_name_0 ) coef_sample_1 = reshape_coef_sample ( sample_dict [ coef_name_1 ], coef_name_1 ) assert coef_sample_0 . shape == coef_sample_1 . shape == ( R , total_computation , positive_integer ) num_obs_times_latent_dim = coef_sample_0 . shape [ - 1 ] obs_name = term [ 'observable' ] obs = reshape_observable ( getattr ( batch , obs_name ), obs_name ) assert obs . shape == ( R , total_computation , positive_integer ) num_obs = obs . shape [ - 1 ] # number of observables. assert ( num_obs_times_latent_dim % num_obs ) == 0 latent_dim = num_obs_times_latent_dim // num_obs coef_sample_0 = coef_sample_0 . view ( R , total_computation , num_obs , latent_dim ) coef_sample_1 = coef_sample_1 . view ( R , total_computation , num_obs , latent_dim ) # compute the factorized coefficient with shape (R, P, I, O). coef = ( coef_sample_0 * coef_sample_1 ) . sum ( dim =- 1 ) additive_term = ( coef * obs ) . sum ( dim =- 1 ) else : raise ValueError ( f 'Undefined term type: { term } ' ) assert additive_term . shape == ( R , total_computation ) utility += additive_term # ========================================================================================== # Mask Out Unavailable Items in Each Session. # ========================================================================================== if batch . item_availability is not None : # expand to the Monte Carlo sample dimension. A = batch . item_availability [ session_index , relevant_item_index ] . unsqueeze ( dim = 0 ) . expand ( R , - 1 ) utility [ ~ A ] = - ( torch . finfo ( utility . dtype ) . max / 2 ) for module in self . additional_modules : # current utility shape: (R, total_computation) additive_term = module ( batch ) assert additive_term . shape == ( R , len ( batch )) or additive_term . shape == ( R , len ( batch ), 1 ) if additive_term . shape == ( R , len ( batch ), 1 ): # TODO: need to make this consistent with log_likelihood_all. # be tolerant for some customized module with BayesianLinear that returns (R, len(batch), 1). additive_term = additive_term . view ( R , len ( batch )) # expand to total number of computation, query by reverse_indices. # reverse_indices has length total_computation, and reverse_indices[i] correspond to the row-id that this # computation is responsible for. additive_term = additive_term [:, reverse_indices ] assert additive_term . shape == ( R , total_computation ) # compute log likelihood log p(choosing item i | user, item latents) if return_logit : log_p = utility else : # compute the log probability from logits/utilities. log_p = scatter_log_softmax ( utility , reverse_indices , dim =- 1 ) # select the log-P of the item actually bought. log_p = log_p [:, item_index_expanded == relevant_item_index ] # output shape: (num_seeds, num_purchases, num_items) return log_p log_prior ( self , batch , sample_dict ) Calculates the log-likelihood of Monte Carlo samples of Bayesian coefficients under their prior distribution. This method assume coefficients are statistically independent. Parameters: Name Type Description Default batch ChoiceDataset a dataset object contains observables for computing the prior distribution if obs2prior is True. required sample_dict Dict[str, torch.Tensor] a dictionary coefficient names to Monte Carlo samples. required Exceptions: Type Description ValueError [description] Returns: Type Description torch.scalar_tensor a tensor with shape (num_seeds,) of [ log P_{prior_distribution}(param[i]) ], where param[i] is the i-th Monte Carlo sample. Source code in bemb/model/bemb.py def log_prior ( self , batch : ChoiceDataset , sample_dict : Dict [ str , torch . Tensor ]) -> torch . Tensor : \"\"\"Calculates the log-likelihood of Monte Carlo samples of Bayesian coefficients under their prior distribution. This method assume coefficients are statistically independent. Args: batch (ChoiceDataset): a dataset object contains observables for computing the prior distribution if obs2prior is True. sample_dict (Dict[str, torch.Tensor]): a dictionary coefficient names to Monte Carlo samples. Raises: ValueError: [description] Returns: torch.scalar_tensor: a tensor with shape (num_seeds,) of [ log P_{prior_distribution}(param[i]) ], where param[i] is the i-th Monte Carlo sample. \"\"\" # assert sample_dict.keys() == self.coef_dict.keys() num_seeds = next ( iter ( sample_dict . values ())) . shape [ 0 ] total = torch . zeros ( num_seeds , device = self . device ) for coef_name , coef in self . coef_dict . items (): if self . obs2prior_dict [ coef_name ]: if coef_name . endswith ( '_item' ): x_obs = batch . item_obs elif coef_name . endswith ( '_user' ): x_obs = batch . user_obs else : raise ValueError ( f 'No observable found to support obs2prior for { coef_name } .' ) total += coef . log_prior ( sample = sample_dict [ coef_name ], H_sample = sample_dict [ coef_name + '.H' ], x_obs = x_obs ) . sum ( dim =- 1 ) else : # log_prob outputs (num_seeds, num_{items, users}), sum to (num_seeds). total += coef . log_prior ( sample = sample_dict [ coef_name ], H_sample = None , x_obs = None ) . sum ( dim =- 1 ) for module in self . additional_modules : raise NotImplementedError () total += module . log_prior () return total log_variational ( self , sample_dict ) Calculate the log-likelihood of samples in sample_dict under the current variational distribution. Parameters: Name Type Description Default sample_dict Dict[str, torch.Tensor] a dictionary coefficient names to Monte Carlo samples. required Returns: Type Description torch.Tensor a tensor of shape (num_seeds) of [ log P_{variational_distribution}(param[i]) ], where param[i] is the i-th Monte Carlo sample. Source code in bemb/model/bemb.py def log_variational ( self , sample_dict : Dict [ str , torch . Tensor ]) -> torch . Tensor : \"\"\"Calculate the log-likelihood of samples in sample_dict under the current variational distribution. Args: sample_dict (Dict[str, torch.Tensor]): a dictionary coefficient names to Monte Carlo samples. Returns: torch.Tensor: a tensor of shape (num_seeds) of [ log P_{variational_distribution}(param[i]) ], where param[i] is the i-th Monte Carlo sample. \"\"\" num_seeds = list ( sample_dict . values ())[ 0 ] . shape [ 0 ] total = torch . zeros ( num_seeds , device = self . device ) for coef_name , coef in self . coef_dict . items (): # log_prob outputs (num_seeds, num_{items, users}), sum to (num_seeds). total += coef . log_variational ( sample_dict [ coef_name ]) . sum ( dim =- 1 ) for module in self . additional_modules : raise NotImplementedError () # with shape (num_seeds,) total += module . log_variational () . sum () return total posterior_mean ( self , coef_name ) Returns the mean of estimated posterior distribution of coefficient coef_name . Parameters: Name Type Description Default coef_name str name of the coefficient to query. required Returns: Type Description torch.Tensor mean of the estimated posterior distribution of coef_name . Source code in bemb/model/bemb.py def posterior_mean ( self , coef_name : str ) -> torch . Tensor : \"\"\"Returns the mean of estimated posterior distribution of coefficient `coef_name`. Args: coef_name (str): name of the coefficient to query. Returns: torch.Tensor: mean of the estimated posterior distribution of `coef_name`. \"\"\" if coef_name in self . coef_dict . keys (): return self . coef_dict [ coef_name ] . variational_mean else : raise KeyError ( f ' { coef_name } is not a valid coefficient name in { self . utility_formula } .' ) sample_coefficient_dictionary ( self , num_seeds ) A helper function to sample parameters from coefficients. Parameters: Name Type Description Default num_seeds int number of random samples. required Returns: Type Description Dict[str, torch.Tensor] a dictionary maps coefficient names to tensor of sampled coefficient parameters, where the first dimension of the sampled tensor has size num_seeds . Each sample tensor has shape (num_seeds, num_classes, dim). Source code in bemb/model/bemb.py def sample_coefficient_dictionary ( self , num_seeds : int ) -> Dict [ str , torch . Tensor ]: \"\"\"A helper function to sample parameters from coefficients. Args: num_seeds (int): number of random samples. Returns: Dict[str, torch.Tensor]: a dictionary maps coefficient names to tensor of sampled coefficient parameters, where the first dimension of the sampled tensor has size `num_seeds`. Each sample tensor has shape (num_seeds, num_classes, dim). \"\"\" sample_dict = dict () for coef_name , coef in self . coef_dict . items (): s = coef . rsample ( num_seeds ) if coef . obs2prior : # sample both obs2prior weight and realization of variable. assert isinstance ( s , tuple ) and len ( s ) == 2 sample_dict [ coef_name ] = s [ 0 ] sample_dict [ coef_name + '.H' ] = s [ 1 ] else : # only sample the realization of variable. assert torch . is_tensor ( s ) sample_dict [ coef_name ] = s return sample_dict parse_utility ( utility_string ) A helper function parse utility string into a list of additive terms. Examples: utility_string = 'lambda_item + theta_user * alpha_item + gamma_user * beta_item * price_obs' output = [ { 'coefficient': ['lambda_item'], 'observable': None }, { 'coefficient': ['theta_user', 'alpha_item'], 'observable': None }, { 'coefficient': ['gamma_user', 'beta_item'], 'observable': 'price_obs' } ] Source code in bemb/model/bemb.py def parse_utility ( utility_string : str ) -> List [ Dict [ str , Union [ List [ str ], None ]]]: \"\"\" A helper function parse utility string into a list of additive terms. Example: utility_string = 'lambda_item + theta_user * alpha_item + gamma_user * beta_item * price_obs' output = [ { 'coefficient': ['lambda_item'], 'observable': None }, { 'coefficient': ['theta_user', 'alpha_item'], 'observable': None }, { 'coefficient': ['gamma_user', 'beta_item'], 'observable': 'price_obs' } ] \"\"\" # split additive terms coefficient_suffix = ( '_item' , '_user' , '_constant' ) observable_prefix = ( 'item_' , 'user_' , 'session_' , 'price_' , 'taste_' ) def is_coefficient ( name : str ) -> bool : return any ( name . endswith ( suffix ) for suffix in coefficient_suffix ) def is_observable ( name : str ) -> bool : return any ( name . startswith ( prefix ) for prefix in observable_prefix ) additive_terms = utility_string . split ( ' + ' ) additive_decomposition = list () for term in additive_terms : atom = { 'coefficient' : [], 'observable' : None } # split multiplicative terms. for x in term . split ( ' * ' ): if is_coefficient ( x ): atom [ 'coefficient' ] . append ( x ) elif is_observable ( x ): atom [ 'observable' ] = x else : raise ValueError ( f ' { x } term cannot be classified.' ) additive_decomposition . append ( atom ) return additive_decomposition bemb_flex_lightning PyTorch lightning wrapper for the BEMB Flex model, allows for more smooth model training and inference. You can still use this package without using LitBEMBFlex. Author: Tianyu Du Update: Apr. 29, 2022 LitBEMBFlex ( LightningModule ) Source code in bemb/model/bemb_flex_lightning.py class LitBEMBFlex ( pl . LightningModule ): def __init__ ( self , learning_rate : float = 0.3 , num_seeds : int = 1 , ** kwargs ): \"\"\"The initialization method of the wrapper model. Args: learning_rate (float, optional): the learning rate of optimization. Defaults to 0.3. num_seeds (int, optional): number of random seeds for the Monte Carlo estimation in the variational inference. Defaults to 1. **kwargs: all keyword arguments used for constructing the wrapped BEMB model. \"\"\" # use kwargs to pass parameter to BEMB Torch. super () . __init__ () self . model = BEMBFlex ( ** kwargs ) self . num_needs = num_seeds self . learning_rate = learning_rate def __str__ ( self ) -> str : return str ( self . model ) def forward ( self , args , kwargs ): \"\"\"Calls the forward method of the wrapped BEMB model, please refer to the documentaton of the BEMB class for detailed definitions of the arguments. Args: args (_type_): arguments passed to the forward method of the wrapped BEMB model. kwargs (_type_): keyword arguments passed to the forward method of the wrapped BEMB model. Returns: _type_: returns whatever the wrapped BEMB model returns. \"\"\" return self . model ( * args , ** kwargs ) def training_step ( self , batch , batch_idx ): elbo = self . model . elbo ( batch , num_seeds = self . num_needs ) self . log ( 'train_elbo' , elbo ) loss = - elbo return loss def _get_performance_dict ( self , batch ): if self . model . pred_item : log_p = self . model ( batch , return_type = 'log_prob' , return_scope = 'all_items' , deterministic = True ) . cpu () . numpy () num_classes = log_p . shape [ 1 ] y_pred = np . argmax ( log_p , axis = 1 ) y_true = batch . item_index . cpu () . numpy () performance = { 'acc' : metrics . accuracy_score ( y_true = y_true , y_pred = y_pred ), 'll' : - metrics . log_loss ( y_true = y_true , y_pred = np . exp ( log_p ), labels = np . arange ( num_classes ))} else : # making binary station. pred = self . model ( batch , return_type = 'utility' , return_scope = 'item_index' , deterministic = True ) y_pred = torch . sigmoid ( pred ) . cpu () . numpy () y_true = batch . label . cpu () . numpy () performance = { 'acc' : metrics . accuracy_score ( y_true = y_true , y_pred = ( y_pred >= 0.5 ) . astype ( int )), 'll' : - metrics . log_loss ( y_true = y_true , y_pred = y_pred , eps = 1E-5 , labels = [ 0 , 1 ]), # 'auc': metrics.roc_auc_score(y_true=y_true, y_score=y_pred), # 'f1': metrics.f1_score(y_true=y_true, y_pred=(y_pred >= 0.5).astype(int)) } return performance def validation_step ( self , batch , batch_idx ): # LL = self.model.forward(batch, return_type='log_prob', return_scope='item_index', deterministic=True).mean() # self.log('val_log_likelihood', LL, prog_bar=True) # pred = self.model(batch) # performance = self.model.get_within_category_accuracy(pred, batch.label) # utility. for key , val in self . _get_performance_dict ( batch ) . items (): self . log ( 'val_' + key , val , prog_bar = True , batch_size = len ( batch )) def test_step ( self , batch , batch_idx ): # LL = self.model.forward(batch, return_logit=False, all_items=False).mean() # self.log('test_log_likelihood', LL) # pred = self.model(batch, return_type='utility', return_scope='item_index', deterministic=True) # y_pred = torch.sigmoid(pred).cpu().numpy() # y_true = batch.label.cpu().numpy() # performance = {'acc': metrics.accuracy_score(y_true=y_true, y_pred=(y_pred >= 0.5).astype(int)), # 'll': - metrics.log_loss(y_true=y_true, y_pred=y_pred, eps=1E-5, labels=[0, 1]), # # 'auc': metrics.roc_auc_score(y_true=y_true, y_score=y_pred), # # 'f1': metrics.f1_score(y_true=y_true, y_pred=(y_pred >= 0.5).astype(int)) # } # pred = self.model(batch) # performance = self.model.get_within_category_accuracy(pred, batch.label) for key , val in self . _get_performance_dict ( batch ) . items (): self . log ( 'test_' + key , val , prog_bar = True , batch_size = len ( batch )) def configure_optimizers ( self ): optimizer = torch . optim . Adam ( self . parameters (), lr = self . learning_rate ) return optimizer __init__ ( self , learning_rate = 0.3 , num_seeds = 1 , ** kwargs ) special The initialization method of the wrapper model. Parameters: Name Type Description Default learning_rate float the learning rate of optimization. Defaults to 0.3. 0.3 num_seeds int number of random seeds for the Monte Carlo estimation in the variational inference. Defaults to 1. 1 **kwargs all keyword arguments used for constructing the wrapped BEMB model. {} Source code in bemb/model/bemb_flex_lightning.py def __init__ ( self , learning_rate : float = 0.3 , num_seeds : int = 1 , ** kwargs ): \"\"\"The initialization method of the wrapper model. Args: learning_rate (float, optional): the learning rate of optimization. Defaults to 0.3. num_seeds (int, optional): number of random seeds for the Monte Carlo estimation in the variational inference. Defaults to 1. **kwargs: all keyword arguments used for constructing the wrapped BEMB model. \"\"\" # use kwargs to pass parameter to BEMB Torch. super () . __init__ () self . model = BEMBFlex ( ** kwargs ) self . num_needs = num_seeds self . learning_rate = learning_rate configure_optimizers ( self ) Choose what optimizers and learning-rate schedulers to use in your optimization. Normally you'd need one. But in the case of GANs or similar you might have multiple. Returns: Type Description Any of these 6 options. Single optimizer . List or Tuple of optimizers. Two lists - The first list has multiple optimizers, and the second has multiple LR schedulers (or multiple lr_scheduler_config ). Dictionary , with an \"optimizer\" key, and (optionally) a \"lr_scheduler\" key whose value is a single LR scheduler or lr_scheduler_config . Tuple of dictionaries as described above, with an optional \"frequency\" key. None - Fit will run without any optimizer. The lr_scheduler_config is a dictionary which contains the scheduler and its associated configuration. The default configuration is shown below. .. code-block:: python lr_scheduler_config = { # REQUIRED: The scheduler instance \"scheduler\": lr_scheduler, # The unit of the scheduler's step size, could also be 'step'. # 'epoch' updates the scheduler on epoch end whereas 'step' # updates it after a optimizer update. \"interval\": \"epoch\", # How many epochs/steps should pass between calls to # `scheduler.step()`. 1 corresponds to updating the learning # rate after every epoch/step. \"frequency\": 1, # Metric to to monitor for schedulers like `ReduceLROnPlateau` \"monitor\": \"val_loss\", # If set to `True`, will enforce that the value specified 'monitor' # is available when the scheduler is updated, thus stopping # training if not found. If set to `False`, it will only produce a warning \"strict\": True, # If using the `LearningRateMonitor` callback to monitor the # learning rate progress, this keyword can be used to specify # a custom logged name \"name\": None, } When there are schedulers in which the .step() method is conditioned on a value, such as the :class: torch.optim.lr_scheduler.ReduceLROnPlateau scheduler, Lightning requires that the lr_scheduler_config contains the keyword \"monitor\" set to the metric name that the scheduler should be conditioned on. .. testcode:: # The ReduceLROnPlateau scheduler requires a monitor def configure_optimizers(self): optimizer = Adam(...) return { \"optimizer\": optimizer, \"lr_scheduler\": { \"scheduler\": ReduceLROnPlateau(optimizer, ...), \"monitor\": \"metric_to_track\", \"frequency\": \"indicates how often the metric is updated\" # If \"monitor\" references validation metrics, then \"frequency\" should be set to a # multiple of \"trainer.check_val_every_n_epoch\". }, } # In the case of two optimizers, only one using the ReduceLROnPlateau scheduler def configure_optimizers(self): optimizer1 = Adam(...) optimizer2 = SGD(...) scheduler1 = ReduceLROnPlateau(optimizer1, ...) scheduler2 = LambdaLR(optimizer2, ...) return ( { \"optimizer\": optimizer1, \"lr_scheduler\": { \"scheduler\": scheduler1, \"monitor\": \"metric_to_track\", }, }, {\"optimizer\": optimizer2, \"lr_scheduler\": scheduler2}, ) Metrics can be made available to monitor by simply logging it using self.log('metric_to_track', metric_val) in your :class: ~pytorch_lightning.core.lightning.LightningModule . !!! note The frequency value specified in a dict along with the optimizer key is an int corresponding to the number of sequential batches optimized with the specific optimizer. It should be given to none or to all of the optimizers. There is a difference between passing multiple optimizers in a list, and passing multiple optimizers in dictionaries with a frequency of 1: - In the former case, all optimizers will operate on the given batch in each optimization step. - In the latter, only one optimizer will operate on the given batch at every step. This is different from the ``frequency`` value specified in the ``lr_scheduler_config`` mentioned above. .. code-block:: python def configure_optimizers(self): optimizer_one = torch.optim.SGD(self.model.parameters(), lr=0.01) optimizer_two = torch.optim.SGD(self.model.parameters(), lr=0.01) return [ {\"optimizer\": optimizer_one, \"frequency\": 5}, {\"optimizer\": optimizer_two, \"frequency\": 10}, ] In this example, the first optimizer will be used for the first 5 steps, the second optimizer for the next 10 steps and that cycle will continue. If an LR scheduler is specified for an optimizer using the ``lr_scheduler`` key in the above dict, the scheduler will only be updated when its optimizer is being used. Examples:: # most cases. no learning rate scheduler def configure_optimizers(self): return Adam(self.parameters(), lr=1e-3) # multiple optimizer case (e.g.: GAN) def configure_optimizers(self): gen_opt = Adam(self.model_gen.parameters(), lr=0.01) dis_opt = Adam(self.model_dis.parameters(), lr=0.02) return gen_opt, dis_opt # example with learning rate schedulers def configure_optimizers(self): gen_opt = Adam(self.model_gen.parameters(), lr=0.01) dis_opt = Adam(self.model_dis.parameters(), lr=0.02) dis_sch = CosineAnnealing(dis_opt, T_max=10) return [gen_opt, dis_opt], [dis_sch] # example with step-based learning rate schedulers # each optimizer has its own scheduler def configure_optimizers(self): gen_opt = Adam(self.model_gen.parameters(), lr=0.01) dis_opt = Adam(self.model_dis.parameters(), lr=0.02) gen_sch = { 'scheduler': ExponentialLR(gen_opt, 0.99), 'interval': 'step' # called after each training step } dis_sch = CosineAnnealing(dis_opt, T_max=10) # called every epoch return [gen_opt, dis_opt], [gen_sch, dis_sch] # example with optimizer frequencies # see training procedure in `Improved Training of Wasserstein GANs`, Algorithm 1 # https://arxiv.org/abs/1704.00028 def configure_optimizers(self): gen_opt = Adam(self.model_gen.parameters(), lr=0.01) dis_opt = Adam(self.model_dis.parameters(), lr=0.02) n_critic = 5 return ( {'optimizer': dis_opt, 'frequency': n_critic}, {'optimizer': gen_opt, 'frequency': 1} ) !!! note Some things to know: - Lightning calls ``.backward()`` and ``.step()`` on each optimizer and learning rate scheduler as needed. - If you use 16-bit precision (``precision=16``), Lightning will automatically handle the optimizers. - If you use multiple optimizers, :meth:`training_step` will have an additional ``optimizer_idx`` parameter. - If you use :class:`torch.optim.LBFGS`, Lightning handles the closure function automatically for you. - If you use multiple optimizers, gradients will be calculated only for the parameters of current optimizer at each training step. - If you need to control how often those optimizers step or override the default ``.step()`` schedule, override the :meth:`optimizer_step` hook. Source code in bemb/model/bemb_flex_lightning.py def configure_optimizers ( self ): optimizer = torch . optim . Adam ( self . parameters (), lr = self . learning_rate ) return optimizer forward ( self , args , kwargs ) Calls the forward method of the wrapped BEMB model, please refer to the documentaton of the BEMB class for detailed definitions of the arguments. Parameters: Name Type Description Default args _type_ arguments passed to the forward method of the wrapped BEMB model. required kwargs _type_ keyword arguments passed to the forward method of the wrapped BEMB model. required Returns: Type Description _type_ returns whatever the wrapped BEMB model returns. Source code in bemb/model/bemb_flex_lightning.py def forward ( self , args , kwargs ): \"\"\"Calls the forward method of the wrapped BEMB model, please refer to the documentaton of the BEMB class for detailed definitions of the arguments. Args: args (_type_): arguments passed to the forward method of the wrapped BEMB model. kwargs (_type_): keyword arguments passed to the forward method of the wrapped BEMB model. Returns: _type_: returns whatever the wrapped BEMB model returns. \"\"\" return self . model ( * args , ** kwargs ) test_step ( self , batch , batch_idx ) Operates on a single batch of data from the test set. In this step you'd normally generate examples or calculate anything of interest such as accuracy. .. code-block:: python # the pseudocode for these calls test_outs = [] for test_batch in test_data: out = test_step(test_batch) test_outs.append(out) test_epoch_end(test_outs) Parameters: Name Type Description Default batch The output of your :class: ~torch.utils.data.DataLoader . required batch_idx The index of this batch. required dataloader_id The index of the dataloader that produced this batch. (only if multiple test dataloaders used). required Returns: Type Description Any of. Any object or value None - Testing will skip to the next batch .. code-block:: python # if you have one test dataloader: def test_step(self, batch, batch_idx): ... # if you have multiple test dataloaders: def test_step(self, batch, batch_idx, dataloader_idx=0): ... Examples:: # CASE 1: A single test dataset def test_step(self, batch, batch_idx): x, y = batch # implement your own out = self(x) loss = self.loss(out, y) # log 6 example images # or generated text... or whatever sample_imgs = x[:6] grid = torchvision.utils.make_grid(sample_imgs) self.logger.experiment.add_image('example_images', grid, 0) # calculate acc labels_hat = torch.argmax(out, dim=1) test_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0) # log the outputs! self.log_dict({'test_loss': loss, 'test_acc': test_acc}) If you pass in multiple test dataloaders, :meth: test_step will have an additional argument. We recommend setting the default value of 0 so that you can quickly switch between single and multiple dataloaders. .. code-block:: python # CASE 2: multiple test dataloaders def test_step(self, batch, batch_idx, dataloader_idx=0): # dataloader_idx tells you which dataset this is. ... !!! note If you don't need to test you don't need to implement this method. !!! note When the :meth: test_step is called, the model has been put in eval mode and PyTorch gradients have been disabled. At the end of the test epoch, the model goes back to training mode and gradients are enabled. Source code in bemb/model/bemb_flex_lightning.py def test_step ( self , batch , batch_idx ): # LL = self.model.forward(batch, return_logit=False, all_items=False).mean() # self.log('test_log_likelihood', LL) # pred = self.model(batch, return_type='utility', return_scope='item_index', deterministic=True) # y_pred = torch.sigmoid(pred).cpu().numpy() # y_true = batch.label.cpu().numpy() # performance = {'acc': metrics.accuracy_score(y_true=y_true, y_pred=(y_pred >= 0.5).astype(int)), # 'll': - metrics.log_loss(y_true=y_true, y_pred=y_pred, eps=1E-5, labels=[0, 1]), # # 'auc': metrics.roc_auc_score(y_true=y_true, y_score=y_pred), # # 'f1': metrics.f1_score(y_true=y_true, y_pred=(y_pred >= 0.5).astype(int)) # } # pred = self.model(batch) # performance = self.model.get_within_category_accuracy(pred, batch.label) for key , val in self . _get_performance_dict ( batch ) . items (): self . log ( 'test_' + key , val , prog_bar = True , batch_size = len ( batch )) training_step ( self , batch , batch_idx ) Here you compute and return the training loss and some additional metrics for e.g. the progress bar or logger. Parameters: Name Type Description Default batch class: ~torch.Tensor | (:class: ~torch.Tensor , ...) | [:class: ~torch.Tensor , ...]): The output of your :class: ~torch.utils.data.DataLoader . A tensor, tuple or list. required batch_idx ``int`` Integer displaying index of this batch required optimizer_idx ``int`` When using multiple optimizers, this argument will also be present. required hiddens ``Any`` Passed in if :paramref: ~pytorch_lightning.core.lightning.LightningModule.truncated_bptt_steps > 0. required Returns: Type Description Any of. - class: ~torch.Tensor - The loss tensor - dict - A dictionary. Can include any keys, but must include the key 'loss' - None - Training will skip to the next batch. This is only for automatic optimization. This is not supported for multi-GPU, TPU, IPU, or DeepSpeed. In this step you'd normally do the forward pass and calculate the loss for a batch. You can also do fancier things like multiple forward passes or something model specific. Example:: def training_step(self, batch, batch_idx): x, y, z = batch out = self.encoder(x) loss = self.loss(out, x) return loss If you define multiple optimizers, this step will be called with an additional optimizer_idx parameter. .. code-block:: python # Multiple optimizers (e.g.: GANs) def training_step(self, batch, batch_idx, optimizer_idx): if optimizer_idx == 0: # do training_step with encoder ... if optimizer_idx == 1: # do training_step with decoder ... If you add truncated back propagation through time you will also get an additional argument with the hidden states of the previous step. .. code-block:: python # Truncated back-propagation through time def training_step(self, batch, batch_idx, hiddens): # hiddens are the hidden states from the previous truncated backprop step out, hiddens = self.lstm(data, hiddens) loss = ... return {\"loss\": loss, \"hiddens\": hiddens} !!! note The loss value shown in the progress bar is smoothed (averaged) over the last values, so it differs from the actual loss returned in train/validation step. Source code in bemb/model/bemb_flex_lightning.py def training_step ( self , batch , batch_idx ): elbo = self . model . elbo ( batch , num_seeds = self . num_needs ) self . log ( 'train_elbo' , elbo ) loss = - elbo return loss validation_step ( self , batch , batch_idx ) Operates on a single batch of data from the validation set. In this step you'd might generate examples or calculate anything of interest like accuracy. .. code-block:: python # the pseudocode for these calls val_outs = [] for val_batch in val_data: out = validation_step(val_batch) val_outs.append(out) validation_epoch_end(val_outs) Parameters: Name Type Description Default batch The output of your :class: ~torch.utils.data.DataLoader . required batch_idx The index of this batch. required dataloader_idx The index of the dataloader that produced this batch. (only if multiple val dataloaders used) required Returns: Type Description Any object or value None - Validation will skip to the next batch .. code-block:: python # pseudocode of order val_outs = [] for val_batch in val_data: out = validation_step(val_batch) if defined(\"validation_step_end\"): out = validation_step_end(out) val_outs.append(out) val_outs = validation_epoch_end(val_outs) .. code-block:: python # if you have one val dataloader: def validation_step(self, batch, batch_idx): ... # if you have multiple val dataloaders: def validation_step(self, batch, batch_idx, dataloader_idx=0): ... Examples:: # CASE 1: A single validation dataset def validation_step(self, batch, batch_idx): x, y = batch # implement your own out = self(x) loss = self.loss(out, y) # log 6 example images # or generated text... or whatever sample_imgs = x[:6] grid = torchvision.utils.make_grid(sample_imgs) self.logger.experiment.add_image('example_images', grid, 0) # calculate acc labels_hat = torch.argmax(out, dim=1) val_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0) # log the outputs! self.log_dict({'val_loss': loss, 'val_acc': val_acc}) If you pass in multiple val dataloaders, :meth: validation_step will have an additional argument. We recommend setting the default value of 0 so that you can quickly switch between single and multiple dataloaders. .. code-block:: python # CASE 2: multiple validation dataloaders def validation_step(self, batch, batch_idx, dataloader_idx=0): # dataloader_idx tells you which dataset this is. ... !!! note If you don't need to validate you don't need to implement this method. !!! note When the :meth: validation_step is called, the model has been put in eval mode and PyTorch gradients have been disabled. At the end of validation, the model goes back to training mode and gradients are enabled. Source code in bemb/model/bemb_flex_lightning.py def validation_step ( self , batch , batch_idx ): # LL = self.model.forward(batch, return_type='log_prob', return_scope='item_index', deterministic=True).mean() # self.log('val_log_likelihood', LL, prog_bar=True) # pred = self.model(batch) # performance = self.model.get_within_category_accuracy(pred, batch.label) # utility. for key , val in self . _get_performance_dict ( batch ) . items (): self . log ( 'val_' + key , val , prog_bar = True , batch_size = len ( batch ))","title":"API Reference BEMB"},{"location":"api_bemb/#api-reference-bemb","text":"","title":"API Reference: BEMB"},{"location":"api_bemb/#bemb.model","text":"","title":"model"},{"location":"api_bemb/#bemb.model.bayesian_coefficient","text":"Bayesian Coefficient is the building block for the BEMB model. Author: Tianyu Du Update: Apr. 28, 2022","title":"bayesian_coefficient"},{"location":"api_bemb/#bemb.model.bayesian_coefficient.BayesianCoefficient","text":"Source code in bemb/model/bayesian_coefficient.py class BayesianCoefficient ( nn . Module ): def __init__ ( self , variation : str , num_classes : int , obs2prior : bool , num_obs : Optional [ int ] = None , dim : int = 1 , prior_variance : float = 1.0 ) -> None : \"\"\"The Bayesian coefficient object represents a learnable tensor mu_i in R^k, where i is from a family (e.g., user, item) so there are num_classes * num_obs learnable weights in total. The prior distribution of mu_i is N(0, I) or N(H*X_obs(H shape=num_obs, X_obs shape=dim), Ix1). The posterior(i.e., variational) distribution of mu_i is a Gaussian distribution with learnable mean mu_i and unit covariance. The mean of the variational distribution consists of two parts: 1. The fixed part, which is not learnable. This part is particularly useful when the researcher want to impose some structure on the variational distribution. For example, the research might have some variational mean learned from another model and wish to use BEMB to polish the learned mean. 2. The flexible part, which is the main learnable part of the variational mean. Args: variation (str): the variation # TODO: this will be removed in the next version, after we have a complete test pipline. num_classes (int): number of classes in the coefficient. For example, if we have user-specific coefficients, `theta_user`, the `num_classes` should be the number of users. If we have item-specific coefficients, the the `num_classes` should be the number of items. obs2prior (bool): whether the mean of coefficient prior depends on the observable or not. num_obs (int, optional): the number of observables associated with each class. For example, if the coefficient if item-specific, and we have `obs2prior` set to True, the `num_obs` should be the number of observables for each item. Defaults to None. dim (int, optional): the dimension of the coefficient. Defaults to 1. prior_variance (float): the variance of the prior distribution of coefficient. Defaults to 1.0. \"\"\" super ( BayesianCoefficient , self ) . __init__ () # do we use this at all? TODO: drop self.variation. assert variation in [ 'item' , 'user' , 'constant' ] self . variation = variation self . obs2prior = obs2prior if variation == 'constant' : assert not obs2prior self . num_classes = num_classes self . num_obs = num_obs self . dim = dim # the dimension of greek letter parameter. self . prior_variance = prior_variance assert self . prior_variance > 0 # create prior distribution. if self . obs2prior : # the mean of prior distribution depends on observables. # initiate a Bayesian Coefficient with shape (dim, num_obs) standard Gaussian. self . prior_H = BayesianCoefficient ( variation = 'constant' , num_classes = dim , obs2prior = False , dim = num_obs , prior_variance = 1.0 ) else : self . register_buffer ( 'prior_zero_mean' , torch . zeros ( num_classes , dim )) # self.prior_cov_factor = nn.Parameter(torch.zeros(num_classes, dim, 1), requires_grad=False) # self.prior_cov_diag = nn.Parameter(torch.ones(num_classes, dim), requires_grad=False) self . register_buffer ( 'prior_cov_factor' , torch . zeros ( num_classes , dim , 1 )) self . register_buffer ( 'prior_cov_diag' , torch . ones ( num_classes , dim ) * self . prior_variance ) # create variational distribution. self . variational_mean_flexible = nn . Parameter ( torch . randn ( num_classes , dim ), requires_grad = True ) self . variational_logstd = nn . Parameter ( torch . randn ( num_classes , dim ), requires_grad = True ) self . register_buffer ( 'variational_cov_factor' , torch . zeros ( num_classes , dim , 1 )) self . variational_mean_fixed = None def __repr__ ( self ) -> str : \"\"\"Constructs a string representation of the Bayesian coefficient object. Returns: str: the string representation of the Bayesian coefficient object. \"\"\" if self . obs2prior : prior_str = f 'prior=N(H*X_obs(H shape= { self . prior_H . prior_zero_mean . shape } , X_obs shape= { self . prior_H . dim } ), Ix { self . prior_variance } )' else : prior_str = f 'prior=N(0, I)' return f 'BayesianCoefficient(num_classes= { self . num_classes } , dimension= { self . dim } , { prior_str } )' def update_variational_mean_fixed ( self , new_value : torch . Tensor ) -> None : \"\"\"Updates the fixed part of the mean of the variational distribution. Args: new_value (torch.Tensor): the new value of the fixed part of the mean of the variational distribution. \"\"\" assert new_value . shape == self . variational_mean_flexible . shape del self . variational_mean_fixed self . register_buffer ( 'variational_mean_fixed' , new_value ) @property def variational_mean ( self ) -> torch . Tensor : \"\"\"Returns the mean of the variational distribution. Returns: torch.Tensor: the current mean of the variational distribution with shape (num_classes, dim). \"\"\" if self . variational_mean_fixed is None : return self . variational_mean_flexible else : return self . variational_mean_fixed + self . variational_mean_flexible def log_prior ( self , sample : torch . Tensor , H_sample : Optional [ torch . Tensor ] = None , x_obs : Optional [ torch . Tensor ] = None ) -> torch . Tensor : \"\"\" Computes the logP_{Prior}(Coefficient Sample) for provided samples of the coefficient. The prior will either be a zero-mean Gaussian (if `obs2prior` is False) or a Gaussian with a learnable mean (if `obs2prior` is True). Args: sample (torch.Tensor): Monte Carlo samples of the variable with shape (num_seeds, num_classes, dim), where sample[i, :, :] corresponds to one sample of the coefficient. # arguments required only if `obs2prior == True`: H_sample (Optional[torch.Tensor], optional): Monte Carlo samples of the weight in obs2prior term, with shape (num_seeds, dim, self.num_obs), this is required if and only if obs2prior == True. Defaults to None. x_obs (Optional[torch.Tensor], optional): observables for obs2prior with shape (num_classes, num_obs), only required if and only if obs2prior == True. Defaults to None. Returns: torch.Tensor: the log prior of the variable with shape (num_seeds, num_classes). \"\"\" # p(sample) num_seeds , num_classes , dim = sample . shape # shape (num_seeds, num_classes) if self . obs2prior : assert H_sample . shape == ( num_seeds , dim , self . num_obs ) assert x_obs . shape == ( num_classes , self . num_obs ) x_obs = x_obs . view ( 1 , num_classes , self . num_obs ) . expand ( num_seeds , - 1 , - 1 ) H_sample = torch . transpose ( H_sample , 1 , 2 ) assert H_sample . shape == ( num_seeds , self . num_obs , dim ) mu = torch . bmm ( x_obs , H_sample ) assert mu . shape == ( num_seeds , num_classes , dim ) else : mu = self . prior_zero_mean out = LowRankMultivariateNormal ( loc = mu , cov_factor = self . prior_cov_factor , cov_diag = self . prior_cov_diag ) . log_prob ( sample ) assert out . shape == ( num_seeds , num_classes ) return out def log_variational ( self , sample : torch . Tensor ) -> torch . Tensor : \"\"\"Given a set of sampled values of coefficients, with shape (num_seeds, num_classes, dim), computes the the log probability of these sampled values of coefficients under the current variational distribution. Args: sample (torch.Tensor): a tensor of shape (num_seeds, num_classes, dim) containing sampled values of coefficients, where sample[i, :, :] corresponds to one sample of the coefficient. Returns: torch.Tensor: a tensor of shape (num_seeds, num_classes) containing the log probability of provided samples under the variational distribution. The output is splitted by random seeds and classes, you can sum along the second axis (i.e., the num_classes axis) to get the total log probability. \"\"\" num_seeds , num_classes , dim = sample . shape out = self . variational_distribution . log_prob ( sample ) assert out . shape == ( num_seeds , num_classes ) return out def rsample ( self , num_seeds : int = 1 ) -> Union [ torch . Tensor , Tuple [ torch . Tensor ]]: \"\"\"Samples values of the coefficient from the variational distribution using re-parameterization trick. Args: num_seeds (int, optional): number of values to be sampled. Defaults to 1. Returns: Union[torch.Tensor, Tuple[torch.Tensor]]: if `obs2prior` is disabled, returns a tensor of shape (num_seeds, num_classes, dim) where each output[i, :, :] corresponds to one sample of the coefficient. If `obs2prior` is enabled, returns a tuple of samples: (1) a tensor of shape (num_seeds, num_classes, dim) containing sampled values of coefficient, and (2) a tensor o shape (num_seeds, dim, num_obs) containing samples of the H weight in the prior distribution. \"\"\" value_sample = self . variational_distribution . rsample ( torch . Size ([ num_seeds ])) if self . obs2prior : # sample obs2prior H as well. H_sample = self . prior_H . rsample ( num_seeds = num_seeds ) return ( value_sample , H_sample ) else : return value_sample @property def variational_distribution ( self ) -> LowRankMultivariateNormal : \"\"\"Constructs the current variational distribution of the coefficient from current variational mean and covariance. \"\"\" return LowRankMultivariateNormal ( loc = self . variational_mean , cov_factor = self . variational_cov_factor , cov_diag = torch . exp ( self . variational_logstd )) @property def device ( self ) -> torch . device : \"\"\"Returns the device of tensors contained in this module.\"\"\" return self . variational_mean . device","title":"BayesianCoefficient"},{"location":"api_bemb/#bemb.model.bayesian_coefficient.BayesianCoefficient.device","text":"Returns the device of tensors contained in this module.","title":"device"},{"location":"api_bemb/#bemb.model.bayesian_coefficient.BayesianCoefficient.variational_distribution","text":"Constructs the current variational distribution of the coefficient from current variational mean and covariance.","title":"variational_distribution"},{"location":"api_bemb/#bemb.model.bayesian_coefficient.BayesianCoefficient.variational_mean","text":"Returns the mean of the variational distribution. Returns: Type Description torch.Tensor the current mean of the variational distribution with shape (num_classes, dim).","title":"variational_mean"},{"location":"api_bemb/#bemb.model.bayesian_coefficient.BayesianCoefficient.__init__","text":"The Bayesian coefficient object represents a learnable tensor mu_i in R^k, where i is from a family (e.g., user, item) so there are num_classes * num_obs learnable weights in total. The prior distribution of mu_i is N(0, I) or N(H*X_obs(H shape=num_obs, X_obs shape=dim), Ix1). The posterior(i.e., variational) distribution of mu_i is a Gaussian distribution with learnable mean mu_i and unit covariance. The mean of the variational distribution consists of two parts: 1. The fixed part, which is not learnable. This part is particularly useful when the researcher want to impose some structure on the variational distribution. For example, the research might have some variational mean learned from another model and wish to use BEMB to polish the learned mean. 2. The flexible part, which is the main learnable part of the variational mean. Parameters: Name Type Description Default variation str the variation # TODO: this will be removed in the next version, after we have a complete test pipline. required num_classes int number of classes in the coefficient. For example, if we have user-specific coefficients, theta_user , the num_classes should be the number of users. If we have item-specific coefficients, the the num_classes should be the number of items. required obs2prior bool whether the mean of coefficient prior depends on the observable or not. required num_obs int the number of observables associated with each class. For example, if the coefficient if item-specific, and we have obs2prior set to True, the num_obs should be the number of observables for each item. Defaults to None. None dim int the dimension of the coefficient. Defaults to 1. 1 prior_variance float the variance of the prior distribution of coefficient. Defaults to 1.0. 1.0 Source code in bemb/model/bayesian_coefficient.py def __init__ ( self , variation : str , num_classes : int , obs2prior : bool , num_obs : Optional [ int ] = None , dim : int = 1 , prior_variance : float = 1.0 ) -> None : \"\"\"The Bayesian coefficient object represents a learnable tensor mu_i in R^k, where i is from a family (e.g., user, item) so there are num_classes * num_obs learnable weights in total. The prior distribution of mu_i is N(0, I) or N(H*X_obs(H shape=num_obs, X_obs shape=dim), Ix1). The posterior(i.e., variational) distribution of mu_i is a Gaussian distribution with learnable mean mu_i and unit covariance. The mean of the variational distribution consists of two parts: 1. The fixed part, which is not learnable. This part is particularly useful when the researcher want to impose some structure on the variational distribution. For example, the research might have some variational mean learned from another model and wish to use BEMB to polish the learned mean. 2. The flexible part, which is the main learnable part of the variational mean. Args: variation (str): the variation # TODO: this will be removed in the next version, after we have a complete test pipline. num_classes (int): number of classes in the coefficient. For example, if we have user-specific coefficients, `theta_user`, the `num_classes` should be the number of users. If we have item-specific coefficients, the the `num_classes` should be the number of items. obs2prior (bool): whether the mean of coefficient prior depends on the observable or not. num_obs (int, optional): the number of observables associated with each class. For example, if the coefficient if item-specific, and we have `obs2prior` set to True, the `num_obs` should be the number of observables for each item. Defaults to None. dim (int, optional): the dimension of the coefficient. Defaults to 1. prior_variance (float): the variance of the prior distribution of coefficient. Defaults to 1.0. \"\"\" super ( BayesianCoefficient , self ) . __init__ () # do we use this at all? TODO: drop self.variation. assert variation in [ 'item' , 'user' , 'constant' ] self . variation = variation self . obs2prior = obs2prior if variation == 'constant' : assert not obs2prior self . num_classes = num_classes self . num_obs = num_obs self . dim = dim # the dimension of greek letter parameter. self . prior_variance = prior_variance assert self . prior_variance > 0 # create prior distribution. if self . obs2prior : # the mean of prior distribution depends on observables. # initiate a Bayesian Coefficient with shape (dim, num_obs) standard Gaussian. self . prior_H = BayesianCoefficient ( variation = 'constant' , num_classes = dim , obs2prior = False , dim = num_obs , prior_variance = 1.0 ) else : self . register_buffer ( 'prior_zero_mean' , torch . zeros ( num_classes , dim )) # self.prior_cov_factor = nn.Parameter(torch.zeros(num_classes, dim, 1), requires_grad=False) # self.prior_cov_diag = nn.Parameter(torch.ones(num_classes, dim), requires_grad=False) self . register_buffer ( 'prior_cov_factor' , torch . zeros ( num_classes , dim , 1 )) self . register_buffer ( 'prior_cov_diag' , torch . ones ( num_classes , dim ) * self . prior_variance ) # create variational distribution. self . variational_mean_flexible = nn . Parameter ( torch . randn ( num_classes , dim ), requires_grad = True ) self . variational_logstd = nn . Parameter ( torch . randn ( num_classes , dim ), requires_grad = True ) self . register_buffer ( 'variational_cov_factor' , torch . zeros ( num_classes , dim , 1 )) self . variational_mean_fixed = None","title":"__init__()"},{"location":"api_bemb/#bemb.model.bayesian_coefficient.BayesianCoefficient.__repr__","text":"Constructs a string representation of the Bayesian coefficient object. Returns: Type Description str the string representation of the Bayesian coefficient object. Source code in bemb/model/bayesian_coefficient.py def __repr__ ( self ) -> str : \"\"\"Constructs a string representation of the Bayesian coefficient object. Returns: str: the string representation of the Bayesian coefficient object. \"\"\" if self . obs2prior : prior_str = f 'prior=N(H*X_obs(H shape= { self . prior_H . prior_zero_mean . shape } , X_obs shape= { self . prior_H . dim } ), Ix { self . prior_variance } )' else : prior_str = f 'prior=N(0, I)' return f 'BayesianCoefficient(num_classes= { self . num_classes } , dimension= { self . dim } , { prior_str } )'","title":"__repr__()"},{"location":"api_bemb/#bemb.model.bayesian_coefficient.BayesianCoefficient.log_prior","text":"Computes the logP_{Prior}(Coefficient Sample) for provided samples of the coefficient. The prior will either be a zero-mean Gaussian (if obs2prior is False) or a Gaussian with a learnable mean (if obs2prior is True). Parameters: Name Type Description Default sample torch.Tensor Monte Carlo samples of the variable with shape (num_seeds, num_classes, dim), where sample[i, :, :] corresponds to one sample of the coefficient. required # arguments required only if `obs2prior == True` required H_sample Optional[torch.Tensor] Monte Carlo samples of the weight in obs2prior term, with shape (num_seeds, dim, self.num_obs), this is required if and only if obs2prior == True. Defaults to None. None x_obs Optional[torch.Tensor] observables for obs2prior with shape (num_classes, num_obs), only required if and only if obs2prior == True. Defaults to None. None Returns: Type Description torch.Tensor the log prior of the variable with shape (num_seeds, num_classes). Source code in bemb/model/bayesian_coefficient.py def log_prior ( self , sample : torch . Tensor , H_sample : Optional [ torch . Tensor ] = None , x_obs : Optional [ torch . Tensor ] = None ) -> torch . Tensor : \"\"\" Computes the logP_{Prior}(Coefficient Sample) for provided samples of the coefficient. The prior will either be a zero-mean Gaussian (if `obs2prior` is False) or a Gaussian with a learnable mean (if `obs2prior` is True). Args: sample (torch.Tensor): Monte Carlo samples of the variable with shape (num_seeds, num_classes, dim), where sample[i, :, :] corresponds to one sample of the coefficient. # arguments required only if `obs2prior == True`: H_sample (Optional[torch.Tensor], optional): Monte Carlo samples of the weight in obs2prior term, with shape (num_seeds, dim, self.num_obs), this is required if and only if obs2prior == True. Defaults to None. x_obs (Optional[torch.Tensor], optional): observables for obs2prior with shape (num_classes, num_obs), only required if and only if obs2prior == True. Defaults to None. Returns: torch.Tensor: the log prior of the variable with shape (num_seeds, num_classes). \"\"\" # p(sample) num_seeds , num_classes , dim = sample . shape # shape (num_seeds, num_classes) if self . obs2prior : assert H_sample . shape == ( num_seeds , dim , self . num_obs ) assert x_obs . shape == ( num_classes , self . num_obs ) x_obs = x_obs . view ( 1 , num_classes , self . num_obs ) . expand ( num_seeds , - 1 , - 1 ) H_sample = torch . transpose ( H_sample , 1 , 2 ) assert H_sample . shape == ( num_seeds , self . num_obs , dim ) mu = torch . bmm ( x_obs , H_sample ) assert mu . shape == ( num_seeds , num_classes , dim ) else : mu = self . prior_zero_mean out = LowRankMultivariateNormal ( loc = mu , cov_factor = self . prior_cov_factor , cov_diag = self . prior_cov_diag ) . log_prob ( sample ) assert out . shape == ( num_seeds , num_classes ) return out","title":"log_prior()"},{"location":"api_bemb/#bemb.model.bayesian_coefficient.BayesianCoefficient.log_variational","text":"Given a set of sampled values of coefficients, with shape (num_seeds, num_classes, dim), computes the the log probability of these sampled values of coefficients under the current variational distribution. Parameters: Name Type Description Default sample torch.Tensor a tensor of shape (num_seeds, num_classes, dim) containing sampled values of coefficients, where sample[i, :, :] corresponds to one sample of the coefficient. required Returns: Type Description torch.Tensor a tensor of shape (num_seeds, num_classes) containing the log probability of provided samples under the variational distribution. The output is splitted by random seeds and classes, you can sum along the second axis (i.e., the num_classes axis) to get the total log probability. Source code in bemb/model/bayesian_coefficient.py def log_variational ( self , sample : torch . Tensor ) -> torch . Tensor : \"\"\"Given a set of sampled values of coefficients, with shape (num_seeds, num_classes, dim), computes the the log probability of these sampled values of coefficients under the current variational distribution. Args: sample (torch.Tensor): a tensor of shape (num_seeds, num_classes, dim) containing sampled values of coefficients, where sample[i, :, :] corresponds to one sample of the coefficient. Returns: torch.Tensor: a tensor of shape (num_seeds, num_classes) containing the log probability of provided samples under the variational distribution. The output is splitted by random seeds and classes, you can sum along the second axis (i.e., the num_classes axis) to get the total log probability. \"\"\" num_seeds , num_classes , dim = sample . shape out = self . variational_distribution . log_prob ( sample ) assert out . shape == ( num_seeds , num_classes ) return out","title":"log_variational()"},{"location":"api_bemb/#bemb.model.bayesian_coefficient.BayesianCoefficient.rsample","text":"Samples values of the coefficient from the variational distribution using re-parameterization trick. Parameters: Name Type Description Default num_seeds int number of values to be sampled. Defaults to 1. 1 Returns: Type Description Union[torch.Tensor, Tuple[torch.Tensor]] if obs2prior is disabled, returns a tensor of shape (num_seeds, num_classes, dim) where each output[i, :, :] corresponds to one sample of the coefficient. If obs2prior is enabled, returns a tuple of samples: (1) a tensor of shape (num_seeds, num_classes, dim) containing sampled values of coefficient, and (2) a tensor o shape (num_seeds, dim, num_obs) containing samples of the H weight in the prior distribution. Source code in bemb/model/bayesian_coefficient.py def rsample ( self , num_seeds : int = 1 ) -> Union [ torch . Tensor , Tuple [ torch . Tensor ]]: \"\"\"Samples values of the coefficient from the variational distribution using re-parameterization trick. Args: num_seeds (int, optional): number of values to be sampled. Defaults to 1. Returns: Union[torch.Tensor, Tuple[torch.Tensor]]: if `obs2prior` is disabled, returns a tensor of shape (num_seeds, num_classes, dim) where each output[i, :, :] corresponds to one sample of the coefficient. If `obs2prior` is enabled, returns a tuple of samples: (1) a tensor of shape (num_seeds, num_classes, dim) containing sampled values of coefficient, and (2) a tensor o shape (num_seeds, dim, num_obs) containing samples of the H weight in the prior distribution. \"\"\" value_sample = self . variational_distribution . rsample ( torch . Size ([ num_seeds ])) if self . obs2prior : # sample obs2prior H as well. H_sample = self . prior_H . rsample ( num_seeds = num_seeds ) return ( value_sample , H_sample ) else : return value_sample","title":"rsample()"},{"location":"api_bemb/#bemb.model.bayesian_coefficient.BayesianCoefficient.update_variational_mean_fixed","text":"Updates the fixed part of the mean of the variational distribution. Parameters: Name Type Description Default new_value torch.Tensor the new value of the fixed part of the mean of the variational distribution. required Source code in bemb/model/bayesian_coefficient.py def update_variational_mean_fixed ( self , new_value : torch . Tensor ) -> None : \"\"\"Updates the fixed part of the mean of the variational distribution. Args: new_value (torch.Tensor): the new value of the fixed part of the mean of the variational distribution. \"\"\" assert new_value . shape == self . variational_mean_flexible . shape del self . variational_mean_fixed self . register_buffer ( 'variational_mean_fixed' , new_value )","title":"update_variational_mean_fixed()"},{"location":"api_bemb/#bemb.model.bayesian_linear","text":"Bayesian tensor object.","title":"bayesian_linear"},{"location":"api_bemb/#bemb.model.bayesian_linear.BayesianLinear","text":"Source code in bemb/model/bayesian_linear.py class BayesianLinear ( nn . Module ): def __init__ ( self , in_features : int , out_features : int , bias : bool = True , W_variational_mean_fixed : Optional [ torch . Tensor ] = None , device = None , dtype = None , W_prior_variance : float = 1.0 , b_prior_variance : float = 1.0 ): \"\"\"Linear layer where weight and bias are modelled as distributions. \"\"\" super () . __init__ () if dtype is not None : raise NotImplementedError ( 'dtype is not Supported yet.' ) self . in_features = in_features # the same as number of classes before. self . out_features = out_features # the same as latent dimension before. self . bias = bias # ============================================================================================================== # prior distributions for mean and bias. # ============================================================================================================== # the prior of weights are gausssian distributions independent across in_feature dimensions. self . register_buffer ( 'W_prior_mean' , torch . zeros ( in_features , out_features )) self . register_buffer ( 'W_prior_logstd' , torch . ones ( in_features , out_features ) * np . log ( W_prior_variance )) if self . bias : self . register_buffer ( 'b_prior_mean' , torch . zeros ( in_features , out_features )) self . register_buffer ( 'b_prior_logstd' , torch . ones ( in_features , out_features ) * np . log ( b_prior_variance )) # ============================================================================================================== # variational distributions for weight and bias. # ============================================================================================================== if W_variational_mean_fixed is None : self . W_variational_mean_fixed = None else : assert W_variational_mean_fixed . shape == ( in_features , out_features ), \\ f 'W_variational_mean_fixed tensor should have shape (in_features, out_features), got { W_variational_mean_fixed . shape } ' self . register_buffer ( 'W_variational_mean_fixed' , W_variational_mean_fixed ) # TODO: optionally add customizable initialization here. self . W_variational_mean_flexible = nn . Parameter ( torch . randn ( in_features , out_features ), requires_grad = True ) self . W_variational_logstd = nn . Parameter ( torch . randn ( in_features , out_features ), requires_grad = True ) if self . bias : self . b_variational_mean = nn . Parameter ( torch . randn ( out_features ), requires_grad = True ) self . b_variational_logstd = nn . Parameter ( torch . randn ( out_features ), requires_grad = True ) if device is not None : self . to ( device ) self . W_sample = None self . b_sample = None self . num_seeds = None @property def W_variational_mean ( self ): if self . W_variational_mean_fixed is None : return self . W_variational_mean_flexible else : return self . W_variational_mean_fixed + self . W_variational_mean_flexible def rsample ( self , num_seeds : int = 1 ) -> Optional [ Tuple [ torch . Tensor , Optional [ torch . Tensor ]]]: \"\"\"sample all parameters using re-parameterization trick. \"\"\" self . num_seeds = num_seeds self . W_sample = self . W_variational_distribution . rsample ( torch . Size ([ num_seeds ])) if self . bias : self . b_sample = self . b_variational_distribution . rsample ( torch . Size ([ num_seeds ])) return self . W_sample , self . b_sample def dsample ( self ): \"\"\"Deterministic sample method, set (W, b) sample to the mean of variational distribution.\"\"\" self . num_seeds = 1 self . W_sample = self . W_variational_mean . unsqueeze ( dim = 0 ) if self . bias : self . b_sample = self . b_variational_mean . unsqueeze ( dim = 0 ) return self . W_sample , self . b_sample def forward ( self , x , mode : str = 'multiply' ): \"\"\" Forward with weight sampling. Forward does out = XW + b, for forward() method behaves like the embedding layer in PyTorch, use the lookup() method. To have determinstic results, call self.dsample() before executing. To have stochastic results, call self.rsample() before executing. mode in ['multiply', 'lookup'] output shape: (num_seeds, batch_size, out_features). \"\"\" assert self . num_seeds is not None , 'run BayesianLinear.rsample() or dsample() first to sample weight and bias.' # if determinstic, num_seeds is set to 1. # w: (num_seeds, in_features=num_classes, out_features) # b: (num_seeds, out_features) # x: (N, in_features) if multiply and (N,) if lookup. # output: (num_seeds, N, out_features) if mode == 'multiply' : x = x . view ( 1 , - 1 , self . in_features ) . expand ( self . num_seeds , - 1 , - 1 ) # (num_seeds, N, in_features) out = x . bmm ( self . W_sample ) # (num_seeds, N, out_features) elif mode == 'lookup' : out = self . W_sample [:, x , :] # (num_seeds, N, out_features) else : raise ValueError ( f 'mode= { mode } is not allowed.' ) if self . bias : out += self . b_sample . view ( self . num_seeds , 1 , self . out_features ) # (num_seeds, N, out_features) return out @property def W_variational_distribution ( self ): \"\"\"the weight variational distribution.\"\"\" return Normal ( loc = self . W_variational_mean , scale = torch . exp ( self . W_variational_logstd )) @property def b_variational_distribution ( self ): return Normal ( loc = self . b_variational_mean , scale = torch . exp ( self . b_variational_logstd )) @property def device ( self ) -> torch . device : return self . W_variational_mean . device def log_prior ( self ): \"\"\"Evaluate the likelihood of the provided samples of parameter under the current prior distribution.\"\"\" assert self . num_seeds is not None , 'run BayesianLinear.rsample() or dsample() first to sample weight and bias.' num_seeds = self . W_sample . shape [ 0 ] total_log_prob = torch . zeros ( num_seeds , device = self . device ) # log P(W_sample). shape = (num_seeds,) W_prior = Normal ( loc = self . W_prior_mean , scale = torch . exp ( self . W_prior_logstd )) total_log_prob += W_prior . log_prob ( self . W_sample ) . sum ( dim = [ 1 , 2 ]) # log P(b_sample) if applicable. if self . bias : b_prior = Normal ( loc = self . b_prior_mean , scale = torch . exp ( self . b_prior_logstd )) total_log_prob += b_prior . log_prob ( self . b_sample ) . sum ( dim = 1 ) assert total_log_prob . shape == ( num_seeds ,) return total_log_prob def log_variational ( self ): \"\"\"Evaluate the likelihood of the provided samples of parameter under the current variational distribution.\"\"\" assert self . num_seeds is not None , 'run BayesianLinear.rsample() or dsample() first to sample weight and bias.' num_seeds = self . W_sample . shape [ 0 ] total_log_prob = torch . zeros ( num_seeds , device = self . device ) total_log_prob += self . W_variational_distribution . log_prob ( self . W_sample ) . sum ( dim = [ 1 , 2 ]) if self . bias : total_log_prob += self . b_variational_distribution . log_prob ( self . b_sample ) . sum ( dim = 1 ) assert total_log_prob . shape == ( num_seeds ,) return total_log_prob def __repr__ ( self ): prior_info = f 'W_prior ~ N(mu= { self . W_prior_mean } , logstd= { self . W_prior_logstd } )' if self . bias : prior_info += f 'b_prior ~ N(mu= { self . b_prior_mean } , logstd= { self . b_prior_logstd } )' return f \"BayesianLinear(in_features= { self . in_features } , out_features= { self . out_features } , bias= { self . bias } , { prior_info } )\"","title":"BayesianLinear"},{"location":"api_bemb/#bemb.model.bayesian_linear.BayesianLinear.W_variational_distribution","text":"the weight variational distribution.","title":"W_variational_distribution"},{"location":"api_bemb/#bemb.model.bayesian_linear.BayesianLinear.__init__","text":"Linear layer where weight and bias are modelled as distributions. Source code in bemb/model/bayesian_linear.py def __init__ ( self , in_features : int , out_features : int , bias : bool = True , W_variational_mean_fixed : Optional [ torch . Tensor ] = None , device = None , dtype = None , W_prior_variance : float = 1.0 , b_prior_variance : float = 1.0 ): \"\"\"Linear layer where weight and bias are modelled as distributions. \"\"\" super () . __init__ () if dtype is not None : raise NotImplementedError ( 'dtype is not Supported yet.' ) self . in_features = in_features # the same as number of classes before. self . out_features = out_features # the same as latent dimension before. self . bias = bias # ============================================================================================================== # prior distributions for mean and bias. # ============================================================================================================== # the prior of weights are gausssian distributions independent across in_feature dimensions. self . register_buffer ( 'W_prior_mean' , torch . zeros ( in_features , out_features )) self . register_buffer ( 'W_prior_logstd' , torch . ones ( in_features , out_features ) * np . log ( W_prior_variance )) if self . bias : self . register_buffer ( 'b_prior_mean' , torch . zeros ( in_features , out_features )) self . register_buffer ( 'b_prior_logstd' , torch . ones ( in_features , out_features ) * np . log ( b_prior_variance )) # ============================================================================================================== # variational distributions for weight and bias. # ============================================================================================================== if W_variational_mean_fixed is None : self . W_variational_mean_fixed = None else : assert W_variational_mean_fixed . shape == ( in_features , out_features ), \\ f 'W_variational_mean_fixed tensor should have shape (in_features, out_features), got { W_variational_mean_fixed . shape } ' self . register_buffer ( 'W_variational_mean_fixed' , W_variational_mean_fixed ) # TODO: optionally add customizable initialization here. self . W_variational_mean_flexible = nn . Parameter ( torch . randn ( in_features , out_features ), requires_grad = True ) self . W_variational_logstd = nn . Parameter ( torch . randn ( in_features , out_features ), requires_grad = True ) if self . bias : self . b_variational_mean = nn . Parameter ( torch . randn ( out_features ), requires_grad = True ) self . b_variational_logstd = nn . Parameter ( torch . randn ( out_features ), requires_grad = True ) if device is not None : self . to ( device ) self . W_sample = None self . b_sample = None self . num_seeds = None","title":"__init__()"},{"location":"api_bemb/#bemb.model.bayesian_linear.BayesianLinear.dsample","text":"Deterministic sample method, set (W, b) sample to the mean of variational distribution. Source code in bemb/model/bayesian_linear.py def dsample ( self ): \"\"\"Deterministic sample method, set (W, b) sample to the mean of variational distribution.\"\"\" self . num_seeds = 1 self . W_sample = self . W_variational_mean . unsqueeze ( dim = 0 ) if self . bias : self . b_sample = self . b_variational_mean . unsqueeze ( dim = 0 ) return self . W_sample , self . b_sample","title":"dsample()"},{"location":"api_bemb/#bemb.model.bayesian_linear.BayesianLinear.forward","text":"Forward with weight sampling. Forward does out = XW + b, for forward() method behaves like the embedding layer in PyTorch, use the lookup() method. To have determinstic results, call self.dsample() before executing. To have stochastic results, call self.rsample() before executing. mode in ['multiply', 'lookup'] output shape: (num_seeds, batch_size, out_features). Source code in bemb/model/bayesian_linear.py def forward ( self , x , mode : str = 'multiply' ): \"\"\" Forward with weight sampling. Forward does out = XW + b, for forward() method behaves like the embedding layer in PyTorch, use the lookup() method. To have determinstic results, call self.dsample() before executing. To have stochastic results, call self.rsample() before executing. mode in ['multiply', 'lookup'] output shape: (num_seeds, batch_size, out_features). \"\"\" assert self . num_seeds is not None , 'run BayesianLinear.rsample() or dsample() first to sample weight and bias.' # if determinstic, num_seeds is set to 1. # w: (num_seeds, in_features=num_classes, out_features) # b: (num_seeds, out_features) # x: (N, in_features) if multiply and (N,) if lookup. # output: (num_seeds, N, out_features) if mode == 'multiply' : x = x . view ( 1 , - 1 , self . in_features ) . expand ( self . num_seeds , - 1 , - 1 ) # (num_seeds, N, in_features) out = x . bmm ( self . W_sample ) # (num_seeds, N, out_features) elif mode == 'lookup' : out = self . W_sample [:, x , :] # (num_seeds, N, out_features) else : raise ValueError ( f 'mode= { mode } is not allowed.' ) if self . bias : out += self . b_sample . view ( self . num_seeds , 1 , self . out_features ) # (num_seeds, N, out_features) return out","title":"forward()"},{"location":"api_bemb/#bemb.model.bayesian_linear.BayesianLinear.log_prior","text":"Evaluate the likelihood of the provided samples of parameter under the current prior distribution. Source code in bemb/model/bayesian_linear.py def log_prior ( self ): \"\"\"Evaluate the likelihood of the provided samples of parameter under the current prior distribution.\"\"\" assert self . num_seeds is not None , 'run BayesianLinear.rsample() or dsample() first to sample weight and bias.' num_seeds = self . W_sample . shape [ 0 ] total_log_prob = torch . zeros ( num_seeds , device = self . device ) # log P(W_sample). shape = (num_seeds,) W_prior = Normal ( loc = self . W_prior_mean , scale = torch . exp ( self . W_prior_logstd )) total_log_prob += W_prior . log_prob ( self . W_sample ) . sum ( dim = [ 1 , 2 ]) # log P(b_sample) if applicable. if self . bias : b_prior = Normal ( loc = self . b_prior_mean , scale = torch . exp ( self . b_prior_logstd )) total_log_prob += b_prior . log_prob ( self . b_sample ) . sum ( dim = 1 ) assert total_log_prob . shape == ( num_seeds ,) return total_log_prob","title":"log_prior()"},{"location":"api_bemb/#bemb.model.bayesian_linear.BayesianLinear.log_variational","text":"Evaluate the likelihood of the provided samples of parameter under the current variational distribution. Source code in bemb/model/bayesian_linear.py def log_variational ( self ): \"\"\"Evaluate the likelihood of the provided samples of parameter under the current variational distribution.\"\"\" assert self . num_seeds is not None , 'run BayesianLinear.rsample() or dsample() first to sample weight and bias.' num_seeds = self . W_sample . shape [ 0 ] total_log_prob = torch . zeros ( num_seeds , device = self . device ) total_log_prob += self . W_variational_distribution . log_prob ( self . W_sample ) . sum ( dim = [ 1 , 2 ]) if self . bias : total_log_prob += self . b_variational_distribution . log_prob ( self . b_sample ) . sum ( dim = 1 ) assert total_log_prob . shape == ( num_seeds ,) return total_log_prob","title":"log_variational()"},{"location":"api_bemb/#bemb.model.bayesian_linear.BayesianLinear.rsample","text":"sample all parameters using re-parameterization trick. Source code in bemb/model/bayesian_linear.py def rsample ( self , num_seeds : int = 1 ) -> Optional [ Tuple [ torch . Tensor , Optional [ torch . Tensor ]]]: \"\"\"sample all parameters using re-parameterization trick. \"\"\" self . num_seeds = num_seeds self . W_sample = self . W_variational_distribution . rsample ( torch . Size ([ num_seeds ])) if self . bias : self . b_sample = self . b_variational_distribution . rsample ( torch . Size ([ num_seeds ])) return self . W_sample , self . b_sample","title":"rsample()"},{"location":"api_bemb/#bemb.model.bemb","text":"The core class of the Bayesian EMBedding (BEMB) model. Author: Tianyu Du Update: Apr. 28, 2022","title":"bemb"},{"location":"api_bemb/#bemb.model.bemb.BEMBFlex","text":"Source code in bemb/model/bemb.py class BEMBFlex ( nn . Module ): # ================================================================================================================== # core function as a PyTorch module. # ================================================================================================================== def __init__ ( self , utility_formula : str , obs2prior_dict : Dict [ str , bool ], coef_dim_dict : Dict [ str , int ], num_items : int , pred_item : bool , prior_variance : Union [ float , Dict [ str , float ]] = 1.0 , num_users : Optional [ int ] = None , num_sessions : Optional [ int ] = None , trace_log_q : bool = False , category_to_item : Dict [ int , List [ int ]] = None , # number of observables. num_user_obs : Optional [ int ] = None , num_item_obs : Optional [ int ] = None , num_session_obs : Optional [ int ] = None , num_price_obs : Optional [ int ] = None , num_taste_obs : Optional [ int ] = None , # additional modules. additional_modules : Optional [ List [ nn . Module ]] = None ) -> None : \"\"\" Args: utility_formula (str): a string representing the utility function U[user, item, session]. See documentation for more details in the documentation for the format of formula. Examples: lambda_item lambda_item + theta_user * alpha_item + zeta_user * item_obs lambda_item + theta_user * alpha_item + gamma_user * beta_item * price_obs See the doc-string of parse_utility for an example. obs2prior_dict (Dict[str, bool]): a dictionary maps coefficient name (e.g., 'lambda_item') to a boolean indicating if observable (e.g., item_obs) enters the prior of the coefficient. coef_dim_dict (Dict[str, int]): a dictionary maps coefficient name (e.g., 'lambda_item') to an integer indicating the dimension of coefficient. For standalone coefficients like U = lambda_item, the dim should be 1. For factorized coefficients like U = theta_user * alpha_item, the dim should be the latent dimension of theta and alpha. For coefficients multiplied with observables like U = zeta_user * item_obs, the dim should be the number of observables in item_obs. For factorized coefficient multiplied with observables like U = gamma_user * beta_item * price_obs, the dim should be the latent dim multiplied by number of observables in price_obs. num_items (int): number of items. pred_item (bool): there are two use cases of this model, suppose we have `user_index[i]` and `item_index[i]` for the i-th observation in the dataset. Case 1: which item among all items user `user_index[i]` is going to purchase, the prediction label is therefore `item_index[i]`. Equivalently, we can ask what's the likelihood for user `user_index[i]` to purchase `item_index[i]`. Case 2: what rating would user `user_index[i]` assign to item `item_index[i]`? In this case, the dataset object needs to contain a separate label. NOTE: for now, we only support binary labels. prior_variance (Union[float, Dict[str, float]]): the variance of prior distribution for coefficients. If a float is provided, all priors will be diagonal matrix with prior_variance along the diagonal. If a dictionary is provided, keys of prior_variance should be coefficient names, and the variance of prior of coef_name would be a diagonal matrix with prior_variance[coef_name] along the diagonal. Defaults to 1.0, which means all prior have identity matrix as the covariance matrix. num_users (int, optional): number of users, required only if coefficient or observable depending on user is in utility. Defaults to None. num_sessions (int, optional): number of sessions, required only if coefficient or observable depending on session is in utility. Defaults to None. trace_log_q (bool, optional): whether to trace the derivative of variational likelihood logQ with respect to variational parameters in the ELBO while conducting gradient update. Defaults to False. category_to_item (Dict[str, List[int]], optional): a dictionary with category id or name as keys, and category_to_item[C] contains the list of item ids belonging to category C. If None is provided, all items are assumed to be in the same category. Defaults to None. num_{user, item, session, price, taste}_obs (int, optional): number of observables of each type of features, only required if observable enters prior. NOTE: currently we only allow coefficient to depend on either user or item, thus only user and item observables can enter the prior of coefficient. Hence session, price, and taste observables are never required, we include it here for completeness. \"\"\" super ( BEMBFlex , self ) . __init__ () self . utility_formula = utility_formula self . obs2prior_dict = obs2prior_dict self . coef_dim_dict = coef_dim_dict self . prior_variance = prior_variance self . pred_item = pred_item self . num_items = num_items self . num_users = num_users self . num_sessions = num_sessions self . trace_log_q = trace_log_q self . category_to_item = category_to_item # ============================================================================================================== # Category ID to Item ID mapping. # Category ID to Category Size mapping. # Item ID to Category ID mapping. # ============================================================================================================== if self . category_to_item is None : if self . pred_item : # assign all items to the same category if predicting items. self . category_to_item = { 0 : list ( np . arange ( self . num_items ))} else : # otherwise, for the j-th observation in the dataset, the label[j] # only depends on user_index[j] and item_index[j], so we put each # item to its own category. self . category_to_item = { i : [ i ] for i in range ( self . num_items )} self . num_categories = len ( self . category_to_item ) max_category_size = max ( len ( x ) for x in self . category_to_item . values ()) category_to_item_tensor = torch . full ( ( self . num_categories , max_category_size ), - 1 ) category_to_size_tensor = torch . empty ( self . num_categories ) for c , item_in_c in self . category_to_item . items (): category_to_item_tensor [ c , : len ( item_in_c )] = torch . LongTensor ( item_in_c ) category_to_size_tensor [ c ] = torch . scalar_tensor ( len ( item_in_c )) self . register_buffer ( 'category_to_item_tensor' , category_to_item_tensor . long ()) self . register_buffer ( 'category_to_size_tensor' , category_to_size_tensor . long ()) item_to_category_tensor = torch . zeros ( self . num_items ) for c , items_in_c in self . category_to_item . items (): item_to_category_tensor [ items_in_c ] = c self . register_buffer ( 'item_to_category_tensor' , item_to_category_tensor . long ()) # ============================================================================================================== # Create Bayesian Coefficient Objects # ============================================================================================================== # model configuration. self . formula = parse_utility ( utility_formula ) print ( 'BEMB: utility formula parsed:' ) pprint ( self . formula ) self . raw_formula = utility_formula self . obs2prior_dict = obs2prior_dict # dimension of each observable, this one is used only for obs2prior. self . num_obs_dict = { 'user' : num_user_obs , 'item' : num_item_obs , 'session' : num_session_obs , 'price' : num_price_obs , 'taste' : num_taste_obs , 'constant' : 1 # not really used, for dummy variables. } # how many classes for the variational distribution. # for example, beta_item would be `num_items` 10-dimensional gaussian if latent dim = 10. variation_to_num_classes = { 'user' : self . num_users , 'item' : self . num_items , 'constant' : 1 } coef_dict = dict () for additive_term in self . formula : for coef_name in additive_term [ 'coefficient' ]: variation = coef_name . split ( '_' )[ - 1 ] s2 = self . prior_variance [ coef_name ] if isinstance ( self . prior_variance , dict ) else self . prior_variance coef_dict [ coef_name ] = BayesianCoefficient ( variation = variation , num_classes = variation_to_num_classes [ variation ], obs2prior = self . obs2prior_dict [ coef_name ], num_obs = self . num_obs_dict [ variation ], dim = self . coef_dim_dict [ coef_name ], prior_variance = s2 ) self . coef_dict = nn . ModuleDict ( coef_dict ) # ============================================================================================================== # Optional: register additional modules. # ============================================================================================================== if additional_modules is None : self . additional_modules = [] else : raise NotImplementedError ( 'Additional modules are temporarily disabled for further development.' ) self . additional_modules = nn . ModuleList ( additional_modules ) def __str__ ( self ): return f 'Bayesian EMBedding Model with U[user, item, session] = { self . raw_formula } \\n ' \\ + f 'Total number of parameters: { self . num_params } . \\n ' \\ + 'With the following coefficients: \\n ' \\ + str ( self . coef_dict ) + ' \\n ' \\ + str ( self . additional_modules ) def posterior_mean ( self , coef_name : str ) -> torch . Tensor : \"\"\"Returns the mean of estimated posterior distribution of coefficient `coef_name`. Args: coef_name (str): name of the coefficient to query. Returns: torch.Tensor: mean of the estimated posterior distribution of `coef_name`. \"\"\" if coef_name in self . coef_dict . keys (): return self . coef_dict [ coef_name ] . variational_mean else : raise KeyError ( f ' { coef_name } is not a valid coefficient name in { self . utility_formula } .' ) def forward ( self , batch : ChoiceDataset , return_type : str , return_scope : str , deterministic : bool = True , sample_dict : Optional [ Dict [ str , torch . Tensor ]] = None , num_seeds : Optional [ int ] = None ) -> torch . Tensor : \"\"\"A combined method for inference with the model. Args: batch (ChoiceDataset): batch data containing choice information. return_type (str): either 'log_prob' or 'utility'. 'log_prob': return the log-probability (by within-category log-softmax) for items 'utility': return the utility value of items. return_scope (str): either 'item_index' or 'all_items'. 'item_index': for each observation i, return log-prob/utility for the chosen item batch.item_index[i] only. 'all_items': for each observation i, return log-prob/utility for all items. deterministic (bool, optional): True: expectations of parameter variational distributions are used for inference. False: the user needs to supply a dictionary of sampled parameters for inference. Defaults to True. sample_dict (Optional[Dict[str, torch.Tensor]], optional): sampled parameters for inference task. This is not needed when `deterministic` is True. When `deterministic` is False, the user can supply a `sample_dict`. If `sample_dict` is not provided, this method will create `num_seeds` samples. Defaults to None. num_seeds (Optional[int]): the number of random samples of parameters to construct. This is only required if `deterministic` is False (i.e., stochastic mode) and `sample_dict` is not provided. Defaults to None. Returns: torch.Tensor: a tensor of log-probabilities or utilities, depending on `return_type`. The shape of the returned tensor depends on `return_scope` and `deterministic`. ------------------------------------------------------------------------- | `return_scope` | `deterministic` | Output shape | ------------------------------------------------------------------------- | 'item_index` | True | (len(batch),) | ------------------------------------------------------------------------- | 'all_items' | True | (len(batch), num_items) | ------------------------------------------------------------------------- | 'item_index' | False | (num_seeds, len(batch)) | ------------------------------------------------------------------------- | 'all_items' | False | (num_seeds, len(batch), num_items) | ------------------------------------------------------------------------- \"\"\" # ============================================================================================================== # check arguments. # ============================================================================================================== assert return_type in [ 'log_prob' , 'utility' ], \"return_type must be either 'log_prob' or 'utility'.\" assert return_scope in [ 'item_index' , 'all_items' ], \"return_scope must be either 'item_index' or 'all_items'.\" assert deterministic in [ True , False ] if ( not deterministic ) and ( sample_dict is None ): assert num_seeds >= 1 , \"A positive interger `num_seeds` is required if `deterministic` is False and no `sample_dict` is provided.\" # when pred_item is true, the model is predicting which item is bought (specified by item_index). if self . pred_item : batch . label = batch . item_index # ============================================================================================================== # get sample_dict ready. # ============================================================================================================== if deterministic : num_seeds = 1 # Use the means of variational distributions as the sole deterministic MC sample. # NOTE: here we don't need to sample the obs2prior weight H since we only compute the log-likelihood. # TODO: is this correct? sample_dict = dict () for coef_name , coef in self . coef_dict . items (): sample_dict [ coef_name ] = coef . variational_distribution . mean . unsqueeze ( dim = 0 ) # (1, num_*, dim) else : if sample_dict is None : # sample stochastic parameters. sample_dict = self . sample_coefficient_dictionary ( num_seeds ) else : # use the provided sample_dict. num_seeds = list ( sample_dict . values ())[ 0 ] . shape [ 0 ] # ============================================================================================================== # call the sampling method of additional modules. # ============================================================================================================== for module in self . additional_modules : # deterministic sample. if deterministic : module . dsample () else : module . rsample ( num_seeds = num_seeds ) # if utility is requested, don't run log-softmax, simply return logit. return_logit = ( return_type == 'utility' ) if return_scope == 'all_items' : # (num_seeds, len(batch), num_items) out = self . log_likelihood_all_items ( batch = batch , sample_dict = sample_dict , return_logit = return_logit ) elif return_scope == 'item_index' : # (num_seeds, len(batch)) out = self . log_likelihood_item_index ( batch = batch , sample_dict = sample_dict , return_logit = return_logit ) if deterministic : # drop the first dimension, which has size of `num_seeds` (equals 1 in the deterministic case). # (len(batch), num_items) or (len(batch),) return out . squeeze ( dim = 0 ) return out @property def num_params ( self ) -> int : return sum ([ p . numel () for p in self . parameters ()]) @property def device ( self ) -> torch . device : for coef in self . coef_dict . values (): return coef . device # ================================================================================================================== # helper functions. # ================================================================================================================== def sample_coefficient_dictionary ( self , num_seeds : int ) -> Dict [ str , torch . Tensor ]: \"\"\"A helper function to sample parameters from coefficients. Args: num_seeds (int): number of random samples. Returns: Dict[str, torch.Tensor]: a dictionary maps coefficient names to tensor of sampled coefficient parameters, where the first dimension of the sampled tensor has size `num_seeds`. Each sample tensor has shape (num_seeds, num_classes, dim). \"\"\" sample_dict = dict () for coef_name , coef in self . coef_dict . items (): s = coef . rsample ( num_seeds ) if coef . obs2prior : # sample both obs2prior weight and realization of variable. assert isinstance ( s , tuple ) and len ( s ) == 2 sample_dict [ coef_name ] = s [ 0 ] sample_dict [ coef_name + '.H' ] = s [ 1 ] else : # only sample the realization of variable. assert torch . is_tensor ( s ) sample_dict [ coef_name ] = s return sample_dict @torch . no_grad () def get_within_category_accuracy ( self , log_p_all_items : torch . Tensor , label : torch . LongTensor ) -> Dict [ str , float ]: \"\"\"A helper function for computing prediction accuracy (i.e., all non-differential metrics) within category. In particular, this method calculates the accuracy, precision, recall and F1 score. This method has the same functionality as the following peusodcode: for C in categories: # get sessions in which item in category C was purchased. T <- (t for t in {0,1,..., len(label)-1} if label[t] is in C) Y <- label[T] predictions = list() for t in T: # get the prediction within category for this session. y_pred = argmax_{items in C} log prob computed before. predictions.append(y_pred) accuracy = mean(Y == predictions) Similarly, this function computes precision, recall and f1score as well. Args: log_p_all_items (torch.Tensor): shape (num_sessions, num_items) the log probability of choosing each item in each session. label (torch.LongTensor): shape (num_sessions,), the IDs of items purchased in each session. Returns: [Dict[str, float]]: A dictionary containing performance metrics. \"\"\" # argmax: (num_sessions, num_categories), within category argmax. # item IDs are consecutive, thus argmax is the same as IDs of the item with highest P. _ , argmax_by_category = scatter_max ( log_p_all_items , self . item_to_category_tensor , dim =- 1 ) # category_purchased[t] = the category of item label[t]. # (num_sessions,) category_purchased = self . item_to_category_tensor [ label ] # pred[t] = the item with highest utility from the category item label[t] belongs to. # (num_sessions,) pred_from_category = argmax_by_category [ torch . arange ( len ( label )), category_purchased ] within_category_accuracy = ( pred_from_category == label ) . float () . mean () . item () # precision precision = list () recall = list () for i in range ( self . num_items ): correct_i = torch . sum ( ( torch . logical_and ( pred_from_category == i , label == i )) . float ()) precision_i = correct_i / \\ torch . sum (( pred_from_category == i ) . float ()) recall_i = correct_i / torch . sum (( label == i ) . float ()) # do not add if divided by zero. if torch . any ( pred_from_category == i ): precision . append ( precision_i . cpu () . item ()) if torch . any ( label == i ): recall . append ( recall_i . cpu () . item ()) precision = float ( np . mean ( precision )) recall = float ( np . mean ( recall )) if precision == recall == 0 : f1 = 0 else : f1 = 2 * precision * recall / ( precision + recall ) return { 'accuracy' : within_category_accuracy , 'precision' : precision , 'recall' : recall , 'f1score' : f1 } # ================================================================================================================== # Methods for terms in the ELBO: prior, likelihood, and variational. # ================================================================================================================== def log_likelihood_all_items ( self , batch : ChoiceDataset , return_logit : bool , sample_dict : Dict [ str , torch . Tensor ]) -> torch . Tensor : \"\"\" NOTE to developers: This method computes utilities for all items available, which is a relatively slow operation. For training the model, you only need the utility/log-prob for the chosen/relevant item (i.e., item_index[i] for each i-th observation). Use this method for inference only. Use self.log_likelihood_item_index() for training instead. Computes the log probability of choosing `each` item in each session based on current model parameters. This method allows for specifying {user, item}_latent_value for Monte Carlo estimation in ELBO. For actual prediction tasks, use the forward() function, which will use means of variational distributions for user and item latents. Args: batch (ChoiceDataset): a ChoiceDataset object containing relevant information. return_logit(bool): if set to True, return the log-probability, otherwise return the logit/utility. sample_dict(Dict[str, torch.Tensor]): Monte Carlo samples for model coefficients (i.e., those Greek letters). sample_dict.keys() should be the same as keys of self.obs2prior_dict, i.e., those greek letters actually enter the functional form of utility. The value of sample_dict should be tensors of shape (num_seeds, num_classes, dim) where num_classes in {num_users, num_items, 1} and dim in {latent_dim(K), num_item_obs, num_user_obs, 1}. Returns: torch.Tensor: a tensor of shape (num_seeds, len(batch), self.num_items), where out[x, y, z] is the probability of choosing item z in session y conditioned on latents to be the x-th Monte Carlo sample. \"\"\" num_seeds = next ( iter ( sample_dict . values ())) . shape [ 0 ] # avoid repeated work when user purchased several items in the same session. user_session_index = torch . stack ( [ batch . user_index , batch . session_index ]) assert user_session_index . shape == ( 2 , len ( batch )) unique_user_sess , inverse_indices = torch . unique ( user_session_index , dim = 1 , return_inverse = True ) user_index = unique_user_sess [ 0 , :] session_index = unique_user_sess [ 1 , :] assert len ( user_index ) == len ( session_index ) # short-hands for easier shape check. R = num_seeds # P = len(batch) # num_purchases. P = unique_user_sess . shape [ 1 ] S = self . num_sessions U = self . num_users I = self . num_items # ============================================================================================================== # Helper Functions for Reshaping. # ============================================================================================================== def reshape_user_coef_sample ( C ): # input shape (R, U, *) C = C . view ( R , U , 1 , - 1 ) . expand ( - 1 , - 1 , I , - 1 ) # (R, U, I, *) C = C [:, user_index , :, :] assert C . shape == ( R , P , I , positive_integer ) return C def reshape_item_coef_sample ( C ): # input shape (R, I, *) C = C . view ( R , 1 , I , - 1 ) . expand ( - 1 , P , - 1 , - 1 ) assert C . shape == ( R , P , I , positive_integer ) return C def reshape_constant_coef_sample ( C ): # input shape (R, *) C = C . view ( R , 1 , 1 , - 1 ) . expand ( - 1 , P , I , - 1 ) assert C . shape == ( R , P , I , positive_integer ) return C def reshape_coef_sample ( sample , name ): # reshape the monte carlo sample of coefficients to (R, P, I, *). if name . endswith ( '_user' ): # (R, U, *) --> (R, P, I, *) return reshape_user_coef_sample ( sample ) elif name . endswith ( '_item' ): # (R, I, *) --> (R, P, I, *) return reshape_item_coef_sample ( sample ) elif name . endswith ( '_constant' ): # (R, *) --> (R, P, I, *) return reshape_constant_coef_sample ( sample ) else : raise ValueError def reshape_observable ( obs , name ): # reshape observable to (R, P, I, *) so that it can be multiplied with monte carlo # samples of coefficients. O = obs . shape [ - 1 ] # number of observables. assert O == positive_integer if name . startswith ( 'item_' ): assert obs . shape == ( I , O ) obs = obs . view ( 1 , 1 , I , O ) . expand ( R , P , - 1 , - 1 ) elif name . startswith ( 'user_' ): assert obs . shape == ( U , O ) obs = obs [ user_index , :] # (P, O) obs = obs . view ( 1 , P , 1 , O ) . expand ( R , - 1 , I , - 1 ) elif name . startswith ( 'session_' ): assert obs . shape == ( S , O ) obs = obs [ session_index , :] # (P, O) return obs . view ( 1 , P , 1 , O ) . expand ( R , - 1 , I , - 1 ) elif name . startswith ( 'price_' ): assert obs . shape == ( S , I , O ) obs = obs [ session_index , :, :] # (P, I, O) return obs . view ( 1 , P , I , O ) . expand ( R , - 1 , - 1 , - 1 ) elif name . startswith ( 'taste_' ): assert obs . shape == ( U , I , O ) obs = obs [ user_index , :, :] # (P, I, O) return obs . view ( 1 , P , I , O ) . expand ( R , - 1 , - 1 , - 1 ) else : raise ValueError assert obs . shape == ( R , P , I , O ) return obs # ============================================================================================================== # Copmute the Utility Term by Term. # ============================================================================================================== # P is the number of unique (user, session) pairs. # (random_seeds, P, num_items). utility = torch . zeros ( R , P , I , device = self . device ) # loop over additive term to utility for term in self . formula : # Type I: single coefficient, e.g., lambda_item or lambda_user. if len ( term [ 'coefficient' ]) == 1 and term [ 'observable' ] is None : # E.g., lambda_item or lambda_user coef_name = term [ 'coefficient' ][ 0 ] coef_sample = reshape_coef_sample ( sample_dict [ coef_name ], coef_name ) assert coef_sample . shape == ( R , P , I , 1 ) additive_term = coef_sample . view ( R , P , I ) # Type II: factorized coefficient, e.g., <theta_user, lambda_item>. elif len ( term [ 'coefficient' ]) == 2 and term [ 'observable' ] is None : coef_name_0 = term [ 'coefficient' ][ 0 ] coef_name_1 = term [ 'coefficient' ][ 1 ] coef_sample_0 = reshape_coef_sample ( sample_dict [ coef_name_0 ], coef_name_0 ) coef_sample_1 = reshape_coef_sample ( sample_dict [ coef_name_1 ], coef_name_1 ) assert coef_sample_0 . shape == coef_sample_1 . shape == ( R , P , I , positive_integer ) additive_term = ( coef_sample_0 * coef_sample_1 ) . sum ( dim =- 1 ) # Type III: single coefficient multiplied by observable, e.g., theta_user * x_obs_item. elif len ( term [ 'coefficient' ]) == 1 and term [ 'observable' ] is not None : coef_name = term [ 'coefficient' ][ 0 ] coef_sample = reshape_coef_sample ( sample_dict [ coef_name ], coef_name ) assert coef_sample . shape == ( R , P , I , positive_integer ) obs_name = term [ 'observable' ] obs = reshape_observable ( getattr ( batch , obs_name ), obs_name ) assert obs . shape == ( R , P , I , positive_integer ) additive_term = ( coef_sample * obs ) . sum ( dim =- 1 ) # Type IV: factorized coefficient multiplied by observable. # e.g., gamma_user * beta_item * price_obs. elif len ( term [ 'coefficient' ]) == 2 and term [ 'observable' ] is not None : coef_name_0 , coef_name_1 = term [ 'coefficient' ][ 0 ], term [ 'coefficient' ][ 1 ] coef_sample_0 = reshape_coef_sample ( sample_dict [ coef_name_0 ], coef_name_0 ) coef_sample_1 = reshape_coef_sample ( sample_dict [ coef_name_1 ], coef_name_1 ) assert coef_sample_0 . shape == coef_sample_1 . shape == ( R , P , I , positive_integer ) num_obs_times_latent_dim = coef_sample_0 . shape [ - 1 ] obs_name = term [ 'observable' ] obs = reshape_observable ( getattr ( batch , obs_name ), obs_name ) assert obs . shape == ( R , P , I , positive_integer ) num_obs = obs . shape [ - 1 ] # number of observables. assert ( num_obs_times_latent_dim % num_obs ) == 0 latent_dim = num_obs_times_latent_dim // num_obs coef_sample_0 = coef_sample_0 . view ( R , P , I , num_obs , latent_dim ) coef_sample_1 = coef_sample_1 . view ( R , P , I , num_obs , latent_dim ) # compute the factorized coefficient with shape (R, P, I, O). coef = ( coef_sample_0 * coef_sample_1 ) . sum ( dim =- 1 ) additive_term = ( coef * obs ) . sum ( dim =- 1 ) else : raise ValueError ( f 'Undefined term type: { term } ' ) assert additive_term . shape == ( R , P , I ) utility += additive_term # ============================================================================================================== # Mask Out Unavailable Items in Each Session. # ============================================================================================================== if batch . item_availability is not None : # expand to the Monte Carlo sample dimension. # (S, I) -> (P, I) -> (1, P, I) -> (R, P, I) A = batch . item_availability [ session_index , :] . unsqueeze ( dim = 0 ) . expand ( R , - 1 , - 1 ) utility [ ~ A ] = - ( torch . finfo ( utility . dtype ) . max / 2 ) utility = utility [:, inverse_indices , :] assert utility . shape == ( R , len ( batch ), I ) for module in self . additional_modules : additive_term = module ( batch ) assert additive_term . shape == ( R , len ( batch ), 1 ) utility += additive_term . expand ( - 1 , - 1 , I ) if return_logit : # output shape: (num_seeds, len(batch), num_items) return utility else : # compute log likelihood log p(choosing item i | user, item latents) # compute log softmax separately within each category. log_p = scatter_log_softmax ( utility , self . item_to_category_tensor , dim =- 1 ) # output shape: (num_seeds, len(batch), num_items) return log_p def log_likelihood_item_index ( self , batch : ChoiceDataset , return_logit : bool , sample_dict : Dict [ str , torch . Tensor ]) -> torch . Tensor : \"\"\" NOTE for developers: This method is more efficient and only computes log-likelihood/logit(utility) for item in item_index[i] for each i-th observation. Developers should use use `log_likelihood_all_items` for inference purpose and to computes log-likelihoods/utilities for ALL items for the i-th observation. Computes the log probability of choosing item_index[i] in each session based on current model parameters. This method allows for specifying {user, item}_latent_value for Monte Carlo estimation in ELBO. For actual prediction tasks, use the forward() function, which will use means of variational distributions for user and item latents. Args: batch (ChoiceDataset): a ChoiceDataset object containing relevant information. return_logit(bool): if set to True, return the log-probability, otherwise return the logit/utility. sample_dict(Dict[str, torch.Tensor]): Monte Carlo samples for model coefficients (i.e., those Greek letters). sample_dict.keys() should be the same as keys of self.obs2prior_dict, i.e., those greek letters actually enter the functional form of utility. The value of sample_dict should be tensors of shape (num_seeds, num_classes, dim) where num_classes in {num_users, num_items, 1} and dim in {latent_dim(K), num_item_obs, num_user_obs, 1}. Returns: torch.Tensor: a tensor of shape (num_seeds, len(batch)), where out[x, y] is the probabilities of choosing item batch.item[y] in session y conditioned on latents to be the x-th Monte Carlo sample. \"\"\" num_seeds = next ( iter ( sample_dict . values ())) . shape [ 0 ] # get category id of the item bought in each row of batch. cate_index = self . item_to_category_tensor [ batch . item_index ] # get item ids of all items from the same category of each item bought. relevant_item_index = self . category_to_item_tensor [ cate_index , :] relevant_item_index = relevant_item_index . view ( - 1 ,) # index were padded with -1's, drop those dummy entries. relevant_item_index = relevant_item_index [ relevant_item_index != - 1 ] # the first repeats[0] entries in relevant_item_index are for the category of item_index[0] repeats = self . category_to_size_tensor [ cate_index ] # argwhere(reverse_indices == k) are positions in relevant_item_index for the category of item_index[k]. reverse_indices = torch . repeat_interleave ( torch . arange ( len ( batch ), device = self . device ), repeats ) # expand the user_index and session_index. user_index = torch . repeat_interleave ( batch . user_index , repeats ) session_index = torch . repeat_interleave ( batch . session_index , repeats ) # duplicate the item focused to match. item_index_expanded = torch . repeat_interleave ( batch . item_index , repeats ) # short-hands for easier shape check. R = num_seeds # total number of relevant items. total_computation = len ( session_index ) S = self . num_sessions U = self . num_users I = self . num_items # ========================================================================================== # Helper Functions for Reshaping. # ========================================================================================== def reshape_coef_sample ( sample , name ): # reshape the monte carlo sample of coefficients to (R, P, I, *). if name . endswith ( '_user' ): # (R, U, *) --> (R, total_computation, *) return sample [:, user_index , :] elif name . endswith ( '_item' ): # (R, I, *) --> (R, total_computation, *) return sample [:, relevant_item_index , :] elif name . endswith ( '_constant' ): # (R, *) --> (R, total_computation, *) return sample . view ( R , 1 , - 1 ) . expand ( - 1 , total_computation , - 1 ) else : raise ValueError def reshape_observable ( obs , name ): # reshape observable to (R, P, I, *) so that it can be multiplied with monte carlo # samples of coefficients. O = obs . shape [ - 1 ] # number of observables. assert O == positive_integer if name . startswith ( 'item_' ): assert obs . shape == ( I , O ) obs = obs [ relevant_item_index , :] elif name . startswith ( 'user_' ): assert obs . shape == ( U , O ) obs = obs [ user_index , :] elif name . startswith ( 'session_' ): assert obs . shape == ( S , O ) obs = obs [ session_index , :] elif name . startswith ( 'price_' ): assert obs . shape == ( S , I , O ) obs = obs [ session_index , relevant_item_index , :] elif name . startswith ( 'taste_' ): assert obs . shape == ( U , I , O ) obs = obs [ user_index , relevant_item_index , :] else : raise ValueError assert obs . shape == ( total_computation , O ) return obs . unsqueeze ( dim = 0 ) . expand ( R , - 1 , - 1 ) # ========================================================================================== # Compute Components related to users and items only. # ========================================================================================== utility = torch . zeros ( R , total_computation , device = self . device ) # loop over additive term to utility for term in self . formula : # Type I: single coefficient, e.g., lambda_item or lambda_user. if len ( term [ 'coefficient' ]) == 1 and term [ 'observable' ] is None : # E.g., lambda_item or lambda_user coef_name = term [ 'coefficient' ][ 0 ] coef_sample = reshape_coef_sample ( sample_dict [ coef_name ], coef_name ) assert coef_sample . shape == ( R , total_computation , 1 ) additive_term = coef_sample . view ( R , total_computation ) # Type II: factorized coefficient, e.g., <theta_user, lambda_item>. elif len ( term [ 'coefficient' ]) == 2 and term [ 'observable' ] is None : coef_name_0 = term [ 'coefficient' ][ 0 ] coef_name_1 = term [ 'coefficient' ][ 1 ] coef_sample_0 = reshape_coef_sample ( sample_dict [ coef_name_0 ], coef_name_0 ) coef_sample_1 = reshape_coef_sample ( sample_dict [ coef_name_1 ], coef_name_1 ) assert coef_sample_0 . shape == coef_sample_1 . shape == ( R , total_computation , positive_integer ) additive_term = ( coef_sample_0 * coef_sample_1 ) . sum ( dim =- 1 ) # Type III: single coefficient multiplied by observable, e.g., theta_user * x_obs_item. elif len ( term [ 'coefficient' ]) == 1 and term [ 'observable' ] is not None : coef_name = term [ 'coefficient' ][ 0 ] coef_sample = reshape_coef_sample ( sample_dict [ coef_name ], coef_name ) assert coef_sample . shape == ( R , total_computation , positive_integer ) obs_name = term [ 'observable' ] obs = reshape_observable ( getattr ( batch , obs_name ), obs_name ) assert obs . shape == ( R , total_computation , positive_integer ) additive_term = ( coef_sample * obs ) . sum ( dim =- 1 ) # Type IV: factorized coefficient multiplied by observable. # e.g., gamma_user * beta_item * price_obs. elif len ( term [ 'coefficient' ]) == 2 and term [ 'observable' ] is not None : coef_name_0 , coef_name_1 = term [ 'coefficient' ][ 0 ], term [ 'coefficient' ][ 1 ] coef_sample_0 = reshape_coef_sample ( sample_dict [ coef_name_0 ], coef_name_0 ) coef_sample_1 = reshape_coef_sample ( sample_dict [ coef_name_1 ], coef_name_1 ) assert coef_sample_0 . shape == coef_sample_1 . shape == ( R , total_computation , positive_integer ) num_obs_times_latent_dim = coef_sample_0 . shape [ - 1 ] obs_name = term [ 'observable' ] obs = reshape_observable ( getattr ( batch , obs_name ), obs_name ) assert obs . shape == ( R , total_computation , positive_integer ) num_obs = obs . shape [ - 1 ] # number of observables. assert ( num_obs_times_latent_dim % num_obs ) == 0 latent_dim = num_obs_times_latent_dim // num_obs coef_sample_0 = coef_sample_0 . view ( R , total_computation , num_obs , latent_dim ) coef_sample_1 = coef_sample_1 . view ( R , total_computation , num_obs , latent_dim ) # compute the factorized coefficient with shape (R, P, I, O). coef = ( coef_sample_0 * coef_sample_1 ) . sum ( dim =- 1 ) additive_term = ( coef * obs ) . sum ( dim =- 1 ) else : raise ValueError ( f 'Undefined term type: { term } ' ) assert additive_term . shape == ( R , total_computation ) utility += additive_term # ========================================================================================== # Mask Out Unavailable Items in Each Session. # ========================================================================================== if batch . item_availability is not None : # expand to the Monte Carlo sample dimension. A = batch . item_availability [ session_index , relevant_item_index ] . unsqueeze ( dim = 0 ) . expand ( R , - 1 ) utility [ ~ A ] = - ( torch . finfo ( utility . dtype ) . max / 2 ) for module in self . additional_modules : # current utility shape: (R, total_computation) additive_term = module ( batch ) assert additive_term . shape == ( R , len ( batch )) or additive_term . shape == ( R , len ( batch ), 1 ) if additive_term . shape == ( R , len ( batch ), 1 ): # TODO: need to make this consistent with log_likelihood_all. # be tolerant for some customized module with BayesianLinear that returns (R, len(batch), 1). additive_term = additive_term . view ( R , len ( batch )) # expand to total number of computation, query by reverse_indices. # reverse_indices has length total_computation, and reverse_indices[i] correspond to the row-id that this # computation is responsible for. additive_term = additive_term [:, reverse_indices ] assert additive_term . shape == ( R , total_computation ) # compute log likelihood log p(choosing item i | user, item latents) if return_logit : log_p = utility else : # compute the log probability from logits/utilities. log_p = scatter_log_softmax ( utility , reverse_indices , dim =- 1 ) # select the log-P of the item actually bought. log_p = log_p [:, item_index_expanded == relevant_item_index ] # output shape: (num_seeds, num_purchases, num_items) return log_p def log_prior ( self , batch : ChoiceDataset , sample_dict : Dict [ str , torch . Tensor ]) -> torch . Tensor : \"\"\"Calculates the log-likelihood of Monte Carlo samples of Bayesian coefficients under their prior distribution. This method assume coefficients are statistically independent. Args: batch (ChoiceDataset): a dataset object contains observables for computing the prior distribution if obs2prior is True. sample_dict (Dict[str, torch.Tensor]): a dictionary coefficient names to Monte Carlo samples. Raises: ValueError: [description] Returns: torch.scalar_tensor: a tensor with shape (num_seeds,) of [ log P_{prior_distribution}(param[i]) ], where param[i] is the i-th Monte Carlo sample. \"\"\" # assert sample_dict.keys() == self.coef_dict.keys() num_seeds = next ( iter ( sample_dict . values ())) . shape [ 0 ] total = torch . zeros ( num_seeds , device = self . device ) for coef_name , coef in self . coef_dict . items (): if self . obs2prior_dict [ coef_name ]: if coef_name . endswith ( '_item' ): x_obs = batch . item_obs elif coef_name . endswith ( '_user' ): x_obs = batch . user_obs else : raise ValueError ( f 'No observable found to support obs2prior for { coef_name } .' ) total += coef . log_prior ( sample = sample_dict [ coef_name ], H_sample = sample_dict [ coef_name + '.H' ], x_obs = x_obs ) . sum ( dim =- 1 ) else : # log_prob outputs (num_seeds, num_{items, users}), sum to (num_seeds). total += coef . log_prior ( sample = sample_dict [ coef_name ], H_sample = None , x_obs = None ) . sum ( dim =- 1 ) for module in self . additional_modules : raise NotImplementedError () total += module . log_prior () return total def log_variational ( self , sample_dict : Dict [ str , torch . Tensor ]) -> torch . Tensor : \"\"\"Calculate the log-likelihood of samples in sample_dict under the current variational distribution. Args: sample_dict (Dict[str, torch.Tensor]): a dictionary coefficient names to Monte Carlo samples. Returns: torch.Tensor: a tensor of shape (num_seeds) of [ log P_{variational_distribution}(param[i]) ], where param[i] is the i-th Monte Carlo sample. \"\"\" num_seeds = list ( sample_dict . values ())[ 0 ] . shape [ 0 ] total = torch . zeros ( num_seeds , device = self . device ) for coef_name , coef in self . coef_dict . items (): # log_prob outputs (num_seeds, num_{items, users}), sum to (num_seeds). total += coef . log_variational ( sample_dict [ coef_name ]) . sum ( dim =- 1 ) for module in self . additional_modules : raise NotImplementedError () # with shape (num_seeds,) total += module . log_variational () . sum () return total def elbo ( self , batch : ChoiceDataset , num_seeds : int = 1 ) -> torch . Tensor : \"\"\"A combined method to computes the current ELBO given a batch, this method is used for training the model. Args: batch (ChoiceDataset): a ChoiceDataset containing necessary information. num_seeds (int, optional): the number of Monte Carlo samples from variational distributions to evaluate the expectation in ELBO. Defaults to 1. Returns: torch.Tensor: a scalar tensor of the ELBO estimated from num_seeds Monte Carlo samples. \"\"\" # ============================================================================================================== # 1. sample latent variables from their variational distributions. # ============================================================================================================== sample_dict = self . sample_coefficient_dictionary ( num_seeds ) # ============================================================================================================== # 2. compute log p(latent) prior. # (num_seeds,) --mean--> scalar. elbo = self . log_prior ( batch , sample_dict ) . mean ( dim = 0 ) # ============================================================================================================== # ============================================================================================================== # 3. compute the log likelihood log p(obs|latent). # sum over independent purchase decision for individual observations, mean over MC seeds. # the forward() function calls module.rsample(num_seeds) for module in self.additional_modules. # ============================================================================================================== if self . pred_item : # the prediction target is item_index. elbo += self . forward ( batch , return_type = 'log_prob' , return_scope = 'item_index' , deterministic = False , sample_dict = sample_dict ) . sum ( dim = 1 ) . mean ( dim = 0 ) # (num_seeds, len(batch)) --> scalar. else : # the prediction target is binary. # TODO: update the prediction function. utility = self . forward ( batch , return_type = 'utility' , return_scope = 'item_index' , deterministic = False , sample_dict = sample_dict ) # (num_seeds, len(batch)) # compute the log-likelihood for binary label. # (num_seeds, len(batch)) y_stacked = torch . stack ([ batch . label ] * num_seeds ) . float () assert y_stacked . shape == utility . shape bce = nn . BCELoss ( reduction = 'none' ) # scalar. ll = - bce ( torch . sigmoid ( utility ), y_stacked ) . sum ( dim = 1 ) . mean ( dim = 0 ) elbo += ll # ============================================================================================================== # 4. optionally add log likelihood under variational distributions q(latent). # ============================================================================================================== if self . trace_log_q : elbo -= self . log_variational ( sample_dict ) . mean ( dim = 0 ) return elbo","title":"BEMBFlex"},{"location":"api_bemb/#bemb.model.bemb.BEMBFlex.__init__","text":"Parameters: Name Type Description Default utility_formula str a string representing the utility function U[user, item, session]. See documentation for more details in the documentation for the format of formula. Examples: lambda_item lambda_item + theta_user * alpha_item + zeta_user * item_obs lambda_item + theta_user * alpha_item + gamma_user * beta_item * price_obs See the doc-string of parse_utility for an example. required obs2prior_dict Dict[str, bool] a dictionary maps coefficient name (e.g., 'lambda_item') to a boolean indicating if observable (e.g., item_obs) enters the prior of the coefficient. required coef_dim_dict Dict[str, int] a dictionary maps coefficient name (e.g., 'lambda_item') to an integer indicating the dimension of coefficient. For standalone coefficients like U = lambda_item, the dim should be 1. For factorized coefficients like U = theta_user * alpha_item, the dim should be the latent dimension of theta and alpha. For coefficients multiplied with observables like U = zeta_user * item_obs, the dim should be the number of observables in item_obs. For factorized coefficient multiplied with observables like U = gamma_user * beta_item * price_obs, the dim should be the latent dim multiplied by number of observables in price_obs. required num_items int number of items. required pred_item bool there are two use cases of this model, suppose we have user_index[i] and item_index[i] for the i-th observation in the dataset. Case 1: which item among all items user user_index[i] is going to purchase, the prediction label is therefore item_index[i] . Equivalently, we can ask what's the likelihood for user user_index[i] to purchase item_index[i] . Case 2: what rating would user user_index[i] assign to item item_index[i] ? In this case, the dataset object needs to contain a separate label. NOTE: for now, we only support binary labels. required prior_variance Union[float, Dict[str, float]] the variance of prior distribution for coefficients. If a float is provided, all priors will be diagonal matrix with prior_variance along the diagonal. If a dictionary is provided, keys of prior_variance should be coefficient names, and the variance of prior of coef_name would be a diagonal matrix with prior_variance[coef_name] along the diagonal. Defaults to 1.0, which means all prior have identity matrix as the covariance matrix. 1.0 num_users int number of users, required only if coefficient or observable depending on user is in utility. Defaults to None. None num_sessions int number of sessions, required only if coefficient or observable depending on session is in utility. Defaults to None. None trace_log_q bool whether to trace the derivative of variational likelihood logQ with respect to variational parameters in the ELBO while conducting gradient update. Defaults to False. False category_to_item Dict[str, List[int]] a dictionary with category id or name as keys, and category_to_item[C] contains the list of item ids belonging to category C. If None is provided, all items are assumed to be in the same category. Defaults to None. None num_{user, item, session, price, taste}_obs (int number of observables of each type of features, only required if observable enters prior. NOTE: currently we only allow coefficient to depend on either user or item, thus only user and item observables can enter the prior of coefficient. Hence session, price, and taste observables are never required, we include it here for completeness. required Source code in bemb/model/bemb.py def __init__ ( self , utility_formula : str , obs2prior_dict : Dict [ str , bool ], coef_dim_dict : Dict [ str , int ], num_items : int , pred_item : bool , prior_variance : Union [ float , Dict [ str , float ]] = 1.0 , num_users : Optional [ int ] = None , num_sessions : Optional [ int ] = None , trace_log_q : bool = False , category_to_item : Dict [ int , List [ int ]] = None , # number of observables. num_user_obs : Optional [ int ] = None , num_item_obs : Optional [ int ] = None , num_session_obs : Optional [ int ] = None , num_price_obs : Optional [ int ] = None , num_taste_obs : Optional [ int ] = None , # additional modules. additional_modules : Optional [ List [ nn . Module ]] = None ) -> None : \"\"\" Args: utility_formula (str): a string representing the utility function U[user, item, session]. See documentation for more details in the documentation for the format of formula. Examples: lambda_item lambda_item + theta_user * alpha_item + zeta_user * item_obs lambda_item + theta_user * alpha_item + gamma_user * beta_item * price_obs See the doc-string of parse_utility for an example. obs2prior_dict (Dict[str, bool]): a dictionary maps coefficient name (e.g., 'lambda_item') to a boolean indicating if observable (e.g., item_obs) enters the prior of the coefficient. coef_dim_dict (Dict[str, int]): a dictionary maps coefficient name (e.g., 'lambda_item') to an integer indicating the dimension of coefficient. For standalone coefficients like U = lambda_item, the dim should be 1. For factorized coefficients like U = theta_user * alpha_item, the dim should be the latent dimension of theta and alpha. For coefficients multiplied with observables like U = zeta_user * item_obs, the dim should be the number of observables in item_obs. For factorized coefficient multiplied with observables like U = gamma_user * beta_item * price_obs, the dim should be the latent dim multiplied by number of observables in price_obs. num_items (int): number of items. pred_item (bool): there are two use cases of this model, suppose we have `user_index[i]` and `item_index[i]` for the i-th observation in the dataset. Case 1: which item among all items user `user_index[i]` is going to purchase, the prediction label is therefore `item_index[i]`. Equivalently, we can ask what's the likelihood for user `user_index[i]` to purchase `item_index[i]`. Case 2: what rating would user `user_index[i]` assign to item `item_index[i]`? In this case, the dataset object needs to contain a separate label. NOTE: for now, we only support binary labels. prior_variance (Union[float, Dict[str, float]]): the variance of prior distribution for coefficients. If a float is provided, all priors will be diagonal matrix with prior_variance along the diagonal. If a dictionary is provided, keys of prior_variance should be coefficient names, and the variance of prior of coef_name would be a diagonal matrix with prior_variance[coef_name] along the diagonal. Defaults to 1.0, which means all prior have identity matrix as the covariance matrix. num_users (int, optional): number of users, required only if coefficient or observable depending on user is in utility. Defaults to None. num_sessions (int, optional): number of sessions, required only if coefficient or observable depending on session is in utility. Defaults to None. trace_log_q (bool, optional): whether to trace the derivative of variational likelihood logQ with respect to variational parameters in the ELBO while conducting gradient update. Defaults to False. category_to_item (Dict[str, List[int]], optional): a dictionary with category id or name as keys, and category_to_item[C] contains the list of item ids belonging to category C. If None is provided, all items are assumed to be in the same category. Defaults to None. num_{user, item, session, price, taste}_obs (int, optional): number of observables of each type of features, only required if observable enters prior. NOTE: currently we only allow coefficient to depend on either user or item, thus only user and item observables can enter the prior of coefficient. Hence session, price, and taste observables are never required, we include it here for completeness. \"\"\" super ( BEMBFlex , self ) . __init__ () self . utility_formula = utility_formula self . obs2prior_dict = obs2prior_dict self . coef_dim_dict = coef_dim_dict self . prior_variance = prior_variance self . pred_item = pred_item self . num_items = num_items self . num_users = num_users self . num_sessions = num_sessions self . trace_log_q = trace_log_q self . category_to_item = category_to_item # ============================================================================================================== # Category ID to Item ID mapping. # Category ID to Category Size mapping. # Item ID to Category ID mapping. # ============================================================================================================== if self . category_to_item is None : if self . pred_item : # assign all items to the same category if predicting items. self . category_to_item = { 0 : list ( np . arange ( self . num_items ))} else : # otherwise, for the j-th observation in the dataset, the label[j] # only depends on user_index[j] and item_index[j], so we put each # item to its own category. self . category_to_item = { i : [ i ] for i in range ( self . num_items )} self . num_categories = len ( self . category_to_item ) max_category_size = max ( len ( x ) for x in self . category_to_item . values ()) category_to_item_tensor = torch . full ( ( self . num_categories , max_category_size ), - 1 ) category_to_size_tensor = torch . empty ( self . num_categories ) for c , item_in_c in self . category_to_item . items (): category_to_item_tensor [ c , : len ( item_in_c )] = torch . LongTensor ( item_in_c ) category_to_size_tensor [ c ] = torch . scalar_tensor ( len ( item_in_c )) self . register_buffer ( 'category_to_item_tensor' , category_to_item_tensor . long ()) self . register_buffer ( 'category_to_size_tensor' , category_to_size_tensor . long ()) item_to_category_tensor = torch . zeros ( self . num_items ) for c , items_in_c in self . category_to_item . items (): item_to_category_tensor [ items_in_c ] = c self . register_buffer ( 'item_to_category_tensor' , item_to_category_tensor . long ()) # ============================================================================================================== # Create Bayesian Coefficient Objects # ============================================================================================================== # model configuration. self . formula = parse_utility ( utility_formula ) print ( 'BEMB: utility formula parsed:' ) pprint ( self . formula ) self . raw_formula = utility_formula self . obs2prior_dict = obs2prior_dict # dimension of each observable, this one is used only for obs2prior. self . num_obs_dict = { 'user' : num_user_obs , 'item' : num_item_obs , 'session' : num_session_obs , 'price' : num_price_obs , 'taste' : num_taste_obs , 'constant' : 1 # not really used, for dummy variables. } # how many classes for the variational distribution. # for example, beta_item would be `num_items` 10-dimensional gaussian if latent dim = 10. variation_to_num_classes = { 'user' : self . num_users , 'item' : self . num_items , 'constant' : 1 } coef_dict = dict () for additive_term in self . formula : for coef_name in additive_term [ 'coefficient' ]: variation = coef_name . split ( '_' )[ - 1 ] s2 = self . prior_variance [ coef_name ] if isinstance ( self . prior_variance , dict ) else self . prior_variance coef_dict [ coef_name ] = BayesianCoefficient ( variation = variation , num_classes = variation_to_num_classes [ variation ], obs2prior = self . obs2prior_dict [ coef_name ], num_obs = self . num_obs_dict [ variation ], dim = self . coef_dim_dict [ coef_name ], prior_variance = s2 ) self . coef_dict = nn . ModuleDict ( coef_dict ) # ============================================================================================================== # Optional: register additional modules. # ============================================================================================================== if additional_modules is None : self . additional_modules = [] else : raise NotImplementedError ( 'Additional modules are temporarily disabled for further development.' ) self . additional_modules = nn . ModuleList ( additional_modules )","title":"__init__()"},{"location":"api_bemb/#bemb.model.bemb.BEMBFlex.elbo","text":"A combined method to computes the current ELBO given a batch, this method is used for training the model. Parameters: Name Type Description Default batch ChoiceDataset a ChoiceDataset containing necessary information. required num_seeds int the number of Monte Carlo samples from variational distributions to evaluate the expectation in ELBO. Defaults to 1. 1 Returns: Type Description torch.Tensor a scalar tensor of the ELBO estimated from num_seeds Monte Carlo samples. Source code in bemb/model/bemb.py def elbo ( self , batch : ChoiceDataset , num_seeds : int = 1 ) -> torch . Tensor : \"\"\"A combined method to computes the current ELBO given a batch, this method is used for training the model. Args: batch (ChoiceDataset): a ChoiceDataset containing necessary information. num_seeds (int, optional): the number of Monte Carlo samples from variational distributions to evaluate the expectation in ELBO. Defaults to 1. Returns: torch.Tensor: a scalar tensor of the ELBO estimated from num_seeds Monte Carlo samples. \"\"\" # ============================================================================================================== # 1. sample latent variables from their variational distributions. # ============================================================================================================== sample_dict = self . sample_coefficient_dictionary ( num_seeds ) # ============================================================================================================== # 2. compute log p(latent) prior. # (num_seeds,) --mean--> scalar. elbo = self . log_prior ( batch , sample_dict ) . mean ( dim = 0 ) # ============================================================================================================== # ============================================================================================================== # 3. compute the log likelihood log p(obs|latent). # sum over independent purchase decision for individual observations, mean over MC seeds. # the forward() function calls module.rsample(num_seeds) for module in self.additional_modules. # ============================================================================================================== if self . pred_item : # the prediction target is item_index. elbo += self . forward ( batch , return_type = 'log_prob' , return_scope = 'item_index' , deterministic = False , sample_dict = sample_dict ) . sum ( dim = 1 ) . mean ( dim = 0 ) # (num_seeds, len(batch)) --> scalar. else : # the prediction target is binary. # TODO: update the prediction function. utility = self . forward ( batch , return_type = 'utility' , return_scope = 'item_index' , deterministic = False , sample_dict = sample_dict ) # (num_seeds, len(batch)) # compute the log-likelihood for binary label. # (num_seeds, len(batch)) y_stacked = torch . stack ([ batch . label ] * num_seeds ) . float () assert y_stacked . shape == utility . shape bce = nn . BCELoss ( reduction = 'none' ) # scalar. ll = - bce ( torch . sigmoid ( utility ), y_stacked ) . sum ( dim = 1 ) . mean ( dim = 0 ) elbo += ll # ============================================================================================================== # 4. optionally add log likelihood under variational distributions q(latent). # ============================================================================================================== if self . trace_log_q : elbo -= self . log_variational ( sample_dict ) . mean ( dim = 0 ) return elbo","title":"elbo()"},{"location":"api_bemb/#bemb.model.bemb.BEMBFlex.forward","text":"A combined method for inference with the model. Parameters: Name Type Description Default batch ChoiceDataset batch data containing choice information. required return_type str either 'log_prob' or 'utility'. 'log_prob': return the log-probability (by within-category log-softmax) for items 'utility': return the utility value of items. required return_scope str either 'item_index' or 'all_items'. 'item_index': for each observation i, return log-prob/utility for the chosen item batch.item_index[i] only. 'all_items': for each observation i, return log-prob/utility for all items. required deterministic bool True: expectations of parameter variational distributions are used for inference. False: the user needs to supply a dictionary of sampled parameters for inference. Defaults to True. True sample_dict Optional[Dict[str, torch.Tensor]] sampled parameters for inference task. This is not needed when deterministic is True. When deterministic is False, the user can supply a sample_dict . If sample_dict is not provided, this method will create num_seeds samples. Defaults to None. None num_seeds Optional[int] the number of random samples of parameters to construct. This is only required if deterministic is False (i.e., stochastic mode) and sample_dict is not provided. Defaults to None. None Returns: Type Description torch.Tensor a tensor of log-probabilities or utilities, depending on return_type . The shape of the returned tensor depends on return_scope and deterministic . ------------------------------------------------------------------------- | return_scope | deterministic | Output shape | ------------------------------------------------------------------------- | 'item_index` | True | (len(batch),) | ------------------------------------------------------------------------- | 'all_items' | True | (len(batch), num_items) | ------------------------------------------------------------------------- | 'item_index' | False | (num_seeds, len(batch)) | ------------------------------------------------------------------------- | 'all_items' | False | (num_seeds, len(batch), num_items) | ------------------------------------------------------------------------- Source code in bemb/model/bemb.py def forward ( self , batch : ChoiceDataset , return_type : str , return_scope : str , deterministic : bool = True , sample_dict : Optional [ Dict [ str , torch . Tensor ]] = None , num_seeds : Optional [ int ] = None ) -> torch . Tensor : \"\"\"A combined method for inference with the model. Args: batch (ChoiceDataset): batch data containing choice information. return_type (str): either 'log_prob' or 'utility'. 'log_prob': return the log-probability (by within-category log-softmax) for items 'utility': return the utility value of items. return_scope (str): either 'item_index' or 'all_items'. 'item_index': for each observation i, return log-prob/utility for the chosen item batch.item_index[i] only. 'all_items': for each observation i, return log-prob/utility for all items. deterministic (bool, optional): True: expectations of parameter variational distributions are used for inference. False: the user needs to supply a dictionary of sampled parameters for inference. Defaults to True. sample_dict (Optional[Dict[str, torch.Tensor]], optional): sampled parameters for inference task. This is not needed when `deterministic` is True. When `deterministic` is False, the user can supply a `sample_dict`. If `sample_dict` is not provided, this method will create `num_seeds` samples. Defaults to None. num_seeds (Optional[int]): the number of random samples of parameters to construct. This is only required if `deterministic` is False (i.e., stochastic mode) and `sample_dict` is not provided. Defaults to None. Returns: torch.Tensor: a tensor of log-probabilities or utilities, depending on `return_type`. The shape of the returned tensor depends on `return_scope` and `deterministic`. ------------------------------------------------------------------------- | `return_scope` | `deterministic` | Output shape | ------------------------------------------------------------------------- | 'item_index` | True | (len(batch),) | ------------------------------------------------------------------------- | 'all_items' | True | (len(batch), num_items) | ------------------------------------------------------------------------- | 'item_index' | False | (num_seeds, len(batch)) | ------------------------------------------------------------------------- | 'all_items' | False | (num_seeds, len(batch), num_items) | ------------------------------------------------------------------------- \"\"\" # ============================================================================================================== # check arguments. # ============================================================================================================== assert return_type in [ 'log_prob' , 'utility' ], \"return_type must be either 'log_prob' or 'utility'.\" assert return_scope in [ 'item_index' , 'all_items' ], \"return_scope must be either 'item_index' or 'all_items'.\" assert deterministic in [ True , False ] if ( not deterministic ) and ( sample_dict is None ): assert num_seeds >= 1 , \"A positive interger `num_seeds` is required if `deterministic` is False and no `sample_dict` is provided.\" # when pred_item is true, the model is predicting which item is bought (specified by item_index). if self . pred_item : batch . label = batch . item_index # ============================================================================================================== # get sample_dict ready. # ============================================================================================================== if deterministic : num_seeds = 1 # Use the means of variational distributions as the sole deterministic MC sample. # NOTE: here we don't need to sample the obs2prior weight H since we only compute the log-likelihood. # TODO: is this correct? sample_dict = dict () for coef_name , coef in self . coef_dict . items (): sample_dict [ coef_name ] = coef . variational_distribution . mean . unsqueeze ( dim = 0 ) # (1, num_*, dim) else : if sample_dict is None : # sample stochastic parameters. sample_dict = self . sample_coefficient_dictionary ( num_seeds ) else : # use the provided sample_dict. num_seeds = list ( sample_dict . values ())[ 0 ] . shape [ 0 ] # ============================================================================================================== # call the sampling method of additional modules. # ============================================================================================================== for module in self . additional_modules : # deterministic sample. if deterministic : module . dsample () else : module . rsample ( num_seeds = num_seeds ) # if utility is requested, don't run log-softmax, simply return logit. return_logit = ( return_type == 'utility' ) if return_scope == 'all_items' : # (num_seeds, len(batch), num_items) out = self . log_likelihood_all_items ( batch = batch , sample_dict = sample_dict , return_logit = return_logit ) elif return_scope == 'item_index' : # (num_seeds, len(batch)) out = self . log_likelihood_item_index ( batch = batch , sample_dict = sample_dict , return_logit = return_logit ) if deterministic : # drop the first dimension, which has size of `num_seeds` (equals 1 in the deterministic case). # (len(batch), num_items) or (len(batch),) return out . squeeze ( dim = 0 ) return out","title":"forward()"},{"location":"api_bemb/#bemb.model.bemb.BEMBFlex.get_within_category_accuracy","text":"A helper function for computing prediction accuracy (i.e., all non-differential metrics) within category. In particular, this method calculates the accuracy, precision, recall and F1 score. This method has the same functionality as the following peusodcode: for C in categories: # get sessions in which item in category C was purchased. T <- (t for t in {0,1,..., len(label)-1} if label[t] is in C) Y <- label[T] predictions = list() for t in T: # get the prediction within category for this session. y_pred = argmax_{items in C} log prob computed before. predictions.append(y_pred) accuracy = mean(Y == predictions) Similarly, this function computes precision, recall and f1score as well. Parameters: Name Type Description Default log_p_all_items torch.Tensor shape (num_sessions, num_items) the log probability of choosing each item in each session. required label torch.LongTensor shape (num_sessions,), the IDs of items purchased in each session. required Returns: Type Description [Dict[str, float]] A dictionary containing performance metrics. Source code in bemb/model/bemb.py @torch . no_grad () def get_within_category_accuracy ( self , log_p_all_items : torch . Tensor , label : torch . LongTensor ) -> Dict [ str , float ]: \"\"\"A helper function for computing prediction accuracy (i.e., all non-differential metrics) within category. In particular, this method calculates the accuracy, precision, recall and F1 score. This method has the same functionality as the following peusodcode: for C in categories: # get sessions in which item in category C was purchased. T <- (t for t in {0,1,..., len(label)-1} if label[t] is in C) Y <- label[T] predictions = list() for t in T: # get the prediction within category for this session. y_pred = argmax_{items in C} log prob computed before. predictions.append(y_pred) accuracy = mean(Y == predictions) Similarly, this function computes precision, recall and f1score as well. Args: log_p_all_items (torch.Tensor): shape (num_sessions, num_items) the log probability of choosing each item in each session. label (torch.LongTensor): shape (num_sessions,), the IDs of items purchased in each session. Returns: [Dict[str, float]]: A dictionary containing performance metrics. \"\"\" # argmax: (num_sessions, num_categories), within category argmax. # item IDs are consecutive, thus argmax is the same as IDs of the item with highest P. _ , argmax_by_category = scatter_max ( log_p_all_items , self . item_to_category_tensor , dim =- 1 ) # category_purchased[t] = the category of item label[t]. # (num_sessions,) category_purchased = self . item_to_category_tensor [ label ] # pred[t] = the item with highest utility from the category item label[t] belongs to. # (num_sessions,) pred_from_category = argmax_by_category [ torch . arange ( len ( label )), category_purchased ] within_category_accuracy = ( pred_from_category == label ) . float () . mean () . item () # precision precision = list () recall = list () for i in range ( self . num_items ): correct_i = torch . sum ( ( torch . logical_and ( pred_from_category == i , label == i )) . float ()) precision_i = correct_i / \\ torch . sum (( pred_from_category == i ) . float ()) recall_i = correct_i / torch . sum (( label == i ) . float ()) # do not add if divided by zero. if torch . any ( pred_from_category == i ): precision . append ( precision_i . cpu () . item ()) if torch . any ( label == i ): recall . append ( recall_i . cpu () . item ()) precision = float ( np . mean ( precision )) recall = float ( np . mean ( recall )) if precision == recall == 0 : f1 = 0 else : f1 = 2 * precision * recall / ( precision + recall ) return { 'accuracy' : within_category_accuracy , 'precision' : precision , 'recall' : recall , 'f1score' : f1 }","title":"get_within_category_accuracy()"},{"location":"api_bemb/#bemb.model.bemb.BEMBFlex.log_likelihood_all_items","text":"NOTE to developers: This method computes utilities for all items available, which is a relatively slow operation. For training the model, you only need the utility/log-prob for the chosen/relevant item (i.e., item_index[i] for each i-th observation). Use this method for inference only. Use self.log_likelihood_item_index() for training instead. Computes the log probability of choosing each item in each session based on current model parameters. This method allows for specifying {user, item}_latent_value for Monte Carlo estimation in ELBO. For actual prediction tasks, use the forward() function, which will use means of variational distributions for user and item latents. Parameters: Name Type Description Default batch ChoiceDataset a ChoiceDataset object containing relevant information. required return_logit(bool) if set to True, return the log-probability, otherwise return the logit/utility. required sample_dict(Dict[str, torch.Tensor] Monte Carlo samples for model coefficients (i.e., those Greek letters). sample_dict.keys() should be the same as keys of self.obs2prior_dict, i.e., those greek letters actually enter the functional form of utility. The value of sample_dict should be tensors of shape (num_seeds, num_classes, dim) where num_classes in {num_users, num_items, 1} and dim in {latent_dim(K), num_item_obs, num_user_obs, 1}. required Returns: Type Description torch.Tensor a tensor of shape (num_seeds, len(batch), self.num_items), where out[x, y, z] is the probability of choosing item z in session y conditioned on latents to be the x-th Monte Carlo sample. Source code in bemb/model/bemb.py def log_likelihood_all_items ( self , batch : ChoiceDataset , return_logit : bool , sample_dict : Dict [ str , torch . Tensor ]) -> torch . Tensor : \"\"\" NOTE to developers: This method computes utilities for all items available, which is a relatively slow operation. For training the model, you only need the utility/log-prob for the chosen/relevant item (i.e., item_index[i] for each i-th observation). Use this method for inference only. Use self.log_likelihood_item_index() for training instead. Computes the log probability of choosing `each` item in each session based on current model parameters. This method allows for specifying {user, item}_latent_value for Monte Carlo estimation in ELBO. For actual prediction tasks, use the forward() function, which will use means of variational distributions for user and item latents. Args: batch (ChoiceDataset): a ChoiceDataset object containing relevant information. return_logit(bool): if set to True, return the log-probability, otherwise return the logit/utility. sample_dict(Dict[str, torch.Tensor]): Monte Carlo samples for model coefficients (i.e., those Greek letters). sample_dict.keys() should be the same as keys of self.obs2prior_dict, i.e., those greek letters actually enter the functional form of utility. The value of sample_dict should be tensors of shape (num_seeds, num_classes, dim) where num_classes in {num_users, num_items, 1} and dim in {latent_dim(K), num_item_obs, num_user_obs, 1}. Returns: torch.Tensor: a tensor of shape (num_seeds, len(batch), self.num_items), where out[x, y, z] is the probability of choosing item z in session y conditioned on latents to be the x-th Monte Carlo sample. \"\"\" num_seeds = next ( iter ( sample_dict . values ())) . shape [ 0 ] # avoid repeated work when user purchased several items in the same session. user_session_index = torch . stack ( [ batch . user_index , batch . session_index ]) assert user_session_index . shape == ( 2 , len ( batch )) unique_user_sess , inverse_indices = torch . unique ( user_session_index , dim = 1 , return_inverse = True ) user_index = unique_user_sess [ 0 , :] session_index = unique_user_sess [ 1 , :] assert len ( user_index ) == len ( session_index ) # short-hands for easier shape check. R = num_seeds # P = len(batch) # num_purchases. P = unique_user_sess . shape [ 1 ] S = self . num_sessions U = self . num_users I = self . num_items # ============================================================================================================== # Helper Functions for Reshaping. # ============================================================================================================== def reshape_user_coef_sample ( C ): # input shape (R, U, *) C = C . view ( R , U , 1 , - 1 ) . expand ( - 1 , - 1 , I , - 1 ) # (R, U, I, *) C = C [:, user_index , :, :] assert C . shape == ( R , P , I , positive_integer ) return C def reshape_item_coef_sample ( C ): # input shape (R, I, *) C = C . view ( R , 1 , I , - 1 ) . expand ( - 1 , P , - 1 , - 1 ) assert C . shape == ( R , P , I , positive_integer ) return C def reshape_constant_coef_sample ( C ): # input shape (R, *) C = C . view ( R , 1 , 1 , - 1 ) . expand ( - 1 , P , I , - 1 ) assert C . shape == ( R , P , I , positive_integer ) return C def reshape_coef_sample ( sample , name ): # reshape the monte carlo sample of coefficients to (R, P, I, *). if name . endswith ( '_user' ): # (R, U, *) --> (R, P, I, *) return reshape_user_coef_sample ( sample ) elif name . endswith ( '_item' ): # (R, I, *) --> (R, P, I, *) return reshape_item_coef_sample ( sample ) elif name . endswith ( '_constant' ): # (R, *) --> (R, P, I, *) return reshape_constant_coef_sample ( sample ) else : raise ValueError def reshape_observable ( obs , name ): # reshape observable to (R, P, I, *) so that it can be multiplied with monte carlo # samples of coefficients. O = obs . shape [ - 1 ] # number of observables. assert O == positive_integer if name . startswith ( 'item_' ): assert obs . shape == ( I , O ) obs = obs . view ( 1 , 1 , I , O ) . expand ( R , P , - 1 , - 1 ) elif name . startswith ( 'user_' ): assert obs . shape == ( U , O ) obs = obs [ user_index , :] # (P, O) obs = obs . view ( 1 , P , 1 , O ) . expand ( R , - 1 , I , - 1 ) elif name . startswith ( 'session_' ): assert obs . shape == ( S , O ) obs = obs [ session_index , :] # (P, O) return obs . view ( 1 , P , 1 , O ) . expand ( R , - 1 , I , - 1 ) elif name . startswith ( 'price_' ): assert obs . shape == ( S , I , O ) obs = obs [ session_index , :, :] # (P, I, O) return obs . view ( 1 , P , I , O ) . expand ( R , - 1 , - 1 , - 1 ) elif name . startswith ( 'taste_' ): assert obs . shape == ( U , I , O ) obs = obs [ user_index , :, :] # (P, I, O) return obs . view ( 1 , P , I , O ) . expand ( R , - 1 , - 1 , - 1 ) else : raise ValueError assert obs . shape == ( R , P , I , O ) return obs # ============================================================================================================== # Copmute the Utility Term by Term. # ============================================================================================================== # P is the number of unique (user, session) pairs. # (random_seeds, P, num_items). utility = torch . zeros ( R , P , I , device = self . device ) # loop over additive term to utility for term in self . formula : # Type I: single coefficient, e.g., lambda_item or lambda_user. if len ( term [ 'coefficient' ]) == 1 and term [ 'observable' ] is None : # E.g., lambda_item or lambda_user coef_name = term [ 'coefficient' ][ 0 ] coef_sample = reshape_coef_sample ( sample_dict [ coef_name ], coef_name ) assert coef_sample . shape == ( R , P , I , 1 ) additive_term = coef_sample . view ( R , P , I ) # Type II: factorized coefficient, e.g., <theta_user, lambda_item>. elif len ( term [ 'coefficient' ]) == 2 and term [ 'observable' ] is None : coef_name_0 = term [ 'coefficient' ][ 0 ] coef_name_1 = term [ 'coefficient' ][ 1 ] coef_sample_0 = reshape_coef_sample ( sample_dict [ coef_name_0 ], coef_name_0 ) coef_sample_1 = reshape_coef_sample ( sample_dict [ coef_name_1 ], coef_name_1 ) assert coef_sample_0 . shape == coef_sample_1 . shape == ( R , P , I , positive_integer ) additive_term = ( coef_sample_0 * coef_sample_1 ) . sum ( dim =- 1 ) # Type III: single coefficient multiplied by observable, e.g., theta_user * x_obs_item. elif len ( term [ 'coefficient' ]) == 1 and term [ 'observable' ] is not None : coef_name = term [ 'coefficient' ][ 0 ] coef_sample = reshape_coef_sample ( sample_dict [ coef_name ], coef_name ) assert coef_sample . shape == ( R , P , I , positive_integer ) obs_name = term [ 'observable' ] obs = reshape_observable ( getattr ( batch , obs_name ), obs_name ) assert obs . shape == ( R , P , I , positive_integer ) additive_term = ( coef_sample * obs ) . sum ( dim =- 1 ) # Type IV: factorized coefficient multiplied by observable. # e.g., gamma_user * beta_item * price_obs. elif len ( term [ 'coefficient' ]) == 2 and term [ 'observable' ] is not None : coef_name_0 , coef_name_1 = term [ 'coefficient' ][ 0 ], term [ 'coefficient' ][ 1 ] coef_sample_0 = reshape_coef_sample ( sample_dict [ coef_name_0 ], coef_name_0 ) coef_sample_1 = reshape_coef_sample ( sample_dict [ coef_name_1 ], coef_name_1 ) assert coef_sample_0 . shape == coef_sample_1 . shape == ( R , P , I , positive_integer ) num_obs_times_latent_dim = coef_sample_0 . shape [ - 1 ] obs_name = term [ 'observable' ] obs = reshape_observable ( getattr ( batch , obs_name ), obs_name ) assert obs . shape == ( R , P , I , positive_integer ) num_obs = obs . shape [ - 1 ] # number of observables. assert ( num_obs_times_latent_dim % num_obs ) == 0 latent_dim = num_obs_times_latent_dim // num_obs coef_sample_0 = coef_sample_0 . view ( R , P , I , num_obs , latent_dim ) coef_sample_1 = coef_sample_1 . view ( R , P , I , num_obs , latent_dim ) # compute the factorized coefficient with shape (R, P, I, O). coef = ( coef_sample_0 * coef_sample_1 ) . sum ( dim =- 1 ) additive_term = ( coef * obs ) . sum ( dim =- 1 ) else : raise ValueError ( f 'Undefined term type: { term } ' ) assert additive_term . shape == ( R , P , I ) utility += additive_term # ============================================================================================================== # Mask Out Unavailable Items in Each Session. # ============================================================================================================== if batch . item_availability is not None : # expand to the Monte Carlo sample dimension. # (S, I) -> (P, I) -> (1, P, I) -> (R, P, I) A = batch . item_availability [ session_index , :] . unsqueeze ( dim = 0 ) . expand ( R , - 1 , - 1 ) utility [ ~ A ] = - ( torch . finfo ( utility . dtype ) . max / 2 ) utility = utility [:, inverse_indices , :] assert utility . shape == ( R , len ( batch ), I ) for module in self . additional_modules : additive_term = module ( batch ) assert additive_term . shape == ( R , len ( batch ), 1 ) utility += additive_term . expand ( - 1 , - 1 , I ) if return_logit : # output shape: (num_seeds, len(batch), num_items) return utility else : # compute log likelihood log p(choosing item i | user, item latents) # compute log softmax separately within each category. log_p = scatter_log_softmax ( utility , self . item_to_category_tensor , dim =- 1 ) # output shape: (num_seeds, len(batch), num_items) return log_p","title":"log_likelihood_all_items()"},{"location":"api_bemb/#bemb.model.bemb.BEMBFlex.log_likelihood_item_index","text":"NOTE for developers: This method is more efficient and only computes log-likelihood/logit(utility) for item in item_index[i] for each i-th observation. Developers should use use log_likelihood_all_items for inference purpose and to computes log-likelihoods/utilities for ALL items for the i-th observation. Computes the log probability of choosing item_index[i] in each session based on current model parameters. This method allows for specifying {user, item}_latent_value for Monte Carlo estimation in ELBO. For actual prediction tasks, use the forward() function, which will use means of variational distributions for user and item latents. Parameters: Name Type Description Default batch ChoiceDataset a ChoiceDataset object containing relevant information. required return_logit(bool) if set to True, return the log-probability, otherwise return the logit/utility. required sample_dict(Dict[str, torch.Tensor] Monte Carlo samples for model coefficients (i.e., those Greek letters). sample_dict.keys() should be the same as keys of self.obs2prior_dict, i.e., those greek letters actually enter the functional form of utility. The value of sample_dict should be tensors of shape (num_seeds, num_classes, dim) where num_classes in {num_users, num_items, 1} and dim in {latent_dim(K), num_item_obs, num_user_obs, 1}. required Returns: Type Description torch.Tensor a tensor of shape (num_seeds, len(batch)), where out[x, y] is the probabilities of choosing item batch.item[y] in session y conditioned on latents to be the x-th Monte Carlo sample. Source code in bemb/model/bemb.py def log_likelihood_item_index ( self , batch : ChoiceDataset , return_logit : bool , sample_dict : Dict [ str , torch . Tensor ]) -> torch . Tensor : \"\"\" NOTE for developers: This method is more efficient and only computes log-likelihood/logit(utility) for item in item_index[i] for each i-th observation. Developers should use use `log_likelihood_all_items` for inference purpose and to computes log-likelihoods/utilities for ALL items for the i-th observation. Computes the log probability of choosing item_index[i] in each session based on current model parameters. This method allows for specifying {user, item}_latent_value for Monte Carlo estimation in ELBO. For actual prediction tasks, use the forward() function, which will use means of variational distributions for user and item latents. Args: batch (ChoiceDataset): a ChoiceDataset object containing relevant information. return_logit(bool): if set to True, return the log-probability, otherwise return the logit/utility. sample_dict(Dict[str, torch.Tensor]): Monte Carlo samples for model coefficients (i.e., those Greek letters). sample_dict.keys() should be the same as keys of self.obs2prior_dict, i.e., those greek letters actually enter the functional form of utility. The value of sample_dict should be tensors of shape (num_seeds, num_classes, dim) where num_classes in {num_users, num_items, 1} and dim in {latent_dim(K), num_item_obs, num_user_obs, 1}. Returns: torch.Tensor: a tensor of shape (num_seeds, len(batch)), where out[x, y] is the probabilities of choosing item batch.item[y] in session y conditioned on latents to be the x-th Monte Carlo sample. \"\"\" num_seeds = next ( iter ( sample_dict . values ())) . shape [ 0 ] # get category id of the item bought in each row of batch. cate_index = self . item_to_category_tensor [ batch . item_index ] # get item ids of all items from the same category of each item bought. relevant_item_index = self . category_to_item_tensor [ cate_index , :] relevant_item_index = relevant_item_index . view ( - 1 ,) # index were padded with -1's, drop those dummy entries. relevant_item_index = relevant_item_index [ relevant_item_index != - 1 ] # the first repeats[0] entries in relevant_item_index are for the category of item_index[0] repeats = self . category_to_size_tensor [ cate_index ] # argwhere(reverse_indices == k) are positions in relevant_item_index for the category of item_index[k]. reverse_indices = torch . repeat_interleave ( torch . arange ( len ( batch ), device = self . device ), repeats ) # expand the user_index and session_index. user_index = torch . repeat_interleave ( batch . user_index , repeats ) session_index = torch . repeat_interleave ( batch . session_index , repeats ) # duplicate the item focused to match. item_index_expanded = torch . repeat_interleave ( batch . item_index , repeats ) # short-hands for easier shape check. R = num_seeds # total number of relevant items. total_computation = len ( session_index ) S = self . num_sessions U = self . num_users I = self . num_items # ========================================================================================== # Helper Functions for Reshaping. # ========================================================================================== def reshape_coef_sample ( sample , name ): # reshape the monte carlo sample of coefficients to (R, P, I, *). if name . endswith ( '_user' ): # (R, U, *) --> (R, total_computation, *) return sample [:, user_index , :] elif name . endswith ( '_item' ): # (R, I, *) --> (R, total_computation, *) return sample [:, relevant_item_index , :] elif name . endswith ( '_constant' ): # (R, *) --> (R, total_computation, *) return sample . view ( R , 1 , - 1 ) . expand ( - 1 , total_computation , - 1 ) else : raise ValueError def reshape_observable ( obs , name ): # reshape observable to (R, P, I, *) so that it can be multiplied with monte carlo # samples of coefficients. O = obs . shape [ - 1 ] # number of observables. assert O == positive_integer if name . startswith ( 'item_' ): assert obs . shape == ( I , O ) obs = obs [ relevant_item_index , :] elif name . startswith ( 'user_' ): assert obs . shape == ( U , O ) obs = obs [ user_index , :] elif name . startswith ( 'session_' ): assert obs . shape == ( S , O ) obs = obs [ session_index , :] elif name . startswith ( 'price_' ): assert obs . shape == ( S , I , O ) obs = obs [ session_index , relevant_item_index , :] elif name . startswith ( 'taste_' ): assert obs . shape == ( U , I , O ) obs = obs [ user_index , relevant_item_index , :] else : raise ValueError assert obs . shape == ( total_computation , O ) return obs . unsqueeze ( dim = 0 ) . expand ( R , - 1 , - 1 ) # ========================================================================================== # Compute Components related to users and items only. # ========================================================================================== utility = torch . zeros ( R , total_computation , device = self . device ) # loop over additive term to utility for term in self . formula : # Type I: single coefficient, e.g., lambda_item or lambda_user. if len ( term [ 'coefficient' ]) == 1 and term [ 'observable' ] is None : # E.g., lambda_item or lambda_user coef_name = term [ 'coefficient' ][ 0 ] coef_sample = reshape_coef_sample ( sample_dict [ coef_name ], coef_name ) assert coef_sample . shape == ( R , total_computation , 1 ) additive_term = coef_sample . view ( R , total_computation ) # Type II: factorized coefficient, e.g., <theta_user, lambda_item>. elif len ( term [ 'coefficient' ]) == 2 and term [ 'observable' ] is None : coef_name_0 = term [ 'coefficient' ][ 0 ] coef_name_1 = term [ 'coefficient' ][ 1 ] coef_sample_0 = reshape_coef_sample ( sample_dict [ coef_name_0 ], coef_name_0 ) coef_sample_1 = reshape_coef_sample ( sample_dict [ coef_name_1 ], coef_name_1 ) assert coef_sample_0 . shape == coef_sample_1 . shape == ( R , total_computation , positive_integer ) additive_term = ( coef_sample_0 * coef_sample_1 ) . sum ( dim =- 1 ) # Type III: single coefficient multiplied by observable, e.g., theta_user * x_obs_item. elif len ( term [ 'coefficient' ]) == 1 and term [ 'observable' ] is not None : coef_name = term [ 'coefficient' ][ 0 ] coef_sample = reshape_coef_sample ( sample_dict [ coef_name ], coef_name ) assert coef_sample . shape == ( R , total_computation , positive_integer ) obs_name = term [ 'observable' ] obs = reshape_observable ( getattr ( batch , obs_name ), obs_name ) assert obs . shape == ( R , total_computation , positive_integer ) additive_term = ( coef_sample * obs ) . sum ( dim =- 1 ) # Type IV: factorized coefficient multiplied by observable. # e.g., gamma_user * beta_item * price_obs. elif len ( term [ 'coefficient' ]) == 2 and term [ 'observable' ] is not None : coef_name_0 , coef_name_1 = term [ 'coefficient' ][ 0 ], term [ 'coefficient' ][ 1 ] coef_sample_0 = reshape_coef_sample ( sample_dict [ coef_name_0 ], coef_name_0 ) coef_sample_1 = reshape_coef_sample ( sample_dict [ coef_name_1 ], coef_name_1 ) assert coef_sample_0 . shape == coef_sample_1 . shape == ( R , total_computation , positive_integer ) num_obs_times_latent_dim = coef_sample_0 . shape [ - 1 ] obs_name = term [ 'observable' ] obs = reshape_observable ( getattr ( batch , obs_name ), obs_name ) assert obs . shape == ( R , total_computation , positive_integer ) num_obs = obs . shape [ - 1 ] # number of observables. assert ( num_obs_times_latent_dim % num_obs ) == 0 latent_dim = num_obs_times_latent_dim // num_obs coef_sample_0 = coef_sample_0 . view ( R , total_computation , num_obs , latent_dim ) coef_sample_1 = coef_sample_1 . view ( R , total_computation , num_obs , latent_dim ) # compute the factorized coefficient with shape (R, P, I, O). coef = ( coef_sample_0 * coef_sample_1 ) . sum ( dim =- 1 ) additive_term = ( coef * obs ) . sum ( dim =- 1 ) else : raise ValueError ( f 'Undefined term type: { term } ' ) assert additive_term . shape == ( R , total_computation ) utility += additive_term # ========================================================================================== # Mask Out Unavailable Items in Each Session. # ========================================================================================== if batch . item_availability is not None : # expand to the Monte Carlo sample dimension. A = batch . item_availability [ session_index , relevant_item_index ] . unsqueeze ( dim = 0 ) . expand ( R , - 1 ) utility [ ~ A ] = - ( torch . finfo ( utility . dtype ) . max / 2 ) for module in self . additional_modules : # current utility shape: (R, total_computation) additive_term = module ( batch ) assert additive_term . shape == ( R , len ( batch )) or additive_term . shape == ( R , len ( batch ), 1 ) if additive_term . shape == ( R , len ( batch ), 1 ): # TODO: need to make this consistent with log_likelihood_all. # be tolerant for some customized module with BayesianLinear that returns (R, len(batch), 1). additive_term = additive_term . view ( R , len ( batch )) # expand to total number of computation, query by reverse_indices. # reverse_indices has length total_computation, and reverse_indices[i] correspond to the row-id that this # computation is responsible for. additive_term = additive_term [:, reverse_indices ] assert additive_term . shape == ( R , total_computation ) # compute log likelihood log p(choosing item i | user, item latents) if return_logit : log_p = utility else : # compute the log probability from logits/utilities. log_p = scatter_log_softmax ( utility , reverse_indices , dim =- 1 ) # select the log-P of the item actually bought. log_p = log_p [:, item_index_expanded == relevant_item_index ] # output shape: (num_seeds, num_purchases, num_items) return log_p","title":"log_likelihood_item_index()"},{"location":"api_bemb/#bemb.model.bemb.BEMBFlex.log_prior","text":"Calculates the log-likelihood of Monte Carlo samples of Bayesian coefficients under their prior distribution. This method assume coefficients are statistically independent. Parameters: Name Type Description Default batch ChoiceDataset a dataset object contains observables for computing the prior distribution if obs2prior is True. required sample_dict Dict[str, torch.Tensor] a dictionary coefficient names to Monte Carlo samples. required Exceptions: Type Description ValueError [description] Returns: Type Description torch.scalar_tensor a tensor with shape (num_seeds,) of [ log P_{prior_distribution}(param[i]) ], where param[i] is the i-th Monte Carlo sample. Source code in bemb/model/bemb.py def log_prior ( self , batch : ChoiceDataset , sample_dict : Dict [ str , torch . Tensor ]) -> torch . Tensor : \"\"\"Calculates the log-likelihood of Monte Carlo samples of Bayesian coefficients under their prior distribution. This method assume coefficients are statistically independent. Args: batch (ChoiceDataset): a dataset object contains observables for computing the prior distribution if obs2prior is True. sample_dict (Dict[str, torch.Tensor]): a dictionary coefficient names to Monte Carlo samples. Raises: ValueError: [description] Returns: torch.scalar_tensor: a tensor with shape (num_seeds,) of [ log P_{prior_distribution}(param[i]) ], where param[i] is the i-th Monte Carlo sample. \"\"\" # assert sample_dict.keys() == self.coef_dict.keys() num_seeds = next ( iter ( sample_dict . values ())) . shape [ 0 ] total = torch . zeros ( num_seeds , device = self . device ) for coef_name , coef in self . coef_dict . items (): if self . obs2prior_dict [ coef_name ]: if coef_name . endswith ( '_item' ): x_obs = batch . item_obs elif coef_name . endswith ( '_user' ): x_obs = batch . user_obs else : raise ValueError ( f 'No observable found to support obs2prior for { coef_name } .' ) total += coef . log_prior ( sample = sample_dict [ coef_name ], H_sample = sample_dict [ coef_name + '.H' ], x_obs = x_obs ) . sum ( dim =- 1 ) else : # log_prob outputs (num_seeds, num_{items, users}), sum to (num_seeds). total += coef . log_prior ( sample = sample_dict [ coef_name ], H_sample = None , x_obs = None ) . sum ( dim =- 1 ) for module in self . additional_modules : raise NotImplementedError () total += module . log_prior () return total","title":"log_prior()"},{"location":"api_bemb/#bemb.model.bemb.BEMBFlex.log_variational","text":"Calculate the log-likelihood of samples in sample_dict under the current variational distribution. Parameters: Name Type Description Default sample_dict Dict[str, torch.Tensor] a dictionary coefficient names to Monte Carlo samples. required Returns: Type Description torch.Tensor a tensor of shape (num_seeds) of [ log P_{variational_distribution}(param[i]) ], where param[i] is the i-th Monte Carlo sample. Source code in bemb/model/bemb.py def log_variational ( self , sample_dict : Dict [ str , torch . Tensor ]) -> torch . Tensor : \"\"\"Calculate the log-likelihood of samples in sample_dict under the current variational distribution. Args: sample_dict (Dict[str, torch.Tensor]): a dictionary coefficient names to Monte Carlo samples. Returns: torch.Tensor: a tensor of shape (num_seeds) of [ log P_{variational_distribution}(param[i]) ], where param[i] is the i-th Monte Carlo sample. \"\"\" num_seeds = list ( sample_dict . values ())[ 0 ] . shape [ 0 ] total = torch . zeros ( num_seeds , device = self . device ) for coef_name , coef in self . coef_dict . items (): # log_prob outputs (num_seeds, num_{items, users}), sum to (num_seeds). total += coef . log_variational ( sample_dict [ coef_name ]) . sum ( dim =- 1 ) for module in self . additional_modules : raise NotImplementedError () # with shape (num_seeds,) total += module . log_variational () . sum () return total","title":"log_variational()"},{"location":"api_bemb/#bemb.model.bemb.BEMBFlex.posterior_mean","text":"Returns the mean of estimated posterior distribution of coefficient coef_name . Parameters: Name Type Description Default coef_name str name of the coefficient to query. required Returns: Type Description torch.Tensor mean of the estimated posterior distribution of coef_name . Source code in bemb/model/bemb.py def posterior_mean ( self , coef_name : str ) -> torch . Tensor : \"\"\"Returns the mean of estimated posterior distribution of coefficient `coef_name`. Args: coef_name (str): name of the coefficient to query. Returns: torch.Tensor: mean of the estimated posterior distribution of `coef_name`. \"\"\" if coef_name in self . coef_dict . keys (): return self . coef_dict [ coef_name ] . variational_mean else : raise KeyError ( f ' { coef_name } is not a valid coefficient name in { self . utility_formula } .' )","title":"posterior_mean()"},{"location":"api_bemb/#bemb.model.bemb.BEMBFlex.sample_coefficient_dictionary","text":"A helper function to sample parameters from coefficients. Parameters: Name Type Description Default num_seeds int number of random samples. required Returns: Type Description Dict[str, torch.Tensor] a dictionary maps coefficient names to tensor of sampled coefficient parameters, where the first dimension of the sampled tensor has size num_seeds . Each sample tensor has shape (num_seeds, num_classes, dim). Source code in bemb/model/bemb.py def sample_coefficient_dictionary ( self , num_seeds : int ) -> Dict [ str , torch . Tensor ]: \"\"\"A helper function to sample parameters from coefficients. Args: num_seeds (int): number of random samples. Returns: Dict[str, torch.Tensor]: a dictionary maps coefficient names to tensor of sampled coefficient parameters, where the first dimension of the sampled tensor has size `num_seeds`. Each sample tensor has shape (num_seeds, num_classes, dim). \"\"\" sample_dict = dict () for coef_name , coef in self . coef_dict . items (): s = coef . rsample ( num_seeds ) if coef . obs2prior : # sample both obs2prior weight and realization of variable. assert isinstance ( s , tuple ) and len ( s ) == 2 sample_dict [ coef_name ] = s [ 0 ] sample_dict [ coef_name + '.H' ] = s [ 1 ] else : # only sample the realization of variable. assert torch . is_tensor ( s ) sample_dict [ coef_name ] = s return sample_dict","title":"sample_coefficient_dictionary()"},{"location":"api_bemb/#bemb.model.bemb.parse_utility","text":"A helper function parse utility string into a list of additive terms. Examples: utility_string = 'lambda_item + theta_user * alpha_item + gamma_user * beta_item * price_obs' output = [ { 'coefficient': ['lambda_item'], 'observable': None }, { 'coefficient': ['theta_user', 'alpha_item'], 'observable': None }, { 'coefficient': ['gamma_user', 'beta_item'], 'observable': 'price_obs' } ] Source code in bemb/model/bemb.py def parse_utility ( utility_string : str ) -> List [ Dict [ str , Union [ List [ str ], None ]]]: \"\"\" A helper function parse utility string into a list of additive terms. Example: utility_string = 'lambda_item + theta_user * alpha_item + gamma_user * beta_item * price_obs' output = [ { 'coefficient': ['lambda_item'], 'observable': None }, { 'coefficient': ['theta_user', 'alpha_item'], 'observable': None }, { 'coefficient': ['gamma_user', 'beta_item'], 'observable': 'price_obs' } ] \"\"\" # split additive terms coefficient_suffix = ( '_item' , '_user' , '_constant' ) observable_prefix = ( 'item_' , 'user_' , 'session_' , 'price_' , 'taste_' ) def is_coefficient ( name : str ) -> bool : return any ( name . endswith ( suffix ) for suffix in coefficient_suffix ) def is_observable ( name : str ) -> bool : return any ( name . startswith ( prefix ) for prefix in observable_prefix ) additive_terms = utility_string . split ( ' + ' ) additive_decomposition = list () for term in additive_terms : atom = { 'coefficient' : [], 'observable' : None } # split multiplicative terms. for x in term . split ( ' * ' ): if is_coefficient ( x ): atom [ 'coefficient' ] . append ( x ) elif is_observable ( x ): atom [ 'observable' ] = x else : raise ValueError ( f ' { x } term cannot be classified.' ) additive_decomposition . append ( atom ) return additive_decomposition","title":"parse_utility()"},{"location":"api_bemb/#bemb.model.bemb_flex_lightning","text":"PyTorch lightning wrapper for the BEMB Flex model, allows for more smooth model training and inference. You can still use this package without using LitBEMBFlex. Author: Tianyu Du Update: Apr. 29, 2022","title":"bemb_flex_lightning"},{"location":"api_bemb/#bemb.model.bemb_flex_lightning.LitBEMBFlex","text":"Source code in bemb/model/bemb_flex_lightning.py class LitBEMBFlex ( pl . LightningModule ): def __init__ ( self , learning_rate : float = 0.3 , num_seeds : int = 1 , ** kwargs ): \"\"\"The initialization method of the wrapper model. Args: learning_rate (float, optional): the learning rate of optimization. Defaults to 0.3. num_seeds (int, optional): number of random seeds for the Monte Carlo estimation in the variational inference. Defaults to 1. **kwargs: all keyword arguments used for constructing the wrapped BEMB model. \"\"\" # use kwargs to pass parameter to BEMB Torch. super () . __init__ () self . model = BEMBFlex ( ** kwargs ) self . num_needs = num_seeds self . learning_rate = learning_rate def __str__ ( self ) -> str : return str ( self . model ) def forward ( self , args , kwargs ): \"\"\"Calls the forward method of the wrapped BEMB model, please refer to the documentaton of the BEMB class for detailed definitions of the arguments. Args: args (_type_): arguments passed to the forward method of the wrapped BEMB model. kwargs (_type_): keyword arguments passed to the forward method of the wrapped BEMB model. Returns: _type_: returns whatever the wrapped BEMB model returns. \"\"\" return self . model ( * args , ** kwargs ) def training_step ( self , batch , batch_idx ): elbo = self . model . elbo ( batch , num_seeds = self . num_needs ) self . log ( 'train_elbo' , elbo ) loss = - elbo return loss def _get_performance_dict ( self , batch ): if self . model . pred_item : log_p = self . model ( batch , return_type = 'log_prob' , return_scope = 'all_items' , deterministic = True ) . cpu () . numpy () num_classes = log_p . shape [ 1 ] y_pred = np . argmax ( log_p , axis = 1 ) y_true = batch . item_index . cpu () . numpy () performance = { 'acc' : metrics . accuracy_score ( y_true = y_true , y_pred = y_pred ), 'll' : - metrics . log_loss ( y_true = y_true , y_pred = np . exp ( log_p ), labels = np . arange ( num_classes ))} else : # making binary station. pred = self . model ( batch , return_type = 'utility' , return_scope = 'item_index' , deterministic = True ) y_pred = torch . sigmoid ( pred ) . cpu () . numpy () y_true = batch . label . cpu () . numpy () performance = { 'acc' : metrics . accuracy_score ( y_true = y_true , y_pred = ( y_pred >= 0.5 ) . astype ( int )), 'll' : - metrics . log_loss ( y_true = y_true , y_pred = y_pred , eps = 1E-5 , labels = [ 0 , 1 ]), # 'auc': metrics.roc_auc_score(y_true=y_true, y_score=y_pred), # 'f1': metrics.f1_score(y_true=y_true, y_pred=(y_pred >= 0.5).astype(int)) } return performance def validation_step ( self , batch , batch_idx ): # LL = self.model.forward(batch, return_type='log_prob', return_scope='item_index', deterministic=True).mean() # self.log('val_log_likelihood', LL, prog_bar=True) # pred = self.model(batch) # performance = self.model.get_within_category_accuracy(pred, batch.label) # utility. for key , val in self . _get_performance_dict ( batch ) . items (): self . log ( 'val_' + key , val , prog_bar = True , batch_size = len ( batch )) def test_step ( self , batch , batch_idx ): # LL = self.model.forward(batch, return_logit=False, all_items=False).mean() # self.log('test_log_likelihood', LL) # pred = self.model(batch, return_type='utility', return_scope='item_index', deterministic=True) # y_pred = torch.sigmoid(pred).cpu().numpy() # y_true = batch.label.cpu().numpy() # performance = {'acc': metrics.accuracy_score(y_true=y_true, y_pred=(y_pred >= 0.5).astype(int)), # 'll': - metrics.log_loss(y_true=y_true, y_pred=y_pred, eps=1E-5, labels=[0, 1]), # # 'auc': metrics.roc_auc_score(y_true=y_true, y_score=y_pred), # # 'f1': metrics.f1_score(y_true=y_true, y_pred=(y_pred >= 0.5).astype(int)) # } # pred = self.model(batch) # performance = self.model.get_within_category_accuracy(pred, batch.label) for key , val in self . _get_performance_dict ( batch ) . items (): self . log ( 'test_' + key , val , prog_bar = True , batch_size = len ( batch )) def configure_optimizers ( self ): optimizer = torch . optim . Adam ( self . parameters (), lr = self . learning_rate ) return optimizer","title":"LitBEMBFlex"},{"location":"api_bemb/#bemb.model.bemb_flex_lightning.LitBEMBFlex.__init__","text":"The initialization method of the wrapper model. Parameters: Name Type Description Default learning_rate float the learning rate of optimization. Defaults to 0.3. 0.3 num_seeds int number of random seeds for the Monte Carlo estimation in the variational inference. Defaults to 1. 1 **kwargs all keyword arguments used for constructing the wrapped BEMB model. {} Source code in bemb/model/bemb_flex_lightning.py def __init__ ( self , learning_rate : float = 0.3 , num_seeds : int = 1 , ** kwargs ): \"\"\"The initialization method of the wrapper model. Args: learning_rate (float, optional): the learning rate of optimization. Defaults to 0.3. num_seeds (int, optional): number of random seeds for the Monte Carlo estimation in the variational inference. Defaults to 1. **kwargs: all keyword arguments used for constructing the wrapped BEMB model. \"\"\" # use kwargs to pass parameter to BEMB Torch. super () . __init__ () self . model = BEMBFlex ( ** kwargs ) self . num_needs = num_seeds self . learning_rate = learning_rate","title":"__init__()"},{"location":"api_bemb/#bemb.model.bemb_flex_lightning.LitBEMBFlex.configure_optimizers","text":"Choose what optimizers and learning-rate schedulers to use in your optimization. Normally you'd need one. But in the case of GANs or similar you might have multiple. Returns: Type Description Any of these 6 options. Single optimizer . List or Tuple of optimizers. Two lists - The first list has multiple optimizers, and the second has multiple LR schedulers (or multiple lr_scheduler_config ). Dictionary , with an \"optimizer\" key, and (optionally) a \"lr_scheduler\" key whose value is a single LR scheduler or lr_scheduler_config . Tuple of dictionaries as described above, with an optional \"frequency\" key. None - Fit will run without any optimizer. The lr_scheduler_config is a dictionary which contains the scheduler and its associated configuration. The default configuration is shown below. .. code-block:: python lr_scheduler_config = { # REQUIRED: The scheduler instance \"scheduler\": lr_scheduler, # The unit of the scheduler's step size, could also be 'step'. # 'epoch' updates the scheduler on epoch end whereas 'step' # updates it after a optimizer update. \"interval\": \"epoch\", # How many epochs/steps should pass between calls to # `scheduler.step()`. 1 corresponds to updating the learning # rate after every epoch/step. \"frequency\": 1, # Metric to to monitor for schedulers like `ReduceLROnPlateau` \"monitor\": \"val_loss\", # If set to `True`, will enforce that the value specified 'monitor' # is available when the scheduler is updated, thus stopping # training if not found. If set to `False`, it will only produce a warning \"strict\": True, # If using the `LearningRateMonitor` callback to monitor the # learning rate progress, this keyword can be used to specify # a custom logged name \"name\": None, } When there are schedulers in which the .step() method is conditioned on a value, such as the :class: torch.optim.lr_scheduler.ReduceLROnPlateau scheduler, Lightning requires that the lr_scheduler_config contains the keyword \"monitor\" set to the metric name that the scheduler should be conditioned on. .. testcode:: # The ReduceLROnPlateau scheduler requires a monitor def configure_optimizers(self): optimizer = Adam(...) return { \"optimizer\": optimizer, \"lr_scheduler\": { \"scheduler\": ReduceLROnPlateau(optimizer, ...), \"monitor\": \"metric_to_track\", \"frequency\": \"indicates how often the metric is updated\" # If \"monitor\" references validation metrics, then \"frequency\" should be set to a # multiple of \"trainer.check_val_every_n_epoch\". }, } # In the case of two optimizers, only one using the ReduceLROnPlateau scheduler def configure_optimizers(self): optimizer1 = Adam(...) optimizer2 = SGD(...) scheduler1 = ReduceLROnPlateau(optimizer1, ...) scheduler2 = LambdaLR(optimizer2, ...) return ( { \"optimizer\": optimizer1, \"lr_scheduler\": { \"scheduler\": scheduler1, \"monitor\": \"metric_to_track\", }, }, {\"optimizer\": optimizer2, \"lr_scheduler\": scheduler2}, ) Metrics can be made available to monitor by simply logging it using self.log('metric_to_track', metric_val) in your :class: ~pytorch_lightning.core.lightning.LightningModule . !!! note The frequency value specified in a dict along with the optimizer key is an int corresponding to the number of sequential batches optimized with the specific optimizer. It should be given to none or to all of the optimizers. There is a difference between passing multiple optimizers in a list, and passing multiple optimizers in dictionaries with a frequency of 1: - In the former case, all optimizers will operate on the given batch in each optimization step. - In the latter, only one optimizer will operate on the given batch at every step. This is different from the ``frequency`` value specified in the ``lr_scheduler_config`` mentioned above. .. code-block:: python def configure_optimizers(self): optimizer_one = torch.optim.SGD(self.model.parameters(), lr=0.01) optimizer_two = torch.optim.SGD(self.model.parameters(), lr=0.01) return [ {\"optimizer\": optimizer_one, \"frequency\": 5}, {\"optimizer\": optimizer_two, \"frequency\": 10}, ] In this example, the first optimizer will be used for the first 5 steps, the second optimizer for the next 10 steps and that cycle will continue. If an LR scheduler is specified for an optimizer using the ``lr_scheduler`` key in the above dict, the scheduler will only be updated when its optimizer is being used. Examples:: # most cases. no learning rate scheduler def configure_optimizers(self): return Adam(self.parameters(), lr=1e-3) # multiple optimizer case (e.g.: GAN) def configure_optimizers(self): gen_opt = Adam(self.model_gen.parameters(), lr=0.01) dis_opt = Adam(self.model_dis.parameters(), lr=0.02) return gen_opt, dis_opt # example with learning rate schedulers def configure_optimizers(self): gen_opt = Adam(self.model_gen.parameters(), lr=0.01) dis_opt = Adam(self.model_dis.parameters(), lr=0.02) dis_sch = CosineAnnealing(dis_opt, T_max=10) return [gen_opt, dis_opt], [dis_sch] # example with step-based learning rate schedulers # each optimizer has its own scheduler def configure_optimizers(self): gen_opt = Adam(self.model_gen.parameters(), lr=0.01) dis_opt = Adam(self.model_dis.parameters(), lr=0.02) gen_sch = { 'scheduler': ExponentialLR(gen_opt, 0.99), 'interval': 'step' # called after each training step } dis_sch = CosineAnnealing(dis_opt, T_max=10) # called every epoch return [gen_opt, dis_opt], [gen_sch, dis_sch] # example with optimizer frequencies # see training procedure in `Improved Training of Wasserstein GANs`, Algorithm 1 # https://arxiv.org/abs/1704.00028 def configure_optimizers(self): gen_opt = Adam(self.model_gen.parameters(), lr=0.01) dis_opt = Adam(self.model_dis.parameters(), lr=0.02) n_critic = 5 return ( {'optimizer': dis_opt, 'frequency': n_critic}, {'optimizer': gen_opt, 'frequency': 1} ) !!! note Some things to know: - Lightning calls ``.backward()`` and ``.step()`` on each optimizer and learning rate scheduler as needed. - If you use 16-bit precision (``precision=16``), Lightning will automatically handle the optimizers. - If you use multiple optimizers, :meth:`training_step` will have an additional ``optimizer_idx`` parameter. - If you use :class:`torch.optim.LBFGS`, Lightning handles the closure function automatically for you. - If you use multiple optimizers, gradients will be calculated only for the parameters of current optimizer at each training step. - If you need to control how often those optimizers step or override the default ``.step()`` schedule, override the :meth:`optimizer_step` hook. Source code in bemb/model/bemb_flex_lightning.py def configure_optimizers ( self ): optimizer = torch . optim . Adam ( self . parameters (), lr = self . learning_rate ) return optimizer","title":"configure_optimizers()"},{"location":"api_bemb/#bemb.model.bemb_flex_lightning.LitBEMBFlex.forward","text":"Calls the forward method of the wrapped BEMB model, please refer to the documentaton of the BEMB class for detailed definitions of the arguments. Parameters: Name Type Description Default args _type_ arguments passed to the forward method of the wrapped BEMB model. required kwargs _type_ keyword arguments passed to the forward method of the wrapped BEMB model. required Returns: Type Description _type_ returns whatever the wrapped BEMB model returns. Source code in bemb/model/bemb_flex_lightning.py def forward ( self , args , kwargs ): \"\"\"Calls the forward method of the wrapped BEMB model, please refer to the documentaton of the BEMB class for detailed definitions of the arguments. Args: args (_type_): arguments passed to the forward method of the wrapped BEMB model. kwargs (_type_): keyword arguments passed to the forward method of the wrapped BEMB model. Returns: _type_: returns whatever the wrapped BEMB model returns. \"\"\" return self . model ( * args , ** kwargs )","title":"forward()"},{"location":"api_bemb/#bemb.model.bemb_flex_lightning.LitBEMBFlex.test_step","text":"Operates on a single batch of data from the test set. In this step you'd normally generate examples or calculate anything of interest such as accuracy. .. code-block:: python # the pseudocode for these calls test_outs = [] for test_batch in test_data: out = test_step(test_batch) test_outs.append(out) test_epoch_end(test_outs) Parameters: Name Type Description Default batch The output of your :class: ~torch.utils.data.DataLoader . required batch_idx The index of this batch. required dataloader_id The index of the dataloader that produced this batch. (only if multiple test dataloaders used). required Returns: Type Description Any of. Any object or value None - Testing will skip to the next batch .. code-block:: python # if you have one test dataloader: def test_step(self, batch, batch_idx): ... # if you have multiple test dataloaders: def test_step(self, batch, batch_idx, dataloader_idx=0): ... Examples:: # CASE 1: A single test dataset def test_step(self, batch, batch_idx): x, y = batch # implement your own out = self(x) loss = self.loss(out, y) # log 6 example images # or generated text... or whatever sample_imgs = x[:6] grid = torchvision.utils.make_grid(sample_imgs) self.logger.experiment.add_image('example_images', grid, 0) # calculate acc labels_hat = torch.argmax(out, dim=1) test_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0) # log the outputs! self.log_dict({'test_loss': loss, 'test_acc': test_acc}) If you pass in multiple test dataloaders, :meth: test_step will have an additional argument. We recommend setting the default value of 0 so that you can quickly switch between single and multiple dataloaders. .. code-block:: python # CASE 2: multiple test dataloaders def test_step(self, batch, batch_idx, dataloader_idx=0): # dataloader_idx tells you which dataset this is. ... !!! note If you don't need to test you don't need to implement this method. !!! note When the :meth: test_step is called, the model has been put in eval mode and PyTorch gradients have been disabled. At the end of the test epoch, the model goes back to training mode and gradients are enabled. Source code in bemb/model/bemb_flex_lightning.py def test_step ( self , batch , batch_idx ): # LL = self.model.forward(batch, return_logit=False, all_items=False).mean() # self.log('test_log_likelihood', LL) # pred = self.model(batch, return_type='utility', return_scope='item_index', deterministic=True) # y_pred = torch.sigmoid(pred).cpu().numpy() # y_true = batch.label.cpu().numpy() # performance = {'acc': metrics.accuracy_score(y_true=y_true, y_pred=(y_pred >= 0.5).astype(int)), # 'll': - metrics.log_loss(y_true=y_true, y_pred=y_pred, eps=1E-5, labels=[0, 1]), # # 'auc': metrics.roc_auc_score(y_true=y_true, y_score=y_pred), # # 'f1': metrics.f1_score(y_true=y_true, y_pred=(y_pred >= 0.5).astype(int)) # } # pred = self.model(batch) # performance = self.model.get_within_category_accuracy(pred, batch.label) for key , val in self . _get_performance_dict ( batch ) . items (): self . log ( 'test_' + key , val , prog_bar = True , batch_size = len ( batch ))","title":"test_step()"},{"location":"api_bemb/#bemb.model.bemb_flex_lightning.LitBEMBFlex.training_step","text":"Here you compute and return the training loss and some additional metrics for e.g. the progress bar or logger. Parameters: Name Type Description Default batch class: ~torch.Tensor | (:class: ~torch.Tensor , ...) | [:class: ~torch.Tensor , ...]): The output of your :class: ~torch.utils.data.DataLoader . A tensor, tuple or list. required batch_idx ``int`` Integer displaying index of this batch required optimizer_idx ``int`` When using multiple optimizers, this argument will also be present. required hiddens ``Any`` Passed in if :paramref: ~pytorch_lightning.core.lightning.LightningModule.truncated_bptt_steps > 0. required Returns: Type Description Any of. - class: ~torch.Tensor - The loss tensor - dict - A dictionary. Can include any keys, but must include the key 'loss' - None - Training will skip to the next batch. This is only for automatic optimization. This is not supported for multi-GPU, TPU, IPU, or DeepSpeed. In this step you'd normally do the forward pass and calculate the loss for a batch. You can also do fancier things like multiple forward passes or something model specific. Example:: def training_step(self, batch, batch_idx): x, y, z = batch out = self.encoder(x) loss = self.loss(out, x) return loss If you define multiple optimizers, this step will be called with an additional optimizer_idx parameter. .. code-block:: python # Multiple optimizers (e.g.: GANs) def training_step(self, batch, batch_idx, optimizer_idx): if optimizer_idx == 0: # do training_step with encoder ... if optimizer_idx == 1: # do training_step with decoder ... If you add truncated back propagation through time you will also get an additional argument with the hidden states of the previous step. .. code-block:: python # Truncated back-propagation through time def training_step(self, batch, batch_idx, hiddens): # hiddens are the hidden states from the previous truncated backprop step out, hiddens = self.lstm(data, hiddens) loss = ... return {\"loss\": loss, \"hiddens\": hiddens} !!! note The loss value shown in the progress bar is smoothed (averaged) over the last values, so it differs from the actual loss returned in train/validation step. Source code in bemb/model/bemb_flex_lightning.py def training_step ( self , batch , batch_idx ): elbo = self . model . elbo ( batch , num_seeds = self . num_needs ) self . log ( 'train_elbo' , elbo ) loss = - elbo return loss","title":"training_step()"},{"location":"api_bemb/#bemb.model.bemb_flex_lightning.LitBEMBFlex.validation_step","text":"Operates on a single batch of data from the validation set. In this step you'd might generate examples or calculate anything of interest like accuracy. .. code-block:: python # the pseudocode for these calls val_outs = [] for val_batch in val_data: out = validation_step(val_batch) val_outs.append(out) validation_epoch_end(val_outs) Parameters: Name Type Description Default batch The output of your :class: ~torch.utils.data.DataLoader . required batch_idx The index of this batch. required dataloader_idx The index of the dataloader that produced this batch. (only if multiple val dataloaders used) required Returns: Type Description Any object or value None - Validation will skip to the next batch .. code-block:: python # pseudocode of order val_outs = [] for val_batch in val_data: out = validation_step(val_batch) if defined(\"validation_step_end\"): out = validation_step_end(out) val_outs.append(out) val_outs = validation_epoch_end(val_outs) .. code-block:: python # if you have one val dataloader: def validation_step(self, batch, batch_idx): ... # if you have multiple val dataloaders: def validation_step(self, batch, batch_idx, dataloader_idx=0): ... Examples:: # CASE 1: A single validation dataset def validation_step(self, batch, batch_idx): x, y = batch # implement your own out = self(x) loss = self.loss(out, y) # log 6 example images # or generated text... or whatever sample_imgs = x[:6] grid = torchvision.utils.make_grid(sample_imgs) self.logger.experiment.add_image('example_images', grid, 0) # calculate acc labels_hat = torch.argmax(out, dim=1) val_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0) # log the outputs! self.log_dict({'val_loss': loss, 'val_acc': val_acc}) If you pass in multiple val dataloaders, :meth: validation_step will have an additional argument. We recommend setting the default value of 0 so that you can quickly switch between single and multiple dataloaders. .. code-block:: python # CASE 2: multiple validation dataloaders def validation_step(self, batch, batch_idx, dataloader_idx=0): # dataloader_idx tells you which dataset this is. ... !!! note If you don't need to validate you don't need to implement this method. !!! note When the :meth: validation_step is called, the model has been put in eval mode and PyTorch gradients have been disabled. At the end of validation, the model goes back to training mode and gradients are enabled. Source code in bemb/model/bemb_flex_lightning.py def validation_step ( self , batch , batch_idx ): # LL = self.model.forward(batch, return_type='log_prob', return_scope='item_index', deterministic=True).mean() # self.log('val_log_likelihood', LL, prog_bar=True) # pred = self.model(batch) # performance = self.model.get_within_category_accuracy(pred, batch.label) # utility. for key , val in self . _get_performance_dict ( batch ) . items (): self . log ( 'val_' + key , val , prog_bar = True , batch_size = len ( batch ))","title":"validation_step()"},{"location":"api_torch_choice/","text":"API Reference: Torch Choice data special choice_dataset The dataset object for management large scale consumer choice datasets. Please refer to the documentation and tutorials for more details on using ChoiceDataset . Author: Tianyu Du Update: Apr. 27, 2022 ChoiceDataset ( Dataset ) Source code in torch_choice/data/choice_dataset.py class ChoiceDataset ( torch . utils . data . Dataset ): def __init__ ( self , item_index : torch . LongTensor , label : Optional [ torch . LongTensor ] = None , user_index : Optional [ torch . LongTensor ] = None , session_index : Optional [ torch . LongTensor ] = None , item_availability : Optional [ torch . BoolTensor ] = None , ** kwargs ) -> None : \"\"\" Initialization methods for the dataset object, researchers should supply all information about the dataset using this initialization method. The number of choice instances are called `batch_size` in the documentation. The `batch_size` corresponds to the file length in wide-format dataset, and often denoted using `N`. We call it `batch_size` to follow the convention in machine learning literature. A `choice instance` is a row of the dataset, so there are `batch_size` choice instances in each `ChoiceDataset`. The dataset consists of: (1) a collection of `batch_size` tuples (item_id, user_id, session_id, label), where each tuple is a choice instance. (2) a collection of `observables` associated with item, user, session, etc. Args: item_index (torch.LongTensor): a tensor of shape (batch_size) indicating the relevant item in each row of the dataset, the relevant item can be: (1) the item bought in this choice instance, (2) or the item reviewed by the user. In the later case, we need the `label` tensor to specify the rating score. NOTE: The support for second case is under-development, currently, we are only supporting binary label. label (Optional[torch.LongTensor], optional): a tensor of shape (batch_size) indicating the label for prediction in each choice instance. While you want to predict the item bought, you can leave the `label` argument as `None` in the initialization method, and the model will use `item_index` as the object to be predicted. But if you are, for example, predicting the rating an user gave an item, label must be provided. Defaults to None. user_index (Optional[torch.LongTensor], optional): a tensor of shape num_purchases (batch_size) indicating the ID of the user who was involved in each choice instance. If `None` user index is provided, it's assumed that the choice instances are from the same user. `user_index` is required if and only if there are multiple users in the dataset, for example: (1) user-observables is involved in the utility form, (2) and/or the coefficient is user-specific. This tensor is used to select the corresponding user observables and coefficients assigned to the user (like theta_user) for making prediction for that purchase. Defaults to None. session_index (Optional[torch.LongTensor], optional): a tensor of shape num_purchases (batch_size) indicating the ID of the session when that choice instance occurred. This tensor is used to select the correct session observables or price observables for making prediction for that choice instance. Therefore, if there is no session/price observables, you can leave this argument as `None`. In this case, the `ChoiceDataset` object will assume each choice instance to be in its own session. Defaults to None. item_availability (Optional[torch.BoolTensor], optional): A boolean tensor of shape (num_sessions, num_items) indicating the availability of each item in each session. Utilities of unavailable items would be set to -infinite, and hence these unavailable items will be set to 0 while making prediction. We assume all items are available if set to None. Defaults to None. Other Kwargs (Observables): One can specify the following types of observables, where * in shape denotes any positive integer. Typically * represents the number of observables. Please refer to the documentation for a detailed guide to use observables. 1. user observables must start with 'user_' and have shape (num_users, *) 2. item observables must start with 'item_' and have shape (num_items, *) 3. session observables must start with 'session_' and have shape (num_sessions, *) 4. taste observables (those vary by user and item) must start with `taste_` and have shape (num_users, num_items, *). NOTE: we don't recommend using taste observables, because num_users * num_items is potentially large. 5. price observables (those vary by session and item) must start with `price_` and have shape (num_sessions, num_items, *) \"\"\" # ENHANCEMENT(Tianyu): add item_names for summary. super ( ChoiceDataset , self ) . __init__ () self . label = label self . item_index = item_index self . user_index = user_index self . session_index = session_index if self . session_index is None : # if any([x.startswith('session_') or x.startswith('price_') for x in kwargs.keys()]): # if any session sensitive observable is provided, but session index is not, # infer each row in the dataset to be a session. # TODO: (design choice) should we assign unique session index to each choice instance or the same session index. print ( 'No `session_index` is provided, assume each choice instance is in its own session.' ) self . session_index = torch . arange ( len ( self . item_index )) . long () self . item_availability = item_availability for key , item in kwargs . items (): setattr ( self , key , item ) # TODO: add a validation procedure to check the consistency of the dataset. def __getitem__ ( self , indices : Union [ int , torch . LongTensor ]) -> \"ChoiceDataset\" : \"\"\"Retrieves samples corresponding to the provided index or list of indices. Args: indices (Union[int, torch.LongTensor]): a single integer index or a tensor of indices. Returns: ChoiceDataset: a subset of the dataset. \"\"\" if isinstance ( indices , int ): # convert single integer index to an array of indices. indices = torch . LongTensor ([ indices ]) new_dict = dict () new_dict [ 'item_index' ] = self . item_index [ indices ] . clone () # copy optional attributes. new_dict [ 'label' ] = self . label [ indices ] . clone () if self . label is not None else None new_dict [ 'user_index' ] = self . user_index [ indices ] . clone () if self . user_index is not None else None new_dict [ 'session_index' ] = self . session_index [ indices ] . clone () if self . session_index is not None else None # item_availability has shape (num_sessions, num_items), no need to re-index it. new_dict [ 'item_availability' ] = self . item_availability # copy other attributes. for key , val in self . __dict__ . items (): if key not in new_dict . keys (): if torch . is_tensor ( val ): new_dict [ key ] = val . clone () else : new_dict [ key ] = copy . deepcopy ( val ) return self . _from_dict ( new_dict ) def __len__ ( self ) -> int : \"\"\"Returns number of samples in this dataset. Returns: int: length of the dataset. \"\"\" return len ( self . item_index ) def __contains__ ( self , key : str ) -> bool : return key in self . keys @property def device ( self ) -> str : \"\"\"Returns the device of the dataset. Returns: str: the device of the dataset. \"\"\" for attr in self . __dict__ . values (): if torch . is_tensor ( attr ): return attr . device @property def num_users ( self ) -> int : \"\"\"Returns number of users involved in this dataset, returns 1 if there is no user identity. Returns: int: the number of users involved in this dataset. \"\"\" # query from user_index if self . user_index is not None : return len ( torch . unique ( self . user_index )) else : return 1 # for key, val in self.__dict__.items(): # if torch.is_tensor(val): # if self._is_user_attribute(key) or self._is_taste_attribute(key): # return val.shape[0] # return 1 @property def num_items ( self ) -> int : \"\"\"Returns the number of items involved in this dataset. Returns: int: the number of items involved in this dataset. \"\"\" return len ( torch . unique ( self . item_index )) # for key, val in self.__dict__.items(): # if torch.is_tensor(val): # if self._is_item_attribute(key): # return val.shape[0] # elif self._is_taste_attribute(key) or self._is_price_attribute(key): # return val.shape[1] # return 1 @property def num_sessions ( self ) -> int : \"\"\"Returns the number of sessions involved in this dataset. Returns: int: the number of sessions involved in this dataset. \"\"\" return len ( torch . unique ( self . session_index )) # if self.session_index is None: # return 1 # for key, val in self.__dict__.items(): # if torch.is_tensor(val): # if self._is_session_attribute(key) or self._is_price_attribute(key): # return val.shape[0] # return 1 @property def x_dict ( self ) -> Dict [ object , torch . Tensor ]: \"\"\"Formats attributes of in this dataset into shape (num_sessions, num_items, num_params) and returns in a dictionary format. Models in this package are expecting this dictionary based data format. Returns: Dict[object, torch.Tensor]: a dictionary with attribute names in the dataset as keys, and reshaped attribute tensors as values. \"\"\" out = dict () for key , val in self . __dict__ . items (): if self . _is_attribute ( key ): # only include attributes. out [ key ] = self . _expand_tensor ( key , val ) # reshape to (num_sessions, num_items, num_params). return out @classmethod def _from_dict ( cls , dictionary : Dict [ str , torch . tensor ]) -> \"ChoiceDataset\" : \"\"\"Creates an instance of ChoiceDataset from a dictionary of arguments. Args: dictionary (Dict[str, torch.tensor]): a dictionary with keys as argument names and values as arguments. Returns: ChoiceDataset: the created copy of dataset. \"\"\" dataset = cls ( ** dictionary ) for key , item in dictionary . items (): setattr ( dataset , key , item ) return dataset def apply_tensor ( self , func : callable ) -> \"ChoiceDataset\" : \"\"\"This s a helper method to apply the provided function to all tensors and tensor values of all dictionaries. Args: func (callable): a callable function to be applied on tensors and tensor-values of dictionaries. Returns: ChoiceDataset: the modified dataset. \"\"\" for key , item in self . __dict__ . items (): if torch . is_tensor ( item ): setattr ( self , key , func ( item )) # boardcast func to dictionary of tensors as well. elif isinstance ( getattr ( self , key ), dict ): for obj_key , obj_item in getattr ( self , key ) . items (): if torch . is_tensor ( obj_item ): setattr ( getattr ( self , key ), obj_key , func ( obj_item )) return self def to ( self , device : Union [ str , torch . device ]) -> \"ChoiceDataset\" : \"\"\"Moves all tensors in this dataset to the specified PyTorch device. Args: device (Union[str, torch.device]): the destination device. Returns: ChoiceDataset: the modified dataset on the new device. \"\"\" return self . apply_tensor ( lambda x : x . to ( device )) def clone ( self ) -> \"ChoiceDataset\" : \"\"\"Creates a copy of self. Returns: ChoiceDataset: a copy of self. \"\"\" dictionary = {} for k , v in self . __dict__ . items (): if torch . is_tensor ( v ): dictionary [ k ] = v . clone () else : dictionary [ k ] = copy . deepcopy ( v ) return self . __class__ . _from_dict ( dictionary ) def _check_device_consistency ( self ) -> None : \"\"\"Checks if all tensors in this dataset are on the same device. Raises: Exception: an exception is raised if not all tensors are on the same device. \"\"\" # assert all tensors are on the same device. devices = list () for val in self . __dict__ . values (): if torch . is_tensor ( val ): devices . append ( val . device ) if len ( set ( devices )) > 1 : raise Exception ( f 'Found tensors on different devices: { set ( devices ) } .' , 'Use dataset.to() method to align devices.' ) def _size_repr ( self , value : object ) -> List [ int ]: \"\"\"A helper method to get the string-representation of object sizes, this is helpful while constructing the string representation of the dataset. Args: value (object): an object to examine its size. Returns: List[int]: list of integers representing the size of the object, length of the list is equal to dimension of `value`. \"\"\" if torch . is_tensor ( value ): return list ( value . size ()) elif isinstance ( value , int ) or isinstance ( value , float ): return [ 1 ] elif isinstance ( value , list ) or isinstance ( value , tuple ): return [ len ( value )] else : return [] def __repr__ ( self ) -> str : \"\"\"A method to get a string representation of the dataset. Returns: str: the string representation of the dataset. \"\"\" info = [ f ' { key } = { self . _size_repr ( item ) } ' for key , item in self . __dict__ . items ()] return f \" { self . __class__ . __name__ } ( { ', ' . join ( info ) } , device= { self . device } )\" # ================================================================================================================== # methods for checking attribute categories. # ================================================================================================================== @staticmethod def _is_item_attribute ( key : str ) -> bool : return key . startswith ( 'item_' ) and ( key != 'item_availability' ) and ( key != 'item_index' ) @staticmethod def _is_user_attribute ( key : str ) -> bool : return key . startswith ( 'user_' ) and ( key != 'user_index' ) @staticmethod def _is_session_attribute ( key : str ) -> bool : return key . startswith ( 'session_' ) and ( key != 'session_index' ) @staticmethod def _is_taste_attribute ( key : str ) -> bool : return key . startswith ( 'taste_' ) @staticmethod def _is_price_attribute ( key : str ) -> bool : return key . startswith ( 'price_' ) def _is_attribute ( self , key : str ) -> bool : return self . _is_item_attribute ( key ) \\ or self . _is_user_attribute ( key ) \\ or self . _is_session_attribute ( key ) \\ or self . _is_taste_attribute ( key ) \\ or self . _is_price_attribute ( key ) def _expand_tensor ( self , key : str , val : torch . Tensor ) -> torch . Tensor : \"\"\"Expands attribute tensor to (num_sessions, num_items, num_params) shape for prediction tasks, this method won't reshape the tensor at all if the `key` (i.e., name of the tensor) suggests its not an attribute of any kind. Args: key (str): name of the attribute used to determine the raw shape of the tensor. For example, 'item_obs' means the raw tensor is in shape (num_items, num_params). val (torch.Tensor): the attribute tensor to be reshaped. Returns: torch.Tensor: the reshaped tensor with shape (num_sessions, num_items, num_params). \"\"\" if not self . _is_attribute ( key ): print ( f 'Warning: the input key { key } is not an attribute of the dataset, will NOT modify the provided tensor.' ) # don't expand non-attribute tensors, if any. return val num_params = val . shape [ - 1 ] if self . _is_user_attribute ( key ): # user_attribute (num_users, *) out = val [ self . user_index , :] . view ( len ( self ), 1 , num_params ) . expand ( - 1 , self . num_items , - 1 ) elif self . _is_item_attribute ( key ): # item_attribute (num_items, *) out = val . view ( 1 , self . num_items , num_params ) . expand ( len ( self ), - 1 , - 1 ) elif self . _is_session_attribute ( key ): # session_attribute (num_sessions, *) out = val [ self . session_index , :] . view ( len ( self ), 1 , num_params ) . expand ( - 1 , self . num_items , - 1 ) elif self . _is_taste_attribute ( key ): # taste_attribute (num_users, num_items, *) out = val [ self . user_index , :, :] elif self . _is_price_attribute ( key ): # price_attribute (num_sessions, num_items, *) out = val [ self . session_index , :, :] assert out . shape == ( len ( self ), self . num_items , num_params ) return out device : str property readonly Returns the device of the dataset. Returns: Type Description str the device of the dataset. num_items : int property readonly Returns the number of items involved in this dataset. Returns: Type Description int the number of items involved in this dataset. num_sessions : int property readonly Returns the number of sessions involved in this dataset. Returns: Type Description int the number of sessions involved in this dataset. num_users : int property readonly Returns number of users involved in this dataset, returns 1 if there is no user identity. Returns: Type Description int the number of users involved in this dataset. x_dict : Dict [ object , torch . Tensor ] property readonly Formats attributes of in this dataset into shape (num_sessions, num_items, num_params) and returns in a dictionary format. Models in this package are expecting this dictionary based data format. Returns: Type Description Dict[object, torch.Tensor] a dictionary with attribute names in the dataset as keys, and reshaped attribute tensors as values. __getitem__ ( self , indices ) special Retrieves samples corresponding to the provided index or list of indices. Parameters: Name Type Description Default indices Union[int, torch.LongTensor] a single integer index or a tensor of indices. required Returns: Type Description ChoiceDataset a subset of the dataset. Source code in torch_choice/data/choice_dataset.py def __getitem__ ( self , indices : Union [ int , torch . LongTensor ]) -> \"ChoiceDataset\" : \"\"\"Retrieves samples corresponding to the provided index or list of indices. Args: indices (Union[int, torch.LongTensor]): a single integer index or a tensor of indices. Returns: ChoiceDataset: a subset of the dataset. \"\"\" if isinstance ( indices , int ): # convert single integer index to an array of indices. indices = torch . LongTensor ([ indices ]) new_dict = dict () new_dict [ 'item_index' ] = self . item_index [ indices ] . clone () # copy optional attributes. new_dict [ 'label' ] = self . label [ indices ] . clone () if self . label is not None else None new_dict [ 'user_index' ] = self . user_index [ indices ] . clone () if self . user_index is not None else None new_dict [ 'session_index' ] = self . session_index [ indices ] . clone () if self . session_index is not None else None # item_availability has shape (num_sessions, num_items), no need to re-index it. new_dict [ 'item_availability' ] = self . item_availability # copy other attributes. for key , val in self . __dict__ . items (): if key not in new_dict . keys (): if torch . is_tensor ( val ): new_dict [ key ] = val . clone () else : new_dict [ key ] = copy . deepcopy ( val ) return self . _from_dict ( new_dict ) __init__ ( self , item_index , label = None , user_index = None , session_index = None , item_availability = None , ** kwargs ) special Initialization methods for the dataset object, researchers should supply all information about the dataset using this initialization method. The number of choice instances are called batch_size in the documentation. The batch_size corresponds to the file length in wide-format dataset, and often denoted using N . We call it batch_size to follow the convention in machine learning literature. A choice instance is a row of the dataset, so there are batch_size choice instances in each ChoiceDataset . The dataset consists of: (1) a collection of batch_size tuples (item_id, user_id, session_id, label), where each tuple is a choice instance. (2) a collection of observables associated with item, user, session, etc. Parameters: Name Type Description Default item_index torch.LongTensor a tensor of shape (batch_size) indicating the relevant item in each row of the dataset, the relevant item can be: (1) the item bought in this choice instance, (2) or the item reviewed by the user. In the later case, we need the label tensor to specify the rating score. NOTE: The support for second case is under-development, currently, we are only supporting binary label. required label Optional[torch.LongTensor] a tensor of shape (batch_size) indicating the label for prediction in each choice instance. While you want to predict the item bought, you can leave the label argument as None in the initialization method, and the model will use item_index as the object to be predicted. But if you are, for example, predicting the rating an user gave an item, label must be provided. Defaults to None. None user_index Optional[torch.LongTensor] a tensor of shape num_purchases (batch_size) indicating the ID of the user who was involved in each choice instance. If None user index is provided, it's assumed that the choice instances are from the same user. user_index is required if and only if there are multiple users in the dataset, for example: (1) user-observables is involved in the utility form, (2) and/or the coefficient is user-specific. This tensor is used to select the corresponding user observables and coefficients assigned to the user (like theta_user) for making prediction for that purchase. Defaults to None. None session_index Optional[torch.LongTensor] a tensor of shape num_purchases (batch_size) indicating the ID of the session when that choice instance occurred. This tensor is used to select the correct session observables or price observables for making prediction for that choice instance. Therefore, if there is no session/price observables, you can leave this argument as None . In this case, the ChoiceDataset object will assume each choice instance to be in its own session. Defaults to None. None item_availability Optional[torch.BoolTensor] A boolean tensor of shape (num_sessions, num_items) indicating the availability of each item in each session. Utilities of unavailable items would be set to -infinite, and hence these unavailable items will be set to 0 while making prediction. We assume all items are available if set to None. Defaults to None. None Other Kwargs (Observables): One can specify the following types of observables, where * in shape denotes any positive integer. Typically * represents the number of observables. Please refer to the documentation for a detailed guide to use observables. 1. user observables must start with 'user_' and have shape (num_users, ) 2. item observables must start with 'item_' and have shape (num_items, ) 3. session observables must start with 'session_' and have shape (num_sessions, ) 4. taste observables (those vary by user and item) must start with taste_ and have shape (num_users, num_items, ). NOTE: we don't recommend using taste observables, because num_users * num_items is potentially large. 5. price observables (those vary by session and item) must start with price_ and have shape (num_sessions, num_items, *) Source code in torch_choice/data/choice_dataset.py def __init__ ( self , item_index : torch . LongTensor , label : Optional [ torch . LongTensor ] = None , user_index : Optional [ torch . LongTensor ] = None , session_index : Optional [ torch . LongTensor ] = None , item_availability : Optional [ torch . BoolTensor ] = None , ** kwargs ) -> None : \"\"\" Initialization methods for the dataset object, researchers should supply all information about the dataset using this initialization method. The number of choice instances are called `batch_size` in the documentation. The `batch_size` corresponds to the file length in wide-format dataset, and often denoted using `N`. We call it `batch_size` to follow the convention in machine learning literature. A `choice instance` is a row of the dataset, so there are `batch_size` choice instances in each `ChoiceDataset`. The dataset consists of: (1) a collection of `batch_size` tuples (item_id, user_id, session_id, label), where each tuple is a choice instance. (2) a collection of `observables` associated with item, user, session, etc. Args: item_index (torch.LongTensor): a tensor of shape (batch_size) indicating the relevant item in each row of the dataset, the relevant item can be: (1) the item bought in this choice instance, (2) or the item reviewed by the user. In the later case, we need the `label` tensor to specify the rating score. NOTE: The support for second case is under-development, currently, we are only supporting binary label. label (Optional[torch.LongTensor], optional): a tensor of shape (batch_size) indicating the label for prediction in each choice instance. While you want to predict the item bought, you can leave the `label` argument as `None` in the initialization method, and the model will use `item_index` as the object to be predicted. But if you are, for example, predicting the rating an user gave an item, label must be provided. Defaults to None. user_index (Optional[torch.LongTensor], optional): a tensor of shape num_purchases (batch_size) indicating the ID of the user who was involved in each choice instance. If `None` user index is provided, it's assumed that the choice instances are from the same user. `user_index` is required if and only if there are multiple users in the dataset, for example: (1) user-observables is involved in the utility form, (2) and/or the coefficient is user-specific. This tensor is used to select the corresponding user observables and coefficients assigned to the user (like theta_user) for making prediction for that purchase. Defaults to None. session_index (Optional[torch.LongTensor], optional): a tensor of shape num_purchases (batch_size) indicating the ID of the session when that choice instance occurred. This tensor is used to select the correct session observables or price observables for making prediction for that choice instance. Therefore, if there is no session/price observables, you can leave this argument as `None`. In this case, the `ChoiceDataset` object will assume each choice instance to be in its own session. Defaults to None. item_availability (Optional[torch.BoolTensor], optional): A boolean tensor of shape (num_sessions, num_items) indicating the availability of each item in each session. Utilities of unavailable items would be set to -infinite, and hence these unavailable items will be set to 0 while making prediction. We assume all items are available if set to None. Defaults to None. Other Kwargs (Observables): One can specify the following types of observables, where * in shape denotes any positive integer. Typically * represents the number of observables. Please refer to the documentation for a detailed guide to use observables. 1. user observables must start with 'user_' and have shape (num_users, *) 2. item observables must start with 'item_' and have shape (num_items, *) 3. session observables must start with 'session_' and have shape (num_sessions, *) 4. taste observables (those vary by user and item) must start with `taste_` and have shape (num_users, num_items, *). NOTE: we don't recommend using taste observables, because num_users * num_items is potentially large. 5. price observables (those vary by session and item) must start with `price_` and have shape (num_sessions, num_items, *) \"\"\" # ENHANCEMENT(Tianyu): add item_names for summary. super ( ChoiceDataset , self ) . __init__ () self . label = label self . item_index = item_index self . user_index = user_index self . session_index = session_index if self . session_index is None : # if any([x.startswith('session_') or x.startswith('price_') for x in kwargs.keys()]): # if any session sensitive observable is provided, but session index is not, # infer each row in the dataset to be a session. # TODO: (design choice) should we assign unique session index to each choice instance or the same session index. print ( 'No `session_index` is provided, assume each choice instance is in its own session.' ) self . session_index = torch . arange ( len ( self . item_index )) . long () self . item_availability = item_availability for key , item in kwargs . items (): setattr ( self , key , item ) # TODO: add a validation procedure to check the consistency of the dataset. __len__ ( self ) special Returns number of samples in this dataset. Returns: Type Description int length of the dataset. Source code in torch_choice/data/choice_dataset.py def __len__ ( self ) -> int : \"\"\"Returns number of samples in this dataset. Returns: int: length of the dataset. \"\"\" return len ( self . item_index ) __repr__ ( self ) special A method to get a string representation of the dataset. Returns: Type Description str the string representation of the dataset. Source code in torch_choice/data/choice_dataset.py def __repr__ ( self ) -> str : \"\"\"A method to get a string representation of the dataset. Returns: str: the string representation of the dataset. \"\"\" info = [ f ' { key } = { self . _size_repr ( item ) } ' for key , item in self . __dict__ . items ()] return f \" { self . __class__ . __name__ } ( { ', ' . join ( info ) } , device= { self . device } )\" apply_tensor ( self , func ) This s a helper method to apply the provided function to all tensors and tensor values of all dictionaries. Parameters: Name Type Description Default func callable a callable function to be applied on tensors and tensor-values of dictionaries. required Returns: Type Description ChoiceDataset the modified dataset. Source code in torch_choice/data/choice_dataset.py def apply_tensor ( self , func : callable ) -> \"ChoiceDataset\" : \"\"\"This s a helper method to apply the provided function to all tensors and tensor values of all dictionaries. Args: func (callable): a callable function to be applied on tensors and tensor-values of dictionaries. Returns: ChoiceDataset: the modified dataset. \"\"\" for key , item in self . __dict__ . items (): if torch . is_tensor ( item ): setattr ( self , key , func ( item )) # boardcast func to dictionary of tensors as well. elif isinstance ( getattr ( self , key ), dict ): for obj_key , obj_item in getattr ( self , key ) . items (): if torch . is_tensor ( obj_item ): setattr ( getattr ( self , key ), obj_key , func ( obj_item )) return self clone ( self ) Creates a copy of self. Returns: Type Description ChoiceDataset a copy of self. Source code in torch_choice/data/choice_dataset.py def clone ( self ) -> \"ChoiceDataset\" : \"\"\"Creates a copy of self. Returns: ChoiceDataset: a copy of self. \"\"\" dictionary = {} for k , v in self . __dict__ . items (): if torch . is_tensor ( v ): dictionary [ k ] = v . clone () else : dictionary [ k ] = copy . deepcopy ( v ) return self . __class__ . _from_dict ( dictionary ) to ( self , device ) Moves all tensors in this dataset to the specified PyTorch device. Parameters: Name Type Description Default device Union[str, torch.device] the destination device. required Returns: Type Description ChoiceDataset the modified dataset on the new device. Source code in torch_choice/data/choice_dataset.py def to ( self , device : Union [ str , torch . device ]) -> \"ChoiceDataset\" : \"\"\"Moves all tensors in this dataset to the specified PyTorch device. Args: device (Union[str, torch.device]): the destination device. Returns: ChoiceDataset: the modified dataset on the new device. \"\"\" return self . apply_tensor ( lambda x : x . to ( device )) joint_dataset The JointDataset class is a wrapper for the torch.utils.data.ChoiceDataset class, it is particularly useful when we need to make prediction from multiple datasets. For example, you have data on consumer purchase records in a fast food store, and suppose every customer will purchase exactly a single main food and a single drink. In this case, you have two separate datasets: FoodDataset and DrinkDataset. You may want to use PyTorch sampler to sample them in a dependent manner: you want to take the i-th sample from both datasets, so that you know what (food, drink) combo the i-th customer purchased. You can do this by using the JointDataset class. Author: Tianyu Du Update: Apr. 28, 2022 JointDataset ( Dataset ) A helper class for joining several pytorch datasets, using JointDataset and pytorch data loader allows for sampling the same batch index from several datasets. The JointDataset class is a wrapper for the torch.utils.data.ChoiceDataset class, it is particularly useful when we need to make prediction from multiple datasets. For example, you have data on consumer purchase records in a fast food store, and suppose every customer will purchase exactly a single main food and a single drink. In this case, you have two separate datasets: FoodDataset and DrinkDataset. You may want to use PyTorch sampler to sample them in a dependent manner: you want to take the i-th sample from both datasets, so that you know what (food, drink) combo the i-th customer purchased. You can do this by using the JointDataset class. Source code in torch_choice/data/joint_dataset.py class JointDataset ( torch . utils . data . Dataset ): \"\"\"A helper class for joining several pytorch datasets, using JointDataset and pytorch data loader allows for sampling the same batch index from several datasets. The JointDataset class is a wrapper for the torch.utils.data.ChoiceDataset class, it is particularly useful when we need to make prediction from multiple datasets. For example, you have data on consumer purchase records in a fast food store, and suppose every customer will purchase exactly a single main food and a single drink. In this case, you have two separate datasets: FoodDataset and DrinkDataset. You may want to use PyTorch sampler to sample them in a dependent manner: you want to take the i-th sample from both datasets, so that you know what (food, drink) combo the i-th customer purchased. You can do this by using the JointDataset class. \"\"\" def __init__ ( self , ** datasets ) -> None : \"\"\"The initialize methods. Args: Arbitrarily many datasets with arbitrary names as keys. In the example above, you can construct ``` dataset = JointDataset(food=FoodDataset, drink=DrinkDataset) ``` All datasets should have the same length. \"\"\" super ( JointDataset , self ) . __init__ () self . datasets = datasets # check the length of sub-datasets are the same. assert len ( set ([ len ( d ) for d in self . datasets . values ()])) == 1 def __len__ ( self ) -> int : \"\"\"Get the number of samples in the joint dataset. Returns: int: the number of samples in the joint dataset, which is the same as the number of samples in each dataset contained. \"\"\" for d in self . datasets . values (): return len ( d ) def __getitem__ ( self , indices : Union [ int , torch . LongTensor ]) -> Dict [ str , ChoiceDataset ]: \"\"\"Queries samples from the dataset by index. Args: indices (Union[int, torch.LongTensor]): an integer or a 1D tensor of multiple indices. Returns: Dict[str, ChoiceDataset]: the subset of the dataset. Keys of the dictionary will be names of each dataset contained (the same as the keys of the ``datasets`` argument in the constructor). Values will be subsets of contained datasets, sliced using the provided indices. \"\"\" return dict (( name , d [ indices ]) for ( name , d ) in self . datasets . items ()) def __repr__ ( self ) -> str : \"\"\"A method to get a string representation of the dataset. Returns: str: the string representation of the dataset. \"\"\" out = [ f 'JointDataset with { len ( self . datasets ) } sub-datasets: (' ] for name , dataset in self . datasets . items (): out . append ( f ' \\t { name } : { str ( dataset ) } ' ) out . append ( ')' ) return ' \\n ' . join ( out ) @property def device ( self ) -> str : \"\"\"Returns the device of datasets contained in the joint dataset. Returns: str: the device of the dataset. \"\"\" for d in self . datasets . values (): return d . device def to ( self , device : Union [ str , torch . device ]) -> \"JointDataset\" : \"\"\"Moves all datasets in this dataset to the specified PyTorch device. Args: device (Union[str, torch.device]): the destination device. Returns: ChoiceDataset: the modified dataset on the new device. \"\"\" for d in self . datasets . values (): d = d . to ( device ) return self device : str property readonly Returns the device of datasets contained in the joint dataset. Returns: Type Description str the device of the dataset. __getitem__ ( self , indices ) special Queries samples from the dataset by index. Parameters: Name Type Description Default indices Union[int, torch.LongTensor] an integer or a 1D tensor of multiple indices. required Returns: Type Description Dict[str, ChoiceDataset] the subset of the dataset. Keys of the dictionary will be names of each dataset contained (the same as the keys of the datasets argument in the constructor). Values will be subsets of contained datasets, sliced using the provided indices. Source code in torch_choice/data/joint_dataset.py def __getitem__ ( self , indices : Union [ int , torch . LongTensor ]) -> Dict [ str , ChoiceDataset ]: \"\"\"Queries samples from the dataset by index. Args: indices (Union[int, torch.LongTensor]): an integer or a 1D tensor of multiple indices. Returns: Dict[str, ChoiceDataset]: the subset of the dataset. Keys of the dictionary will be names of each dataset contained (the same as the keys of the ``datasets`` argument in the constructor). Values will be subsets of contained datasets, sliced using the provided indices. \"\"\" return dict (( name , d [ indices ]) for ( name , d ) in self . datasets . items ()) __init__ ( self , ** datasets ) special The initialize methods. Source code in torch_choice/data/joint_dataset.py def __init__ ( self , ** datasets ) -> None : \"\"\"The initialize methods. Args: Arbitrarily many datasets with arbitrary names as keys. In the example above, you can construct ``` dataset = JointDataset(food=FoodDataset, drink=DrinkDataset) ``` All datasets should have the same length. \"\"\" super ( JointDataset , self ) . __init__ () self . datasets = datasets # check the length of sub-datasets are the same. assert len ( set ([ len ( d ) for d in self . datasets . values ()])) == 1 __len__ ( self ) special Get the number of samples in the joint dataset. Returns: Type Description int the number of samples in the joint dataset, which is the same as the number of samples in each dataset contained. Source code in torch_choice/data/joint_dataset.py def __len__ ( self ) -> int : \"\"\"Get the number of samples in the joint dataset. Returns: int: the number of samples in the joint dataset, which is the same as the number of samples in each dataset contained. \"\"\" for d in self . datasets . values (): return len ( d ) __repr__ ( self ) special A method to get a string representation of the dataset. Returns: Type Description str the string representation of the dataset. Source code in torch_choice/data/joint_dataset.py def __repr__ ( self ) -> str : \"\"\"A method to get a string representation of the dataset. Returns: str: the string representation of the dataset. \"\"\" out = [ f 'JointDataset with { len ( self . datasets ) } sub-datasets: (' ] for name , dataset in self . datasets . items (): out . append ( f ' \\t { name } : { str ( dataset ) } ' ) out . append ( ')' ) return ' \\n ' . join ( out ) to ( self , device ) Moves all datasets in this dataset to the specified PyTorch device. Parameters: Name Type Description Default device Union[str, torch.device] the destination device. required Returns: Type Description ChoiceDataset the modified dataset on the new device. Source code in torch_choice/data/joint_dataset.py def to ( self , device : Union [ str , torch . device ]) -> \"JointDataset\" : \"\"\"Moves all datasets in this dataset to the specified PyTorch device. Args: device (Union[str, torch.device]): the destination device. Returns: ChoiceDataset: the modified dataset on the new device. \"\"\" for d in self . datasets . values (): d = d . to ( device ) return self utils pivot3d ( df , dim0 , dim1 , values ) Creates a tensor of shape (df[dim0].nunique(), df[dim1].nunique(), len(values)) from the provided data frame. Example, if dim0 is the column of session ID, dim1 is the column of alternative names, then out[t, i, k] is the feature values[k] of item i in session t. The returned tensor has shape (num_sessions, num_items, num_params), which fits the purpose of conditioanl logit models. Source code in torch_choice/data/utils.py def pivot3d ( df : pd . DataFrame , dim0 : str , dim1 : str , values : Union [ str , List [ str ]]) -> torch . Tensor : \"\"\" Creates a tensor of shape (df[dim0].nunique(), df[dim1].nunique(), len(values)) from the provided data frame. Example, if dim0 is the column of session ID, dim1 is the column of alternative names, then out[t, i, k] is the feature values[k] of item i in session t. The returned tensor has shape (num_sessions, num_items, num_params), which fits the purpose of conditioanl logit models. \"\"\" if not isinstance ( values , list ): values = [ values ] dim1_list = sorted ( df [ dim1 ] . unique ()) tensor_slice = list () for value in values : layer = df . pivot ( index = dim0 , columns = dim1 , values = value ) tensor_slice . append ( torch . Tensor ( layer [ dim1_list ] . values )) tensor = torch . stack ( tensor_slice , dim =- 1 ) assert tensor . shape == ( df [ dim0 ] . nunique (), df [ dim1 ] . nunique (), len ( values )) return tensor model special coefficient The general class of learnable coefficients in various models, this class serves as the building blocks for models in this package. The weights (i.e., learnable parameters) in the Coefficient class are implemented using PyTorch and can be trained directly using optimizers from PyTorch. NOTE: torch-choice package users don't interact with classes in this file directly, please use conditional_logit_model.py and nested_logit_model.py instead. Author: Tianyu Du Update: Apr. 28, 2022 Coefficient ( Module ) Source code in torch_choice/model/coefficient.py class Coefficient ( nn . Module ): def __init__ ( self , variation : str , num_params : int , num_items : Optional [ int ] = None , num_users : Optional [ int ] = None ) -> None : \"\"\"A generic coefficient object storing trainable parameters. This class corresponds to those variables typically in Greek letters in the model's utility representation. Args: variation (str): the degree of variation of this coefficient. For example, the coefficient can vary by users or items. Currently, we support variations 'constant', 'item', 'item-full', 'user', 'user-item', 'user-item-full'. For detailed explanation of these variations, please refer to the documentation of ConditionalLogitModel. num_params (int): number of parameters in this coefficient. Note that this number is the number of parameters per class, not the total number of parameters. For example, suppose we have U users and you want to initiate an user-specific coefficient called `theta_user`. The coefficient enters the utility form while being multiplied with some K-dimension observables. Then, for each user, there are K parameters to be multiplied with the K-dimensional observable. However, the total number of parameters is K * U (K for each of U users). In this case, `num_params` should be set to `K`, NOT `K*U`. num_items (int): the number of items in the prediction problem, this is required to reshape the parameter correctly. num_users (Optional[int], optional): number of users, this is only necessary if the coefficient varies by users. Defaults to None. \"\"\" super ( Coefficient , self ) . __init__ () self . variation = variation self . num_items = num_items self . num_users = num_users self . num_params = num_params # construct the trainable. if self . variation == 'constant' : # constant for all users and items. self . coef = nn . Parameter ( torch . randn ( num_params ), requires_grad = True ) elif self . variation == 'item' : # coef depends on item j but not on user i. # force coefficients for the first item class to be zero. self . coef = nn . Parameter ( torch . zeros ( num_items - 1 , num_params ), requires_grad = True ) elif self . variation == 'item-full' : # coef depends on item j but not on user i. # model coefficient for every item. self . coef = nn . Parameter ( torch . zeros ( num_items , num_params ), requires_grad = True ) elif self . variation == 'user' : # coef depends on the user. # we always model coefficient for all users. self . coef = nn . Parameter ( torch . zeros ( num_users , num_params ), requires_grad = True ) elif self . variation == 'user-item' : # coefficients of the first item is forced to be zero, model coefficients for N - 1 items only. self . coef = nn . Parameter ( torch . zeros ( num_users , num_items - 1 , num_params ), requires_grad = True ) elif self . variation == 'user-item-full' : # construct coefficients for every items. self . coef = nn . Parameter ( torch . zeros ( num_users , num_items , num_params ), requires_grad = True ) else : raise ValueError ( f 'Unsupported type of variation: { self . variation } .' ) def __repr__ ( self ) -> str : \"\"\"Returns a string representation of the coefficient. Returns: str: the string representation of the coefficient. \"\"\" return f 'Coefficient(variation= { self . variation } , num_items= { self . num_items } ,' \\ + f ' num_users= { self . num_users } , num_params= { self . num_params } ,' \\ + f ' { self . coef . numel () } trainable parameters in total).' def forward ( self , x : torch . Tensor , user_index : Optional [ torch . Tensor ] = None , manual_coef_value : Optional [ torch . Tensor ] = None ) -> torch . Tensor : \"\"\" The forward function of the coefficient, which computes the utility from purchasing each item in each session. The output shape will be (num_sessions, num_items). Args: x (torch.Tensor): a tensor of shape (num_sessions, num_items, num_params). Please note that the Coefficient class will NOT reshape input tensors itself, this reshaping needs to be done in the model class. user_index (Optional[torch.Tensor], optional): a tensor of shape (num_sessions,) contain IDs of the user involved in that session. If set to None, assume the same user is making all decisions. Defaults to None. manual_coef_value (Optional[torch.Tensor], optional): a tensor with the same number of entries as self.coef. If provided, the forward function uses provided values as coefficient and return the predicted utility, this feature is useful when the researcher wishes to manually specify values for coefficients and examine prediction with specified coefficient values. If not provided, forward function is executed using values from self.coef. Defaults to None. Returns: torch.Tensor: a tensor of shape (num_sessions, num_items) whose (t, i) entry represents the utility of purchasing item i in session t. \"\"\" if manual_coef_value is not None : assert manual_coef_value . numel () == self . coef . numel () # plugin the provided coefficient values, coef is a tensor. coef = manual_coef_value . reshape ( * self . coef . shape ) else : # use the learned coefficient values, coef is a nn.Parameter. coef = self . coef num_trips , num_items , num_feats = x . shape assert self . num_params == num_feats # cast coefficient tensor to (num_trips, num_items, self.num_params). if self . variation == 'constant' : coef = coef . view ( 1 , 1 , self . num_params ) . expand ( num_trips , num_items , - 1 ) elif self . variation == 'item' : # coef has shape (num_items-1, num_params) # force coefficient for the first item to be zero. zeros = torch . zeros ( 1 , self . num_params ) . to ( coef . device ) coef = torch . cat (( zeros , coef ), dim = 0 ) # (num_items, num_params) coef = coef . view ( 1 , self . num_items , self . num_params ) . expand ( num_trips , - 1 , - 1 ) elif self . variation == 'item-full' : # coef has shape (num_items, num_params) coef = coef . view ( 1 , self . num_items , self . num_params ) . expand ( num_trips , - 1 , - 1 ) elif self . variation == 'user' : # coef has shape (num_users, num_params) coef = coef [ user_index , :] # (num_trips, num_params) user-specific coefficients. coef = coef . view ( num_trips , 1 , self . num_params ) . expand ( - 1 , num_items , - 1 ) elif self . variation == 'user-item' : # (num_trips,) long tensor of user ID. # originally, coef has shape (num_users, num_items-1, num_params) # transform to (num_trips, num_items - 1, num_params), user-specific. coef = coef [ user_index , :, :] # coefs for the first item for all users are enforced to 0. zeros = torch . zeros ( num_trips , 1 , self . num_params ) . to ( coef . device ) coef = torch . cat (( zeros , coef ), dim = 1 ) # (num_trips, num_items, num_params) elif self . variation == 'user-item-full' : # originally, coef has shape (num_users, num_items, num_params) coef = coef [ user_index , :, :] # (num_trips, num_items, num_params) else : raise ValueError ( f 'Unsupported type of variation: { self . variation } .' ) assert coef . shape == ( num_trips , num_items , num_feats ) == x . shape # compute the utility of each item in each trip, take summation along the feature dimension, the same as taking # the inner product. return ( x * coef ) . sum ( dim =- 1 ) __init__ ( self , variation , num_params , num_items = None , num_users = None ) special A generic coefficient object storing trainable parameters. This class corresponds to those variables typically in Greek letters in the model's utility representation. Parameters: Name Type Description Default variation str the degree of variation of this coefficient. For example, the coefficient can vary by users or items. Currently, we support variations 'constant', 'item', 'item-full', 'user', 'user-item', 'user-item-full'. For detailed explanation of these variations, please refer to the documentation of ConditionalLogitModel. required num_params int number of parameters in this coefficient. Note that this number is the number of parameters per class, not the total number of parameters. For example, suppose we have U users and you want to initiate an user-specific coefficient called theta_user . The coefficient enters the utility form while being multiplied with some K-dimension observables. Then, for each user, there are K parameters to be multiplied with the K-dimensional observable. However, the total number of parameters is K * U (K for each of U users). In this case, num_params should be set to K , NOT K*U . required num_items int the number of items in the prediction problem, this is required to reshape the parameter correctly. None num_users Optional[int] number of users, this is only necessary if the coefficient varies by users. Defaults to None. None Source code in torch_choice/model/coefficient.py def __init__ ( self , variation : str , num_params : int , num_items : Optional [ int ] = None , num_users : Optional [ int ] = None ) -> None : \"\"\"A generic coefficient object storing trainable parameters. This class corresponds to those variables typically in Greek letters in the model's utility representation. Args: variation (str): the degree of variation of this coefficient. For example, the coefficient can vary by users or items. Currently, we support variations 'constant', 'item', 'item-full', 'user', 'user-item', 'user-item-full'. For detailed explanation of these variations, please refer to the documentation of ConditionalLogitModel. num_params (int): number of parameters in this coefficient. Note that this number is the number of parameters per class, not the total number of parameters. For example, suppose we have U users and you want to initiate an user-specific coefficient called `theta_user`. The coefficient enters the utility form while being multiplied with some K-dimension observables. Then, for each user, there are K parameters to be multiplied with the K-dimensional observable. However, the total number of parameters is K * U (K for each of U users). In this case, `num_params` should be set to `K`, NOT `K*U`. num_items (int): the number of items in the prediction problem, this is required to reshape the parameter correctly. num_users (Optional[int], optional): number of users, this is only necessary if the coefficient varies by users. Defaults to None. \"\"\" super ( Coefficient , self ) . __init__ () self . variation = variation self . num_items = num_items self . num_users = num_users self . num_params = num_params # construct the trainable. if self . variation == 'constant' : # constant for all users and items. self . coef = nn . Parameter ( torch . randn ( num_params ), requires_grad = True ) elif self . variation == 'item' : # coef depends on item j but not on user i. # force coefficients for the first item class to be zero. self . coef = nn . Parameter ( torch . zeros ( num_items - 1 , num_params ), requires_grad = True ) elif self . variation == 'item-full' : # coef depends on item j but not on user i. # model coefficient for every item. self . coef = nn . Parameter ( torch . zeros ( num_items , num_params ), requires_grad = True ) elif self . variation == 'user' : # coef depends on the user. # we always model coefficient for all users. self . coef = nn . Parameter ( torch . zeros ( num_users , num_params ), requires_grad = True ) elif self . variation == 'user-item' : # coefficients of the first item is forced to be zero, model coefficients for N - 1 items only. self . coef = nn . Parameter ( torch . zeros ( num_users , num_items - 1 , num_params ), requires_grad = True ) elif self . variation == 'user-item-full' : # construct coefficients for every items. self . coef = nn . Parameter ( torch . zeros ( num_users , num_items , num_params ), requires_grad = True ) else : raise ValueError ( f 'Unsupported type of variation: { self . variation } .' ) __repr__ ( self ) special Returns a string representation of the coefficient. Returns: Type Description str the string representation of the coefficient. Source code in torch_choice/model/coefficient.py def __repr__ ( self ) -> str : \"\"\"Returns a string representation of the coefficient. Returns: str: the string representation of the coefficient. \"\"\" return f 'Coefficient(variation= { self . variation } , num_items= { self . num_items } ,' \\ + f ' num_users= { self . num_users } , num_params= { self . num_params } ,' \\ + f ' { self . coef . numel () } trainable parameters in total).' forward ( self , x , user_index = None , manual_coef_value = None ) The forward function of the coefficient, which computes the utility from purchasing each item in each session. The output shape will be (num_sessions, num_items). Parameters: Name Type Description Default x torch.Tensor a tensor of shape (num_sessions, num_items, num_params). Please note that the Coefficient class will NOT reshape input tensors itself, this reshaping needs to be done in the model class. required user_index Optional[torch.Tensor] a tensor of shape (num_sessions,) contain IDs of the user involved in that session. If set to None, assume the same user is making all decisions. Defaults to None. None manual_coef_value Optional[torch.Tensor] a tensor with the same number of entries as self.coef. If provided, the forward function uses provided values as coefficient and return the predicted utility, this feature is useful when the researcher wishes to manually specify values for coefficients and examine prediction with specified coefficient values. If not provided, forward function is executed using values from self.coef. Defaults to None. None Returns: Type Description torch.Tensor a tensor of shape (num_sessions, num_items) whose (t, i) entry represents the utility of purchasing item i in session t. Source code in torch_choice/model/coefficient.py def forward ( self , x : torch . Tensor , user_index : Optional [ torch . Tensor ] = None , manual_coef_value : Optional [ torch . Tensor ] = None ) -> torch . Tensor : \"\"\" The forward function of the coefficient, which computes the utility from purchasing each item in each session. The output shape will be (num_sessions, num_items). Args: x (torch.Tensor): a tensor of shape (num_sessions, num_items, num_params). Please note that the Coefficient class will NOT reshape input tensors itself, this reshaping needs to be done in the model class. user_index (Optional[torch.Tensor], optional): a tensor of shape (num_sessions,) contain IDs of the user involved in that session. If set to None, assume the same user is making all decisions. Defaults to None. manual_coef_value (Optional[torch.Tensor], optional): a tensor with the same number of entries as self.coef. If provided, the forward function uses provided values as coefficient and return the predicted utility, this feature is useful when the researcher wishes to manually specify values for coefficients and examine prediction with specified coefficient values. If not provided, forward function is executed using values from self.coef. Defaults to None. Returns: torch.Tensor: a tensor of shape (num_sessions, num_items) whose (t, i) entry represents the utility of purchasing item i in session t. \"\"\" if manual_coef_value is not None : assert manual_coef_value . numel () == self . coef . numel () # plugin the provided coefficient values, coef is a tensor. coef = manual_coef_value . reshape ( * self . coef . shape ) else : # use the learned coefficient values, coef is a nn.Parameter. coef = self . coef num_trips , num_items , num_feats = x . shape assert self . num_params == num_feats # cast coefficient tensor to (num_trips, num_items, self.num_params). if self . variation == 'constant' : coef = coef . view ( 1 , 1 , self . num_params ) . expand ( num_trips , num_items , - 1 ) elif self . variation == 'item' : # coef has shape (num_items-1, num_params) # force coefficient for the first item to be zero. zeros = torch . zeros ( 1 , self . num_params ) . to ( coef . device ) coef = torch . cat (( zeros , coef ), dim = 0 ) # (num_items, num_params) coef = coef . view ( 1 , self . num_items , self . num_params ) . expand ( num_trips , - 1 , - 1 ) elif self . variation == 'item-full' : # coef has shape (num_items, num_params) coef = coef . view ( 1 , self . num_items , self . num_params ) . expand ( num_trips , - 1 , - 1 ) elif self . variation == 'user' : # coef has shape (num_users, num_params) coef = coef [ user_index , :] # (num_trips, num_params) user-specific coefficients. coef = coef . view ( num_trips , 1 , self . num_params ) . expand ( - 1 , num_items , - 1 ) elif self . variation == 'user-item' : # (num_trips,) long tensor of user ID. # originally, coef has shape (num_users, num_items-1, num_params) # transform to (num_trips, num_items - 1, num_params), user-specific. coef = coef [ user_index , :, :] # coefs for the first item for all users are enforced to 0. zeros = torch . zeros ( num_trips , 1 , self . num_params ) . to ( coef . device ) coef = torch . cat (( zeros , coef ), dim = 1 ) # (num_trips, num_items, num_params) elif self . variation == 'user-item-full' : # originally, coef has shape (num_users, num_items, num_params) coef = coef [ user_index , :, :] # (num_trips, num_items, num_params) else : raise ValueError ( f 'Unsupported type of variation: { self . variation } .' ) assert coef . shape == ( num_trips , num_items , num_feats ) == x . shape # compute the utility of each item in each trip, take summation along the feature dimension, the same as taking # the inner product. return ( x * coef ) . sum ( dim =- 1 ) conditional_logit_model Conditional Logit Model. Author: Tianyu Du Date: Aug. 8, 2021 Update: Apr. 28, 2022 ConditionalLogitModel ( Module ) The more generalized version of conditional logit model, the model allows for research specific variable types(groups) and different levels of variations for coefficient. The model allows for the following levels for variable variations: !!! note \"unless the -full flag is specified (which means we want to explicitly model coefficients\" for all items), for all variation levels related to item (item specific and user-item specific), the model force coefficients for the first item to be zero. This design follows standard econometric practice. constant: constant over all users and items, user: user-specific parameters but constant across all items, item: item-specific parameters but constant across all users, parameters for the first item are forced to be zero. item-full: item-specific parameters but constant across all users, explicitly model for all items. user-item: parameters that are specific to both user and item, parameter for the first item for all users are forced to be zero. user-item-full: parameters that are specific to both user and item, explicitly model for all items. Source code in torch_choice/model/conditional_logit_model.py class ConditionalLogitModel ( nn . Module ): \"\"\"The more generalized version of conditional logit model, the model allows for research specific variable types(groups) and different levels of variations for coefficient. The model allows for the following levels for variable variations: NOTE: unless the `-full` flag is specified (which means we want to explicitly model coefficients for all items), for all variation levels related to item (item specific and user-item specific), the model force coefficients for the first item to be zero. This design follows standard econometric practice. - constant: constant over all users and items, - user: user-specific parameters but constant across all items, - item: item-specific parameters but constant across all users, parameters for the first item are forced to be zero. - item-full: item-specific parameters but constant across all users, explicitly model for all items. - user-item: parameters that are specific to both user and item, parameter for the first item for all users are forced to be zero. - user-item-full: parameters that are specific to both user and item, explicitly model for all items. \"\"\" def __init__ ( self , coef_variation_dict : Dict [ str , str ], num_param_dict : Dict [ str , int ], num_items : Optional [ int ] = None , num_users : Optional [ int ] = None ) -> None : \"\"\" Args: num_items (int): number of items in the dataset. num_users (int): number of users in the dataset. coef_variation_dict (Dict[str, str]): variable type to variation level dictionary. Keys of this dictionary should be variable names in the dataset (i.e., these starting with `price_`, `user_`, etc), or `intercept` if the researcher requires an intercept term. For each variable name X_var (e.g., `user_income`) or `intercept`, the corresponding dictionary key should be one of the following values, this value specifies the \"level of variation\" of the coefficient. - `constant`: the coefficient constant over all users and items: $X \\beta$. - `user`: user-specific parameters but constant across all items: $X \\beta_{u}$. - `item`: item-specific parameters but constant across all users, $X \\beta_{i}$. Note that the coefficients for the first item are forced to be zero following the standard practice in econometrics. - `item-full`: the same configuration as `item`, but does not force the coefficients of the first item to be zeros. The following configurations are supported by the package, but we don't recommend using them due to the large number of parameters. - `user-item`: parameters that are specific to both user and item, parameter for the first item for all users are forced to be zero. - `user-item-full`: parameters that are specific to both user and item, explicitly model for all items. num_param_dict (Dict[str, int]): variable type to number of parameters dictionary with keys exactly the same as the `coef_variation_dict`. Values of `num_param_dict` records numbers of features in each kind of variable. \"\"\" super ( ConditionalLogitModel , self ) . __init__ () assert coef_variation_dict . keys () == num_param_dict . keys () self . variable_types = list ( deepcopy ( num_param_dict ) . keys ()) self . coef_variation_dict = deepcopy ( coef_variation_dict ) self . num_param_dict = deepcopy ( num_param_dict ) self . num_items = num_items self . num_users = num_users # check number of parameters specified are all positive. for var_type , num_params in self . num_param_dict . items (): assert num_params > 0 , f 'num_params needs to be positive, got: { num_params } .' # infer the number of parameters for intercept if the researcher forgets. if 'intercept' in self . coef_variation_dict . keys () and 'intercept' not in self . num_param_dict . keys (): warnings . warn ( \"'intercept' key found in coef_variation_dict but not in num_param_dict, num_param_dict['intercept'] has been set to 1.\" ) self . num_param_dict [ 'intercept' ] = 1 # construct trainable parameters. coef_dict = dict () for var_type , variation in self . coef_variation_dict . items (): coef_dict [ var_type ] = Coefficient ( variation = variation , num_items = self . num_items , num_users = self . num_users , num_params = self . num_param_dict [ var_type ]) # A ModuleDict is required to properly register all trainable parameters. # self.parameter() will fail if a python dictionary is used instead. self . coef_dict = nn . ModuleDict ( coef_dict ) def __repr__ ( self ) -> str : \"\"\"Return a string representation of the model. Returns: str: the string representation of the model. \"\"\" out_str_lst = [ 'Conditional logistic discrete choice model, expects input features: \\n ' ] for var_type , num_params in self . num_param_dict . items (): out_str_lst . append ( f 'X[ { var_type } ] with { num_params } parameters, with { self . coef_variation_dict [ var_type ] } level variation.' ) return super () . __repr__ () + ' \\n ' + ' \\n ' . join ( out_str_lst ) @property def num_params ( self ) -> int : \"\"\"Get the total number of parameters. For example, if there is only an user-specific coefficient to be multiplied with the K-dimensional observable, then the total number of parameters would be K x number of users, assuming no intercept is involved. Returns: int: the total number of learnable parameters. \"\"\" return sum ( w . numel () for w in self . parameters ()) def summary ( self ): \"\"\"Print out the current model parameter.\"\"\" for var_type , coefficient in self . coef_dict . items (): if coefficient is not None : print ( 'Variable Type: ' , var_type ) print ( coefficient . coef ) def forward ( self , batch : ChoiceDataset , manual_coef_value_dict : Optional [ Dict [ str , torch . Tensor ]] = None ) -> torch . Tensor : \"\"\" Forward pass of the model. Args: batch: a `ChoiceDataset` object. manual_coef_value_dict (Optional[Dict[str, torch.Tensor]], optional): a dictionary with keys in {'u', 'i'} etc and tensors as values. If provided, the model will force coefficient to be the provided values and compute utility conditioned on the provided coefficient values. This feature is useful when the research wishes to plug in particular values of coefficients and examine the utility values. If not provided, the model will use the learned coefficient values in self.coef_dict. Defaults to None. Returns: torch.Tensor: a tensor of shape (num_trips, num_items) whose (t, i) entry represents the utility from item i in trip t for the user involved in that trip. \"\"\" x_dict = batch . x_dict if 'intercept' in self . coef_variation_dict . keys (): # intercept term has no input tensor, which has only 1 feature. x_dict [ 'intercept' ] = torch . ones (( len ( batch ), self . num_items , 1 ), device = batch . device ) # compute the utility from each item in each choice session. total_utility = torch . zeros (( len ( batch ), self . num_items ), device = batch . device ) # for each type of variables, apply the corresponding coefficient to input x. for var_type , coef in self . coef_dict . items (): total_utility += coef ( x_dict [ var_type ], batch . user_index , manual_coef_value = None if manual_coef_value_dict is None else manual_coef_value_dict [ var_type ]) assert total_utility . shape == ( len ( batch ), self . num_items ) if batch . item_availability is not None : # mask out unavilable items. total_utility [ ~ batch . item_availability [ batch . session_index , :]] = torch . finfo ( total_utility . dtype ) . min / 2 return total_utility def negative_log_likelihood ( self , batch : ChoiceDataset , y : torch . Tensor , is_train : bool = True ) -> torch . Tensor : \"\"\"Computes the log-likelihood for the batch and label. TODO: consider remove y, change to label. TODO: consider move this method outside the model, the role of the model is to compute the utility. Args: batch (ChoiceDataset): a ChoiceDataset object containing the data. y (torch.Tensor): the label. is_train (bool, optional): whether to trace the gradient. Defaults to True. Returns: torch.Tensor: the negative log-likelihood. \"\"\" if is_train : self . train () else : self . eval () # (num_trips, num_items) total_utility = self . forward ( batch ) logP = torch . log_softmax ( total_utility , dim = 1 ) nll = - logP [ torch . arange ( len ( y )), y ] . sum () return nll # NOTE: the method for computing Hessian and standard deviation has been moved to std.py. # @staticmethod # def flatten_coef_dict(coef_dict: Dict[str, Union[torch.Tensor, torch.nn.Parameter]]) -> Tuple[torch.Tensor, dict]: # \"\"\"Flattens the coef_dict into a 1-dimension tensor, used for hessian computation. # Args: # coef_dict (Dict[str, Union[torch.Tensor, torch.nn.Parameter]]): a dictionary holding learnable parameters. # Returns: # Tuple[torch.Tensor, dict]: 1. the flattened tensors with shape (num_params,), 2. an indexing dictionary # used for reconstructing the original coef_dict from the flatten tensor. # \"\"\" # type2idx = dict() # param_list = list() # start = 0 # for var_type in coef_dict.keys(): # num_params = coef_dict[var_type].coef.numel() # # track which portion of all_param tensor belongs to this variable type. # type2idx[var_type] = (start, start + num_params) # start += num_params # # use reshape instead of view to make a copy. # param_list.append(coef_dict[var_type].coef.clone().reshape(-1,)) # all_param = torch.cat(param_list) # (self.num_params(), ) # return all_param, type2idx # @staticmethod # def unwrap_coef_dict(param: torch.Tensor, type2idx: Dict[str, Tuple[int, int]]) -> Dict[str, torch.Tensor]: # \"\"\"Rebuilds coef_dict from output of self.flatten_coef_dict method. # Args: # param (torch.Tensor): the flattened coef_dict from self.flatten_coef_dict. # type2idx (Dict[str, Tuple[int, int]]): the indexing dictionary from self.flatten_coef_dict. # Returns: # Dict[str, torch.Tensor]: the re-constructed coefficient dictionary. # \"\"\" # coef_dict = dict() # for var_type in type2idx.keys(): # start, end = type2idx[var_type] # # no need to reshape here, Coefficient handles it. # coef_dict[var_type] = param[start:end] # return coef_dict # def compute_hessian(self, x_dict, availability, user_index, y) -> torch.Tensor: # \"\"\"Computes the Hessian of negative log-likelihood (total cross-entropy loss) with respect # to all parameters in this model. The Hessian can be later used for constructing the standard deviation of # parameters. # Args: # x_dict ,availability, user_index: see definitions in self.forward method. # y (torch.LongTensor): a tensor with shape (num_trips,) of IDs of items actually purchased. # Returns: # torch.Tensor: a (self.num_params, self.num_params) tensor of the Hessian matrix. # \"\"\" # all_coefs, type2idx = self.flatten_coef_dict(self.coef_dict) # def compute_nll(P: torch.Tensor) -> float: # coef_dict = self.unwrap_coef_dict(P, type2idx) # y_pred = self._forward(x_dict=x_dict, # availability=availability, # user_index=user_index, # manual_coef_value_dict=coef_dict) # # the reduction needs to be 'sum' to obtain NLL. # loss = F.cross_entropy(y_pred, y, reduction='sum') # return loss # H = torch.autograd.functional.hessian(compute_nll, all_coefs) # assert H.shape == (self.num_params, self.num_params) # return H # def compute_std(self, x_dict, availability, user_index, y) -> Dict[str, torch.Tensor]: # \"\"\"Computes # Args:f # See definitions in self.compute_hessian. # Returns: # Dict[str, torch.Tensor]: a dictionary whose keys are the same as self.coef_dict.keys() # the values are standard errors of coefficients in each coefficient group. # \"\"\" # _, type2idx = self.flatten_coef_dict(self.coef_dict) # H = self.compute_hessian(x_dict, availability, user_index, y) # std_all = torch.sqrt(torch.diag(torch.inverse(H))) # std_dict = dict() # for var_type in type2idx.keys(): # # get std of variables belonging to each type. # start, end = type2idx[var_type] # std_dict[var_type] = std_all[start:end] # return std_dict num_params : int property readonly Get the total number of parameters. For example, if there is only an user-specific coefficient to be multiplied with the K-dimensional observable, then the total number of parameters would be K x number of users, assuming no intercept is involved. Returns: Type Description int the total number of learnable parameters. __init__ ( self , coef_variation_dict , num_param_dict , num_items = None , num_users = None ) special Parameters: Name Type Description Default num_items int number of items in the dataset. None num_users int number of users in the dataset. None coef_variation_dict Dict[str, str] variable type to variation level dictionary. Keys of this dictionary should be variable names in the dataset (i.e., these starting with price_ , user_ , etc), or intercept if the researcher requires an intercept term. For each variable name X_var (e.g., user_income ) or intercept , the corresponding dictionary key should be one of the following values, this value specifies the \"level of variation\" of the coefficient. constant : the coefficient constant over all users and items: \\(X \beta\\) . user : user-specific parameters but constant across all items: \\(X \beta_{u}\\) . item : item-specific parameters but constant across all users, \\(X \beta_{i}\\) . Note that the coefficients for the first item are forced to be zero following the standard practice in econometrics. item-full : the same configuration as item , but does not force the coefficients of the first item to be zeros. The following configurations are supported by the package, but we don't recommend using them due to the large number of parameters. - user-item : parameters that are specific to both user and item, parameter for the first item for all users are forced to be zero. user-item-full : parameters that are specific to both user and item, explicitly model for all items. required num_param_dict Dict[str, int] variable type to number of parameters dictionary with keys exactly the same as the coef_variation_dict . Values of num_param_dict records numbers of features in each kind of variable. required Source code in torch_choice/model/conditional_logit_model.py def __init__ ( self , coef_variation_dict : Dict [ str , str ], num_param_dict : Dict [ str , int ], num_items : Optional [ int ] = None , num_users : Optional [ int ] = None ) -> None : \"\"\" Args: num_items (int): number of items in the dataset. num_users (int): number of users in the dataset. coef_variation_dict (Dict[str, str]): variable type to variation level dictionary. Keys of this dictionary should be variable names in the dataset (i.e., these starting with `price_`, `user_`, etc), or `intercept` if the researcher requires an intercept term. For each variable name X_var (e.g., `user_income`) or `intercept`, the corresponding dictionary key should be one of the following values, this value specifies the \"level of variation\" of the coefficient. - `constant`: the coefficient constant over all users and items: $X \\beta$. - `user`: user-specific parameters but constant across all items: $X \\beta_{u}$. - `item`: item-specific parameters but constant across all users, $X \\beta_{i}$. Note that the coefficients for the first item are forced to be zero following the standard practice in econometrics. - `item-full`: the same configuration as `item`, but does not force the coefficients of the first item to be zeros. The following configurations are supported by the package, but we don't recommend using them due to the large number of parameters. - `user-item`: parameters that are specific to both user and item, parameter for the first item for all users are forced to be zero. - `user-item-full`: parameters that are specific to both user and item, explicitly model for all items. num_param_dict (Dict[str, int]): variable type to number of parameters dictionary with keys exactly the same as the `coef_variation_dict`. Values of `num_param_dict` records numbers of features in each kind of variable. \"\"\" super ( ConditionalLogitModel , self ) . __init__ () assert coef_variation_dict . keys () == num_param_dict . keys () self . variable_types = list ( deepcopy ( num_param_dict ) . keys ()) self . coef_variation_dict = deepcopy ( coef_variation_dict ) self . num_param_dict = deepcopy ( num_param_dict ) self . num_items = num_items self . num_users = num_users # check number of parameters specified are all positive. for var_type , num_params in self . num_param_dict . items (): assert num_params > 0 , f 'num_params needs to be positive, got: { num_params } .' # infer the number of parameters for intercept if the researcher forgets. if 'intercept' in self . coef_variation_dict . keys () and 'intercept' not in self . num_param_dict . keys (): warnings . warn ( \"'intercept' key found in coef_variation_dict but not in num_param_dict, num_param_dict['intercept'] has been set to 1.\" ) self . num_param_dict [ 'intercept' ] = 1 # construct trainable parameters. coef_dict = dict () for var_type , variation in self . coef_variation_dict . items (): coef_dict [ var_type ] = Coefficient ( variation = variation , num_items = self . num_items , num_users = self . num_users , num_params = self . num_param_dict [ var_type ]) # A ModuleDict is required to properly register all trainable parameters. # self.parameter() will fail if a python dictionary is used instead. self . coef_dict = nn . ModuleDict ( coef_dict ) __repr__ ( self ) special Return a string representation of the model. Returns: Type Description str the string representation of the model. Source code in torch_choice/model/conditional_logit_model.py def __repr__ ( self ) -> str : \"\"\"Return a string representation of the model. Returns: str: the string representation of the model. \"\"\" out_str_lst = [ 'Conditional logistic discrete choice model, expects input features: \\n ' ] for var_type , num_params in self . num_param_dict . items (): out_str_lst . append ( f 'X[ { var_type } ] with { num_params } parameters, with { self . coef_variation_dict [ var_type ] } level variation.' ) return super () . __repr__ () + ' \\n ' + ' \\n ' . join ( out_str_lst ) forward ( self , batch , manual_coef_value_dict = None ) Forward pass of the model. Parameters: Name Type Description Default batch ChoiceDataset a ChoiceDataset object. required manual_coef_value_dict Optional[Dict[str, torch.Tensor]] a dictionary with keys in {'u', 'i'} etc and tensors as values. If provided, the model will force coefficient to be the provided values and compute utility conditioned on the provided coefficient values. This feature is useful when the research wishes to plug in particular values of coefficients and examine the utility values. If not provided, the model will use the learned coefficient values in self.coef_dict. Defaults to None. None Returns: Type Description torch.Tensor a tensor of shape (num_trips, num_items) whose (t, i) entry represents the utility from item i in trip t for the user involved in that trip. Source code in torch_choice/model/conditional_logit_model.py def forward ( self , batch : ChoiceDataset , manual_coef_value_dict : Optional [ Dict [ str , torch . Tensor ]] = None ) -> torch . Tensor : \"\"\" Forward pass of the model. Args: batch: a `ChoiceDataset` object. manual_coef_value_dict (Optional[Dict[str, torch.Tensor]], optional): a dictionary with keys in {'u', 'i'} etc and tensors as values. If provided, the model will force coefficient to be the provided values and compute utility conditioned on the provided coefficient values. This feature is useful when the research wishes to plug in particular values of coefficients and examine the utility values. If not provided, the model will use the learned coefficient values in self.coef_dict. Defaults to None. Returns: torch.Tensor: a tensor of shape (num_trips, num_items) whose (t, i) entry represents the utility from item i in trip t for the user involved in that trip. \"\"\" x_dict = batch . x_dict if 'intercept' in self . coef_variation_dict . keys (): # intercept term has no input tensor, which has only 1 feature. x_dict [ 'intercept' ] = torch . ones (( len ( batch ), self . num_items , 1 ), device = batch . device ) # compute the utility from each item in each choice session. total_utility = torch . zeros (( len ( batch ), self . num_items ), device = batch . device ) # for each type of variables, apply the corresponding coefficient to input x. for var_type , coef in self . coef_dict . items (): total_utility += coef ( x_dict [ var_type ], batch . user_index , manual_coef_value = None if manual_coef_value_dict is None else manual_coef_value_dict [ var_type ]) assert total_utility . shape == ( len ( batch ), self . num_items ) if batch . item_availability is not None : # mask out unavilable items. total_utility [ ~ batch . item_availability [ batch . session_index , :]] = torch . finfo ( total_utility . dtype ) . min / 2 return total_utility negative_log_likelihood ( self , batch , y , is_train = True ) Computes the log-likelihood for the batch and label. TODO: consider remove y, change to label. TODO: consider move this method outside the model, the role of the model is to compute the utility. Parameters: Name Type Description Default batch ChoiceDataset a ChoiceDataset object containing the data. required y torch.Tensor the label. required is_train bool whether to trace the gradient. Defaults to True. True Returns: Type Description torch.Tensor the negative log-likelihood. Source code in torch_choice/model/conditional_logit_model.py def negative_log_likelihood ( self , batch : ChoiceDataset , y : torch . Tensor , is_train : bool = True ) -> torch . Tensor : \"\"\"Computes the log-likelihood for the batch and label. TODO: consider remove y, change to label. TODO: consider move this method outside the model, the role of the model is to compute the utility. Args: batch (ChoiceDataset): a ChoiceDataset object containing the data. y (torch.Tensor): the label. is_train (bool, optional): whether to trace the gradient. Defaults to True. Returns: torch.Tensor: the negative log-likelihood. \"\"\" if is_train : self . train () else : self . eval () # (num_trips, num_items) total_utility = self . forward ( batch ) logP = torch . log_softmax ( total_utility , dim = 1 ) nll = - logP [ torch . arange ( len ( y )), y ] . sum () return nll summary ( self ) Print out the current model parameter. Source code in torch_choice/model/conditional_logit_model.py def summary ( self ): \"\"\"Print out the current model parameter.\"\"\" for var_type , coefficient in self . coef_dict . items (): if coefficient is not None : print ( 'Variable Type: ' , var_type ) print ( coefficient . coef ) nested_logit_model Implementation of the nested logit model, see page 86 of the book \"discrete choice methods with simulation\" by Train. for more details. Author: Tianyu Du Update; Apr. 28, 2022 NestedLogitModel ( Module ) Source code in torch_choice/model/nested_logit_model.py class NestedLogitModel ( nn . Module ): def __init__ ( self , category_to_item : Dict [ object , List [ int ]], category_coef_variation_dict : Dict [ str , str ], category_num_param_dict : Dict [ str , int ], item_coef_variation_dict : Dict [ str , str ], item_num_param_dict : Dict [ str , int ], num_users : Optional [ int ] = None , shared_lambda : bool = False ) -> None : \"\"\"Initialization method of the nested logit model. Args: category_to_item (Dict[object, List[int]]): a dictionary maps a category ID to a list of items IDs of the queried category. category_coef_variation_dict (Dict[str, str]): a dictionary maps a variable type (i.e., variable group) to the level of variation for the coefficient of this type of variables. category_num_param_dict (Dict[str, int]): a dictionary maps a variable type name to the number of parameters in this variable group. item_coef_variation_dict (Dict[str, str]): the same as category_coef_variation_dict but for item features. item_num_param_dict (Dict[str, int]): the same as category_num_param_dict but for item features. num_users (Optional[int], optional): number of users to be modelled, this is only required if any of variable type requires user-specific variations. Defaults to None. shared_lambda (bool): a boolean indicating whether to enforce the elasticity lambda, which is the coefficient for inclusive values, to be constant for all categories. The lambda enters the category-level selection as the following Utility of choosing category k = lambda * inclusive value of category k + linear combination of some other category level features If set to True, a single lambda will be learned for all categories, otherwise, the model learns an individual lambda for each category. Defaults to False. \"\"\" super ( NestedLogitModel , self ) . __init__ () self . category_to_item = category_to_item self . category_coef_variation_dict = category_coef_variation_dict self . category_num_param_dict = category_num_param_dict self . item_coef_variation_dict = item_coef_variation_dict self . item_num_param_dict = item_num_param_dict self . num_users = num_users self . categories = list ( category_to_item . keys ()) self . num_categories = len ( self . categories ) self . num_items = sum ( len ( items ) for items in category_to_item . values ()) # category coefficients. self . category_coef_dict = self . _build_coef_dict ( self . category_coef_variation_dict , self . category_num_param_dict , self . num_categories ) # item coefficients. self . item_coef_dict = self . _build_coef_dict ( self . item_coef_variation_dict , self . item_num_param_dict , self . num_items ) self . shared_lambda = shared_lambda if self . shared_lambda : self . lambda_weight = nn . Parameter ( torch . ones ( 1 ), requires_grad = True ) else : self . lambda_weight = nn . Parameter ( torch . ones ( self . num_categories ) / 2 , requires_grad = True ) # breakpoint() # self.iv_weights = nn.Parameter(torch.ones(1), requires_grad=True) # used to warn users if forgot to call clamp. self . _clamp_called_flag = True @property def num_params ( self ) -> int : \"\"\"Get the total number of parameters. For example, if there is only an user-specific coefficient to be multiplied with the K-dimensional observable, then the total number of parameters would be K x number of users, assuming no intercept is involved. Returns: int: the total number of learnable parameters. \"\"\" return sum ( w . numel () for w in self . parameters ()) def _build_coef_dict ( self , coef_variation_dict : Dict [ str , str ], num_param_dict : Dict [ str , int ], num_items : int ) -> nn . ModuleDict : \"\"\"Builds a coefficient dictionary containing all trainable components of the model, mapping coefficient names to the corresponding Coefficient Module. num_items could be the actual number of items or the number of categories depends on the use case. NOTE: torch-choice users don't directly interact with this method. Args: coef_variation_dict (Dict[str, str]): a dictionary mapping coefficient names (e.g., theta_user) to the level of variation (e.g., 'user'). num_param_dict (Dict[str, int]): a dictionary mapping coefficient names to the number of parameters in this coefficient. Be aware that, for example, if there is one K-dimensional coefficient for every user, then the `num_param` should be K instead of K x number of users. num_items (int): the total number of items in the prediction problem. `num_items` should be the number of categories if _build_coef_dict() is used for category-level prediction. Returns: nn.ModuleDict: a PyTorch ModuleDict object mapping from coefficient names to training Coefficient. \"\"\" coef_dict = dict () for var_type , variation in coef_variation_dict . items (): num_params = num_param_dict [ var_type ] coef_dict [ var_type ] = Coefficient ( variation = variation , num_items = num_items , num_users = self . num_users , num_params = num_params ) return nn . ModuleDict ( coef_dict ) # def _check_input_shapes(self, category_x_dict, item_x_dict, user_index, item_availability) -> None: # T = list(category_x_dict.values())[0].shape[0] # batch size. # for var_type, x_category in category_x_dict.items(): # x_item = item_x_dict[var_type] # assert len(x_item.shape) == len(x_item.shape) == 3 # assert x_category.shape[0] == x_item.shape[0] # assert x_category.shape == (T, self.num_categories, self.category_num_param_dict[var_type]) # assert x_item.shape == (T, self.num_items, self.item_num_param_dict[var_type]) # if (user_index is not None) and (self.num_users is not None): # assert user_index.shape == (T,) # if item_availability is not None: # assert item_availability.shape == (T, self.num_items) def forward ( self , batch : ChoiceDataset ) -> torch . Tensor : \"\"\"An standard forward method for the model, the user feeds a ChoiceDataset batch and the model returns the predicted log-likelihood tensor. The main forward passing happens in the _forward() method, but we provide this wrapper forward() method for a cleaner API, as forward() only requires a single batch argument. For more details about the forward passing, please refer to the _forward() method. # TODO: the ConditionaLogitModel returns predicted utility, the NestedLogitModel behaves the same? Args: batch (ChoiceDataset): a ChoiceDataset object containing the data batch. Returns: torch.Tensor: a tensor of shape (num_trips, num_items) including the log probability of choosing item i in trip t. \"\"\" return self . _forward ( batch [ 'category' ] . x_dict , batch [ 'item' ] . x_dict , batch [ 'item' ] . user_index , batch [ 'item' ] . item_availability ) def _forward ( self , category_x_dict : Dict [ str , torch . Tensor ], item_x_dict : Dict [ str , torch . Tensor ], user_index : Optional [ torch . LongTensor ] = None , item_availability : Optional [ torch . BoolTensor ] = None ) -> torch . Tensor : \"\"\"\"Computes log P[t, i] = the log probability for the user involved in trip t to choose item i. Let n denote the ID of the user involved in trip t, then P[t, i] = P_{ni} on page 86 of the book \"discrete choice methods with simulation\" by Train. Args: x_category (torch.Tensor): a tensor with shape (num_trips, num_categories, *) including features of all categories in each trip. x_item (torch.Tensor): a tensor with shape (num_trips, num_items, *) including features of all items in each trip. user_index (torch.LongTensor): a tensor of shape (num_trips,) indicating which user is making decision in each trip. Setting user_index = None assumes the same user is making decisions in all trips. item_availability (torch.BoolTensor): a boolean tensor with shape (num_trips, num_items) indicating the aviliability of items in each trip. If item_availability[t, i] = False, the utility of choosing item i in trip t, V[t, i], will be set to -inf. Given the decomposition V[t, i] = W[t, k(i)] + Y[t, i] + eps, V[t, i] is set to -inf by setting Y[t, i] = -inf for unavilable items. Returns: torch.Tensor: a tensor of shape (num_trips, num_items) including the log probability of choosing item i in trip t. \"\"\" if self . shared_lambda : self . lambdas = self . lambda_weight . expand ( self . num_categories ) else : self . lambdas = self . lambda_weight # if not self._clamp_called_flag: # warnings.warn('Did you forget to call clamp_lambdas() after optimizer.step()?') # The overall utility of item can be decomposed into V[item] = W[category] + Y[item] + eps. T = list ( item_x_dict . values ())[ 0 ] . shape [ 0 ] device = list ( item_x_dict . values ())[ 0 ] . device # compute category-specific utility with shape (T, num_categories). W = torch . zeros ( T , self . num_categories ) . to ( device ) if 'intercept' in self . category_coef_variation_dict . keys (): category_x_dict [ 'intercept' ] = torch . ones (( T , self . num_categories , 1 )) . to ( device ) for var_type , coef in self . category_coef_dict . items (): W += coef ( category_x_dict [ var_type ], user_index ) # compute item-specific utility (T, num_items). Y = torch . zeros ( T , self . num_items ) . to ( device ) for var_type , coef in self . item_coef_dict . items (): Y += coef ( item_x_dict [ var_type ], user_index ) if item_availability is not None : Y [ ~ item_availability ] = torch . finfo ( Y . dtype ) . min / 2 # ============================================================================= # compute the inclusive value of each category. inclusive_value = dict () for k , Bk in self . category_to_item . items (): # for nest k, divide the Y of all items in Bk by lambda_k. Y [:, Bk ] /= self . lambdas [ k ] # compute inclusive value for category k. # mask out unavilable items. inclusive_value [ k ] = torch . logsumexp ( Y [:, Bk ], dim = 1 , keepdim = False ) # (T,) # boardcast inclusive value from (T, num_categories) to (T, num_items). # for trip t, I[t, i] is the inclusive value of the category item i belongs to. I = torch . zeros ( T , self . num_items ) . to ( device ) for k , Bk in self . category_to_item . items (): I [:, Bk ] = inclusive_value [ k ] . view ( - 1 , 1 ) # (T, |Bk|) # logP_item[t, i] = log P(ni|Bk), where Bk is the category item i is in, n is the user in trip t. logP_item = Y - I # (T, num_items) # ============================================================================= # logP_category[t, i] = log P(Bk), for item i in trip t, the probability of choosing the nest/bucket # item i belongs to. logP_category has shape (T, num_items) # logit[t, i] = W[n, k] + lambda[k] I[n, k], where n is the user involved in trip t, k is # the category item i belongs to. logit = torch . zeros ( T , self . num_items ) . to ( device ) for k , Bk in self . category_to_item . items (): logit [:, Bk ] = ( W [:, k ] + self . lambdas [ k ] * inclusive_value [ k ]) . view ( - 1 , 1 ) # (T, |Bk|) # only count each category once in the logsumexp within the category level model. cols = [ x [ 0 ] for x in self . category_to_item . values ()] logP_category = logit - torch . logsumexp ( logit [:, cols ], dim = 1 , keepdim = True ) # ============================================================================= # compute the joint log P_{ni} as in the textbook. logP = logP_item + logP_category self . _clamp_called_flag = False return logP def log_likelihood ( self , * args ): \"\"\"Computes the log likelihood of the model, please refer to the negative_log_likelihood() method. Returns: _type_: the log likelihood of the model. \"\"\" return - self . negative_log_likelihood ( * args ) def negative_log_likelihood ( self , batch : ChoiceDataset , y : torch . LongTensor , is_train : bool = True ) -> torch . scalar_tensor : \"\"\"Computes the negative log likelihood of the model. Please note the log-likelihood is summed over all samples in batch instead of the average. Args: batch (ChoiceDataset): the ChoiceDataset object containing the data. y (torch.LongTensor): the label. is_train (bool, optional): which mode of the model to be used for the forward passing, if we need Hessian of the NLL through auto-grad, `is_train` should be set to True. If we merely need a performance metric, then `is_train` can be set to False for better performance. Defaults to True. Returns: torch.scalar_tensor: the negative log likelihood of the model. \"\"\" # compute the negative log-likelihood loss directly. if is_train : self . train () else : self . eval () # (num_trips, num_items) logP = self . forward ( batch ) nll = - logP [ torch . arange ( len ( y )), y ] . sum () return nll # def clamp_lambdas(self): # \"\"\" # Restrict values of lambdas to 0 < lambda <= 1 to guarantee the utility maximization property # of the model. # This method should be called everytime after optimizer.step(). # We add a self_clamp_called_flag to remind researchers if this method is not called. # \"\"\" # for k in range(len(self.lambdas)): # self.lambdas[k] = torch.clamp(self.lambdas[k], 1e-5, 1) # self._clam_called_flag = True # @staticmethod # def add_constant(x: torch.Tensor, where: str='prepend') -> torch.Tensor: # \"\"\"A helper function used to add constant to feature tensor, # x has shape (batch_size, num_classes, num_parameters), # returns a tensor of shape (*, num_parameters+1). # \"\"\" # batch_size, num_classes, num_parameters = x.shape # ones = torch.ones((batch_size, num_classes, 1)) # if where == 'prepend': # new = torch.cat((ones, x), dim=-1) # elif where == 'append': # new = torch.cat((x, ones), dim=-1) # else: # raise Exception # return new num_params : int property readonly Get the total number of parameters. For example, if there is only an user-specific coefficient to be multiplied with the K-dimensional observable, then the total number of parameters would be K x number of users, assuming no intercept is involved. Returns: Type Description int the total number of learnable parameters. __init__ ( self , category_to_item , category_coef_variation_dict , category_num_param_dict , item_coef_variation_dict , item_num_param_dict , num_users = None , shared_lambda = False ) special Initialization method of the nested logit model. Parameters: Name Type Description Default category_to_item Dict[object, List[int]] a dictionary maps a category ID to a list of items IDs of the queried category. required category_coef_variation_dict Dict[str, str] a dictionary maps a variable type (i.e., variable group) to the level of variation for the coefficient of this type of variables. required category_num_param_dict Dict[str, int] a dictionary maps a variable type name to the number of parameters in this variable group. required item_coef_variation_dict Dict[str, str] the same as category_coef_variation_dict but for item features. required item_num_param_dict Dict[str, int] the same as category_num_param_dict but for item features. required num_users Optional[int] number of users to be modelled, this is only required if any of variable type requires user-specific variations. Defaults to None. None shared_lambda bool a boolean indicating whether to enforce the elasticity lambda, which is the coefficient for inclusive values, to be constant for all categories. The lambda enters the category-level selection as the following Utility of choosing category k = lambda * inclusive value of category k + linear combination of some other category level features If set to True, a single lambda will be learned for all categories, otherwise, the model learns an individual lambda for each category. Defaults to False. False Source code in torch_choice/model/nested_logit_model.py def __init__ ( self , category_to_item : Dict [ object , List [ int ]], category_coef_variation_dict : Dict [ str , str ], category_num_param_dict : Dict [ str , int ], item_coef_variation_dict : Dict [ str , str ], item_num_param_dict : Dict [ str , int ], num_users : Optional [ int ] = None , shared_lambda : bool = False ) -> None : \"\"\"Initialization method of the nested logit model. Args: category_to_item (Dict[object, List[int]]): a dictionary maps a category ID to a list of items IDs of the queried category. category_coef_variation_dict (Dict[str, str]): a dictionary maps a variable type (i.e., variable group) to the level of variation for the coefficient of this type of variables. category_num_param_dict (Dict[str, int]): a dictionary maps a variable type name to the number of parameters in this variable group. item_coef_variation_dict (Dict[str, str]): the same as category_coef_variation_dict but for item features. item_num_param_dict (Dict[str, int]): the same as category_num_param_dict but for item features. num_users (Optional[int], optional): number of users to be modelled, this is only required if any of variable type requires user-specific variations. Defaults to None. shared_lambda (bool): a boolean indicating whether to enforce the elasticity lambda, which is the coefficient for inclusive values, to be constant for all categories. The lambda enters the category-level selection as the following Utility of choosing category k = lambda * inclusive value of category k + linear combination of some other category level features If set to True, a single lambda will be learned for all categories, otherwise, the model learns an individual lambda for each category. Defaults to False. \"\"\" super ( NestedLogitModel , self ) . __init__ () self . category_to_item = category_to_item self . category_coef_variation_dict = category_coef_variation_dict self . category_num_param_dict = category_num_param_dict self . item_coef_variation_dict = item_coef_variation_dict self . item_num_param_dict = item_num_param_dict self . num_users = num_users self . categories = list ( category_to_item . keys ()) self . num_categories = len ( self . categories ) self . num_items = sum ( len ( items ) for items in category_to_item . values ()) # category coefficients. self . category_coef_dict = self . _build_coef_dict ( self . category_coef_variation_dict , self . category_num_param_dict , self . num_categories ) # item coefficients. self . item_coef_dict = self . _build_coef_dict ( self . item_coef_variation_dict , self . item_num_param_dict , self . num_items ) self . shared_lambda = shared_lambda if self . shared_lambda : self . lambda_weight = nn . Parameter ( torch . ones ( 1 ), requires_grad = True ) else : self . lambda_weight = nn . Parameter ( torch . ones ( self . num_categories ) / 2 , requires_grad = True ) # breakpoint() # self.iv_weights = nn.Parameter(torch.ones(1), requires_grad=True) # used to warn users if forgot to call clamp. self . _clamp_called_flag = True forward ( self , batch ) An standard forward method for the model, the user feeds a ChoiceDataset batch and the model returns the predicted log-likelihood tensor. The main forward passing happens in the _forward() method, but we provide this wrapper forward() method for a cleaner API, as forward() only requires a single batch argument. For more details about the forward passing, please refer to the _forward() method. TODO: the ConditionaLogitModel returns predicted utility, the NestedLogitModel behaves the same? Parameters: Name Type Description Default batch ChoiceDataset a ChoiceDataset object containing the data batch. required Returns: Type Description torch.Tensor a tensor of shape (num_trips, num_items) including the log probability of choosing item i in trip t. Source code in torch_choice/model/nested_logit_model.py def forward ( self , batch : ChoiceDataset ) -> torch . Tensor : \"\"\"An standard forward method for the model, the user feeds a ChoiceDataset batch and the model returns the predicted log-likelihood tensor. The main forward passing happens in the _forward() method, but we provide this wrapper forward() method for a cleaner API, as forward() only requires a single batch argument. For more details about the forward passing, please refer to the _forward() method. # TODO: the ConditionaLogitModel returns predicted utility, the NestedLogitModel behaves the same? Args: batch (ChoiceDataset): a ChoiceDataset object containing the data batch. Returns: torch.Tensor: a tensor of shape (num_trips, num_items) including the log probability of choosing item i in trip t. \"\"\" return self . _forward ( batch [ 'category' ] . x_dict , batch [ 'item' ] . x_dict , batch [ 'item' ] . user_index , batch [ 'item' ] . item_availability ) log_likelihood ( self , * args ) Computes the log likelihood of the model, please refer to the negative_log_likelihood() method. Returns: Type Description _type_ the log likelihood of the model. Source code in torch_choice/model/nested_logit_model.py def log_likelihood ( self , * args ): \"\"\"Computes the log likelihood of the model, please refer to the negative_log_likelihood() method. Returns: _type_: the log likelihood of the model. \"\"\" return - self . negative_log_likelihood ( * args ) negative_log_likelihood ( self , batch , y , is_train = True ) Computes the negative log likelihood of the model. Please note the log-likelihood is summed over all samples in batch instead of the average. Parameters: Name Type Description Default batch ChoiceDataset the ChoiceDataset object containing the data. required y torch.LongTensor the label. required is_train bool which mode of the model to be used for the forward passing, if we need Hessian of the NLL through auto-grad, is_train should be set to True. If we merely need a performance metric, then is_train can be set to False for better performance. Defaults to True. True Returns: Type Description torch.scalar_tensor the negative log likelihood of the model. Source code in torch_choice/model/nested_logit_model.py def negative_log_likelihood ( self , batch : ChoiceDataset , y : torch . LongTensor , is_train : bool = True ) -> torch . scalar_tensor : \"\"\"Computes the negative log likelihood of the model. Please note the log-likelihood is summed over all samples in batch instead of the average. Args: batch (ChoiceDataset): the ChoiceDataset object containing the data. y (torch.LongTensor): the label. is_train (bool, optional): which mode of the model to be used for the forward passing, if we need Hessian of the NLL through auto-grad, `is_train` should be set to True. If we merely need a performance metric, then `is_train` can be set to False for better performance. Defaults to True. Returns: torch.scalar_tensor: the negative log likelihood of the model. \"\"\" # compute the negative log-likelihood loss directly. if is_train : self . train () else : self . eval () # (num_trips, num_items) logP = self . forward ( batch ) nll = - logP [ torch . arange ( len ( y )), y ] . sum () return nll","title":"API Reference Torch-Choice"},{"location":"api_torch_choice/#api-reference-torch-choice","text":"","title":"API Reference: Torch Choice"},{"location":"api_torch_choice/#torch_choice.data","text":"","title":"data"},{"location":"api_torch_choice/#torch_choice.data.choice_dataset","text":"The dataset object for management large scale consumer choice datasets. Please refer to the documentation and tutorials for more details on using ChoiceDataset . Author: Tianyu Du Update: Apr. 27, 2022","title":"choice_dataset"},{"location":"api_torch_choice/#torch_choice.data.choice_dataset.ChoiceDataset","text":"Source code in torch_choice/data/choice_dataset.py class ChoiceDataset ( torch . utils . data . Dataset ): def __init__ ( self , item_index : torch . LongTensor , label : Optional [ torch . LongTensor ] = None , user_index : Optional [ torch . LongTensor ] = None , session_index : Optional [ torch . LongTensor ] = None , item_availability : Optional [ torch . BoolTensor ] = None , ** kwargs ) -> None : \"\"\" Initialization methods for the dataset object, researchers should supply all information about the dataset using this initialization method. The number of choice instances are called `batch_size` in the documentation. The `batch_size` corresponds to the file length in wide-format dataset, and often denoted using `N`. We call it `batch_size` to follow the convention in machine learning literature. A `choice instance` is a row of the dataset, so there are `batch_size` choice instances in each `ChoiceDataset`. The dataset consists of: (1) a collection of `batch_size` tuples (item_id, user_id, session_id, label), where each tuple is a choice instance. (2) a collection of `observables` associated with item, user, session, etc. Args: item_index (torch.LongTensor): a tensor of shape (batch_size) indicating the relevant item in each row of the dataset, the relevant item can be: (1) the item bought in this choice instance, (2) or the item reviewed by the user. In the later case, we need the `label` tensor to specify the rating score. NOTE: The support for second case is under-development, currently, we are only supporting binary label. label (Optional[torch.LongTensor], optional): a tensor of shape (batch_size) indicating the label for prediction in each choice instance. While you want to predict the item bought, you can leave the `label` argument as `None` in the initialization method, and the model will use `item_index` as the object to be predicted. But if you are, for example, predicting the rating an user gave an item, label must be provided. Defaults to None. user_index (Optional[torch.LongTensor], optional): a tensor of shape num_purchases (batch_size) indicating the ID of the user who was involved in each choice instance. If `None` user index is provided, it's assumed that the choice instances are from the same user. `user_index` is required if and only if there are multiple users in the dataset, for example: (1) user-observables is involved in the utility form, (2) and/or the coefficient is user-specific. This tensor is used to select the corresponding user observables and coefficients assigned to the user (like theta_user) for making prediction for that purchase. Defaults to None. session_index (Optional[torch.LongTensor], optional): a tensor of shape num_purchases (batch_size) indicating the ID of the session when that choice instance occurred. This tensor is used to select the correct session observables or price observables for making prediction for that choice instance. Therefore, if there is no session/price observables, you can leave this argument as `None`. In this case, the `ChoiceDataset` object will assume each choice instance to be in its own session. Defaults to None. item_availability (Optional[torch.BoolTensor], optional): A boolean tensor of shape (num_sessions, num_items) indicating the availability of each item in each session. Utilities of unavailable items would be set to -infinite, and hence these unavailable items will be set to 0 while making prediction. We assume all items are available if set to None. Defaults to None. Other Kwargs (Observables): One can specify the following types of observables, where * in shape denotes any positive integer. Typically * represents the number of observables. Please refer to the documentation for a detailed guide to use observables. 1. user observables must start with 'user_' and have shape (num_users, *) 2. item observables must start with 'item_' and have shape (num_items, *) 3. session observables must start with 'session_' and have shape (num_sessions, *) 4. taste observables (those vary by user and item) must start with `taste_` and have shape (num_users, num_items, *). NOTE: we don't recommend using taste observables, because num_users * num_items is potentially large. 5. price observables (those vary by session and item) must start with `price_` and have shape (num_sessions, num_items, *) \"\"\" # ENHANCEMENT(Tianyu): add item_names for summary. super ( ChoiceDataset , self ) . __init__ () self . label = label self . item_index = item_index self . user_index = user_index self . session_index = session_index if self . session_index is None : # if any([x.startswith('session_') or x.startswith('price_') for x in kwargs.keys()]): # if any session sensitive observable is provided, but session index is not, # infer each row in the dataset to be a session. # TODO: (design choice) should we assign unique session index to each choice instance or the same session index. print ( 'No `session_index` is provided, assume each choice instance is in its own session.' ) self . session_index = torch . arange ( len ( self . item_index )) . long () self . item_availability = item_availability for key , item in kwargs . items (): setattr ( self , key , item ) # TODO: add a validation procedure to check the consistency of the dataset. def __getitem__ ( self , indices : Union [ int , torch . LongTensor ]) -> \"ChoiceDataset\" : \"\"\"Retrieves samples corresponding to the provided index or list of indices. Args: indices (Union[int, torch.LongTensor]): a single integer index or a tensor of indices. Returns: ChoiceDataset: a subset of the dataset. \"\"\" if isinstance ( indices , int ): # convert single integer index to an array of indices. indices = torch . LongTensor ([ indices ]) new_dict = dict () new_dict [ 'item_index' ] = self . item_index [ indices ] . clone () # copy optional attributes. new_dict [ 'label' ] = self . label [ indices ] . clone () if self . label is not None else None new_dict [ 'user_index' ] = self . user_index [ indices ] . clone () if self . user_index is not None else None new_dict [ 'session_index' ] = self . session_index [ indices ] . clone () if self . session_index is not None else None # item_availability has shape (num_sessions, num_items), no need to re-index it. new_dict [ 'item_availability' ] = self . item_availability # copy other attributes. for key , val in self . __dict__ . items (): if key not in new_dict . keys (): if torch . is_tensor ( val ): new_dict [ key ] = val . clone () else : new_dict [ key ] = copy . deepcopy ( val ) return self . _from_dict ( new_dict ) def __len__ ( self ) -> int : \"\"\"Returns number of samples in this dataset. Returns: int: length of the dataset. \"\"\" return len ( self . item_index ) def __contains__ ( self , key : str ) -> bool : return key in self . keys @property def device ( self ) -> str : \"\"\"Returns the device of the dataset. Returns: str: the device of the dataset. \"\"\" for attr in self . __dict__ . values (): if torch . is_tensor ( attr ): return attr . device @property def num_users ( self ) -> int : \"\"\"Returns number of users involved in this dataset, returns 1 if there is no user identity. Returns: int: the number of users involved in this dataset. \"\"\" # query from user_index if self . user_index is not None : return len ( torch . unique ( self . user_index )) else : return 1 # for key, val in self.__dict__.items(): # if torch.is_tensor(val): # if self._is_user_attribute(key) or self._is_taste_attribute(key): # return val.shape[0] # return 1 @property def num_items ( self ) -> int : \"\"\"Returns the number of items involved in this dataset. Returns: int: the number of items involved in this dataset. \"\"\" return len ( torch . unique ( self . item_index )) # for key, val in self.__dict__.items(): # if torch.is_tensor(val): # if self._is_item_attribute(key): # return val.shape[0] # elif self._is_taste_attribute(key) or self._is_price_attribute(key): # return val.shape[1] # return 1 @property def num_sessions ( self ) -> int : \"\"\"Returns the number of sessions involved in this dataset. Returns: int: the number of sessions involved in this dataset. \"\"\" return len ( torch . unique ( self . session_index )) # if self.session_index is None: # return 1 # for key, val in self.__dict__.items(): # if torch.is_tensor(val): # if self._is_session_attribute(key) or self._is_price_attribute(key): # return val.shape[0] # return 1 @property def x_dict ( self ) -> Dict [ object , torch . Tensor ]: \"\"\"Formats attributes of in this dataset into shape (num_sessions, num_items, num_params) and returns in a dictionary format. Models in this package are expecting this dictionary based data format. Returns: Dict[object, torch.Tensor]: a dictionary with attribute names in the dataset as keys, and reshaped attribute tensors as values. \"\"\" out = dict () for key , val in self . __dict__ . items (): if self . _is_attribute ( key ): # only include attributes. out [ key ] = self . _expand_tensor ( key , val ) # reshape to (num_sessions, num_items, num_params). return out @classmethod def _from_dict ( cls , dictionary : Dict [ str , torch . tensor ]) -> \"ChoiceDataset\" : \"\"\"Creates an instance of ChoiceDataset from a dictionary of arguments. Args: dictionary (Dict[str, torch.tensor]): a dictionary with keys as argument names and values as arguments. Returns: ChoiceDataset: the created copy of dataset. \"\"\" dataset = cls ( ** dictionary ) for key , item in dictionary . items (): setattr ( dataset , key , item ) return dataset def apply_tensor ( self , func : callable ) -> \"ChoiceDataset\" : \"\"\"This s a helper method to apply the provided function to all tensors and tensor values of all dictionaries. Args: func (callable): a callable function to be applied on tensors and tensor-values of dictionaries. Returns: ChoiceDataset: the modified dataset. \"\"\" for key , item in self . __dict__ . items (): if torch . is_tensor ( item ): setattr ( self , key , func ( item )) # boardcast func to dictionary of tensors as well. elif isinstance ( getattr ( self , key ), dict ): for obj_key , obj_item in getattr ( self , key ) . items (): if torch . is_tensor ( obj_item ): setattr ( getattr ( self , key ), obj_key , func ( obj_item )) return self def to ( self , device : Union [ str , torch . device ]) -> \"ChoiceDataset\" : \"\"\"Moves all tensors in this dataset to the specified PyTorch device. Args: device (Union[str, torch.device]): the destination device. Returns: ChoiceDataset: the modified dataset on the new device. \"\"\" return self . apply_tensor ( lambda x : x . to ( device )) def clone ( self ) -> \"ChoiceDataset\" : \"\"\"Creates a copy of self. Returns: ChoiceDataset: a copy of self. \"\"\" dictionary = {} for k , v in self . __dict__ . items (): if torch . is_tensor ( v ): dictionary [ k ] = v . clone () else : dictionary [ k ] = copy . deepcopy ( v ) return self . __class__ . _from_dict ( dictionary ) def _check_device_consistency ( self ) -> None : \"\"\"Checks if all tensors in this dataset are on the same device. Raises: Exception: an exception is raised if not all tensors are on the same device. \"\"\" # assert all tensors are on the same device. devices = list () for val in self . __dict__ . values (): if torch . is_tensor ( val ): devices . append ( val . device ) if len ( set ( devices )) > 1 : raise Exception ( f 'Found tensors on different devices: { set ( devices ) } .' , 'Use dataset.to() method to align devices.' ) def _size_repr ( self , value : object ) -> List [ int ]: \"\"\"A helper method to get the string-representation of object sizes, this is helpful while constructing the string representation of the dataset. Args: value (object): an object to examine its size. Returns: List[int]: list of integers representing the size of the object, length of the list is equal to dimension of `value`. \"\"\" if torch . is_tensor ( value ): return list ( value . size ()) elif isinstance ( value , int ) or isinstance ( value , float ): return [ 1 ] elif isinstance ( value , list ) or isinstance ( value , tuple ): return [ len ( value )] else : return [] def __repr__ ( self ) -> str : \"\"\"A method to get a string representation of the dataset. Returns: str: the string representation of the dataset. \"\"\" info = [ f ' { key } = { self . _size_repr ( item ) } ' for key , item in self . __dict__ . items ()] return f \" { self . __class__ . __name__ } ( { ', ' . join ( info ) } , device= { self . device } )\" # ================================================================================================================== # methods for checking attribute categories. # ================================================================================================================== @staticmethod def _is_item_attribute ( key : str ) -> bool : return key . startswith ( 'item_' ) and ( key != 'item_availability' ) and ( key != 'item_index' ) @staticmethod def _is_user_attribute ( key : str ) -> bool : return key . startswith ( 'user_' ) and ( key != 'user_index' ) @staticmethod def _is_session_attribute ( key : str ) -> bool : return key . startswith ( 'session_' ) and ( key != 'session_index' ) @staticmethod def _is_taste_attribute ( key : str ) -> bool : return key . startswith ( 'taste_' ) @staticmethod def _is_price_attribute ( key : str ) -> bool : return key . startswith ( 'price_' ) def _is_attribute ( self , key : str ) -> bool : return self . _is_item_attribute ( key ) \\ or self . _is_user_attribute ( key ) \\ or self . _is_session_attribute ( key ) \\ or self . _is_taste_attribute ( key ) \\ or self . _is_price_attribute ( key ) def _expand_tensor ( self , key : str , val : torch . Tensor ) -> torch . Tensor : \"\"\"Expands attribute tensor to (num_sessions, num_items, num_params) shape for prediction tasks, this method won't reshape the tensor at all if the `key` (i.e., name of the tensor) suggests its not an attribute of any kind. Args: key (str): name of the attribute used to determine the raw shape of the tensor. For example, 'item_obs' means the raw tensor is in shape (num_items, num_params). val (torch.Tensor): the attribute tensor to be reshaped. Returns: torch.Tensor: the reshaped tensor with shape (num_sessions, num_items, num_params). \"\"\" if not self . _is_attribute ( key ): print ( f 'Warning: the input key { key } is not an attribute of the dataset, will NOT modify the provided tensor.' ) # don't expand non-attribute tensors, if any. return val num_params = val . shape [ - 1 ] if self . _is_user_attribute ( key ): # user_attribute (num_users, *) out = val [ self . user_index , :] . view ( len ( self ), 1 , num_params ) . expand ( - 1 , self . num_items , - 1 ) elif self . _is_item_attribute ( key ): # item_attribute (num_items, *) out = val . view ( 1 , self . num_items , num_params ) . expand ( len ( self ), - 1 , - 1 ) elif self . _is_session_attribute ( key ): # session_attribute (num_sessions, *) out = val [ self . session_index , :] . view ( len ( self ), 1 , num_params ) . expand ( - 1 , self . num_items , - 1 ) elif self . _is_taste_attribute ( key ): # taste_attribute (num_users, num_items, *) out = val [ self . user_index , :, :] elif self . _is_price_attribute ( key ): # price_attribute (num_sessions, num_items, *) out = val [ self . session_index , :, :] assert out . shape == ( len ( self ), self . num_items , num_params ) return out","title":"ChoiceDataset"},{"location":"api_torch_choice/#torch_choice.data.choice_dataset.ChoiceDataset.device","text":"Returns the device of the dataset. Returns: Type Description str the device of the dataset.","title":"device"},{"location":"api_torch_choice/#torch_choice.data.choice_dataset.ChoiceDataset.num_items","text":"Returns the number of items involved in this dataset. Returns: Type Description int the number of items involved in this dataset.","title":"num_items"},{"location":"api_torch_choice/#torch_choice.data.choice_dataset.ChoiceDataset.num_sessions","text":"Returns the number of sessions involved in this dataset. Returns: Type Description int the number of sessions involved in this dataset.","title":"num_sessions"},{"location":"api_torch_choice/#torch_choice.data.choice_dataset.ChoiceDataset.num_users","text":"Returns number of users involved in this dataset, returns 1 if there is no user identity. Returns: Type Description int the number of users involved in this dataset.","title":"num_users"},{"location":"api_torch_choice/#torch_choice.data.choice_dataset.ChoiceDataset.x_dict","text":"Formats attributes of in this dataset into shape (num_sessions, num_items, num_params) and returns in a dictionary format. Models in this package are expecting this dictionary based data format. Returns: Type Description Dict[object, torch.Tensor] a dictionary with attribute names in the dataset as keys, and reshaped attribute tensors as values.","title":"x_dict"},{"location":"api_torch_choice/#torch_choice.data.choice_dataset.ChoiceDataset.__getitem__","text":"Retrieves samples corresponding to the provided index or list of indices. Parameters: Name Type Description Default indices Union[int, torch.LongTensor] a single integer index or a tensor of indices. required Returns: Type Description ChoiceDataset a subset of the dataset. Source code in torch_choice/data/choice_dataset.py def __getitem__ ( self , indices : Union [ int , torch . LongTensor ]) -> \"ChoiceDataset\" : \"\"\"Retrieves samples corresponding to the provided index or list of indices. Args: indices (Union[int, torch.LongTensor]): a single integer index or a tensor of indices. Returns: ChoiceDataset: a subset of the dataset. \"\"\" if isinstance ( indices , int ): # convert single integer index to an array of indices. indices = torch . LongTensor ([ indices ]) new_dict = dict () new_dict [ 'item_index' ] = self . item_index [ indices ] . clone () # copy optional attributes. new_dict [ 'label' ] = self . label [ indices ] . clone () if self . label is not None else None new_dict [ 'user_index' ] = self . user_index [ indices ] . clone () if self . user_index is not None else None new_dict [ 'session_index' ] = self . session_index [ indices ] . clone () if self . session_index is not None else None # item_availability has shape (num_sessions, num_items), no need to re-index it. new_dict [ 'item_availability' ] = self . item_availability # copy other attributes. for key , val in self . __dict__ . items (): if key not in new_dict . keys (): if torch . is_tensor ( val ): new_dict [ key ] = val . clone () else : new_dict [ key ] = copy . deepcopy ( val ) return self . _from_dict ( new_dict )","title":"__getitem__()"},{"location":"api_torch_choice/#torch_choice.data.choice_dataset.ChoiceDataset.__init__","text":"Initialization methods for the dataset object, researchers should supply all information about the dataset using this initialization method. The number of choice instances are called batch_size in the documentation. The batch_size corresponds to the file length in wide-format dataset, and often denoted using N . We call it batch_size to follow the convention in machine learning literature. A choice instance is a row of the dataset, so there are batch_size choice instances in each ChoiceDataset . The dataset consists of: (1) a collection of batch_size tuples (item_id, user_id, session_id, label), where each tuple is a choice instance. (2) a collection of observables associated with item, user, session, etc. Parameters: Name Type Description Default item_index torch.LongTensor a tensor of shape (batch_size) indicating the relevant item in each row of the dataset, the relevant item can be: (1) the item bought in this choice instance, (2) or the item reviewed by the user. In the later case, we need the label tensor to specify the rating score. NOTE: The support for second case is under-development, currently, we are only supporting binary label. required label Optional[torch.LongTensor] a tensor of shape (batch_size) indicating the label for prediction in each choice instance. While you want to predict the item bought, you can leave the label argument as None in the initialization method, and the model will use item_index as the object to be predicted. But if you are, for example, predicting the rating an user gave an item, label must be provided. Defaults to None. None user_index Optional[torch.LongTensor] a tensor of shape num_purchases (batch_size) indicating the ID of the user who was involved in each choice instance. If None user index is provided, it's assumed that the choice instances are from the same user. user_index is required if and only if there are multiple users in the dataset, for example: (1) user-observables is involved in the utility form, (2) and/or the coefficient is user-specific. This tensor is used to select the corresponding user observables and coefficients assigned to the user (like theta_user) for making prediction for that purchase. Defaults to None. None session_index Optional[torch.LongTensor] a tensor of shape num_purchases (batch_size) indicating the ID of the session when that choice instance occurred. This tensor is used to select the correct session observables or price observables for making prediction for that choice instance. Therefore, if there is no session/price observables, you can leave this argument as None . In this case, the ChoiceDataset object will assume each choice instance to be in its own session. Defaults to None. None item_availability Optional[torch.BoolTensor] A boolean tensor of shape (num_sessions, num_items) indicating the availability of each item in each session. Utilities of unavailable items would be set to -infinite, and hence these unavailable items will be set to 0 while making prediction. We assume all items are available if set to None. Defaults to None. None Other Kwargs (Observables): One can specify the following types of observables, where * in shape denotes any positive integer. Typically * represents the number of observables. Please refer to the documentation for a detailed guide to use observables. 1. user observables must start with 'user_' and have shape (num_users, ) 2. item observables must start with 'item_' and have shape (num_items, ) 3. session observables must start with 'session_' and have shape (num_sessions, ) 4. taste observables (those vary by user and item) must start with taste_ and have shape (num_users, num_items, ). NOTE: we don't recommend using taste observables, because num_users * num_items is potentially large. 5. price observables (those vary by session and item) must start with price_ and have shape (num_sessions, num_items, *) Source code in torch_choice/data/choice_dataset.py def __init__ ( self , item_index : torch . LongTensor , label : Optional [ torch . LongTensor ] = None , user_index : Optional [ torch . LongTensor ] = None , session_index : Optional [ torch . LongTensor ] = None , item_availability : Optional [ torch . BoolTensor ] = None , ** kwargs ) -> None : \"\"\" Initialization methods for the dataset object, researchers should supply all information about the dataset using this initialization method. The number of choice instances are called `batch_size` in the documentation. The `batch_size` corresponds to the file length in wide-format dataset, and often denoted using `N`. We call it `batch_size` to follow the convention in machine learning literature. A `choice instance` is a row of the dataset, so there are `batch_size` choice instances in each `ChoiceDataset`. The dataset consists of: (1) a collection of `batch_size` tuples (item_id, user_id, session_id, label), where each tuple is a choice instance. (2) a collection of `observables` associated with item, user, session, etc. Args: item_index (torch.LongTensor): a tensor of shape (batch_size) indicating the relevant item in each row of the dataset, the relevant item can be: (1) the item bought in this choice instance, (2) or the item reviewed by the user. In the later case, we need the `label` tensor to specify the rating score. NOTE: The support for second case is under-development, currently, we are only supporting binary label. label (Optional[torch.LongTensor], optional): a tensor of shape (batch_size) indicating the label for prediction in each choice instance. While you want to predict the item bought, you can leave the `label` argument as `None` in the initialization method, and the model will use `item_index` as the object to be predicted. But if you are, for example, predicting the rating an user gave an item, label must be provided. Defaults to None. user_index (Optional[torch.LongTensor], optional): a tensor of shape num_purchases (batch_size) indicating the ID of the user who was involved in each choice instance. If `None` user index is provided, it's assumed that the choice instances are from the same user. `user_index` is required if and only if there are multiple users in the dataset, for example: (1) user-observables is involved in the utility form, (2) and/or the coefficient is user-specific. This tensor is used to select the corresponding user observables and coefficients assigned to the user (like theta_user) for making prediction for that purchase. Defaults to None. session_index (Optional[torch.LongTensor], optional): a tensor of shape num_purchases (batch_size) indicating the ID of the session when that choice instance occurred. This tensor is used to select the correct session observables or price observables for making prediction for that choice instance. Therefore, if there is no session/price observables, you can leave this argument as `None`. In this case, the `ChoiceDataset` object will assume each choice instance to be in its own session. Defaults to None. item_availability (Optional[torch.BoolTensor], optional): A boolean tensor of shape (num_sessions, num_items) indicating the availability of each item in each session. Utilities of unavailable items would be set to -infinite, and hence these unavailable items will be set to 0 while making prediction. We assume all items are available if set to None. Defaults to None. Other Kwargs (Observables): One can specify the following types of observables, where * in shape denotes any positive integer. Typically * represents the number of observables. Please refer to the documentation for a detailed guide to use observables. 1. user observables must start with 'user_' and have shape (num_users, *) 2. item observables must start with 'item_' and have shape (num_items, *) 3. session observables must start with 'session_' and have shape (num_sessions, *) 4. taste observables (those vary by user and item) must start with `taste_` and have shape (num_users, num_items, *). NOTE: we don't recommend using taste observables, because num_users * num_items is potentially large. 5. price observables (those vary by session and item) must start with `price_` and have shape (num_sessions, num_items, *) \"\"\" # ENHANCEMENT(Tianyu): add item_names for summary. super ( ChoiceDataset , self ) . __init__ () self . label = label self . item_index = item_index self . user_index = user_index self . session_index = session_index if self . session_index is None : # if any([x.startswith('session_') or x.startswith('price_') for x in kwargs.keys()]): # if any session sensitive observable is provided, but session index is not, # infer each row in the dataset to be a session. # TODO: (design choice) should we assign unique session index to each choice instance or the same session index. print ( 'No `session_index` is provided, assume each choice instance is in its own session.' ) self . session_index = torch . arange ( len ( self . item_index )) . long () self . item_availability = item_availability for key , item in kwargs . items (): setattr ( self , key , item ) # TODO: add a validation procedure to check the consistency of the dataset.","title":"__init__()"},{"location":"api_torch_choice/#torch_choice.data.choice_dataset.ChoiceDataset.__len__","text":"Returns number of samples in this dataset. Returns: Type Description int length of the dataset. Source code in torch_choice/data/choice_dataset.py def __len__ ( self ) -> int : \"\"\"Returns number of samples in this dataset. Returns: int: length of the dataset. \"\"\" return len ( self . item_index )","title":"__len__()"},{"location":"api_torch_choice/#torch_choice.data.choice_dataset.ChoiceDataset.__repr__","text":"A method to get a string representation of the dataset. Returns: Type Description str the string representation of the dataset. Source code in torch_choice/data/choice_dataset.py def __repr__ ( self ) -> str : \"\"\"A method to get a string representation of the dataset. Returns: str: the string representation of the dataset. \"\"\" info = [ f ' { key } = { self . _size_repr ( item ) } ' for key , item in self . __dict__ . items ()] return f \" { self . __class__ . __name__ } ( { ', ' . join ( info ) } , device= { self . device } )\"","title":"__repr__()"},{"location":"api_torch_choice/#torch_choice.data.choice_dataset.ChoiceDataset.apply_tensor","text":"This s a helper method to apply the provided function to all tensors and tensor values of all dictionaries. Parameters: Name Type Description Default func callable a callable function to be applied on tensors and tensor-values of dictionaries. required Returns: Type Description ChoiceDataset the modified dataset. Source code in torch_choice/data/choice_dataset.py def apply_tensor ( self , func : callable ) -> \"ChoiceDataset\" : \"\"\"This s a helper method to apply the provided function to all tensors and tensor values of all dictionaries. Args: func (callable): a callable function to be applied on tensors and tensor-values of dictionaries. Returns: ChoiceDataset: the modified dataset. \"\"\" for key , item in self . __dict__ . items (): if torch . is_tensor ( item ): setattr ( self , key , func ( item )) # boardcast func to dictionary of tensors as well. elif isinstance ( getattr ( self , key ), dict ): for obj_key , obj_item in getattr ( self , key ) . items (): if torch . is_tensor ( obj_item ): setattr ( getattr ( self , key ), obj_key , func ( obj_item )) return self","title":"apply_tensor()"},{"location":"api_torch_choice/#torch_choice.data.choice_dataset.ChoiceDataset.clone","text":"Creates a copy of self. Returns: Type Description ChoiceDataset a copy of self. Source code in torch_choice/data/choice_dataset.py def clone ( self ) -> \"ChoiceDataset\" : \"\"\"Creates a copy of self. Returns: ChoiceDataset: a copy of self. \"\"\" dictionary = {} for k , v in self . __dict__ . items (): if torch . is_tensor ( v ): dictionary [ k ] = v . clone () else : dictionary [ k ] = copy . deepcopy ( v ) return self . __class__ . _from_dict ( dictionary )","title":"clone()"},{"location":"api_torch_choice/#torch_choice.data.choice_dataset.ChoiceDataset.to","text":"Moves all tensors in this dataset to the specified PyTorch device. Parameters: Name Type Description Default device Union[str, torch.device] the destination device. required Returns: Type Description ChoiceDataset the modified dataset on the new device. Source code in torch_choice/data/choice_dataset.py def to ( self , device : Union [ str , torch . device ]) -> \"ChoiceDataset\" : \"\"\"Moves all tensors in this dataset to the specified PyTorch device. Args: device (Union[str, torch.device]): the destination device. Returns: ChoiceDataset: the modified dataset on the new device. \"\"\" return self . apply_tensor ( lambda x : x . to ( device ))","title":"to()"},{"location":"api_torch_choice/#torch_choice.data.joint_dataset","text":"The JointDataset class is a wrapper for the torch.utils.data.ChoiceDataset class, it is particularly useful when we need to make prediction from multiple datasets. For example, you have data on consumer purchase records in a fast food store, and suppose every customer will purchase exactly a single main food and a single drink. In this case, you have two separate datasets: FoodDataset and DrinkDataset. You may want to use PyTorch sampler to sample them in a dependent manner: you want to take the i-th sample from both datasets, so that you know what (food, drink) combo the i-th customer purchased. You can do this by using the JointDataset class. Author: Tianyu Du Update: Apr. 28, 2022","title":"joint_dataset"},{"location":"api_torch_choice/#torch_choice.data.joint_dataset.JointDataset","text":"A helper class for joining several pytorch datasets, using JointDataset and pytorch data loader allows for sampling the same batch index from several datasets. The JointDataset class is a wrapper for the torch.utils.data.ChoiceDataset class, it is particularly useful when we need to make prediction from multiple datasets. For example, you have data on consumer purchase records in a fast food store, and suppose every customer will purchase exactly a single main food and a single drink. In this case, you have two separate datasets: FoodDataset and DrinkDataset. You may want to use PyTorch sampler to sample them in a dependent manner: you want to take the i-th sample from both datasets, so that you know what (food, drink) combo the i-th customer purchased. You can do this by using the JointDataset class. Source code in torch_choice/data/joint_dataset.py class JointDataset ( torch . utils . data . Dataset ): \"\"\"A helper class for joining several pytorch datasets, using JointDataset and pytorch data loader allows for sampling the same batch index from several datasets. The JointDataset class is a wrapper for the torch.utils.data.ChoiceDataset class, it is particularly useful when we need to make prediction from multiple datasets. For example, you have data on consumer purchase records in a fast food store, and suppose every customer will purchase exactly a single main food and a single drink. In this case, you have two separate datasets: FoodDataset and DrinkDataset. You may want to use PyTorch sampler to sample them in a dependent manner: you want to take the i-th sample from both datasets, so that you know what (food, drink) combo the i-th customer purchased. You can do this by using the JointDataset class. \"\"\" def __init__ ( self , ** datasets ) -> None : \"\"\"The initialize methods. Args: Arbitrarily many datasets with arbitrary names as keys. In the example above, you can construct ``` dataset = JointDataset(food=FoodDataset, drink=DrinkDataset) ``` All datasets should have the same length. \"\"\" super ( JointDataset , self ) . __init__ () self . datasets = datasets # check the length of sub-datasets are the same. assert len ( set ([ len ( d ) for d in self . datasets . values ()])) == 1 def __len__ ( self ) -> int : \"\"\"Get the number of samples in the joint dataset. Returns: int: the number of samples in the joint dataset, which is the same as the number of samples in each dataset contained. \"\"\" for d in self . datasets . values (): return len ( d ) def __getitem__ ( self , indices : Union [ int , torch . LongTensor ]) -> Dict [ str , ChoiceDataset ]: \"\"\"Queries samples from the dataset by index. Args: indices (Union[int, torch.LongTensor]): an integer or a 1D tensor of multiple indices. Returns: Dict[str, ChoiceDataset]: the subset of the dataset. Keys of the dictionary will be names of each dataset contained (the same as the keys of the ``datasets`` argument in the constructor). Values will be subsets of contained datasets, sliced using the provided indices. \"\"\" return dict (( name , d [ indices ]) for ( name , d ) in self . datasets . items ()) def __repr__ ( self ) -> str : \"\"\"A method to get a string representation of the dataset. Returns: str: the string representation of the dataset. \"\"\" out = [ f 'JointDataset with { len ( self . datasets ) } sub-datasets: (' ] for name , dataset in self . datasets . items (): out . append ( f ' \\t { name } : { str ( dataset ) } ' ) out . append ( ')' ) return ' \\n ' . join ( out ) @property def device ( self ) -> str : \"\"\"Returns the device of datasets contained in the joint dataset. Returns: str: the device of the dataset. \"\"\" for d in self . datasets . values (): return d . device def to ( self , device : Union [ str , torch . device ]) -> \"JointDataset\" : \"\"\"Moves all datasets in this dataset to the specified PyTorch device. Args: device (Union[str, torch.device]): the destination device. Returns: ChoiceDataset: the modified dataset on the new device. \"\"\" for d in self . datasets . values (): d = d . to ( device ) return self","title":"JointDataset"},{"location":"api_torch_choice/#torch_choice.data.joint_dataset.JointDataset.device","text":"Returns the device of datasets contained in the joint dataset. Returns: Type Description str the device of the dataset.","title":"device"},{"location":"api_torch_choice/#torch_choice.data.joint_dataset.JointDataset.__getitem__","text":"Queries samples from the dataset by index. Parameters: Name Type Description Default indices Union[int, torch.LongTensor] an integer or a 1D tensor of multiple indices. required Returns: Type Description Dict[str, ChoiceDataset] the subset of the dataset. Keys of the dictionary will be names of each dataset contained (the same as the keys of the datasets argument in the constructor). Values will be subsets of contained datasets, sliced using the provided indices. Source code in torch_choice/data/joint_dataset.py def __getitem__ ( self , indices : Union [ int , torch . LongTensor ]) -> Dict [ str , ChoiceDataset ]: \"\"\"Queries samples from the dataset by index. Args: indices (Union[int, torch.LongTensor]): an integer or a 1D tensor of multiple indices. Returns: Dict[str, ChoiceDataset]: the subset of the dataset. Keys of the dictionary will be names of each dataset contained (the same as the keys of the ``datasets`` argument in the constructor). Values will be subsets of contained datasets, sliced using the provided indices. \"\"\" return dict (( name , d [ indices ]) for ( name , d ) in self . datasets . items ())","title":"__getitem__()"},{"location":"api_torch_choice/#torch_choice.data.joint_dataset.JointDataset.__init__","text":"The initialize methods. Source code in torch_choice/data/joint_dataset.py def __init__ ( self , ** datasets ) -> None : \"\"\"The initialize methods. Args: Arbitrarily many datasets with arbitrary names as keys. In the example above, you can construct ``` dataset = JointDataset(food=FoodDataset, drink=DrinkDataset) ``` All datasets should have the same length. \"\"\" super ( JointDataset , self ) . __init__ () self . datasets = datasets # check the length of sub-datasets are the same. assert len ( set ([ len ( d ) for d in self . datasets . values ()])) == 1","title":"__init__()"},{"location":"api_torch_choice/#torch_choice.data.joint_dataset.JointDataset.__len__","text":"Get the number of samples in the joint dataset. Returns: Type Description int the number of samples in the joint dataset, which is the same as the number of samples in each dataset contained. Source code in torch_choice/data/joint_dataset.py def __len__ ( self ) -> int : \"\"\"Get the number of samples in the joint dataset. Returns: int: the number of samples in the joint dataset, which is the same as the number of samples in each dataset contained. \"\"\" for d in self . datasets . values (): return len ( d )","title":"__len__()"},{"location":"api_torch_choice/#torch_choice.data.joint_dataset.JointDataset.__repr__","text":"A method to get a string representation of the dataset. Returns: Type Description str the string representation of the dataset. Source code in torch_choice/data/joint_dataset.py def __repr__ ( self ) -> str : \"\"\"A method to get a string representation of the dataset. Returns: str: the string representation of the dataset. \"\"\" out = [ f 'JointDataset with { len ( self . datasets ) } sub-datasets: (' ] for name , dataset in self . datasets . items (): out . append ( f ' \\t { name } : { str ( dataset ) } ' ) out . append ( ')' ) return ' \\n ' . join ( out )","title":"__repr__()"},{"location":"api_torch_choice/#torch_choice.data.joint_dataset.JointDataset.to","text":"Moves all datasets in this dataset to the specified PyTorch device. Parameters: Name Type Description Default device Union[str, torch.device] the destination device. required Returns: Type Description ChoiceDataset the modified dataset on the new device. Source code in torch_choice/data/joint_dataset.py def to ( self , device : Union [ str , torch . device ]) -> \"JointDataset\" : \"\"\"Moves all datasets in this dataset to the specified PyTorch device. Args: device (Union[str, torch.device]): the destination device. Returns: ChoiceDataset: the modified dataset on the new device. \"\"\" for d in self . datasets . values (): d = d . to ( device ) return self","title":"to()"},{"location":"api_torch_choice/#torch_choice.data.utils","text":"","title":"utils"},{"location":"api_torch_choice/#torch_choice.data.utils.pivot3d","text":"Creates a tensor of shape (df[dim0].nunique(), df[dim1].nunique(), len(values)) from the provided data frame. Example, if dim0 is the column of session ID, dim1 is the column of alternative names, then out[t, i, k] is the feature values[k] of item i in session t. The returned tensor has shape (num_sessions, num_items, num_params), which fits the purpose of conditioanl logit models. Source code in torch_choice/data/utils.py def pivot3d ( df : pd . DataFrame , dim0 : str , dim1 : str , values : Union [ str , List [ str ]]) -> torch . Tensor : \"\"\" Creates a tensor of shape (df[dim0].nunique(), df[dim1].nunique(), len(values)) from the provided data frame. Example, if dim0 is the column of session ID, dim1 is the column of alternative names, then out[t, i, k] is the feature values[k] of item i in session t. The returned tensor has shape (num_sessions, num_items, num_params), which fits the purpose of conditioanl logit models. \"\"\" if not isinstance ( values , list ): values = [ values ] dim1_list = sorted ( df [ dim1 ] . unique ()) tensor_slice = list () for value in values : layer = df . pivot ( index = dim0 , columns = dim1 , values = value ) tensor_slice . append ( torch . Tensor ( layer [ dim1_list ] . values )) tensor = torch . stack ( tensor_slice , dim =- 1 ) assert tensor . shape == ( df [ dim0 ] . nunique (), df [ dim1 ] . nunique (), len ( values )) return tensor","title":"pivot3d()"},{"location":"api_torch_choice/#torch_choice.model","text":"","title":"model"},{"location":"api_torch_choice/#torch_choice.model.coefficient","text":"The general class of learnable coefficients in various models, this class serves as the building blocks for models in this package. The weights (i.e., learnable parameters) in the Coefficient class are implemented using PyTorch and can be trained directly using optimizers from PyTorch. NOTE: torch-choice package users don't interact with classes in this file directly, please use conditional_logit_model.py and nested_logit_model.py instead. Author: Tianyu Du Update: Apr. 28, 2022","title":"coefficient"},{"location":"api_torch_choice/#torch_choice.model.coefficient.Coefficient","text":"Source code in torch_choice/model/coefficient.py class Coefficient ( nn . Module ): def __init__ ( self , variation : str , num_params : int , num_items : Optional [ int ] = None , num_users : Optional [ int ] = None ) -> None : \"\"\"A generic coefficient object storing trainable parameters. This class corresponds to those variables typically in Greek letters in the model's utility representation. Args: variation (str): the degree of variation of this coefficient. For example, the coefficient can vary by users or items. Currently, we support variations 'constant', 'item', 'item-full', 'user', 'user-item', 'user-item-full'. For detailed explanation of these variations, please refer to the documentation of ConditionalLogitModel. num_params (int): number of parameters in this coefficient. Note that this number is the number of parameters per class, not the total number of parameters. For example, suppose we have U users and you want to initiate an user-specific coefficient called `theta_user`. The coefficient enters the utility form while being multiplied with some K-dimension observables. Then, for each user, there are K parameters to be multiplied with the K-dimensional observable. However, the total number of parameters is K * U (K for each of U users). In this case, `num_params` should be set to `K`, NOT `K*U`. num_items (int): the number of items in the prediction problem, this is required to reshape the parameter correctly. num_users (Optional[int], optional): number of users, this is only necessary if the coefficient varies by users. Defaults to None. \"\"\" super ( Coefficient , self ) . __init__ () self . variation = variation self . num_items = num_items self . num_users = num_users self . num_params = num_params # construct the trainable. if self . variation == 'constant' : # constant for all users and items. self . coef = nn . Parameter ( torch . randn ( num_params ), requires_grad = True ) elif self . variation == 'item' : # coef depends on item j but not on user i. # force coefficients for the first item class to be zero. self . coef = nn . Parameter ( torch . zeros ( num_items - 1 , num_params ), requires_grad = True ) elif self . variation == 'item-full' : # coef depends on item j but not on user i. # model coefficient for every item. self . coef = nn . Parameter ( torch . zeros ( num_items , num_params ), requires_grad = True ) elif self . variation == 'user' : # coef depends on the user. # we always model coefficient for all users. self . coef = nn . Parameter ( torch . zeros ( num_users , num_params ), requires_grad = True ) elif self . variation == 'user-item' : # coefficients of the first item is forced to be zero, model coefficients for N - 1 items only. self . coef = nn . Parameter ( torch . zeros ( num_users , num_items - 1 , num_params ), requires_grad = True ) elif self . variation == 'user-item-full' : # construct coefficients for every items. self . coef = nn . Parameter ( torch . zeros ( num_users , num_items , num_params ), requires_grad = True ) else : raise ValueError ( f 'Unsupported type of variation: { self . variation } .' ) def __repr__ ( self ) -> str : \"\"\"Returns a string representation of the coefficient. Returns: str: the string representation of the coefficient. \"\"\" return f 'Coefficient(variation= { self . variation } , num_items= { self . num_items } ,' \\ + f ' num_users= { self . num_users } , num_params= { self . num_params } ,' \\ + f ' { self . coef . numel () } trainable parameters in total).' def forward ( self , x : torch . Tensor , user_index : Optional [ torch . Tensor ] = None , manual_coef_value : Optional [ torch . Tensor ] = None ) -> torch . Tensor : \"\"\" The forward function of the coefficient, which computes the utility from purchasing each item in each session. The output shape will be (num_sessions, num_items). Args: x (torch.Tensor): a tensor of shape (num_sessions, num_items, num_params). Please note that the Coefficient class will NOT reshape input tensors itself, this reshaping needs to be done in the model class. user_index (Optional[torch.Tensor], optional): a tensor of shape (num_sessions,) contain IDs of the user involved in that session. If set to None, assume the same user is making all decisions. Defaults to None. manual_coef_value (Optional[torch.Tensor], optional): a tensor with the same number of entries as self.coef. If provided, the forward function uses provided values as coefficient and return the predicted utility, this feature is useful when the researcher wishes to manually specify values for coefficients and examine prediction with specified coefficient values. If not provided, forward function is executed using values from self.coef. Defaults to None. Returns: torch.Tensor: a tensor of shape (num_sessions, num_items) whose (t, i) entry represents the utility of purchasing item i in session t. \"\"\" if manual_coef_value is not None : assert manual_coef_value . numel () == self . coef . numel () # plugin the provided coefficient values, coef is a tensor. coef = manual_coef_value . reshape ( * self . coef . shape ) else : # use the learned coefficient values, coef is a nn.Parameter. coef = self . coef num_trips , num_items , num_feats = x . shape assert self . num_params == num_feats # cast coefficient tensor to (num_trips, num_items, self.num_params). if self . variation == 'constant' : coef = coef . view ( 1 , 1 , self . num_params ) . expand ( num_trips , num_items , - 1 ) elif self . variation == 'item' : # coef has shape (num_items-1, num_params) # force coefficient for the first item to be zero. zeros = torch . zeros ( 1 , self . num_params ) . to ( coef . device ) coef = torch . cat (( zeros , coef ), dim = 0 ) # (num_items, num_params) coef = coef . view ( 1 , self . num_items , self . num_params ) . expand ( num_trips , - 1 , - 1 ) elif self . variation == 'item-full' : # coef has shape (num_items, num_params) coef = coef . view ( 1 , self . num_items , self . num_params ) . expand ( num_trips , - 1 , - 1 ) elif self . variation == 'user' : # coef has shape (num_users, num_params) coef = coef [ user_index , :] # (num_trips, num_params) user-specific coefficients. coef = coef . view ( num_trips , 1 , self . num_params ) . expand ( - 1 , num_items , - 1 ) elif self . variation == 'user-item' : # (num_trips,) long tensor of user ID. # originally, coef has shape (num_users, num_items-1, num_params) # transform to (num_trips, num_items - 1, num_params), user-specific. coef = coef [ user_index , :, :] # coefs for the first item for all users are enforced to 0. zeros = torch . zeros ( num_trips , 1 , self . num_params ) . to ( coef . device ) coef = torch . cat (( zeros , coef ), dim = 1 ) # (num_trips, num_items, num_params) elif self . variation == 'user-item-full' : # originally, coef has shape (num_users, num_items, num_params) coef = coef [ user_index , :, :] # (num_trips, num_items, num_params) else : raise ValueError ( f 'Unsupported type of variation: { self . variation } .' ) assert coef . shape == ( num_trips , num_items , num_feats ) == x . shape # compute the utility of each item in each trip, take summation along the feature dimension, the same as taking # the inner product. return ( x * coef ) . sum ( dim =- 1 )","title":"Coefficient"},{"location":"api_torch_choice/#torch_choice.model.coefficient.Coefficient.__init__","text":"A generic coefficient object storing trainable parameters. This class corresponds to those variables typically in Greek letters in the model's utility representation. Parameters: Name Type Description Default variation str the degree of variation of this coefficient. For example, the coefficient can vary by users or items. Currently, we support variations 'constant', 'item', 'item-full', 'user', 'user-item', 'user-item-full'. For detailed explanation of these variations, please refer to the documentation of ConditionalLogitModel. required num_params int number of parameters in this coefficient. Note that this number is the number of parameters per class, not the total number of parameters. For example, suppose we have U users and you want to initiate an user-specific coefficient called theta_user . The coefficient enters the utility form while being multiplied with some K-dimension observables. Then, for each user, there are K parameters to be multiplied with the K-dimensional observable. However, the total number of parameters is K * U (K for each of U users). In this case, num_params should be set to K , NOT K*U . required num_items int the number of items in the prediction problem, this is required to reshape the parameter correctly. None num_users Optional[int] number of users, this is only necessary if the coefficient varies by users. Defaults to None. None Source code in torch_choice/model/coefficient.py def __init__ ( self , variation : str , num_params : int , num_items : Optional [ int ] = None , num_users : Optional [ int ] = None ) -> None : \"\"\"A generic coefficient object storing trainable parameters. This class corresponds to those variables typically in Greek letters in the model's utility representation. Args: variation (str): the degree of variation of this coefficient. For example, the coefficient can vary by users or items. Currently, we support variations 'constant', 'item', 'item-full', 'user', 'user-item', 'user-item-full'. For detailed explanation of these variations, please refer to the documentation of ConditionalLogitModel. num_params (int): number of parameters in this coefficient. Note that this number is the number of parameters per class, not the total number of parameters. For example, suppose we have U users and you want to initiate an user-specific coefficient called `theta_user`. The coefficient enters the utility form while being multiplied with some K-dimension observables. Then, for each user, there are K parameters to be multiplied with the K-dimensional observable. However, the total number of parameters is K * U (K for each of U users). In this case, `num_params` should be set to `K`, NOT `K*U`. num_items (int): the number of items in the prediction problem, this is required to reshape the parameter correctly. num_users (Optional[int], optional): number of users, this is only necessary if the coefficient varies by users. Defaults to None. \"\"\" super ( Coefficient , self ) . __init__ () self . variation = variation self . num_items = num_items self . num_users = num_users self . num_params = num_params # construct the trainable. if self . variation == 'constant' : # constant for all users and items. self . coef = nn . Parameter ( torch . randn ( num_params ), requires_grad = True ) elif self . variation == 'item' : # coef depends on item j but not on user i. # force coefficients for the first item class to be zero. self . coef = nn . Parameter ( torch . zeros ( num_items - 1 , num_params ), requires_grad = True ) elif self . variation == 'item-full' : # coef depends on item j but not on user i. # model coefficient for every item. self . coef = nn . Parameter ( torch . zeros ( num_items , num_params ), requires_grad = True ) elif self . variation == 'user' : # coef depends on the user. # we always model coefficient for all users. self . coef = nn . Parameter ( torch . zeros ( num_users , num_params ), requires_grad = True ) elif self . variation == 'user-item' : # coefficients of the first item is forced to be zero, model coefficients for N - 1 items only. self . coef = nn . Parameter ( torch . zeros ( num_users , num_items - 1 , num_params ), requires_grad = True ) elif self . variation == 'user-item-full' : # construct coefficients for every items. self . coef = nn . Parameter ( torch . zeros ( num_users , num_items , num_params ), requires_grad = True ) else : raise ValueError ( f 'Unsupported type of variation: { self . variation } .' )","title":"__init__()"},{"location":"api_torch_choice/#torch_choice.model.coefficient.Coefficient.__repr__","text":"Returns a string representation of the coefficient. Returns: Type Description str the string representation of the coefficient. Source code in torch_choice/model/coefficient.py def __repr__ ( self ) -> str : \"\"\"Returns a string representation of the coefficient. Returns: str: the string representation of the coefficient. \"\"\" return f 'Coefficient(variation= { self . variation } , num_items= { self . num_items } ,' \\ + f ' num_users= { self . num_users } , num_params= { self . num_params } ,' \\ + f ' { self . coef . numel () } trainable parameters in total).'","title":"__repr__()"},{"location":"api_torch_choice/#torch_choice.model.coefficient.Coefficient.forward","text":"The forward function of the coefficient, which computes the utility from purchasing each item in each session. The output shape will be (num_sessions, num_items). Parameters: Name Type Description Default x torch.Tensor a tensor of shape (num_sessions, num_items, num_params). Please note that the Coefficient class will NOT reshape input tensors itself, this reshaping needs to be done in the model class. required user_index Optional[torch.Tensor] a tensor of shape (num_sessions,) contain IDs of the user involved in that session. If set to None, assume the same user is making all decisions. Defaults to None. None manual_coef_value Optional[torch.Tensor] a tensor with the same number of entries as self.coef. If provided, the forward function uses provided values as coefficient and return the predicted utility, this feature is useful when the researcher wishes to manually specify values for coefficients and examine prediction with specified coefficient values. If not provided, forward function is executed using values from self.coef. Defaults to None. None Returns: Type Description torch.Tensor a tensor of shape (num_sessions, num_items) whose (t, i) entry represents the utility of purchasing item i in session t. Source code in torch_choice/model/coefficient.py def forward ( self , x : torch . Tensor , user_index : Optional [ torch . Tensor ] = None , manual_coef_value : Optional [ torch . Tensor ] = None ) -> torch . Tensor : \"\"\" The forward function of the coefficient, which computes the utility from purchasing each item in each session. The output shape will be (num_sessions, num_items). Args: x (torch.Tensor): a tensor of shape (num_sessions, num_items, num_params). Please note that the Coefficient class will NOT reshape input tensors itself, this reshaping needs to be done in the model class. user_index (Optional[torch.Tensor], optional): a tensor of shape (num_sessions,) contain IDs of the user involved in that session. If set to None, assume the same user is making all decisions. Defaults to None. manual_coef_value (Optional[torch.Tensor], optional): a tensor with the same number of entries as self.coef. If provided, the forward function uses provided values as coefficient and return the predicted utility, this feature is useful when the researcher wishes to manually specify values for coefficients and examine prediction with specified coefficient values. If not provided, forward function is executed using values from self.coef. Defaults to None. Returns: torch.Tensor: a tensor of shape (num_sessions, num_items) whose (t, i) entry represents the utility of purchasing item i in session t. \"\"\" if manual_coef_value is not None : assert manual_coef_value . numel () == self . coef . numel () # plugin the provided coefficient values, coef is a tensor. coef = manual_coef_value . reshape ( * self . coef . shape ) else : # use the learned coefficient values, coef is a nn.Parameter. coef = self . coef num_trips , num_items , num_feats = x . shape assert self . num_params == num_feats # cast coefficient tensor to (num_trips, num_items, self.num_params). if self . variation == 'constant' : coef = coef . view ( 1 , 1 , self . num_params ) . expand ( num_trips , num_items , - 1 ) elif self . variation == 'item' : # coef has shape (num_items-1, num_params) # force coefficient for the first item to be zero. zeros = torch . zeros ( 1 , self . num_params ) . to ( coef . device ) coef = torch . cat (( zeros , coef ), dim = 0 ) # (num_items, num_params) coef = coef . view ( 1 , self . num_items , self . num_params ) . expand ( num_trips , - 1 , - 1 ) elif self . variation == 'item-full' : # coef has shape (num_items, num_params) coef = coef . view ( 1 , self . num_items , self . num_params ) . expand ( num_trips , - 1 , - 1 ) elif self . variation == 'user' : # coef has shape (num_users, num_params) coef = coef [ user_index , :] # (num_trips, num_params) user-specific coefficients. coef = coef . view ( num_trips , 1 , self . num_params ) . expand ( - 1 , num_items , - 1 ) elif self . variation == 'user-item' : # (num_trips,) long tensor of user ID. # originally, coef has shape (num_users, num_items-1, num_params) # transform to (num_trips, num_items - 1, num_params), user-specific. coef = coef [ user_index , :, :] # coefs for the first item for all users are enforced to 0. zeros = torch . zeros ( num_trips , 1 , self . num_params ) . to ( coef . device ) coef = torch . cat (( zeros , coef ), dim = 1 ) # (num_trips, num_items, num_params) elif self . variation == 'user-item-full' : # originally, coef has shape (num_users, num_items, num_params) coef = coef [ user_index , :, :] # (num_trips, num_items, num_params) else : raise ValueError ( f 'Unsupported type of variation: { self . variation } .' ) assert coef . shape == ( num_trips , num_items , num_feats ) == x . shape # compute the utility of each item in each trip, take summation along the feature dimension, the same as taking # the inner product. return ( x * coef ) . sum ( dim =- 1 )","title":"forward()"},{"location":"api_torch_choice/#torch_choice.model.conditional_logit_model","text":"Conditional Logit Model. Author: Tianyu Du Date: Aug. 8, 2021 Update: Apr. 28, 2022","title":"conditional_logit_model"},{"location":"api_torch_choice/#torch_choice.model.conditional_logit_model.ConditionalLogitModel","text":"The more generalized version of conditional logit model, the model allows for research specific variable types(groups) and different levels of variations for coefficient. The model allows for the following levels for variable variations: !!! note \"unless the -full flag is specified (which means we want to explicitly model coefficients\" for all items), for all variation levels related to item (item specific and user-item specific), the model force coefficients for the first item to be zero. This design follows standard econometric practice. constant: constant over all users and items, user: user-specific parameters but constant across all items, item: item-specific parameters but constant across all users, parameters for the first item are forced to be zero. item-full: item-specific parameters but constant across all users, explicitly model for all items. user-item: parameters that are specific to both user and item, parameter for the first item for all users are forced to be zero. user-item-full: parameters that are specific to both user and item, explicitly model for all items. Source code in torch_choice/model/conditional_logit_model.py class ConditionalLogitModel ( nn . Module ): \"\"\"The more generalized version of conditional logit model, the model allows for research specific variable types(groups) and different levels of variations for coefficient. The model allows for the following levels for variable variations: NOTE: unless the `-full` flag is specified (which means we want to explicitly model coefficients for all items), for all variation levels related to item (item specific and user-item specific), the model force coefficients for the first item to be zero. This design follows standard econometric practice. - constant: constant over all users and items, - user: user-specific parameters but constant across all items, - item: item-specific parameters but constant across all users, parameters for the first item are forced to be zero. - item-full: item-specific parameters but constant across all users, explicitly model for all items. - user-item: parameters that are specific to both user and item, parameter for the first item for all users are forced to be zero. - user-item-full: parameters that are specific to both user and item, explicitly model for all items. \"\"\" def __init__ ( self , coef_variation_dict : Dict [ str , str ], num_param_dict : Dict [ str , int ], num_items : Optional [ int ] = None , num_users : Optional [ int ] = None ) -> None : \"\"\" Args: num_items (int): number of items in the dataset. num_users (int): number of users in the dataset. coef_variation_dict (Dict[str, str]): variable type to variation level dictionary. Keys of this dictionary should be variable names in the dataset (i.e., these starting with `price_`, `user_`, etc), or `intercept` if the researcher requires an intercept term. For each variable name X_var (e.g., `user_income`) or `intercept`, the corresponding dictionary key should be one of the following values, this value specifies the \"level of variation\" of the coefficient. - `constant`: the coefficient constant over all users and items: $X \\beta$. - `user`: user-specific parameters but constant across all items: $X \\beta_{u}$. - `item`: item-specific parameters but constant across all users, $X \\beta_{i}$. Note that the coefficients for the first item are forced to be zero following the standard practice in econometrics. - `item-full`: the same configuration as `item`, but does not force the coefficients of the first item to be zeros. The following configurations are supported by the package, but we don't recommend using them due to the large number of parameters. - `user-item`: parameters that are specific to both user and item, parameter for the first item for all users are forced to be zero. - `user-item-full`: parameters that are specific to both user and item, explicitly model for all items. num_param_dict (Dict[str, int]): variable type to number of parameters dictionary with keys exactly the same as the `coef_variation_dict`. Values of `num_param_dict` records numbers of features in each kind of variable. \"\"\" super ( ConditionalLogitModel , self ) . __init__ () assert coef_variation_dict . keys () == num_param_dict . keys () self . variable_types = list ( deepcopy ( num_param_dict ) . keys ()) self . coef_variation_dict = deepcopy ( coef_variation_dict ) self . num_param_dict = deepcopy ( num_param_dict ) self . num_items = num_items self . num_users = num_users # check number of parameters specified are all positive. for var_type , num_params in self . num_param_dict . items (): assert num_params > 0 , f 'num_params needs to be positive, got: { num_params } .' # infer the number of parameters for intercept if the researcher forgets. if 'intercept' in self . coef_variation_dict . keys () and 'intercept' not in self . num_param_dict . keys (): warnings . warn ( \"'intercept' key found in coef_variation_dict but not in num_param_dict, num_param_dict['intercept'] has been set to 1.\" ) self . num_param_dict [ 'intercept' ] = 1 # construct trainable parameters. coef_dict = dict () for var_type , variation in self . coef_variation_dict . items (): coef_dict [ var_type ] = Coefficient ( variation = variation , num_items = self . num_items , num_users = self . num_users , num_params = self . num_param_dict [ var_type ]) # A ModuleDict is required to properly register all trainable parameters. # self.parameter() will fail if a python dictionary is used instead. self . coef_dict = nn . ModuleDict ( coef_dict ) def __repr__ ( self ) -> str : \"\"\"Return a string representation of the model. Returns: str: the string representation of the model. \"\"\" out_str_lst = [ 'Conditional logistic discrete choice model, expects input features: \\n ' ] for var_type , num_params in self . num_param_dict . items (): out_str_lst . append ( f 'X[ { var_type } ] with { num_params } parameters, with { self . coef_variation_dict [ var_type ] } level variation.' ) return super () . __repr__ () + ' \\n ' + ' \\n ' . join ( out_str_lst ) @property def num_params ( self ) -> int : \"\"\"Get the total number of parameters. For example, if there is only an user-specific coefficient to be multiplied with the K-dimensional observable, then the total number of parameters would be K x number of users, assuming no intercept is involved. Returns: int: the total number of learnable parameters. \"\"\" return sum ( w . numel () for w in self . parameters ()) def summary ( self ): \"\"\"Print out the current model parameter.\"\"\" for var_type , coefficient in self . coef_dict . items (): if coefficient is not None : print ( 'Variable Type: ' , var_type ) print ( coefficient . coef ) def forward ( self , batch : ChoiceDataset , manual_coef_value_dict : Optional [ Dict [ str , torch . Tensor ]] = None ) -> torch . Tensor : \"\"\" Forward pass of the model. Args: batch: a `ChoiceDataset` object. manual_coef_value_dict (Optional[Dict[str, torch.Tensor]], optional): a dictionary with keys in {'u', 'i'} etc and tensors as values. If provided, the model will force coefficient to be the provided values and compute utility conditioned on the provided coefficient values. This feature is useful when the research wishes to plug in particular values of coefficients and examine the utility values. If not provided, the model will use the learned coefficient values in self.coef_dict. Defaults to None. Returns: torch.Tensor: a tensor of shape (num_trips, num_items) whose (t, i) entry represents the utility from item i in trip t for the user involved in that trip. \"\"\" x_dict = batch . x_dict if 'intercept' in self . coef_variation_dict . keys (): # intercept term has no input tensor, which has only 1 feature. x_dict [ 'intercept' ] = torch . ones (( len ( batch ), self . num_items , 1 ), device = batch . device ) # compute the utility from each item in each choice session. total_utility = torch . zeros (( len ( batch ), self . num_items ), device = batch . device ) # for each type of variables, apply the corresponding coefficient to input x. for var_type , coef in self . coef_dict . items (): total_utility += coef ( x_dict [ var_type ], batch . user_index , manual_coef_value = None if manual_coef_value_dict is None else manual_coef_value_dict [ var_type ]) assert total_utility . shape == ( len ( batch ), self . num_items ) if batch . item_availability is not None : # mask out unavilable items. total_utility [ ~ batch . item_availability [ batch . session_index , :]] = torch . finfo ( total_utility . dtype ) . min / 2 return total_utility def negative_log_likelihood ( self , batch : ChoiceDataset , y : torch . Tensor , is_train : bool = True ) -> torch . Tensor : \"\"\"Computes the log-likelihood for the batch and label. TODO: consider remove y, change to label. TODO: consider move this method outside the model, the role of the model is to compute the utility. Args: batch (ChoiceDataset): a ChoiceDataset object containing the data. y (torch.Tensor): the label. is_train (bool, optional): whether to trace the gradient. Defaults to True. Returns: torch.Tensor: the negative log-likelihood. \"\"\" if is_train : self . train () else : self . eval () # (num_trips, num_items) total_utility = self . forward ( batch ) logP = torch . log_softmax ( total_utility , dim = 1 ) nll = - logP [ torch . arange ( len ( y )), y ] . sum () return nll # NOTE: the method for computing Hessian and standard deviation has been moved to std.py. # @staticmethod # def flatten_coef_dict(coef_dict: Dict[str, Union[torch.Tensor, torch.nn.Parameter]]) -> Tuple[torch.Tensor, dict]: # \"\"\"Flattens the coef_dict into a 1-dimension tensor, used for hessian computation. # Args: # coef_dict (Dict[str, Union[torch.Tensor, torch.nn.Parameter]]): a dictionary holding learnable parameters. # Returns: # Tuple[torch.Tensor, dict]: 1. the flattened tensors with shape (num_params,), 2. an indexing dictionary # used for reconstructing the original coef_dict from the flatten tensor. # \"\"\" # type2idx = dict() # param_list = list() # start = 0 # for var_type in coef_dict.keys(): # num_params = coef_dict[var_type].coef.numel() # # track which portion of all_param tensor belongs to this variable type. # type2idx[var_type] = (start, start + num_params) # start += num_params # # use reshape instead of view to make a copy. # param_list.append(coef_dict[var_type].coef.clone().reshape(-1,)) # all_param = torch.cat(param_list) # (self.num_params(), ) # return all_param, type2idx # @staticmethod # def unwrap_coef_dict(param: torch.Tensor, type2idx: Dict[str, Tuple[int, int]]) -> Dict[str, torch.Tensor]: # \"\"\"Rebuilds coef_dict from output of self.flatten_coef_dict method. # Args: # param (torch.Tensor): the flattened coef_dict from self.flatten_coef_dict. # type2idx (Dict[str, Tuple[int, int]]): the indexing dictionary from self.flatten_coef_dict. # Returns: # Dict[str, torch.Tensor]: the re-constructed coefficient dictionary. # \"\"\" # coef_dict = dict() # for var_type in type2idx.keys(): # start, end = type2idx[var_type] # # no need to reshape here, Coefficient handles it. # coef_dict[var_type] = param[start:end] # return coef_dict # def compute_hessian(self, x_dict, availability, user_index, y) -> torch.Tensor: # \"\"\"Computes the Hessian of negative log-likelihood (total cross-entropy loss) with respect # to all parameters in this model. The Hessian can be later used for constructing the standard deviation of # parameters. # Args: # x_dict ,availability, user_index: see definitions in self.forward method. # y (torch.LongTensor): a tensor with shape (num_trips,) of IDs of items actually purchased. # Returns: # torch.Tensor: a (self.num_params, self.num_params) tensor of the Hessian matrix. # \"\"\" # all_coefs, type2idx = self.flatten_coef_dict(self.coef_dict) # def compute_nll(P: torch.Tensor) -> float: # coef_dict = self.unwrap_coef_dict(P, type2idx) # y_pred = self._forward(x_dict=x_dict, # availability=availability, # user_index=user_index, # manual_coef_value_dict=coef_dict) # # the reduction needs to be 'sum' to obtain NLL. # loss = F.cross_entropy(y_pred, y, reduction='sum') # return loss # H = torch.autograd.functional.hessian(compute_nll, all_coefs) # assert H.shape == (self.num_params, self.num_params) # return H # def compute_std(self, x_dict, availability, user_index, y) -> Dict[str, torch.Tensor]: # \"\"\"Computes # Args:f # See definitions in self.compute_hessian. # Returns: # Dict[str, torch.Tensor]: a dictionary whose keys are the same as self.coef_dict.keys() # the values are standard errors of coefficients in each coefficient group. # \"\"\" # _, type2idx = self.flatten_coef_dict(self.coef_dict) # H = self.compute_hessian(x_dict, availability, user_index, y) # std_all = torch.sqrt(torch.diag(torch.inverse(H))) # std_dict = dict() # for var_type in type2idx.keys(): # # get std of variables belonging to each type. # start, end = type2idx[var_type] # std_dict[var_type] = std_all[start:end] # return std_dict","title":"ConditionalLogitModel"},{"location":"api_torch_choice/#torch_choice.model.conditional_logit_model.ConditionalLogitModel.num_params","text":"Get the total number of parameters. For example, if there is only an user-specific coefficient to be multiplied with the K-dimensional observable, then the total number of parameters would be K x number of users, assuming no intercept is involved. Returns: Type Description int the total number of learnable parameters.","title":"num_params"},{"location":"api_torch_choice/#torch_choice.model.conditional_logit_model.ConditionalLogitModel.__init__","text":"Parameters: Name Type Description Default num_items int number of items in the dataset. None num_users int number of users in the dataset. None coef_variation_dict Dict[str, str] variable type to variation level dictionary. Keys of this dictionary should be variable names in the dataset (i.e., these starting with price_ , user_ , etc), or intercept if the researcher requires an intercept term. For each variable name X_var (e.g., user_income ) or intercept , the corresponding dictionary key should be one of the following values, this value specifies the \"level of variation\" of the coefficient. constant : the coefficient constant over all users and items: \\(X \beta\\) . user : user-specific parameters but constant across all items: \\(X \beta_{u}\\) . item : item-specific parameters but constant across all users, \\(X \beta_{i}\\) . Note that the coefficients for the first item are forced to be zero following the standard practice in econometrics. item-full : the same configuration as item , but does not force the coefficients of the first item to be zeros. The following configurations are supported by the package, but we don't recommend using them due to the large number of parameters. - user-item : parameters that are specific to both user and item, parameter for the first item for all users are forced to be zero. user-item-full : parameters that are specific to both user and item, explicitly model for all items. required num_param_dict Dict[str, int] variable type to number of parameters dictionary with keys exactly the same as the coef_variation_dict . Values of num_param_dict records numbers of features in each kind of variable. required Source code in torch_choice/model/conditional_logit_model.py def __init__ ( self , coef_variation_dict : Dict [ str , str ], num_param_dict : Dict [ str , int ], num_items : Optional [ int ] = None , num_users : Optional [ int ] = None ) -> None : \"\"\" Args: num_items (int): number of items in the dataset. num_users (int): number of users in the dataset. coef_variation_dict (Dict[str, str]): variable type to variation level dictionary. Keys of this dictionary should be variable names in the dataset (i.e., these starting with `price_`, `user_`, etc), or `intercept` if the researcher requires an intercept term. For each variable name X_var (e.g., `user_income`) or `intercept`, the corresponding dictionary key should be one of the following values, this value specifies the \"level of variation\" of the coefficient. - `constant`: the coefficient constant over all users and items: $X \\beta$. - `user`: user-specific parameters but constant across all items: $X \\beta_{u}$. - `item`: item-specific parameters but constant across all users, $X \\beta_{i}$. Note that the coefficients for the first item are forced to be zero following the standard practice in econometrics. - `item-full`: the same configuration as `item`, but does not force the coefficients of the first item to be zeros. The following configurations are supported by the package, but we don't recommend using them due to the large number of parameters. - `user-item`: parameters that are specific to both user and item, parameter for the first item for all users are forced to be zero. - `user-item-full`: parameters that are specific to both user and item, explicitly model for all items. num_param_dict (Dict[str, int]): variable type to number of parameters dictionary with keys exactly the same as the `coef_variation_dict`. Values of `num_param_dict` records numbers of features in each kind of variable. \"\"\" super ( ConditionalLogitModel , self ) . __init__ () assert coef_variation_dict . keys () == num_param_dict . keys () self . variable_types = list ( deepcopy ( num_param_dict ) . keys ()) self . coef_variation_dict = deepcopy ( coef_variation_dict ) self . num_param_dict = deepcopy ( num_param_dict ) self . num_items = num_items self . num_users = num_users # check number of parameters specified are all positive. for var_type , num_params in self . num_param_dict . items (): assert num_params > 0 , f 'num_params needs to be positive, got: { num_params } .' # infer the number of parameters for intercept if the researcher forgets. if 'intercept' in self . coef_variation_dict . keys () and 'intercept' not in self . num_param_dict . keys (): warnings . warn ( \"'intercept' key found in coef_variation_dict but not in num_param_dict, num_param_dict['intercept'] has been set to 1.\" ) self . num_param_dict [ 'intercept' ] = 1 # construct trainable parameters. coef_dict = dict () for var_type , variation in self . coef_variation_dict . items (): coef_dict [ var_type ] = Coefficient ( variation = variation , num_items = self . num_items , num_users = self . num_users , num_params = self . num_param_dict [ var_type ]) # A ModuleDict is required to properly register all trainable parameters. # self.parameter() will fail if a python dictionary is used instead. self . coef_dict = nn . ModuleDict ( coef_dict )","title":"__init__()"},{"location":"api_torch_choice/#torch_choice.model.conditional_logit_model.ConditionalLogitModel.__repr__","text":"Return a string representation of the model. Returns: Type Description str the string representation of the model. Source code in torch_choice/model/conditional_logit_model.py def __repr__ ( self ) -> str : \"\"\"Return a string representation of the model. Returns: str: the string representation of the model. \"\"\" out_str_lst = [ 'Conditional logistic discrete choice model, expects input features: \\n ' ] for var_type , num_params in self . num_param_dict . items (): out_str_lst . append ( f 'X[ { var_type } ] with { num_params } parameters, with { self . coef_variation_dict [ var_type ] } level variation.' ) return super () . __repr__ () + ' \\n ' + ' \\n ' . join ( out_str_lst )","title":"__repr__()"},{"location":"api_torch_choice/#torch_choice.model.conditional_logit_model.ConditionalLogitModel.forward","text":"Forward pass of the model. Parameters: Name Type Description Default batch ChoiceDataset a ChoiceDataset object. required manual_coef_value_dict Optional[Dict[str, torch.Tensor]] a dictionary with keys in {'u', 'i'} etc and tensors as values. If provided, the model will force coefficient to be the provided values and compute utility conditioned on the provided coefficient values. This feature is useful when the research wishes to plug in particular values of coefficients and examine the utility values. If not provided, the model will use the learned coefficient values in self.coef_dict. Defaults to None. None Returns: Type Description torch.Tensor a tensor of shape (num_trips, num_items) whose (t, i) entry represents the utility from item i in trip t for the user involved in that trip. Source code in torch_choice/model/conditional_logit_model.py def forward ( self , batch : ChoiceDataset , manual_coef_value_dict : Optional [ Dict [ str , torch . Tensor ]] = None ) -> torch . Tensor : \"\"\" Forward pass of the model. Args: batch: a `ChoiceDataset` object. manual_coef_value_dict (Optional[Dict[str, torch.Tensor]], optional): a dictionary with keys in {'u', 'i'} etc and tensors as values. If provided, the model will force coefficient to be the provided values and compute utility conditioned on the provided coefficient values. This feature is useful when the research wishes to plug in particular values of coefficients and examine the utility values. If not provided, the model will use the learned coefficient values in self.coef_dict. Defaults to None. Returns: torch.Tensor: a tensor of shape (num_trips, num_items) whose (t, i) entry represents the utility from item i in trip t for the user involved in that trip. \"\"\" x_dict = batch . x_dict if 'intercept' in self . coef_variation_dict . keys (): # intercept term has no input tensor, which has only 1 feature. x_dict [ 'intercept' ] = torch . ones (( len ( batch ), self . num_items , 1 ), device = batch . device ) # compute the utility from each item in each choice session. total_utility = torch . zeros (( len ( batch ), self . num_items ), device = batch . device ) # for each type of variables, apply the corresponding coefficient to input x. for var_type , coef in self . coef_dict . items (): total_utility += coef ( x_dict [ var_type ], batch . user_index , manual_coef_value = None if manual_coef_value_dict is None else manual_coef_value_dict [ var_type ]) assert total_utility . shape == ( len ( batch ), self . num_items ) if batch . item_availability is not None : # mask out unavilable items. total_utility [ ~ batch . item_availability [ batch . session_index , :]] = torch . finfo ( total_utility . dtype ) . min / 2 return total_utility","title":"forward()"},{"location":"api_torch_choice/#torch_choice.model.conditional_logit_model.ConditionalLogitModel.negative_log_likelihood","text":"Computes the log-likelihood for the batch and label. TODO: consider remove y, change to label. TODO: consider move this method outside the model, the role of the model is to compute the utility. Parameters: Name Type Description Default batch ChoiceDataset a ChoiceDataset object containing the data. required y torch.Tensor the label. required is_train bool whether to trace the gradient. Defaults to True. True Returns: Type Description torch.Tensor the negative log-likelihood. Source code in torch_choice/model/conditional_logit_model.py def negative_log_likelihood ( self , batch : ChoiceDataset , y : torch . Tensor , is_train : bool = True ) -> torch . Tensor : \"\"\"Computes the log-likelihood for the batch and label. TODO: consider remove y, change to label. TODO: consider move this method outside the model, the role of the model is to compute the utility. Args: batch (ChoiceDataset): a ChoiceDataset object containing the data. y (torch.Tensor): the label. is_train (bool, optional): whether to trace the gradient. Defaults to True. Returns: torch.Tensor: the negative log-likelihood. \"\"\" if is_train : self . train () else : self . eval () # (num_trips, num_items) total_utility = self . forward ( batch ) logP = torch . log_softmax ( total_utility , dim = 1 ) nll = - logP [ torch . arange ( len ( y )), y ] . sum () return nll","title":"negative_log_likelihood()"},{"location":"api_torch_choice/#torch_choice.model.conditional_logit_model.ConditionalLogitModel.summary","text":"Print out the current model parameter. Source code in torch_choice/model/conditional_logit_model.py def summary ( self ): \"\"\"Print out the current model parameter.\"\"\" for var_type , coefficient in self . coef_dict . items (): if coefficient is not None : print ( 'Variable Type: ' , var_type ) print ( coefficient . coef )","title":"summary()"},{"location":"api_torch_choice/#torch_choice.model.nested_logit_model","text":"Implementation of the nested logit model, see page 86 of the book \"discrete choice methods with simulation\" by Train. for more details. Author: Tianyu Du Update; Apr. 28, 2022","title":"nested_logit_model"},{"location":"api_torch_choice/#torch_choice.model.nested_logit_model.NestedLogitModel","text":"Source code in torch_choice/model/nested_logit_model.py class NestedLogitModel ( nn . Module ): def __init__ ( self , category_to_item : Dict [ object , List [ int ]], category_coef_variation_dict : Dict [ str , str ], category_num_param_dict : Dict [ str , int ], item_coef_variation_dict : Dict [ str , str ], item_num_param_dict : Dict [ str , int ], num_users : Optional [ int ] = None , shared_lambda : bool = False ) -> None : \"\"\"Initialization method of the nested logit model. Args: category_to_item (Dict[object, List[int]]): a dictionary maps a category ID to a list of items IDs of the queried category. category_coef_variation_dict (Dict[str, str]): a dictionary maps a variable type (i.e., variable group) to the level of variation for the coefficient of this type of variables. category_num_param_dict (Dict[str, int]): a dictionary maps a variable type name to the number of parameters in this variable group. item_coef_variation_dict (Dict[str, str]): the same as category_coef_variation_dict but for item features. item_num_param_dict (Dict[str, int]): the same as category_num_param_dict but for item features. num_users (Optional[int], optional): number of users to be modelled, this is only required if any of variable type requires user-specific variations. Defaults to None. shared_lambda (bool): a boolean indicating whether to enforce the elasticity lambda, which is the coefficient for inclusive values, to be constant for all categories. The lambda enters the category-level selection as the following Utility of choosing category k = lambda * inclusive value of category k + linear combination of some other category level features If set to True, a single lambda will be learned for all categories, otherwise, the model learns an individual lambda for each category. Defaults to False. \"\"\" super ( NestedLogitModel , self ) . __init__ () self . category_to_item = category_to_item self . category_coef_variation_dict = category_coef_variation_dict self . category_num_param_dict = category_num_param_dict self . item_coef_variation_dict = item_coef_variation_dict self . item_num_param_dict = item_num_param_dict self . num_users = num_users self . categories = list ( category_to_item . keys ()) self . num_categories = len ( self . categories ) self . num_items = sum ( len ( items ) for items in category_to_item . values ()) # category coefficients. self . category_coef_dict = self . _build_coef_dict ( self . category_coef_variation_dict , self . category_num_param_dict , self . num_categories ) # item coefficients. self . item_coef_dict = self . _build_coef_dict ( self . item_coef_variation_dict , self . item_num_param_dict , self . num_items ) self . shared_lambda = shared_lambda if self . shared_lambda : self . lambda_weight = nn . Parameter ( torch . ones ( 1 ), requires_grad = True ) else : self . lambda_weight = nn . Parameter ( torch . ones ( self . num_categories ) / 2 , requires_grad = True ) # breakpoint() # self.iv_weights = nn.Parameter(torch.ones(1), requires_grad=True) # used to warn users if forgot to call clamp. self . _clamp_called_flag = True @property def num_params ( self ) -> int : \"\"\"Get the total number of parameters. For example, if there is only an user-specific coefficient to be multiplied with the K-dimensional observable, then the total number of parameters would be K x number of users, assuming no intercept is involved. Returns: int: the total number of learnable parameters. \"\"\" return sum ( w . numel () for w in self . parameters ()) def _build_coef_dict ( self , coef_variation_dict : Dict [ str , str ], num_param_dict : Dict [ str , int ], num_items : int ) -> nn . ModuleDict : \"\"\"Builds a coefficient dictionary containing all trainable components of the model, mapping coefficient names to the corresponding Coefficient Module. num_items could be the actual number of items or the number of categories depends on the use case. NOTE: torch-choice users don't directly interact with this method. Args: coef_variation_dict (Dict[str, str]): a dictionary mapping coefficient names (e.g., theta_user) to the level of variation (e.g., 'user'). num_param_dict (Dict[str, int]): a dictionary mapping coefficient names to the number of parameters in this coefficient. Be aware that, for example, if there is one K-dimensional coefficient for every user, then the `num_param` should be K instead of K x number of users. num_items (int): the total number of items in the prediction problem. `num_items` should be the number of categories if _build_coef_dict() is used for category-level prediction. Returns: nn.ModuleDict: a PyTorch ModuleDict object mapping from coefficient names to training Coefficient. \"\"\" coef_dict = dict () for var_type , variation in coef_variation_dict . items (): num_params = num_param_dict [ var_type ] coef_dict [ var_type ] = Coefficient ( variation = variation , num_items = num_items , num_users = self . num_users , num_params = num_params ) return nn . ModuleDict ( coef_dict ) # def _check_input_shapes(self, category_x_dict, item_x_dict, user_index, item_availability) -> None: # T = list(category_x_dict.values())[0].shape[0] # batch size. # for var_type, x_category in category_x_dict.items(): # x_item = item_x_dict[var_type] # assert len(x_item.shape) == len(x_item.shape) == 3 # assert x_category.shape[0] == x_item.shape[0] # assert x_category.shape == (T, self.num_categories, self.category_num_param_dict[var_type]) # assert x_item.shape == (T, self.num_items, self.item_num_param_dict[var_type]) # if (user_index is not None) and (self.num_users is not None): # assert user_index.shape == (T,) # if item_availability is not None: # assert item_availability.shape == (T, self.num_items) def forward ( self , batch : ChoiceDataset ) -> torch . Tensor : \"\"\"An standard forward method for the model, the user feeds a ChoiceDataset batch and the model returns the predicted log-likelihood tensor. The main forward passing happens in the _forward() method, but we provide this wrapper forward() method for a cleaner API, as forward() only requires a single batch argument. For more details about the forward passing, please refer to the _forward() method. # TODO: the ConditionaLogitModel returns predicted utility, the NestedLogitModel behaves the same? Args: batch (ChoiceDataset): a ChoiceDataset object containing the data batch. Returns: torch.Tensor: a tensor of shape (num_trips, num_items) including the log probability of choosing item i in trip t. \"\"\" return self . _forward ( batch [ 'category' ] . x_dict , batch [ 'item' ] . x_dict , batch [ 'item' ] . user_index , batch [ 'item' ] . item_availability ) def _forward ( self , category_x_dict : Dict [ str , torch . Tensor ], item_x_dict : Dict [ str , torch . Tensor ], user_index : Optional [ torch . LongTensor ] = None , item_availability : Optional [ torch . BoolTensor ] = None ) -> torch . Tensor : \"\"\"\"Computes log P[t, i] = the log probability for the user involved in trip t to choose item i. Let n denote the ID of the user involved in trip t, then P[t, i] = P_{ni} on page 86 of the book \"discrete choice methods with simulation\" by Train. Args: x_category (torch.Tensor): a tensor with shape (num_trips, num_categories, *) including features of all categories in each trip. x_item (torch.Tensor): a tensor with shape (num_trips, num_items, *) including features of all items in each trip. user_index (torch.LongTensor): a tensor of shape (num_trips,) indicating which user is making decision in each trip. Setting user_index = None assumes the same user is making decisions in all trips. item_availability (torch.BoolTensor): a boolean tensor with shape (num_trips, num_items) indicating the aviliability of items in each trip. If item_availability[t, i] = False, the utility of choosing item i in trip t, V[t, i], will be set to -inf. Given the decomposition V[t, i] = W[t, k(i)] + Y[t, i] + eps, V[t, i] is set to -inf by setting Y[t, i] = -inf for unavilable items. Returns: torch.Tensor: a tensor of shape (num_trips, num_items) including the log probability of choosing item i in trip t. \"\"\" if self . shared_lambda : self . lambdas = self . lambda_weight . expand ( self . num_categories ) else : self . lambdas = self . lambda_weight # if not self._clamp_called_flag: # warnings.warn('Did you forget to call clamp_lambdas() after optimizer.step()?') # The overall utility of item can be decomposed into V[item] = W[category] + Y[item] + eps. T = list ( item_x_dict . values ())[ 0 ] . shape [ 0 ] device = list ( item_x_dict . values ())[ 0 ] . device # compute category-specific utility with shape (T, num_categories). W = torch . zeros ( T , self . num_categories ) . to ( device ) if 'intercept' in self . category_coef_variation_dict . keys (): category_x_dict [ 'intercept' ] = torch . ones (( T , self . num_categories , 1 )) . to ( device ) for var_type , coef in self . category_coef_dict . items (): W += coef ( category_x_dict [ var_type ], user_index ) # compute item-specific utility (T, num_items). Y = torch . zeros ( T , self . num_items ) . to ( device ) for var_type , coef in self . item_coef_dict . items (): Y += coef ( item_x_dict [ var_type ], user_index ) if item_availability is not None : Y [ ~ item_availability ] = torch . finfo ( Y . dtype ) . min / 2 # ============================================================================= # compute the inclusive value of each category. inclusive_value = dict () for k , Bk in self . category_to_item . items (): # for nest k, divide the Y of all items in Bk by lambda_k. Y [:, Bk ] /= self . lambdas [ k ] # compute inclusive value for category k. # mask out unavilable items. inclusive_value [ k ] = torch . logsumexp ( Y [:, Bk ], dim = 1 , keepdim = False ) # (T,) # boardcast inclusive value from (T, num_categories) to (T, num_items). # for trip t, I[t, i] is the inclusive value of the category item i belongs to. I = torch . zeros ( T , self . num_items ) . to ( device ) for k , Bk in self . category_to_item . items (): I [:, Bk ] = inclusive_value [ k ] . view ( - 1 , 1 ) # (T, |Bk|) # logP_item[t, i] = log P(ni|Bk), where Bk is the category item i is in, n is the user in trip t. logP_item = Y - I # (T, num_items) # ============================================================================= # logP_category[t, i] = log P(Bk), for item i in trip t, the probability of choosing the nest/bucket # item i belongs to. logP_category has shape (T, num_items) # logit[t, i] = W[n, k] + lambda[k] I[n, k], where n is the user involved in trip t, k is # the category item i belongs to. logit = torch . zeros ( T , self . num_items ) . to ( device ) for k , Bk in self . category_to_item . items (): logit [:, Bk ] = ( W [:, k ] + self . lambdas [ k ] * inclusive_value [ k ]) . view ( - 1 , 1 ) # (T, |Bk|) # only count each category once in the logsumexp within the category level model. cols = [ x [ 0 ] for x in self . category_to_item . values ()] logP_category = logit - torch . logsumexp ( logit [:, cols ], dim = 1 , keepdim = True ) # ============================================================================= # compute the joint log P_{ni} as in the textbook. logP = logP_item + logP_category self . _clamp_called_flag = False return logP def log_likelihood ( self , * args ): \"\"\"Computes the log likelihood of the model, please refer to the negative_log_likelihood() method. Returns: _type_: the log likelihood of the model. \"\"\" return - self . negative_log_likelihood ( * args ) def negative_log_likelihood ( self , batch : ChoiceDataset , y : torch . LongTensor , is_train : bool = True ) -> torch . scalar_tensor : \"\"\"Computes the negative log likelihood of the model. Please note the log-likelihood is summed over all samples in batch instead of the average. Args: batch (ChoiceDataset): the ChoiceDataset object containing the data. y (torch.LongTensor): the label. is_train (bool, optional): which mode of the model to be used for the forward passing, if we need Hessian of the NLL through auto-grad, `is_train` should be set to True. If we merely need a performance metric, then `is_train` can be set to False for better performance. Defaults to True. Returns: torch.scalar_tensor: the negative log likelihood of the model. \"\"\" # compute the negative log-likelihood loss directly. if is_train : self . train () else : self . eval () # (num_trips, num_items) logP = self . forward ( batch ) nll = - logP [ torch . arange ( len ( y )), y ] . sum () return nll # def clamp_lambdas(self): # \"\"\" # Restrict values of lambdas to 0 < lambda <= 1 to guarantee the utility maximization property # of the model. # This method should be called everytime after optimizer.step(). # We add a self_clamp_called_flag to remind researchers if this method is not called. # \"\"\" # for k in range(len(self.lambdas)): # self.lambdas[k] = torch.clamp(self.lambdas[k], 1e-5, 1) # self._clam_called_flag = True # @staticmethod # def add_constant(x: torch.Tensor, where: str='prepend') -> torch.Tensor: # \"\"\"A helper function used to add constant to feature tensor, # x has shape (batch_size, num_classes, num_parameters), # returns a tensor of shape (*, num_parameters+1). # \"\"\" # batch_size, num_classes, num_parameters = x.shape # ones = torch.ones((batch_size, num_classes, 1)) # if where == 'prepend': # new = torch.cat((ones, x), dim=-1) # elif where == 'append': # new = torch.cat((x, ones), dim=-1) # else: # raise Exception # return new","title":"NestedLogitModel"},{"location":"api_torch_choice/#torch_choice.model.nested_logit_model.NestedLogitModel.num_params","text":"Get the total number of parameters. For example, if there is only an user-specific coefficient to be multiplied with the K-dimensional observable, then the total number of parameters would be K x number of users, assuming no intercept is involved. Returns: Type Description int the total number of learnable parameters.","title":"num_params"},{"location":"api_torch_choice/#torch_choice.model.nested_logit_model.NestedLogitModel.__init__","text":"Initialization method of the nested logit model. Parameters: Name Type Description Default category_to_item Dict[object, List[int]] a dictionary maps a category ID to a list of items IDs of the queried category. required category_coef_variation_dict Dict[str, str] a dictionary maps a variable type (i.e., variable group) to the level of variation for the coefficient of this type of variables. required category_num_param_dict Dict[str, int] a dictionary maps a variable type name to the number of parameters in this variable group. required item_coef_variation_dict Dict[str, str] the same as category_coef_variation_dict but for item features. required item_num_param_dict Dict[str, int] the same as category_num_param_dict but for item features. required num_users Optional[int] number of users to be modelled, this is only required if any of variable type requires user-specific variations. Defaults to None. None shared_lambda bool a boolean indicating whether to enforce the elasticity lambda, which is the coefficient for inclusive values, to be constant for all categories. The lambda enters the category-level selection as the following Utility of choosing category k = lambda * inclusive value of category k + linear combination of some other category level features If set to True, a single lambda will be learned for all categories, otherwise, the model learns an individual lambda for each category. Defaults to False. False Source code in torch_choice/model/nested_logit_model.py def __init__ ( self , category_to_item : Dict [ object , List [ int ]], category_coef_variation_dict : Dict [ str , str ], category_num_param_dict : Dict [ str , int ], item_coef_variation_dict : Dict [ str , str ], item_num_param_dict : Dict [ str , int ], num_users : Optional [ int ] = None , shared_lambda : bool = False ) -> None : \"\"\"Initialization method of the nested logit model. Args: category_to_item (Dict[object, List[int]]): a dictionary maps a category ID to a list of items IDs of the queried category. category_coef_variation_dict (Dict[str, str]): a dictionary maps a variable type (i.e., variable group) to the level of variation for the coefficient of this type of variables. category_num_param_dict (Dict[str, int]): a dictionary maps a variable type name to the number of parameters in this variable group. item_coef_variation_dict (Dict[str, str]): the same as category_coef_variation_dict but for item features. item_num_param_dict (Dict[str, int]): the same as category_num_param_dict but for item features. num_users (Optional[int], optional): number of users to be modelled, this is only required if any of variable type requires user-specific variations. Defaults to None. shared_lambda (bool): a boolean indicating whether to enforce the elasticity lambda, which is the coefficient for inclusive values, to be constant for all categories. The lambda enters the category-level selection as the following Utility of choosing category k = lambda * inclusive value of category k + linear combination of some other category level features If set to True, a single lambda will be learned for all categories, otherwise, the model learns an individual lambda for each category. Defaults to False. \"\"\" super ( NestedLogitModel , self ) . __init__ () self . category_to_item = category_to_item self . category_coef_variation_dict = category_coef_variation_dict self . category_num_param_dict = category_num_param_dict self . item_coef_variation_dict = item_coef_variation_dict self . item_num_param_dict = item_num_param_dict self . num_users = num_users self . categories = list ( category_to_item . keys ()) self . num_categories = len ( self . categories ) self . num_items = sum ( len ( items ) for items in category_to_item . values ()) # category coefficients. self . category_coef_dict = self . _build_coef_dict ( self . category_coef_variation_dict , self . category_num_param_dict , self . num_categories ) # item coefficients. self . item_coef_dict = self . _build_coef_dict ( self . item_coef_variation_dict , self . item_num_param_dict , self . num_items ) self . shared_lambda = shared_lambda if self . shared_lambda : self . lambda_weight = nn . Parameter ( torch . ones ( 1 ), requires_grad = True ) else : self . lambda_weight = nn . Parameter ( torch . ones ( self . num_categories ) / 2 , requires_grad = True ) # breakpoint() # self.iv_weights = nn.Parameter(torch.ones(1), requires_grad=True) # used to warn users if forgot to call clamp. self . _clamp_called_flag = True","title":"__init__()"},{"location":"api_torch_choice/#torch_choice.model.nested_logit_model.NestedLogitModel.forward","text":"An standard forward method for the model, the user feeds a ChoiceDataset batch and the model returns the predicted log-likelihood tensor. The main forward passing happens in the _forward() method, but we provide this wrapper forward() method for a cleaner API, as forward() only requires a single batch argument. For more details about the forward passing, please refer to the _forward() method.","title":"forward()"},{"location":"api_torch_choice/#torch_choice.model.nested_logit_model.NestedLogitModel.forward--todo-the-conditionalogitmodel-returns-predicted-utility-the-nestedlogitmodel-behaves-the-same","text":"Parameters: Name Type Description Default batch ChoiceDataset a ChoiceDataset object containing the data batch. required Returns: Type Description torch.Tensor a tensor of shape (num_trips, num_items) including the log probability of choosing item i in trip t. Source code in torch_choice/model/nested_logit_model.py def forward ( self , batch : ChoiceDataset ) -> torch . Tensor : \"\"\"An standard forward method for the model, the user feeds a ChoiceDataset batch and the model returns the predicted log-likelihood tensor. The main forward passing happens in the _forward() method, but we provide this wrapper forward() method for a cleaner API, as forward() only requires a single batch argument. For more details about the forward passing, please refer to the _forward() method. # TODO: the ConditionaLogitModel returns predicted utility, the NestedLogitModel behaves the same? Args: batch (ChoiceDataset): a ChoiceDataset object containing the data batch. Returns: torch.Tensor: a tensor of shape (num_trips, num_items) including the log probability of choosing item i in trip t. \"\"\" return self . _forward ( batch [ 'category' ] . x_dict , batch [ 'item' ] . x_dict , batch [ 'item' ] . user_index , batch [ 'item' ] . item_availability )","title":"TODO: the ConditionaLogitModel returns predicted utility, the NestedLogitModel behaves the same?"},{"location":"api_torch_choice/#torch_choice.model.nested_logit_model.NestedLogitModel.log_likelihood","text":"Computes the log likelihood of the model, please refer to the negative_log_likelihood() method. Returns: Type Description _type_ the log likelihood of the model. Source code in torch_choice/model/nested_logit_model.py def log_likelihood ( self , * args ): \"\"\"Computes the log likelihood of the model, please refer to the negative_log_likelihood() method. Returns: _type_: the log likelihood of the model. \"\"\" return - self . negative_log_likelihood ( * args )","title":"log_likelihood()"},{"location":"api_torch_choice/#torch_choice.model.nested_logit_model.NestedLogitModel.negative_log_likelihood","text":"Computes the negative log likelihood of the model. Please note the log-likelihood is summed over all samples in batch instead of the average. Parameters: Name Type Description Default batch ChoiceDataset the ChoiceDataset object containing the data. required y torch.LongTensor the label. required is_train bool which mode of the model to be used for the forward passing, if we need Hessian of the NLL through auto-grad, is_train should be set to True. If we merely need a performance metric, then is_train can be set to False for better performance. Defaults to True. True Returns: Type Description torch.scalar_tensor the negative log likelihood of the model. Source code in torch_choice/model/nested_logit_model.py def negative_log_likelihood ( self , batch : ChoiceDataset , y : torch . LongTensor , is_train : bool = True ) -> torch . scalar_tensor : \"\"\"Computes the negative log likelihood of the model. Please note the log-likelihood is summed over all samples in batch instead of the average. Args: batch (ChoiceDataset): the ChoiceDataset object containing the data. y (torch.LongTensor): the label. is_train (bool, optional): which mode of the model to be used for the forward passing, if we need Hessian of the NLL through auto-grad, `is_train` should be set to True. If we merely need a performance metric, then `is_train` can be set to False for better performance. Defaults to True. Returns: torch.scalar_tensor: the negative log likelihood of the model. \"\"\" # compute the negative log-likelihood loss directly. if is_train : self . train () else : self . eval () # (num_trips, num_items) logP = self . forward ( batch ) nll = - logP [ torch . arange ( len ( y )), y ] . sum () return nll","title":"negative_log_likelihood()"},{"location":"bemb/","text":"BEMB Tutorial This tutorial assumes the reader has ready gone through the Data Management tutorial. Through this tutorial, we use Greek letters (except for \\(\\varepsilon\\) as error term) to denote learnable coefficients of the model. However, researchers are not restricted to use Greek letters in practice. Bayesian EMBedding (BEMB) is a hierarchical Bayesian model for modelling consumer choices. The model can naturally extend to other use cases which can be formulated into the consumer choice framework. For example, in a job-transition modelling study, we formulated the starting job as the user and ending job as the item and applied the BEMB framework. Suppose we have a dataset of purchase records consisting of \\(U\\) users, \\(I\\) items, and \\(S\\) sessions, at it's core (assume no \\(s\\) -level effect for now), the BEMB model aims to build user embeddings \\(\\theta_u \\in \\mathbb{R}^{L}\\) and item embeddings \\(\\alpha_i \\in \\mathbb{R}^{L}\\) , then the model predicts the probability for user \\(u\\) to purchase item \\(i\\) as $$ P(i|u,s) \\propto \\theta_u^\\top \\alpha_i. $$ Both of \\(\\theta_u\\) and \\(\\alpha_i\\) are Bayesian , which means there is a prior distribution and a variational distribution associated with each of them. By default, the prior distribution of all entries of \\(\\theta_u\\) and \\(\\alpha_i\\) are i.i.d. standard Gaussian distributions. The variational distributions are Gaussian with learnable mean and standard deviation, these parameters are trained by minimizing the ELBO so that the predicted purchasing probabilities best fit the observed dataset. TODO : add reference to the paper introducing BEMB for a complete description of the model. Running BEMB Running BEMB requires you to (1) build the ChoiceDataset object and (2) training the model. The ChoiceDataset Please refer to the Data Management tutorial for a detailed walk-through of how to constructing the dataset. For simplicity, we assume that item/user/session/price observables are named as {item, user, session, price}_obs in the ChoiceDataset , the researcher can use arbitrary variable names as long as they satisfy the naming convention (e.g., user-level observables should start with user_ and cannot be user_index ) and have the correct shape (e.g., user-level observables should have shape (num_users, num_obs) ). Setup the BEMB Model (PyTorch-Lightning Interface) You will be constructing the LitBEMBFlex class, which is a PyTorch-lightning wrapper of the BEMB model implemented in plain PyTorch. The lighting wrapper free researchers from complications such as setting up the training loop and optimizers. To initialize the LitBEMBFlex class, the researcher needs to provide it with the following arguments. We recommend the research to encompass all arguments in a separate yaml file. Most of these arguments should be self explanatory, Please refer to the doc string of BEMBFlex.__init__() for a detailed elaboration. Utility Formula: utility_formula Note : for the string parsing to work correctly, please do add spaces around + and * . This section covers how to convert the utility representation in a choice problem into the utility_formula argument of the BEMBFlex model and LitBEMBFlex wrapper. The core of specifying a BEMB model is to specify the utility function \\(\\mathcal{U}(u,i,s)\\) for user \\(u\\) to purchase item \\(i\\) in session \\(s\\) , the bemb package provides an easy-to-use string-parsing mechanism for researchers to provide their ideal utility representations. With the utility representation, the probability for consumer \\(u\\) to purchase item \\(i\\) in session \\(s\\) is the following \\[ P(i|u,s) = \\frac{e^{\\mathcal{U}(u, i, s)}}{\\sum_{i' \\in I_c} e^{\\mathcal{U}(u, i', s)}} \\] where \\(I_c\\) is the set of items in the same category of item \\(i\\) . If there is no category information, the model considers all items to be in the same category, i.e., \\(I_c = \\{1, 2, \\dots I\\}\\) . The BEMB admits a linear additive form of utility formula. For example, the model parses utility formula string lambda_item + theta_user * alpha_item + zeta_user * item_obs into the following representation: \\[ \\mathcal{U}(u, i, s)= \\lambda_i + \\theta_u^\\top \\alpha_i + \\zeta_u^\\top X^{item}_i + \\varepsilon \\in \\mathbb{R} \\] The utility_formula consists of two classes of objects: 1. learnable coefficients (i.e., Greek letters): the string-parser identifies learnable coefficients by looking at their suffix. These variables can be (1) constant across all items and users, (2) user-specific, or (3) item-specific. For example, the \\(\\lambda_i\\) term above is item-specific intercept and it is presented as item_item in the utility_formula . To ensure the string-parsing is working properly, learnable coefficients must ends with one of {_item, _user, _constant} . 2. Observable Tensors are identified by their prefix, which tells whether they are item-specific (with item_ prefix), user-specific (with user_ prefix), session-specific (with session_ prefix), or session-and-item-specific (with price_ prefix) observables. Each of these observables should present in the ChoiceDataset data structure constructed. Warning : the utility_formula parser identifies learnable coefficients as using suffix and observables using prefix, the researcher should never name things with both prefix in {user_, item_, session_, price_} and suffix {_constant, _user, _item} such as item_quality_user . Overall, there are four types of additive component, except the error term \\(\\epsilon\\) , in the utility representation: Standalone coefficients \\(\\lambda, \\lambda_i, \\lambda_u \\in \\mathbb{R}\\) representing intercepts and item/user level fixed effects. \u201cMatrix factorization\u201d coefficients \\(\\theta_u^\\top \\alpha_i\\) , where \\(\\theta_u,\\alpha_i \\in \\mathbb{R}^L\\) are embedding/latent of users and items, \\(L\\) is the latent dimension specified by the researcher. Observable terms \\(\\zeta_u^\\top X^{item}_i\\) , where each \\(\\zeta_u \\in \\mathbb{R}^{K_{item}}\\) is the user specific coefficients for item observables. This type of component is written as zeta_user * item_obs in the utility formula. For sure, one can use coefficients constant among users by simply putting zeta_constant in the utility formula. \u201cMatrix factorization\u201d coefficients of observables written as gamma_user * beta_item * price_obs . This type of component factorizes the coefficient of observables into user and item latents. For example, suppose there are \\(K_{price}\\) price observables (i.e., observables varying by both item and session, price is one of them!), for each of price observable \\(X^{price}_{is}[k] \\in \\mathbb{R}\\) , a pair of latent \\(\\gamma_u^k, \\beta_i^k \\in \\mathbb{R}^L\\) is trained to construct the coefficient of the \\(k^{th}\\) price observable, where \\(L\\) is the latent dimension specified by the researcher. In this case, the utility is \\(\\mathcal{U}(u, i, s) = \\sum_{k=1}^K (\\gamma_u^{k\\top} \\beta_i^k) X^{price}_{is}[k]\\) . One can for sure replace the price_obs with any of {user, item, session}_obs . If the researcher wish to treat different part of item observable differently, for example, \\[ \\mathcal{U}(u, i, s) = \\dots + \\zeta_u^\\top Y^{item}_i + \\omega^\\top Z^{item}_i + \\dots \\] where we partition item observables into two parts \\(X^{item}_i = [Y^{item}_i, Z^{item}_i]\\) , and the coefficient for \\(Y^{item}_i\\) is user-specific but the coefficient for the second part is constant across all users. In this case, the researcher should use separate tensors item_obs_part1 and item_obs_part2 while constructing the ChoiceDataset (both of them needs to start with item_ ), and use the utility formula with zeta_user * item_obs_part1 + omega_constant * item_obs_part2 . With the above four cases as building blocks, the researcher can specify all kinds of utility functions. Number of Users/Items/Sessions num_{users, items, sessions} The researcher is responsible for providing the size of the prediction problem. For every model, the num_items is required . However, num_users and num_sessions are required only if there is any user/session-specific observables or parameters involved in the utility_formula . Specifying the Dimensions of Coefficients with the coef_dim_dict dictionary To correctly initialize the model, the constructor needs to know the shape of each learnable coefficients (i.e., Greek letters above). For item/user-specific parameters, the value of coef_dim_dict is the number of parameters for each user/item, not the total number of parameters. 1. For standalone coefficients like lambda_item , coef_dim_dict['lambda_item'] = 1 always. 2. For matrix factorization coefficients like theta_user and alpha_item , coef_dim_dict['theta_user'] = coef_dim_dict[alpha_item] = L , where L is the desired latent dimension. For the inner product between \\(\\alpha_i\\) and \\(\\theta_u\\) to work properly, coef_dim_dict['theta_user'] == coef_dim_dict['alpha_item'] . 3. For terms like \\(\\zeta_u^\\top X^{item}_i\\) , coef_dim_dict['zeta_user'] needs to be the dimension of \\(X^{item}_i\\) . 4. For matrix factorization coefficients, the dimension needs to be the latent dimension multiplied by the number of observables. For example, if you have a 3-dimensional feature \\(X = (x_1, x_2, x_3)\\) , the utility is \\(\\mathcal{U}(u, i, s) = \\zeta_{u, i}^\\top X\\) , and \\(\\zeta_{u, i}\\) needs to be factorized into two an user-specific and item-specific part (both in \\(\\mathbb{R}^L\\) ) as below \\[ \\mathcal{U}(u, i, s) = \\sum_{k=1}^3 (\\gamma_u^{k\\top} \\beta_i^k) x_k \\] then coef_dim_dict[gamma_user] = coef_dim_dict[beta_item] = 3 * L . TODO : sounds like a lot of work? we are currently developing helper function to infer all these information from the ChoiceDataset , but we will still provide researchers with the full control over the configuration. Specifying Variance of Coefficient Prior Distributions with prior_variance The prior_variance term can be either a scalar or a dictionary with the same keys of coef_dim_dict , which provides the variance of prior distribution for each learnable coefficients. If a float is provided, all priors will be Gaussian distribution with diagonal covariance matrix with prior_variance along the diagonal. If a dictionary is provided, keys of prior_variance should be coefficient names, and the prior of each coef_name would be a Gaussian with diagonal covariance matrix with prior_variance[coef_name] along the diagonal. This value is default to be 1.0 , which means priors of all coefficients are standard Gaussian distributions. Incorporating Observables to the Bayesian Prior with obs2prior_dict BEMB is a Bayesian factorization model trained by optimizing the evidence lower bound (ELBO). Each parameter (i.e., these with _item, _user, _constant suffix.) in the BEMB model carries a prior distribution, which is set to \\(\\mathcal{N}(\\mathbf{0}, \\mathbf{I})\\) by default. With prior_variance argument described above, one can specify different scales/variances for different learnable coefficients. Beyond this baseline case, the hierarchical nature of BEMB allows the mean of the prior distribution to depend on observables as a (learnable) linear mapping. For example: \\[ \\theta_{i} \\overset{prior}{\\sim} \\mathcal{N}(HX^{item}_i, \\mathbf{I}) \\] where the prior mean is a linear transformation of the item observable and \\(H: \\mathbb{R}^{K_{item}} \\to \\mathbb{R}^L\\) . To enable the observable-to-prior feature, one needs to set obs2prior_dict['theta_item']=True . In order to leverage obs-to-prior for item-specific coefficients like theta_item , the researchers need to include item_obs tensor to the ChoiceDataset , the attribute name needs to be exactly item_obs , just with item_ prefix is not sufficient. Similarly, user_obs are required if obs-to-prior is turned on for any of user-specific coefficients. Grouping Items into Categories with category_to_item In some cases the researcher wishes to provide additional guidance to the model by providing the category of the bought item in teach purchasing record. In this case, the probability of purchasing each \\(i\\) will be normalized only across other items from the same category rather than all items. The category_to_item argument provides a dictionary with category id or name as keys, and category_to_item[C] contains the list of item ids belonging to category C . With category_to_item provided, for the probability of purchasing item \\(i\\) by user \\(u\\) in session, let \\(I_c\\) denote the set of items belonging to the same category \\(i\\) , the probability of purchasing is \\[ P(i|u,s) = \\frac{e^{\\mathcal{U}(u, i, s)}}{\\sum_{i' \\in I_c} e^{\\mathcal{U}(u, i', s)}} \\] If category_to_item is not provided (or None is provided), the probability of purchasing item \\(i\\) by user \\(u\\) in session \\(s\\) is (note the difference in summation scope, this is computed as if all items are from the same category): \\[ P(i|u,s) = \\frac{e^{\\mathcal{U}(u, i, s)}}{\\sum_{i'=1}^I e^{\\mathcal{U}(u, i', s)}} \\] Last Step: Create the LitBEMBFlex wrapper The last step is to create the LitBEMBFlex object which contains all information we gathered above. You will also need to provide a learning_rate for the the optimizer and a num_seeds for the Monte-Carlo estimator of gradient in ELBO. model = bemb . model . LitBEMBFlex ( learning_rate = 0.01 , num_seeds = 4 , utility_formula = utility_formula , num_users = num_users , num_items = num_items , num_sessions = num_sessions , obs2prior_dict = obs2prior_dict , coef_dim_dict = coef_dim_dict , category_to_item = category_to_item , num_user_obs = num_user_obs , num_item_obs = num_item_obs , ) Training the Model We provide a ready-to-use scrip to train the model, where dataset_list is a list consists of three ChoiceDataset objects (see the Data Management tutorial for splitting datasets), the training, validation, and testing dataset. model = model . to ( 'cuda' ) # only if GPU is installed model = bemb . utils . run_helper . run ( model , dataset_list , batch_size = 32 , num_epochs = 10 ) Inference Lastly, to get the utilities (i.e., the logit) of the item bought for each row of the test dataset, the model.model.forward() method does the trick. You can either compute the utility for the purchased item or for all items, we put significant effort on optimizing the pipeline for estimating utility of the bought item, so it's much faster than computing utilities of all items. with torch . no_grad (): # disable gradient tracking to save computational cost. utility_chosen = model . model . forward ( dataset_list [ 2 ], return_logit = True , all_items = False ) # uses much higher memory! utility_all = model . model . forward ( dataset_list [ 2 ], return_logit = True , all_items = True )","title":"Tutorial for Bayesian Embedding (BEMB)"},{"location":"bemb/#bemb-tutorial","text":"This tutorial assumes the reader has ready gone through the Data Management tutorial. Through this tutorial, we use Greek letters (except for \\(\\varepsilon\\) as error term) to denote learnable coefficients of the model. However, researchers are not restricted to use Greek letters in practice. Bayesian EMBedding (BEMB) is a hierarchical Bayesian model for modelling consumer choices. The model can naturally extend to other use cases which can be formulated into the consumer choice framework. For example, in a job-transition modelling study, we formulated the starting job as the user and ending job as the item and applied the BEMB framework. Suppose we have a dataset of purchase records consisting of \\(U\\) users, \\(I\\) items, and \\(S\\) sessions, at it's core (assume no \\(s\\) -level effect for now), the BEMB model aims to build user embeddings \\(\\theta_u \\in \\mathbb{R}^{L}\\) and item embeddings \\(\\alpha_i \\in \\mathbb{R}^{L}\\) , then the model predicts the probability for user \\(u\\) to purchase item \\(i\\) as $$ P(i|u,s) \\propto \\theta_u^\\top \\alpha_i. $$ Both of \\(\\theta_u\\) and \\(\\alpha_i\\) are Bayesian , which means there is a prior distribution and a variational distribution associated with each of them. By default, the prior distribution of all entries of \\(\\theta_u\\) and \\(\\alpha_i\\) are i.i.d. standard Gaussian distributions. The variational distributions are Gaussian with learnable mean and standard deviation, these parameters are trained by minimizing the ELBO so that the predicted purchasing probabilities best fit the observed dataset. TODO : add reference to the paper introducing BEMB for a complete description of the model.","title":"BEMB Tutorial"},{"location":"bemb/#running-bemb","text":"Running BEMB requires you to (1) build the ChoiceDataset object and (2) training the model.","title":"Running BEMB"},{"location":"bemb/#the-choicedataset","text":"Please refer to the Data Management tutorial for a detailed walk-through of how to constructing the dataset. For simplicity, we assume that item/user/session/price observables are named as {item, user, session, price}_obs in the ChoiceDataset , the researcher can use arbitrary variable names as long as they satisfy the naming convention (e.g., user-level observables should start with user_ and cannot be user_index ) and have the correct shape (e.g., user-level observables should have shape (num_users, num_obs) ).","title":"The ChoiceDataset"},{"location":"bemb/#setup-the-bemb-model-pytorch-lightning-interface","text":"You will be constructing the LitBEMBFlex class, which is a PyTorch-lightning wrapper of the BEMB model implemented in plain PyTorch. The lighting wrapper free researchers from complications such as setting up the training loop and optimizers. To initialize the LitBEMBFlex class, the researcher needs to provide it with the following arguments. We recommend the research to encompass all arguments in a separate yaml file. Most of these arguments should be self explanatory, Please refer to the doc string of BEMBFlex.__init__() for a detailed elaboration.","title":"Setup the BEMB Model (PyTorch-Lightning Interface)"},{"location":"bemb/#utility-formula-utility_formula","text":"Note : for the string parsing to work correctly, please do add spaces around + and * . This section covers how to convert the utility representation in a choice problem into the utility_formula argument of the BEMBFlex model and LitBEMBFlex wrapper. The core of specifying a BEMB model is to specify the utility function \\(\\mathcal{U}(u,i,s)\\) for user \\(u\\) to purchase item \\(i\\) in session \\(s\\) , the bemb package provides an easy-to-use string-parsing mechanism for researchers to provide their ideal utility representations. With the utility representation, the probability for consumer \\(u\\) to purchase item \\(i\\) in session \\(s\\) is the following \\[ P(i|u,s) = \\frac{e^{\\mathcal{U}(u, i, s)}}{\\sum_{i' \\in I_c} e^{\\mathcal{U}(u, i', s)}} \\] where \\(I_c\\) is the set of items in the same category of item \\(i\\) . If there is no category information, the model considers all items to be in the same category, i.e., \\(I_c = \\{1, 2, \\dots I\\}\\) . The BEMB admits a linear additive form of utility formula. For example, the model parses utility formula string lambda_item + theta_user * alpha_item + zeta_user * item_obs into the following representation: \\[ \\mathcal{U}(u, i, s)= \\lambda_i + \\theta_u^\\top \\alpha_i + \\zeta_u^\\top X^{item}_i + \\varepsilon \\in \\mathbb{R} \\] The utility_formula consists of two classes of objects: 1. learnable coefficients (i.e., Greek letters): the string-parser identifies learnable coefficients by looking at their suffix. These variables can be (1) constant across all items and users, (2) user-specific, or (3) item-specific. For example, the \\(\\lambda_i\\) term above is item-specific intercept and it is presented as item_item in the utility_formula . To ensure the string-parsing is working properly, learnable coefficients must ends with one of {_item, _user, _constant} . 2. Observable Tensors are identified by their prefix, which tells whether they are item-specific (with item_ prefix), user-specific (with user_ prefix), session-specific (with session_ prefix), or session-and-item-specific (with price_ prefix) observables. Each of these observables should present in the ChoiceDataset data structure constructed. Warning : the utility_formula parser identifies learnable coefficients as using suffix and observables using prefix, the researcher should never name things with both prefix in {user_, item_, session_, price_} and suffix {_constant, _user, _item} such as item_quality_user . Overall, there are four types of additive component, except the error term \\(\\epsilon\\) , in the utility representation: Standalone coefficients \\(\\lambda, \\lambda_i, \\lambda_u \\in \\mathbb{R}\\) representing intercepts and item/user level fixed effects. \u201cMatrix factorization\u201d coefficients \\(\\theta_u^\\top \\alpha_i\\) , where \\(\\theta_u,\\alpha_i \\in \\mathbb{R}^L\\) are embedding/latent of users and items, \\(L\\) is the latent dimension specified by the researcher. Observable terms \\(\\zeta_u^\\top X^{item}_i\\) , where each \\(\\zeta_u \\in \\mathbb{R}^{K_{item}}\\) is the user specific coefficients for item observables. This type of component is written as zeta_user * item_obs in the utility formula. For sure, one can use coefficients constant among users by simply putting zeta_constant in the utility formula. \u201cMatrix factorization\u201d coefficients of observables written as gamma_user * beta_item * price_obs . This type of component factorizes the coefficient of observables into user and item latents. For example, suppose there are \\(K_{price}\\) price observables (i.e., observables varying by both item and session, price is one of them!), for each of price observable \\(X^{price}_{is}[k] \\in \\mathbb{R}\\) , a pair of latent \\(\\gamma_u^k, \\beta_i^k \\in \\mathbb{R}^L\\) is trained to construct the coefficient of the \\(k^{th}\\) price observable, where \\(L\\) is the latent dimension specified by the researcher. In this case, the utility is \\(\\mathcal{U}(u, i, s) = \\sum_{k=1}^K (\\gamma_u^{k\\top} \\beta_i^k) X^{price}_{is}[k]\\) . One can for sure replace the price_obs with any of {user, item, session}_obs . If the researcher wish to treat different part of item observable differently, for example, \\[ \\mathcal{U}(u, i, s) = \\dots + \\zeta_u^\\top Y^{item}_i + \\omega^\\top Z^{item}_i + \\dots \\] where we partition item observables into two parts \\(X^{item}_i = [Y^{item}_i, Z^{item}_i]\\) , and the coefficient for \\(Y^{item}_i\\) is user-specific but the coefficient for the second part is constant across all users. In this case, the researcher should use separate tensors item_obs_part1 and item_obs_part2 while constructing the ChoiceDataset (both of them needs to start with item_ ), and use the utility formula with zeta_user * item_obs_part1 + omega_constant * item_obs_part2 . With the above four cases as building blocks, the researcher can specify all kinds of utility functions.","title":"Utility Formula: utility_formula"},{"location":"bemb/#number-of-usersitemssessions-num_users-items-sessions","text":"The researcher is responsible for providing the size of the prediction problem. For every model, the num_items is required . However, num_users and num_sessions are required only if there is any user/session-specific observables or parameters involved in the utility_formula .","title":"Number of Users/Items/Sessions num_{users, items, sessions}"},{"location":"bemb/#specifying-the-dimensions-of-coefficients-with-the-coef_dim_dict-dictionary","text":"To correctly initialize the model, the constructor needs to know the shape of each learnable coefficients (i.e., Greek letters above). For item/user-specific parameters, the value of coef_dim_dict is the number of parameters for each user/item, not the total number of parameters. 1. For standalone coefficients like lambda_item , coef_dim_dict['lambda_item'] = 1 always. 2. For matrix factorization coefficients like theta_user and alpha_item , coef_dim_dict['theta_user'] = coef_dim_dict[alpha_item] = L , where L is the desired latent dimension. For the inner product between \\(\\alpha_i\\) and \\(\\theta_u\\) to work properly, coef_dim_dict['theta_user'] == coef_dim_dict['alpha_item'] . 3. For terms like \\(\\zeta_u^\\top X^{item}_i\\) , coef_dim_dict['zeta_user'] needs to be the dimension of \\(X^{item}_i\\) . 4. For matrix factorization coefficients, the dimension needs to be the latent dimension multiplied by the number of observables. For example, if you have a 3-dimensional feature \\(X = (x_1, x_2, x_3)\\) , the utility is \\(\\mathcal{U}(u, i, s) = \\zeta_{u, i}^\\top X\\) , and \\(\\zeta_{u, i}\\) needs to be factorized into two an user-specific and item-specific part (both in \\(\\mathbb{R}^L\\) ) as below \\[ \\mathcal{U}(u, i, s) = \\sum_{k=1}^3 (\\gamma_u^{k\\top} \\beta_i^k) x_k \\] then coef_dim_dict[gamma_user] = coef_dim_dict[beta_item] = 3 * L . TODO : sounds like a lot of work? we are currently developing helper function to infer all these information from the ChoiceDataset , but we will still provide researchers with the full control over the configuration.","title":"Specifying the Dimensions of Coefficients with the coef_dim_dict dictionary"},{"location":"bemb/#specifying-variance-of-coefficient-prior-distributions-with-prior_variance","text":"The prior_variance term can be either a scalar or a dictionary with the same keys of coef_dim_dict , which provides the variance of prior distribution for each learnable coefficients. If a float is provided, all priors will be Gaussian distribution with diagonal covariance matrix with prior_variance along the diagonal. If a dictionary is provided, keys of prior_variance should be coefficient names, and the prior of each coef_name would be a Gaussian with diagonal covariance matrix with prior_variance[coef_name] along the diagonal. This value is default to be 1.0 , which means priors of all coefficients are standard Gaussian distributions.","title":"Specifying Variance of Coefficient Prior Distributions with prior_variance"},{"location":"bemb/#incorporating-observables-to-the-bayesian-prior-with-obs2prior_dict","text":"BEMB is a Bayesian factorization model trained by optimizing the evidence lower bound (ELBO). Each parameter (i.e., these with _item, _user, _constant suffix.) in the BEMB model carries a prior distribution, which is set to \\(\\mathcal{N}(\\mathbf{0}, \\mathbf{I})\\) by default. With prior_variance argument described above, one can specify different scales/variances for different learnable coefficients. Beyond this baseline case, the hierarchical nature of BEMB allows the mean of the prior distribution to depend on observables as a (learnable) linear mapping. For example: \\[ \\theta_{i} \\overset{prior}{\\sim} \\mathcal{N}(HX^{item}_i, \\mathbf{I}) \\] where the prior mean is a linear transformation of the item observable and \\(H: \\mathbb{R}^{K_{item}} \\to \\mathbb{R}^L\\) . To enable the observable-to-prior feature, one needs to set obs2prior_dict['theta_item']=True . In order to leverage obs-to-prior for item-specific coefficients like theta_item , the researchers need to include item_obs tensor to the ChoiceDataset , the attribute name needs to be exactly item_obs , just with item_ prefix is not sufficient. Similarly, user_obs are required if obs-to-prior is turned on for any of user-specific coefficients.","title":"Incorporating Observables to the Bayesian Prior with obs2prior_dict"},{"location":"bemb/#grouping-items-into-categories-with-category_to_item","text":"In some cases the researcher wishes to provide additional guidance to the model by providing the category of the bought item in teach purchasing record. In this case, the probability of purchasing each \\(i\\) will be normalized only across other items from the same category rather than all items. The category_to_item argument provides a dictionary with category id or name as keys, and category_to_item[C] contains the list of item ids belonging to category C . With category_to_item provided, for the probability of purchasing item \\(i\\) by user \\(u\\) in session, let \\(I_c\\) denote the set of items belonging to the same category \\(i\\) , the probability of purchasing is \\[ P(i|u,s) = \\frac{e^{\\mathcal{U}(u, i, s)}}{\\sum_{i' \\in I_c} e^{\\mathcal{U}(u, i', s)}} \\] If category_to_item is not provided (or None is provided), the probability of purchasing item \\(i\\) by user \\(u\\) in session \\(s\\) is (note the difference in summation scope, this is computed as if all items are from the same category): \\[ P(i|u,s) = \\frac{e^{\\mathcal{U}(u, i, s)}}{\\sum_{i'=1}^I e^{\\mathcal{U}(u, i', s)}} \\]","title":"Grouping Items into Categories with category_to_item"},{"location":"bemb/#last-step-create-the-litbembflex-wrapper","text":"The last step is to create the LitBEMBFlex object which contains all information we gathered above. You will also need to provide a learning_rate for the the optimizer and a num_seeds for the Monte-Carlo estimator of gradient in ELBO. model = bemb . model . LitBEMBFlex ( learning_rate = 0.01 , num_seeds = 4 , utility_formula = utility_formula , num_users = num_users , num_items = num_items , num_sessions = num_sessions , obs2prior_dict = obs2prior_dict , coef_dim_dict = coef_dim_dict , category_to_item = category_to_item , num_user_obs = num_user_obs , num_item_obs = num_item_obs , )","title":"Last Step: Create the LitBEMBFlex wrapper"},{"location":"bemb/#training-the-model","text":"We provide a ready-to-use scrip to train the model, where dataset_list is a list consists of three ChoiceDataset objects (see the Data Management tutorial for splitting datasets), the training, validation, and testing dataset. model = model . to ( 'cuda' ) # only if GPU is installed model = bemb . utils . run_helper . run ( model , dataset_list , batch_size = 32 , num_epochs = 10 )","title":"Training the Model"},{"location":"bemb/#inference","text":"Lastly, to get the utilities (i.e., the logit) of the item bought for each row of the test dataset, the model.model.forward() method does the trick. You can either compute the utility for the purchased item or for all items, we put significant effort on optimizing the pipeline for estimating utility of the bought item, so it's much faster than computing utilities of all items. with torch . no_grad (): # disable gradient tracking to save computational cost. utility_chosen = model . model . forward ( dataset_list [ 2 ], return_logit = True , all_items = False ) # uses much higher memory! utility_all = model . model . forward ( dataset_list [ 2 ], return_logit = True , all_items = True )","title":"Inference"},{"location":"bemb_obs2prior_simulation/","text":"Tutorial for BEMB with Simulated Data and the obs2prior Option Author: Tianyu Du Update: May. 6, 2022 This tutorial offers a simple simulation exercise to demonstrate how to use BEMB model and the power of BEMB's obs2prior feature. We highly recommend you to read the BEMB tutorial first. The executable Jupyter notebook for this tutorial can be found here import numpy as np import pandas as pd import torch from torch_choice.data import ChoiceDataset from bemb.model import LitBEMBFlex from bemb.utils.run_helper import run import matplotlib.pyplot as plt import seaborn as sns Simulate Dataset We first specify the number of users and number of items in the dataset. The data_size denotes the number of user-item choice pairs to generate. Each user-item choice pair is called a purchasing record in our terminology, you can revise the data management tutorial. Please note that the data_size is much smaller than num_users \\(\\times\\) num_items and we are factorizing a spare matrix here. num_users = 1500 num_items = 50 data_size = 1000 For each of data_size purchasing records, we randomly select one user as the decision maker. This information is stored the user_index tensor, which has length data_size . user_index = torch . LongTensor ( np . random . choice ( num_users , size = data_size )) We further assign each individual some preferences so that our simulated is not totally random. In particular, for each user \\(u \\in \\{0, 1, \\dots, num\\_users - 1\\}\\) , we assume \\(u\\) particularly loves the item \\(i^*(u) \\in \\{0, 1, \\dots, num\\_item - 1\\}\\) : \\[ i^{love}(u) = \\left \\lfloor \\frac{\\sin \\left( \\frac{u}{num\\_users} \\times 4 \\times \\pi \\right) + 1}{2} \\times num\\_items \\right \\rfloor \\] The PREFERENCE dictionary maps each user \\(u\\) to the item she loves. Us = np . arange ( num_users ) Is = np . sin ( np . arange ( num_users ) / num_users * 4 * np . pi ) Is = ( Is + 1 ) / 2 * num_items Is = Is . astype ( int ) PREFERENCE = dict (( u , i ) for ( u , i ) in zip ( Us , Is )) Even though the the formula looks complicated, the who-love-what pattern is quite simple. The figure below draws which item (y-axis) each user (x-axis) likes. plt . close () plt . plot ( Us , Is ) plt . xlabel ( 'User ID' ) plt . ylabel ( 'Item ID the user loves: $i^ {love} (u)$' ) plt . title ( 'A visualization of $i^ {love} (u)$ pattern defined above.' ) plt . show () To add some randomness, for each purchasing records, with 50\\% chance, user \\(u\\) chooses the item \\(i^*(u)\\) she loves, and with 50\\% of chance she chooses an item randomly. # construct users. item_index = torch . LongTensor ( np . random . choice ( num_items , size = data_size )) for idx in range ( data_size ): if np . random . rand () <= 0.5 : item_index [ idx ] = PREFERENCE [ int ( user_index [ idx ])] To have a visual inspection on the preference we added, we can plot a heat map indexed by (user, item) and visualize the frequency of bought items by each user. In the heat map below, each row represents the empirical distribution of items (x-axis) bought. Warmer color (red) indicates high purchasing frequencies, which shows the synthetic sin-curve of preference we enforced above. df = pd . DataFrame ( data = { 'item' : item_index , 'user' : user_index }) . groupby ([ 'item' , 'user' ]) . size () . rename ( 'size' ) . reset_index () df = df . pivot ( 'item' , 'user' , 'size' ) . fillna ( 0.0 ) fig , ax = plt . subplots ( figsize = ( 18 , 3 )) sns . heatmap ( df . values , square = False , ax = ax , cmap = 'coolwarm' ) ax . set ( xlabel = 'item' , ylabel = 'user' ) fig . show () Build the ChoiceDataset Object We have created the user_index and item_index tensors, let's create a dataset object encompassing these tensors. Further, we split the dataset into train-validation-test subsets with ratio 80\\%-10\\%-10\\%. We wish to add some dummy user observables and item observables to that we can experiment the obs2prior feature of BEMB later. The default item observable is simply the one-hot vector of the item identity. The observable of a particular user is a one-hot vector with width num_items and one on the position of item this user loves (as mentioned previously). user_obs = torch . zeros ( num_users , num_items ) user_obs [ torch . arange ( num_users ), Is ] = 1 item_obs = torch . eye ( num_items ) dataset = ChoiceDataset ( user_index = user_index , item_index = item_index , user_obs = user_obs , item_obs = item_obs ) idx = np . random . permutation ( len ( dataset )) train_size = int ( 0.8 * len ( dataset )) val_size = int ( 0.1 * len ( dataset )) train_idx = idx [: train_size ] val_idx = idx [ train_size : train_size + val_size ] test_idx = idx [ train_size + val_size :] dataset_list = [ dataset [ train_idx ], dataset [ val_idx ], dataset [ test_idx ]] No `session_index` is provided, assume each choice instance is in its own session. dataset ChoiceDataset(label=[], item_index=[1000], user_index=[1000], session_index=[1000], item_availability=[], user_obs=[1500, 50], item_obs=[50, 50], device=cpu) Fitting the Model We will be fitting a Bayesian matrix factorization model with utility form $$ \\mathcal{U}_{u, i} = \\theta_u^\\top \\alpha_i $$ where \\(\\theta_u\\) and \\(\\alpha_i\\) are Bayesian variables. Please refer to the BEMB tutorial for a detailed description on how this kind of model works. There are two options on the prior distributions of these Bayesian variables \\(\\theta_u\\) and \\(\\alpha_i\\) . Firstly, we can simply use standard Gaussian as the prior distribution: \\[ \\theta_u \\overset{prior}{\\sim} \\mathcal{N}(\\mathbf{0}, I) \\quad \\alpha_i \\overset{prior}{\\sim} \\mathcal{N}(\\mathbf{0}, I) \\] Alternatively, the prior can be chosen using a data-driven method called obs2prior . In particular, the mean of prior distribution can be a learnable linear function of user/item observables. Let \\(X^{(user)}_u\\) and \\(X^{(item)}_i\\) denote the observables of user \\(u\\) and item \\(i\\) respectively. The obs2prior -augmented prior distribution is the following: \\[ \\theta_u \\overset{prior}{\\sim} \\mathcal{N}(H X^{(user)}_u, I) \\quad \\alpha_i \\overset{prior}{\\sim} \\mathcal{N}(W X^{(item)}_i, I) \\] where \\(H\\) and \\(W\\) are two learnable parameters. def fit_model ( obs2prior : bool ): LATENT_DIM = 10 # the dimension of alpha and theta. bemb = LitBEMBFlex ( learning_rate = 0.03 , # set the learning rate, feel free to play with different levels. pred_item = True , # let the model predict item_index, don't change this one. num_seeds = 32 , # number of Monte Carlo samples for estimating the ELBO. utility_formula = 'theta_user * alpha_item' , # the utility formula. num_users = num_users , num_items = num_items , num_user_obs = dataset . user_obs . shape [ 1 ], num_item_obs = dataset . item_obs . shape [ 1 ], # whether to turn on obs2prior for each parameter. obs2prior_dict = { 'theta_user' : obs2prior , 'alpha_item' : obs2prior }, # the dimension of latents, since the utility is an inner product of theta and alpha, they should have # the same dimension. coef_dim_dict = { 'theta_user' : LATENT_DIM , 'alpha_item' : LATENT_DIM } ) # use GPU if available. if torch . cuda . is_available (): bemb = bemb . to ( 'cuda' ) # use the provided run helper to train the model. # we set batch size to be 5% of the data size, and train the model for 10 epochs. # there would be 20*10=200 gradient update steps in total. bemb = run ( bemb , dataset_list , batch_size = len ( dataset ) // 20 , num_epochs = 50 ) # visualize the prediction. T = bemb . model . coef_dict [ 'theta_user' ] . variational_mean_flexible . data A = bemb . model . coef_dict [ 'alpha_item' ] . variational_mean_flexible . data fig , ax = plt . subplots ( figsize = ( 18 , 6 )) sns . heatmap (( A @ T . T ) . numpy (), square = False , ax = ax , cmap = 'coolwarm' ) ax . set_title ( f 'obs2prior = { obs2prior } ' ) fig . show () fit_model ( obs2prior = False ) BEMB: utility formula parsed: [{'coefficient': ['theta_user', 'alpha_item'], 'observable': None}] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params ----------------------------------- 0 | model | BEMBFlex | 31.0 K ----------------------------------- 31.0 K Trainable params 0 Non-trainable params 31.0 K Total params 0.124 Total estimated model params size (MB) ==================== model received ==================== Bayesian EMBedding Model with U[user, item, session] = theta_user * alpha_item Total number of parameters: 31000. With the following coefficients: ModuleDict( (theta_user): BayesianCoefficient(num_classes=1500, dimension=10, prior=N(0, I)) (alpha_item): BayesianCoefficient(num_classes=50, dimension=10, prior=N(0, I)) ) [] ==================== data set received ==================== [Training dataset] ChoiceDataset(label=[], item_index=[800], user_index=[800], session_index=[800], item_availability=[], user_obs=[1500, 50], item_obs=[50, 50], device=cpu) [Validation dataset] ChoiceDataset(label=[], item_index=[100], user_index=[100], session_index=[100], item_availability=[], user_obs=[1500, 50], item_obs=[50, 50], device=cpu) [Testing dataset] ChoiceDataset(label=[], item_index=[100], user_index=[100], session_index=[100], item_availability=[], user_obs=[1500, 50], item_obs=[50, 50], device=cpu) ==================== train the model ==================== time taken: 40.19812321662903 ==================== test performance ==================== Testing: 0it [00:00, ?it/s] \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Test metric DataLoader 0 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 test_acc 0.02 test_ll -3.912011494636536 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 fit_model ( obs2prior = True ) GPU available: True, used: True TPU available: False, using: 0 TPU cores IPU available: False, using: 0 IPUs HPU available: False, using: 0 HPUs LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params ----------------------------------- 0 | model | BEMBFlex | 33.0 K ----------------------------------- 33.0 K Trainable params 0 Non-trainable params 33.0 K Total params 0.132 Total estimated model params size (MB) BEMB: utility formula parsed: [{'coefficient': ['theta_user', 'alpha_item'], 'observable': None}] ==================== model received ==================== Bayesian EMBedding Model with U[user, item, session] = theta_user * alpha_item Total number of parameters: 33000. With the following coefficients: ModuleDict( (theta_user): BayesianCoefficient(num_classes=1500, dimension=10, prior=N(H*X_obs(H shape=torch.Size([10, 50]), X_obs shape=50), Ix1.0)) (alpha_item): BayesianCoefficient(num_classes=50, dimension=10, prior=N(H*X_obs(H shape=torch.Size([10, 50]), X_obs shape=50), Ix1.0)) ) [] ==================== data set received ==================== [Training dataset] ChoiceDataset(label=[], item_index=[800], user_index=[800], session_index=[800], item_availability=[], user_obs=[1500, 50], item_obs=[50, 50], device=cpu) [Validation dataset] ChoiceDataset(label=[], item_index=[100], user_index=[100], session_index=[100], item_availability=[], user_obs=[1500, 50], item_obs=[50, 50], device=cpu) [Testing dataset] ChoiceDataset(label=[], item_index=[100], user_index=[100], session_index=[100], item_availability=[], user_obs=[1500, 50], item_obs=[50, 50], device=cpu) ==================== train the model ==================== time taken: 40.98820662498474 ==================== test performance ==================== Testing: 0it [00:00, ?it/s] \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Test metric DataLoader 0 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 test_acc 0.47 test_ll -3.126977977901697 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Now we compare the difference between two options of prior distributions. We provide a fit_model helper function to train and visualize the model. You can go through fit_model method to have a preliminary understanding on how to train a BEMB model. Visualization : The method visualize the fitted model by plotting \\(\\theta_u^\\top \\alpha_i\\) for all pairs of user \\(u\\) and item \\(i\\) on a heat map. The sine-curve on the heat map indicates the model successfully recovered the preference pattern we added.","title":"Tutorial for BEMB obs2prior feature"},{"location":"bemb_obs2prior_simulation/#tutorial-for-bemb-with-simulated-data-and-the-obs2prior-option","text":"Author: Tianyu Du Update: May. 6, 2022 This tutorial offers a simple simulation exercise to demonstrate how to use BEMB model and the power of BEMB's obs2prior feature. We highly recommend you to read the BEMB tutorial first. The executable Jupyter notebook for this tutorial can be found here import numpy as np import pandas as pd import torch from torch_choice.data import ChoiceDataset from bemb.model import LitBEMBFlex from bemb.utils.run_helper import run import matplotlib.pyplot as plt import seaborn as sns","title":"Tutorial for BEMB with Simulated Data and the obs2prior Option"},{"location":"bemb_obs2prior_simulation/#simulate-dataset","text":"We first specify the number of users and number of items in the dataset. The data_size denotes the number of user-item choice pairs to generate. Each user-item choice pair is called a purchasing record in our terminology, you can revise the data management tutorial. Please note that the data_size is much smaller than num_users \\(\\times\\) num_items and we are factorizing a spare matrix here. num_users = 1500 num_items = 50 data_size = 1000 For each of data_size purchasing records, we randomly select one user as the decision maker. This information is stored the user_index tensor, which has length data_size . user_index = torch . LongTensor ( np . random . choice ( num_users , size = data_size )) We further assign each individual some preferences so that our simulated is not totally random. In particular, for each user \\(u \\in \\{0, 1, \\dots, num\\_users - 1\\}\\) , we assume \\(u\\) particularly loves the item \\(i^*(u) \\in \\{0, 1, \\dots, num\\_item - 1\\}\\) : \\[ i^{love}(u) = \\left \\lfloor \\frac{\\sin \\left( \\frac{u}{num\\_users} \\times 4 \\times \\pi \\right) + 1}{2} \\times num\\_items \\right \\rfloor \\] The PREFERENCE dictionary maps each user \\(u\\) to the item she loves. Us = np . arange ( num_users ) Is = np . sin ( np . arange ( num_users ) / num_users * 4 * np . pi ) Is = ( Is + 1 ) / 2 * num_items Is = Is . astype ( int ) PREFERENCE = dict (( u , i ) for ( u , i ) in zip ( Us , Is )) Even though the the formula looks complicated, the who-love-what pattern is quite simple. The figure below draws which item (y-axis) each user (x-axis) likes. plt . close () plt . plot ( Us , Is ) plt . xlabel ( 'User ID' ) plt . ylabel ( 'Item ID the user loves: $i^ {love} (u)$' ) plt . title ( 'A visualization of $i^ {love} (u)$ pattern defined above.' ) plt . show () To add some randomness, for each purchasing records, with 50\\% chance, user \\(u\\) chooses the item \\(i^*(u)\\) she loves, and with 50\\% of chance she chooses an item randomly. # construct users. item_index = torch . LongTensor ( np . random . choice ( num_items , size = data_size )) for idx in range ( data_size ): if np . random . rand () <= 0.5 : item_index [ idx ] = PREFERENCE [ int ( user_index [ idx ])] To have a visual inspection on the preference we added, we can plot a heat map indexed by (user, item) and visualize the frequency of bought items by each user. In the heat map below, each row represents the empirical distribution of items (x-axis) bought. Warmer color (red) indicates high purchasing frequencies, which shows the synthetic sin-curve of preference we enforced above. df = pd . DataFrame ( data = { 'item' : item_index , 'user' : user_index }) . groupby ([ 'item' , 'user' ]) . size () . rename ( 'size' ) . reset_index () df = df . pivot ( 'item' , 'user' , 'size' ) . fillna ( 0.0 ) fig , ax = plt . subplots ( figsize = ( 18 , 3 )) sns . heatmap ( df . values , square = False , ax = ax , cmap = 'coolwarm' ) ax . set ( xlabel = 'item' , ylabel = 'user' ) fig . show ()","title":"Simulate Dataset"},{"location":"bemb_obs2prior_simulation/#build-the-choicedataset-object","text":"We have created the user_index and item_index tensors, let's create a dataset object encompassing these tensors. Further, we split the dataset into train-validation-test subsets with ratio 80\\%-10\\%-10\\%. We wish to add some dummy user observables and item observables to that we can experiment the obs2prior feature of BEMB later. The default item observable is simply the one-hot vector of the item identity. The observable of a particular user is a one-hot vector with width num_items and one on the position of item this user loves (as mentioned previously). user_obs = torch . zeros ( num_users , num_items ) user_obs [ torch . arange ( num_users ), Is ] = 1 item_obs = torch . eye ( num_items ) dataset = ChoiceDataset ( user_index = user_index , item_index = item_index , user_obs = user_obs , item_obs = item_obs ) idx = np . random . permutation ( len ( dataset )) train_size = int ( 0.8 * len ( dataset )) val_size = int ( 0.1 * len ( dataset )) train_idx = idx [: train_size ] val_idx = idx [ train_size : train_size + val_size ] test_idx = idx [ train_size + val_size :] dataset_list = [ dataset [ train_idx ], dataset [ val_idx ], dataset [ test_idx ]] No `session_index` is provided, assume each choice instance is in its own session. dataset ChoiceDataset(label=[], item_index=[1000], user_index=[1000], session_index=[1000], item_availability=[], user_obs=[1500, 50], item_obs=[50, 50], device=cpu)","title":"Build the ChoiceDataset Object"},{"location":"bemb_obs2prior_simulation/#fitting-the-model","text":"We will be fitting a Bayesian matrix factorization model with utility form $$ \\mathcal{U}_{u, i} = \\theta_u^\\top \\alpha_i $$ where \\(\\theta_u\\) and \\(\\alpha_i\\) are Bayesian variables. Please refer to the BEMB tutorial for a detailed description on how this kind of model works. There are two options on the prior distributions of these Bayesian variables \\(\\theta_u\\) and \\(\\alpha_i\\) . Firstly, we can simply use standard Gaussian as the prior distribution: \\[ \\theta_u \\overset{prior}{\\sim} \\mathcal{N}(\\mathbf{0}, I) \\quad \\alpha_i \\overset{prior}{\\sim} \\mathcal{N}(\\mathbf{0}, I) \\] Alternatively, the prior can be chosen using a data-driven method called obs2prior . In particular, the mean of prior distribution can be a learnable linear function of user/item observables. Let \\(X^{(user)}_u\\) and \\(X^{(item)}_i\\) denote the observables of user \\(u\\) and item \\(i\\) respectively. The obs2prior -augmented prior distribution is the following: \\[ \\theta_u \\overset{prior}{\\sim} \\mathcal{N}(H X^{(user)}_u, I) \\quad \\alpha_i \\overset{prior}{\\sim} \\mathcal{N}(W X^{(item)}_i, I) \\] where \\(H\\) and \\(W\\) are two learnable parameters. def fit_model ( obs2prior : bool ): LATENT_DIM = 10 # the dimension of alpha and theta. bemb = LitBEMBFlex ( learning_rate = 0.03 , # set the learning rate, feel free to play with different levels. pred_item = True , # let the model predict item_index, don't change this one. num_seeds = 32 , # number of Monte Carlo samples for estimating the ELBO. utility_formula = 'theta_user * alpha_item' , # the utility formula. num_users = num_users , num_items = num_items , num_user_obs = dataset . user_obs . shape [ 1 ], num_item_obs = dataset . item_obs . shape [ 1 ], # whether to turn on obs2prior for each parameter. obs2prior_dict = { 'theta_user' : obs2prior , 'alpha_item' : obs2prior }, # the dimension of latents, since the utility is an inner product of theta and alpha, they should have # the same dimension. coef_dim_dict = { 'theta_user' : LATENT_DIM , 'alpha_item' : LATENT_DIM } ) # use GPU if available. if torch . cuda . is_available (): bemb = bemb . to ( 'cuda' ) # use the provided run helper to train the model. # we set batch size to be 5% of the data size, and train the model for 10 epochs. # there would be 20*10=200 gradient update steps in total. bemb = run ( bemb , dataset_list , batch_size = len ( dataset ) // 20 , num_epochs = 50 ) # visualize the prediction. T = bemb . model . coef_dict [ 'theta_user' ] . variational_mean_flexible . data A = bemb . model . coef_dict [ 'alpha_item' ] . variational_mean_flexible . data fig , ax = plt . subplots ( figsize = ( 18 , 6 )) sns . heatmap (( A @ T . T ) . numpy (), square = False , ax = ax , cmap = 'coolwarm' ) ax . set_title ( f 'obs2prior = { obs2prior } ' ) fig . show () fit_model ( obs2prior = False ) BEMB: utility formula parsed: [{'coefficient': ['theta_user', 'alpha_item'], 'observable': None}] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params ----------------------------------- 0 | model | BEMBFlex | 31.0 K ----------------------------------- 31.0 K Trainable params 0 Non-trainable params 31.0 K Total params 0.124 Total estimated model params size (MB) ==================== model received ==================== Bayesian EMBedding Model with U[user, item, session] = theta_user * alpha_item Total number of parameters: 31000. With the following coefficients: ModuleDict( (theta_user): BayesianCoefficient(num_classes=1500, dimension=10, prior=N(0, I)) (alpha_item): BayesianCoefficient(num_classes=50, dimension=10, prior=N(0, I)) ) [] ==================== data set received ==================== [Training dataset] ChoiceDataset(label=[], item_index=[800], user_index=[800], session_index=[800], item_availability=[], user_obs=[1500, 50], item_obs=[50, 50], device=cpu) [Validation dataset] ChoiceDataset(label=[], item_index=[100], user_index=[100], session_index=[100], item_availability=[], user_obs=[1500, 50], item_obs=[50, 50], device=cpu) [Testing dataset] ChoiceDataset(label=[], item_index=[100], user_index=[100], session_index=[100], item_availability=[], user_obs=[1500, 50], item_obs=[50, 50], device=cpu) ==================== train the model ==================== time taken: 40.19812321662903 ==================== test performance ==================== Testing: 0it [00:00, ?it/s] \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Test metric DataLoader 0 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 test_acc 0.02 test_ll -3.912011494636536 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 fit_model ( obs2prior = True ) GPU available: True, used: True TPU available: False, using: 0 TPU cores IPU available: False, using: 0 IPUs HPU available: False, using: 0 HPUs LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params ----------------------------------- 0 | model | BEMBFlex | 33.0 K ----------------------------------- 33.0 K Trainable params 0 Non-trainable params 33.0 K Total params 0.132 Total estimated model params size (MB) BEMB: utility formula parsed: [{'coefficient': ['theta_user', 'alpha_item'], 'observable': None}] ==================== model received ==================== Bayesian EMBedding Model with U[user, item, session] = theta_user * alpha_item Total number of parameters: 33000. With the following coefficients: ModuleDict( (theta_user): BayesianCoefficient(num_classes=1500, dimension=10, prior=N(H*X_obs(H shape=torch.Size([10, 50]), X_obs shape=50), Ix1.0)) (alpha_item): BayesianCoefficient(num_classes=50, dimension=10, prior=N(H*X_obs(H shape=torch.Size([10, 50]), X_obs shape=50), Ix1.0)) ) [] ==================== data set received ==================== [Training dataset] ChoiceDataset(label=[], item_index=[800], user_index=[800], session_index=[800], item_availability=[], user_obs=[1500, 50], item_obs=[50, 50], device=cpu) [Validation dataset] ChoiceDataset(label=[], item_index=[100], user_index=[100], session_index=[100], item_availability=[], user_obs=[1500, 50], item_obs=[50, 50], device=cpu) [Testing dataset] ChoiceDataset(label=[], item_index=[100], user_index=[100], session_index=[100], item_availability=[], user_obs=[1500, 50], item_obs=[50, 50], device=cpu) ==================== train the model ==================== time taken: 40.98820662498474 ==================== test performance ==================== Testing: 0it [00:00, ?it/s] \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Test metric DataLoader 0 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 test_acc 0.47 test_ll -3.126977977901697 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Now we compare the difference between two options of prior distributions. We provide a fit_model helper function to train and visualize the model. You can go through fit_model method to have a preliminary understanding on how to train a BEMB model. Visualization : The method visualize the fitted model by plotting \\(\\theta_u^\\top \\alpha_i\\) for all pairs of user \\(u\\) and item \\(i\\) on a heat map. The sine-curve on the heat map indicates the model successfully recovered the preference pattern we added.","title":"Fitting the Model"},{"location":"conditional_logit_model_mode_canada/","text":"Tutorial: Conditional Logit Model on ModeCanada Dataset Author: Tianyu Du (tianyudu@stanford.edu) Update: May. 3, 2022 Reference: This tutorial is modified from the Random utility model and the multinomial logit model in th documentation of mlogit package in R. Please note that the dataset involved in this example is fairly small (2,779 choice records), so we don't expect the performance to be faster than the R implementation. We provide this tutorial mainly to check the correctness of our prediction. The fully potential of PyTorch is better exploited on much larger dataset. The executable Jupyter notebook for this tutorial is located at Random Utility Model (RUM) 1: Conditional Logit Model . Let's first import essential Python packages. from time import time import numpy as np import pandas as pd import torch import torch.nn.functional as F from torch_choice.data import ChoiceDataset , utils from torch_choice.model import ConditionalLogitModel from torch_choice.utils.run_helper import run This tutorial will run both with and without graphic processing unit (GPU). However, our package is much faster with GPU. if torch . cuda . is_available (): print ( f 'CUDA device used: { torch . cuda . get_device_name () } ' ) device = 'cuda' else : print ( 'Running tutorial on CPU.' ) device = 'cpu' Running tutorial on CPU. Load Dataset We have included the ModeCanada dataset in our package, which is located at ./public_datasets/ . The ModeCanada dataset contains individuals' choice on traveling methods. The raw dataset is in a long-format, in which the case variable identifies each choice. Using the terminology mentioned in the data management tutorial, each choice is called a purchasing record (i.e., consumer bought the ticket of a particular travelling mode), and the total number of choices made is denoted as \\(B\\) . For example, the first four row below (with case == 109 ) corresponds to the first choice, the alt column lists all alternatives/items available. The choice column identifies which alternative/item is chosen. The second row in the data snapshot below, we have choice == 1 and alt == 'air' for case == 109 . This indicates the travelling mode chosen in case = 109 was air . Now we convert the raw dataset into the format compatible with our model, for a detailed tutorial on the compatible formats, please refer to the data management tutorial. We focus on cases when four alternatives were available by filtering noalt == 4 . df = pd . read_csv ( './public_datasets/ModeCanada.csv' ) df = df . query ( 'noalt == 4' ) . reset_index ( drop = True ) df . sort_values ( by = 'case' , inplace = True ) df . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Unnamed: 0 case alt choice dist cost ivt ovt freq income urban noalt 0 304 109 train 0 377 58.25 215 74 4 45 0 4 1 305 109 air 1 377 142.80 56 85 9 45 0 4 2 306 109 bus 0 377 27.52 301 63 8 45 0 4 3 307 109 car 0 377 71.63 262 0 0 45 0 4 4 308 110 train 0 377 58.25 215 74 4 70 0 4 Since there are 4 rows corresponding to each purchasing record , the length of the long-format data is \\(4 \\times B\\) . Please refer to the data management tutorial for notations. df . shape (11116, 12) Construct the item_index tensor The first thing is to construct the item_index tensor identifying which item (i.e., travel mode) was chosen in each purchasing record. We can now construct the item_index array containing which item was chosen in each purchasing record. item_index = df [ df [ 'choice' ] == 1 ] . sort_values ( by = 'case' )[ 'alt' ] . reset_index ( drop = True ) print ( item_index ) 0 air 1 air 2 air 3 air 4 air ... 2774 car 2775 car 2776 car 2777 car 2778 car Name: alt, Length: 2779, dtype: object Since we will be training our model using PyTorch , we need to encode {'air', 'bus', 'car', 'train'} into integer values. Travel Mode Name Encoded Integer Values air 0 bus 1 car 2 train 3 The generated item_index would be a tensor of shape 2,778 (i.e., number of purchasing records in this dataset) with values {0, 1, 2, 3} . item_names = [ 'air' , 'bus' , 'car' , 'train' ] num_items = 4 encoder = dict ( zip ( item_names , range ( num_items ))) print ( f \" { encoder =:} \" ) item_index = item_index . map ( lambda x : encoder [ x ]) item_index = torch . LongTensor ( item_index ) print ( f \" { item_index =:} \" ) encoder={'air': 0, 'bus': 1, 'car': 2, 'train': 3} item_index=tensor([0, 0, 0, ..., 2, 2, 2]) Construct Observables Then let's constrct tensors for observables. As mentioned in the data management tutorial, the session is capturing the temporal dimension of our data. Since we have different values cost , freq and ovt for each purchasing record and for each item, it's natural to say each purchasing record has its own session. Consequently, these three variables are price observables since they vary by both item and session. The tensor holding these observables has shape \\((\\text{numer of purchasing records}, \\text{number of items}, 3)\\) We do the same for variable ivt , we put ivt into a separate tensor because we want to model its coefficient differently later. price_cost_freq_ovt = utils . pivot3d ( df , dim0 = 'case' , dim1 = 'alt' , values = [ 'cost' , 'freq' , 'ovt' ]) print ( f ' { price_cost_freq_ovt . shape =:} ' ) price_ivt = utils . pivot3d ( df , dim0 = 'case' , dim1 = 'alt' , values = 'ivt' ) print ( f ' { price_ivt . shape =:} ' ) price_cost_freq_ovt.shape=torch.Size([2779, 4, 3]) price_ivt.shape=torch.Size([2779, 4, 1]) In contrast, the income variable varies only by session (i.e., purchasing record), but not by item. income is therefore naturally a session variable. session_income = df . groupby ( 'case' )[ 'income' ] . first () session_income = torch . Tensor ( session_income . values ) . view ( - 1 , 1 ) print ( f ' { session_income . shape =:} ' ) session_income.shape=torch.Size([2779, 1]) To summarize, the ChoiceDataset constructed contains 2779 choice records. Since the original dataset did not reveal the identity of each decision maker, we consider all 2779 choices were made by a single user but in 2779 different sessions to handle variations. In this case, the cost , freq and ovt are observables depending on both sessions and items, we created a price_cost_freq_ovt tensor with shape (num_sessions, num_items, 3) = (2779, 4, 3) to contain these variables. In contrast, the income information depends only on session but not on items, hence we create the session_income tensor to store it. Because we wish to fit item-specific coefficients for the ivt variable, which varies by both sessions and items as well, we create another price_ivt tensor in addition to the price_cost_freq_ovt tensor. Lastly, we put all tensors we created to a single ChoiceDataset object, and move the dataset to the appropriate device. dataset = ChoiceDataset ( item_index = item_index , price_cost_freq_ovt = price_cost_freq_ovt , session_income = session_income , price_ivt = price_ivt ) . to ( device ) You can print(dataset) to check shapes of tensors contained in the ChoiceDataset . print ( dataset ) ChoiceDataset(label=[], item_index=[2779], user_index=[], session_index=[2779], item_availability=[], price_cost_freq_ovt=[2779, 4, 3], session_income=[2779, 1], price_ivt=[2779, 4, 1], device=cpu) Create the Model We now construct the ConditionalLogitModel to fit the dataset we constructed above. To start with, we aim to estimate the following model formulation: \\[ U_{uit} = \\beta^0_i + \\beta^{1\\top} X^{price: (cost, freq, ovt)}_{it} + \\beta^2_i X^{session:income}_t + \\beta^3_i X_{it}^{price:ivt} + \\epsilon_{uit} \\] We now initialize the ConditionalLogitModel to predict choices from the dataset. Please see the documentation for a complete description of the ConditionalLogitModel class. At it's core, the ConditionalLogitModel constructor requires the following four components. Define variation of each \\(\\beta\\) using coef_variation_dict The keyword coef_variation_dict is a dictionary with variable names (defined above while constructing the dataset) as keys and values from {constant, user, item, item-full} . For instance, since we wish to have constant coefficients for cost , freq and ovt observables, and these three observables are stored in the price_cost_freq_ovt tensor of the choice dataset, we set coef_variation_dict['price_cost_freq_ovt'] = 'constant' (corresponding to the \\(\\beta^{1\\top} X^{price: (cost, freq, ovt)}_{it}\\) term above). The models allows for the option of zeroing coefficient for one item. The variation of \\(\\beta^3\\) above is specified as item-full which indicates 4 values of \\(\\beta^3\\) is learned (one for each item). In contrast, \\(\\beta^0, \\beta^2\\) are specified to have variation item instead of item-full . In this case, the \\(\\beta\\) correspond to the first item (i.e., the baseline item, which is encoded as 0 in the label tensor, air in our example) is force to be zero. The researcher needs to declare intercept explicitly for the model to fit an intercept as well, otherwise the model assumes zero intercept term. Define the dimension of each \\(\\beta\\) using num_param_dict The num_param_dict is a dictionary with keys exactly the same as the coef_variation_dict . Each of dictionary values tells the dimension of the corresponding observables, hence the dimension of the coefficient. For example, the price_cost_freq_ovt consists of three observables and we set the corresponding to three. Even the model can infer num_param_dict['intercept'] = 1 , but we recommend the research to include it for completeness. Number of items The num_items keyword informs the model how many alternatives users are choosing from. Number of users The num_users keyword is an optional integer informing the model how many users there are in the dataset. However, in this example we implicitly assume there is only one user making all the decisions and we do not have any user_obs involved, hence num_users argument is not supplied. model = ConditionalLogitModel ( coef_variation_dict = { 'price_cost_freq_ovt' : 'constant' , 'session_income' : 'item' , 'price_ivt' : 'item-full' , 'intercept' : 'item' }, num_param_dict = { 'price_cost_freq_ovt' : 3 , 'session_income' : 1 , 'price_ivt' : 1 , 'intercept' : 1 }, num_items = 4 ) Then we move the model to the appropriate device. model = model . to ( device ) One can print the ConditionalLogitModel object to obtain a summary of the model. print ( model ) ConditionalLogitModel( (coef_dict): ModuleDict( (price_cost_freq_ovt): Coefficient(variation=constant, num_items=4, num_users=None, num_params=3, 3 trainable parameters in total). (session_income): Coefficient(variation=item, num_items=4, num_users=None, num_params=1, 3 trainable parameters in total). (price_ivt): Coefficient(variation=item-full, num_items=4, num_users=None, num_params=1, 4 trainable parameters in total). (intercept): Coefficient(variation=item, num_items=4, num_users=None, num_params=1, 3 trainable parameters in total). ) ) Conditional logistic discrete choice model, expects input features: X[price_cost_freq_ovt] with 3 parameters, with constant level variation. X[session_income] with 1 parameters, with item level variation. X[price_ivt] with 1 parameters, with item-full level variation. X[intercept] with 1 parameters, with item level variation. Train the Model We provide an easy-to-use helper function run() imported from torch_choice.utils.run_helper to fit the model with a particular dataset. We provide an easy-to-use model runner for both ConditionalLogitModel and NestedLogitModel (see later) instances. The run() mehtod supports mini-batch updating as well, for small datasets like the one we are dealing right now, we can use batch_size = -1 to conduct full-batch gradient update. start_time = time () run ( model , dataset , num_epochs = 50000 , learning_rate = 0.01 , batch_size =- 1 ) print ( 'Time taken:' , time () - start_time ) ==================== received model ==================== ConditionalLogitModel( (coef_dict): ModuleDict( (price_cost_freq_ovt): Coefficient(variation=constant, num_items=4, num_users=None, num_params=3, 3 trainable parameters in total). (session_income): Coefficient(variation=item, num_items=4, num_users=None, num_params=1, 3 trainable parameters in total). (price_ivt): Coefficient(variation=item-full, num_items=4, num_users=None, num_params=1, 4 trainable parameters in total). (intercept): Coefficient(variation=item, num_items=4, num_users=None, num_params=1, 3 trainable parameters in total). ) ) Conditional logistic discrete choice model, expects input features: X[price_cost_freq_ovt] with 3 parameters, with constant level variation. X[session_income] with 1 parameters, with item level variation. X[price_ivt] with 1 parameters, with item-full level variation. X[intercept] with 1 parameters, with item level variation. ==================== received dataset ==================== ChoiceDataset(label=[], item_index=[2779], user_index=[], session_index=[2779], item_availability=[], price_cost_freq_ovt=[2779, 4, 3], session_income=[2779, 1], price_ivt=[2779, 4, 1], device=cpu) ==================== training the model ==================== Epoch 5000: Log-likelihood=-1875.552490234375 Epoch 10000: Log-likelihood=-1892.94775390625 Epoch 15000: Log-likelihood=-1877.9156494140625 Epoch 20000: Log-likelihood=-1881.0845947265625 Epoch 25000: Log-likelihood=-1884.7335205078125 Epoch 30000: Log-likelihood=-1874.423828125 Epoch 35000: Log-likelihood=-1875.3016357421875 Epoch 40000: Log-likelihood=-1874.3779296875 Epoch 45000: Log-likelihood=-1875.703125 Epoch 50000: Log-likelihood=-1899.8175048828125 ==================== model results ==================== Training Epochs: 50000 Learning Rate: 0.01 Batch Size: 2779 out of 2779 observations in total Final Log-likelihood: -1899.8175048828125 Coefficients: | Coefficient | Estimation | Std. Err. | |:----------------------|-------------:|------------:| | price_cost_freq_ovt_0 | -0.0342194 | 0.00731707 | | price_cost_freq_ovt_1 | 0.092262 | 0.00520946 | | price_cost_freq_ovt_2 | -0.0439827 | 0.00342765 | | session_income_0 | -0.0901207 | 0.0205214 | | session_income_1 | -0.0272581 | 0.00385396 | | session_income_2 | -0.0390468 | 0.00428838 | | price_ivt_0 | 0.0592097 | 0.0102933 | | price_ivt_1 | -0.00753696 | 0.00496264 | | price_ivt_2 | -0.00604297 | 0.00193414 | | price_ivt_3 | -0.00207518 | 0.00123286 | | intercept_0 | 0.700786 | 1.39368 | | intercept_1 | 1.85016 | 0.728283 | | intercept_2 | 3.2782 | 0.648064 | Time taken: 179.84411025047302 Parameter Estimation from R The following is the R-output from the mlogit implementation, the estimation, standard error, and log-likelihood from our torch_choice implementation is the same as the result from mlogit implementation. We see that the final log-likelihood of models estimated using two packages are all around -1874 . The run() method calculates the standard deviation using \\(\\sqrt{\\text{diag}(H^{-1})}\\) , where \\(H\\) is the hessian of negative log-likelihood with repsect to model parameters. Names of coefficients are slightly different, one can use the following conversion table to compare estimations and standard deviations reported by both packages. Coefficient Name in Python Estimation Std. Err. Coeffcient Name in R R Estimation R Std. Err. price_cost_freq_ovt_0 -0.0342194 0.00731707 cost -0.0333389 0.0070955 price_cost_freq_ovt_1 0.092262 0.00520946 freq 0.0925297 0.0050976 price_cost_freq_ovt_2 -0.0439827 0.00342765 ovt -0.0430036 0.0032247 session_income_0 -0.0901207 0.0205214 income:bus -0.0890867 0.0183471 session_income_1 -0.0272581 0.00385396 income:car -0.0279930 0.0038726 session_income_2 -0.0390468 0.00428838 ivt:train -0.0014504 0.0011875 price_ivt_0 0.0592097 0.0102933 ivt:air 0.0595097 0.0100727 price_ivt_1 -0.00753696 0.00496264 ivt:bus -0.0067835 0.0044334 price_ivt_2 -0.00604297 0.00193414 ivt:car -0.0064603 0.0018985 price_ivt_3 -0.00207518 0.00123286 ivt:train -0.0014504 0.0011875 intercept_0 0.700786 1.39368 (Intercept):bus 0.6983381 1.2802466 intercept_1 1.85016 0.728283 (Intercept):car 1.8441129 0.7085089 intercept_2 3.2782 0.648064 (Intercept):train 3.2741952 0.6244152 R Output install.packages ( \"mlogit\" ) library ( \"mlogit\" ) data ( \"ModeCanada\" , package = \"mlogit\" ) MC <- dfidx ( ModeCanada , subset = noalt == 4 ) ml.MC1 <- mlogit ( choice ~ cost + freq + ovt | income | ivt , MC , reflevel = 'air' ) summary ( ml.MC1 ) Call: mlogit(formula = choice ~ cost + freq + ovt | income | ivt, data = MC, reflevel = \"air\", method = \"nr\") Frequencies of alternatives:choice air train bus car 0.3738755 0.1666067 0.0035984 0.4559194 nr method 9 iterations, 0h:0m:0s g'(-H)^-1g = 0.00014 successive function values within tolerance limits Coefficients : Estimate Std. Error z-value Pr(>|z|) (Intercept):train 3.2741952 0.6244152 5.2436 1.575e-07 *** (Intercept):bus 0.6983381 1.2802466 0.5455 0.5854292 (Intercept):car 1.8441129 0.7085089 2.6028 0.0092464 ** cost -0.0333389 0.0070955 -4.6986 2.620e-06 *** freq 0.0925297 0.0050976 18.1517 < 2.2e-16 *** ovt -0.0430036 0.0032247 -13.3356 < 2.2e-16 *** income:train -0.0381466 0.0040831 -9.3426 < 2.2e-16 *** income:bus -0.0890867 0.0183471 -4.8556 1.200e-06 *** income:car -0.0279930 0.0038726 -7.2286 4.881e-13 *** ivt:air 0.0595097 0.0100727 5.9080 3.463e-09 *** ivt:train -0.0014504 0.0011875 -1.2214 0.2219430 ivt:bus -0.0067835 0.0044334 -1.5301 0.1259938 ivt:car -0.0064603 0.0018985 -3.4029 0.0006668 *** --- Signif. codes: 0 \u2018***\u2019 0.001 \u2018**\u2019 0.01 \u2018*\u2019 0.05 \u2018.\u2019 0.1 \u2018 \u2019 1 Log-Likelihood: -1874.3 McFadden R^2: 0.35443 Likelihood ratio test : chisq = 2058.1 (p.value = < 2.22e-16)","title":"Tutorial for Conditional Logit Model"},{"location":"conditional_logit_model_mode_canada/#tutorial-conditional-logit-model-on-modecanada-dataset","text":"Author: Tianyu Du (tianyudu@stanford.edu) Update: May. 3, 2022 Reference: This tutorial is modified from the Random utility model and the multinomial logit model in th documentation of mlogit package in R. Please note that the dataset involved in this example is fairly small (2,779 choice records), so we don't expect the performance to be faster than the R implementation. We provide this tutorial mainly to check the correctness of our prediction. The fully potential of PyTorch is better exploited on much larger dataset. The executable Jupyter notebook for this tutorial is located at Random Utility Model (RUM) 1: Conditional Logit Model . Let's first import essential Python packages. from time import time import numpy as np import pandas as pd import torch import torch.nn.functional as F from torch_choice.data import ChoiceDataset , utils from torch_choice.model import ConditionalLogitModel from torch_choice.utils.run_helper import run This tutorial will run both with and without graphic processing unit (GPU). However, our package is much faster with GPU. if torch . cuda . is_available (): print ( f 'CUDA device used: { torch . cuda . get_device_name () } ' ) device = 'cuda' else : print ( 'Running tutorial on CPU.' ) device = 'cpu' Running tutorial on CPU.","title":"Tutorial: Conditional Logit Model on ModeCanada Dataset"},{"location":"conditional_logit_model_mode_canada/#load-dataset","text":"We have included the ModeCanada dataset in our package, which is located at ./public_datasets/ . The ModeCanada dataset contains individuals' choice on traveling methods. The raw dataset is in a long-format, in which the case variable identifies each choice. Using the terminology mentioned in the data management tutorial, each choice is called a purchasing record (i.e., consumer bought the ticket of a particular travelling mode), and the total number of choices made is denoted as \\(B\\) . For example, the first four row below (with case == 109 ) corresponds to the first choice, the alt column lists all alternatives/items available. The choice column identifies which alternative/item is chosen. The second row in the data snapshot below, we have choice == 1 and alt == 'air' for case == 109 . This indicates the travelling mode chosen in case = 109 was air . Now we convert the raw dataset into the format compatible with our model, for a detailed tutorial on the compatible formats, please refer to the data management tutorial. We focus on cases when four alternatives were available by filtering noalt == 4 . df = pd . read_csv ( './public_datasets/ModeCanada.csv' ) df = df . query ( 'noalt == 4' ) . reset_index ( drop = True ) df . sort_values ( by = 'case' , inplace = True ) df . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Unnamed: 0 case alt choice dist cost ivt ovt freq income urban noalt 0 304 109 train 0 377 58.25 215 74 4 45 0 4 1 305 109 air 1 377 142.80 56 85 9 45 0 4 2 306 109 bus 0 377 27.52 301 63 8 45 0 4 3 307 109 car 0 377 71.63 262 0 0 45 0 4 4 308 110 train 0 377 58.25 215 74 4 70 0 4 Since there are 4 rows corresponding to each purchasing record , the length of the long-format data is \\(4 \\times B\\) . Please refer to the data management tutorial for notations. df . shape (11116, 12)","title":"Load Dataset"},{"location":"conditional_logit_model_mode_canada/#construct-the-item_index-tensor","text":"The first thing is to construct the item_index tensor identifying which item (i.e., travel mode) was chosen in each purchasing record. We can now construct the item_index array containing which item was chosen in each purchasing record. item_index = df [ df [ 'choice' ] == 1 ] . sort_values ( by = 'case' )[ 'alt' ] . reset_index ( drop = True ) print ( item_index ) 0 air 1 air 2 air 3 air 4 air ... 2774 car 2775 car 2776 car 2777 car 2778 car Name: alt, Length: 2779, dtype: object Since we will be training our model using PyTorch , we need to encode {'air', 'bus', 'car', 'train'} into integer values. Travel Mode Name Encoded Integer Values air 0 bus 1 car 2 train 3 The generated item_index would be a tensor of shape 2,778 (i.e., number of purchasing records in this dataset) with values {0, 1, 2, 3} . item_names = [ 'air' , 'bus' , 'car' , 'train' ] num_items = 4 encoder = dict ( zip ( item_names , range ( num_items ))) print ( f \" { encoder =:} \" ) item_index = item_index . map ( lambda x : encoder [ x ]) item_index = torch . LongTensor ( item_index ) print ( f \" { item_index =:} \" ) encoder={'air': 0, 'bus': 1, 'car': 2, 'train': 3} item_index=tensor([0, 0, 0, ..., 2, 2, 2])","title":"Construct the item_index tensor"},{"location":"conditional_logit_model_mode_canada/#construct-observables","text":"Then let's constrct tensors for observables. As mentioned in the data management tutorial, the session is capturing the temporal dimension of our data. Since we have different values cost , freq and ovt for each purchasing record and for each item, it's natural to say each purchasing record has its own session. Consequently, these three variables are price observables since they vary by both item and session. The tensor holding these observables has shape \\((\\text{numer of purchasing records}, \\text{number of items}, 3)\\) We do the same for variable ivt , we put ivt into a separate tensor because we want to model its coefficient differently later. price_cost_freq_ovt = utils . pivot3d ( df , dim0 = 'case' , dim1 = 'alt' , values = [ 'cost' , 'freq' , 'ovt' ]) print ( f ' { price_cost_freq_ovt . shape =:} ' ) price_ivt = utils . pivot3d ( df , dim0 = 'case' , dim1 = 'alt' , values = 'ivt' ) print ( f ' { price_ivt . shape =:} ' ) price_cost_freq_ovt.shape=torch.Size([2779, 4, 3]) price_ivt.shape=torch.Size([2779, 4, 1]) In contrast, the income variable varies only by session (i.e., purchasing record), but not by item. income is therefore naturally a session variable. session_income = df . groupby ( 'case' )[ 'income' ] . first () session_income = torch . Tensor ( session_income . values ) . view ( - 1 , 1 ) print ( f ' { session_income . shape =:} ' ) session_income.shape=torch.Size([2779, 1]) To summarize, the ChoiceDataset constructed contains 2779 choice records. Since the original dataset did not reveal the identity of each decision maker, we consider all 2779 choices were made by a single user but in 2779 different sessions to handle variations. In this case, the cost , freq and ovt are observables depending on both sessions and items, we created a price_cost_freq_ovt tensor with shape (num_sessions, num_items, 3) = (2779, 4, 3) to contain these variables. In contrast, the income information depends only on session but not on items, hence we create the session_income tensor to store it. Because we wish to fit item-specific coefficients for the ivt variable, which varies by both sessions and items as well, we create another price_ivt tensor in addition to the price_cost_freq_ovt tensor. Lastly, we put all tensors we created to a single ChoiceDataset object, and move the dataset to the appropriate device. dataset = ChoiceDataset ( item_index = item_index , price_cost_freq_ovt = price_cost_freq_ovt , session_income = session_income , price_ivt = price_ivt ) . to ( device ) You can print(dataset) to check shapes of tensors contained in the ChoiceDataset . print ( dataset ) ChoiceDataset(label=[], item_index=[2779], user_index=[], session_index=[2779], item_availability=[], price_cost_freq_ovt=[2779, 4, 3], session_income=[2779, 1], price_ivt=[2779, 4, 1], device=cpu)","title":"Construct Observables"},{"location":"conditional_logit_model_mode_canada/#create-the-model","text":"We now construct the ConditionalLogitModel to fit the dataset we constructed above. To start with, we aim to estimate the following model formulation: \\[ U_{uit} = \\beta^0_i + \\beta^{1\\top} X^{price: (cost, freq, ovt)}_{it} + \\beta^2_i X^{session:income}_t + \\beta^3_i X_{it}^{price:ivt} + \\epsilon_{uit} \\] We now initialize the ConditionalLogitModel to predict choices from the dataset. Please see the documentation for a complete description of the ConditionalLogitModel class. At it's core, the ConditionalLogitModel constructor requires the following four components.","title":"Create the Model"},{"location":"conditional_logit_model_mode_canada/#define-variation-of-each-beta-using-coef_variation_dict","text":"The keyword coef_variation_dict is a dictionary with variable names (defined above while constructing the dataset) as keys and values from {constant, user, item, item-full} . For instance, since we wish to have constant coefficients for cost , freq and ovt observables, and these three observables are stored in the price_cost_freq_ovt tensor of the choice dataset, we set coef_variation_dict['price_cost_freq_ovt'] = 'constant' (corresponding to the \\(\\beta^{1\\top} X^{price: (cost, freq, ovt)}_{it}\\) term above). The models allows for the option of zeroing coefficient for one item. The variation of \\(\\beta^3\\) above is specified as item-full which indicates 4 values of \\(\\beta^3\\) is learned (one for each item). In contrast, \\(\\beta^0, \\beta^2\\) are specified to have variation item instead of item-full . In this case, the \\(\\beta\\) correspond to the first item (i.e., the baseline item, which is encoded as 0 in the label tensor, air in our example) is force to be zero. The researcher needs to declare intercept explicitly for the model to fit an intercept as well, otherwise the model assumes zero intercept term.","title":"Define variation of each \\(\\beta\\) using coef_variation_dict"},{"location":"conditional_logit_model_mode_canada/#define-the-dimension-of-each-beta-using-num_param_dict","text":"The num_param_dict is a dictionary with keys exactly the same as the coef_variation_dict . Each of dictionary values tells the dimension of the corresponding observables, hence the dimension of the coefficient. For example, the price_cost_freq_ovt consists of three observables and we set the corresponding to three. Even the model can infer num_param_dict['intercept'] = 1 , but we recommend the research to include it for completeness.","title":"Define the dimension of each \\(\\beta\\) using num_param_dict"},{"location":"conditional_logit_model_mode_canada/#number-of-items","text":"The num_items keyword informs the model how many alternatives users are choosing from.","title":"Number of items"},{"location":"conditional_logit_model_mode_canada/#number-of-users","text":"The num_users keyword is an optional integer informing the model how many users there are in the dataset. However, in this example we implicitly assume there is only one user making all the decisions and we do not have any user_obs involved, hence num_users argument is not supplied. model = ConditionalLogitModel ( coef_variation_dict = { 'price_cost_freq_ovt' : 'constant' , 'session_income' : 'item' , 'price_ivt' : 'item-full' , 'intercept' : 'item' }, num_param_dict = { 'price_cost_freq_ovt' : 3 , 'session_income' : 1 , 'price_ivt' : 1 , 'intercept' : 1 }, num_items = 4 ) Then we move the model to the appropriate device. model = model . to ( device ) One can print the ConditionalLogitModel object to obtain a summary of the model. print ( model ) ConditionalLogitModel( (coef_dict): ModuleDict( (price_cost_freq_ovt): Coefficient(variation=constant, num_items=4, num_users=None, num_params=3, 3 trainable parameters in total). (session_income): Coefficient(variation=item, num_items=4, num_users=None, num_params=1, 3 trainable parameters in total). (price_ivt): Coefficient(variation=item-full, num_items=4, num_users=None, num_params=1, 4 trainable parameters in total). (intercept): Coefficient(variation=item, num_items=4, num_users=None, num_params=1, 3 trainable parameters in total). ) ) Conditional logistic discrete choice model, expects input features: X[price_cost_freq_ovt] with 3 parameters, with constant level variation. X[session_income] with 1 parameters, with item level variation. X[price_ivt] with 1 parameters, with item-full level variation. X[intercept] with 1 parameters, with item level variation.","title":"Number of users"},{"location":"conditional_logit_model_mode_canada/#train-the-model","text":"We provide an easy-to-use helper function run() imported from torch_choice.utils.run_helper to fit the model with a particular dataset. We provide an easy-to-use model runner for both ConditionalLogitModel and NestedLogitModel (see later) instances. The run() mehtod supports mini-batch updating as well, for small datasets like the one we are dealing right now, we can use batch_size = -1 to conduct full-batch gradient update. start_time = time () run ( model , dataset , num_epochs = 50000 , learning_rate = 0.01 , batch_size =- 1 ) print ( 'Time taken:' , time () - start_time ) ==================== received model ==================== ConditionalLogitModel( (coef_dict): ModuleDict( (price_cost_freq_ovt): Coefficient(variation=constant, num_items=4, num_users=None, num_params=3, 3 trainable parameters in total). (session_income): Coefficient(variation=item, num_items=4, num_users=None, num_params=1, 3 trainable parameters in total). (price_ivt): Coefficient(variation=item-full, num_items=4, num_users=None, num_params=1, 4 trainable parameters in total). (intercept): Coefficient(variation=item, num_items=4, num_users=None, num_params=1, 3 trainable parameters in total). ) ) Conditional logistic discrete choice model, expects input features: X[price_cost_freq_ovt] with 3 parameters, with constant level variation. X[session_income] with 1 parameters, with item level variation. X[price_ivt] with 1 parameters, with item-full level variation. X[intercept] with 1 parameters, with item level variation. ==================== received dataset ==================== ChoiceDataset(label=[], item_index=[2779], user_index=[], session_index=[2779], item_availability=[], price_cost_freq_ovt=[2779, 4, 3], session_income=[2779, 1], price_ivt=[2779, 4, 1], device=cpu) ==================== training the model ==================== Epoch 5000: Log-likelihood=-1875.552490234375 Epoch 10000: Log-likelihood=-1892.94775390625 Epoch 15000: Log-likelihood=-1877.9156494140625 Epoch 20000: Log-likelihood=-1881.0845947265625 Epoch 25000: Log-likelihood=-1884.7335205078125 Epoch 30000: Log-likelihood=-1874.423828125 Epoch 35000: Log-likelihood=-1875.3016357421875 Epoch 40000: Log-likelihood=-1874.3779296875 Epoch 45000: Log-likelihood=-1875.703125 Epoch 50000: Log-likelihood=-1899.8175048828125 ==================== model results ==================== Training Epochs: 50000 Learning Rate: 0.01 Batch Size: 2779 out of 2779 observations in total Final Log-likelihood: -1899.8175048828125 Coefficients: | Coefficient | Estimation | Std. Err. | |:----------------------|-------------:|------------:| | price_cost_freq_ovt_0 | -0.0342194 | 0.00731707 | | price_cost_freq_ovt_1 | 0.092262 | 0.00520946 | | price_cost_freq_ovt_2 | -0.0439827 | 0.00342765 | | session_income_0 | -0.0901207 | 0.0205214 | | session_income_1 | -0.0272581 | 0.00385396 | | session_income_2 | -0.0390468 | 0.00428838 | | price_ivt_0 | 0.0592097 | 0.0102933 | | price_ivt_1 | -0.00753696 | 0.00496264 | | price_ivt_2 | -0.00604297 | 0.00193414 | | price_ivt_3 | -0.00207518 | 0.00123286 | | intercept_0 | 0.700786 | 1.39368 | | intercept_1 | 1.85016 | 0.728283 | | intercept_2 | 3.2782 | 0.648064 | Time taken: 179.84411025047302","title":"Train the Model"},{"location":"conditional_logit_model_mode_canada/#parameter-estimation-from-r","text":"The following is the R-output from the mlogit implementation, the estimation, standard error, and log-likelihood from our torch_choice implementation is the same as the result from mlogit implementation. We see that the final log-likelihood of models estimated using two packages are all around -1874 . The run() method calculates the standard deviation using \\(\\sqrt{\\text{diag}(H^{-1})}\\) , where \\(H\\) is the hessian of negative log-likelihood with repsect to model parameters. Names of coefficients are slightly different, one can use the following conversion table to compare estimations and standard deviations reported by both packages. Coefficient Name in Python Estimation Std. Err. Coeffcient Name in R R Estimation R Std. Err. price_cost_freq_ovt_0 -0.0342194 0.00731707 cost -0.0333389 0.0070955 price_cost_freq_ovt_1 0.092262 0.00520946 freq 0.0925297 0.0050976 price_cost_freq_ovt_2 -0.0439827 0.00342765 ovt -0.0430036 0.0032247 session_income_0 -0.0901207 0.0205214 income:bus -0.0890867 0.0183471 session_income_1 -0.0272581 0.00385396 income:car -0.0279930 0.0038726 session_income_2 -0.0390468 0.00428838 ivt:train -0.0014504 0.0011875 price_ivt_0 0.0592097 0.0102933 ivt:air 0.0595097 0.0100727 price_ivt_1 -0.00753696 0.00496264 ivt:bus -0.0067835 0.0044334 price_ivt_2 -0.00604297 0.00193414 ivt:car -0.0064603 0.0018985 price_ivt_3 -0.00207518 0.00123286 ivt:train -0.0014504 0.0011875 intercept_0 0.700786 1.39368 (Intercept):bus 0.6983381 1.2802466 intercept_1 1.85016 0.728283 (Intercept):car 1.8441129 0.7085089 intercept_2 3.2782 0.648064 (Intercept):train 3.2741952 0.6244152","title":"Parameter Estimation from R"},{"location":"conditional_logit_model_mode_canada/#r-output","text":"install.packages ( \"mlogit\" ) library ( \"mlogit\" ) data ( \"ModeCanada\" , package = \"mlogit\" ) MC <- dfidx ( ModeCanada , subset = noalt == 4 ) ml.MC1 <- mlogit ( choice ~ cost + freq + ovt | income | ivt , MC , reflevel = 'air' ) summary ( ml.MC1 ) Call: mlogit(formula = choice ~ cost + freq + ovt | income | ivt, data = MC, reflevel = \"air\", method = \"nr\") Frequencies of alternatives:choice air train bus car 0.3738755 0.1666067 0.0035984 0.4559194 nr method 9 iterations, 0h:0m:0s g'(-H)^-1g = 0.00014 successive function values within tolerance limits Coefficients : Estimate Std. Error z-value Pr(>|z|) (Intercept):train 3.2741952 0.6244152 5.2436 1.575e-07 *** (Intercept):bus 0.6983381 1.2802466 0.5455 0.5854292 (Intercept):car 1.8441129 0.7085089 2.6028 0.0092464 ** cost -0.0333389 0.0070955 -4.6986 2.620e-06 *** freq 0.0925297 0.0050976 18.1517 < 2.2e-16 *** ovt -0.0430036 0.0032247 -13.3356 < 2.2e-16 *** income:train -0.0381466 0.0040831 -9.3426 < 2.2e-16 *** income:bus -0.0890867 0.0183471 -4.8556 1.200e-06 *** income:car -0.0279930 0.0038726 -7.2286 4.881e-13 *** ivt:air 0.0595097 0.0100727 5.9080 3.463e-09 *** ivt:train -0.0014504 0.0011875 -1.2214 0.2219430 ivt:bus -0.0067835 0.0044334 -1.5301 0.1259938 ivt:car -0.0064603 0.0018985 -3.4029 0.0006668 *** --- Signif. codes: 0 \u2018***\u2019 0.001 \u2018**\u2019 0.01 \u2018*\u2019 0.05 \u2018.\u2019 0.1 \u2018 \u2019 1 Log-Likelihood: -1874.3 McFadden R^2: 0.35443 Likelihood ratio test : chisq = 2058.1 (p.value = < 2.22e-16)","title":"R Output"},{"location":"data_management/","text":"Tutorial: Data Management Author: Tianyu Du (tianyudu@stanford.edu) This notebook aims to help users understand the functionality of ChoiceDataset object. The ChoiceDataset is an instance of the more general PyTorch dataset object holding information of consumer choices. The ChoiceDataset offers easy, clean and efficient data management. Note : since this package was initially proposed for modelling consumer choices, attribute names of ChoiceDataset are borrowed from the consumer choice literature. The BEMB model was initially designed for predicting consumers\u2019 purchasing choices from the supermarket purchase dataset, we use the same setup in this tutorial as a running example. However, one can easily adopt the ChoiceDataset data structure to other use cases. Note : the Jupyter-notebook version of this tutorial can be found here . Components of the Consumer Choice Modelling Problem We begin with essential component of the consumer choice modelling problem. Walking through these components should help you understand what kind of data our models are working on. Purchasing Record Each row (record) of the dataset is called a purchasing record , which includes who bought what at when and where . Let \\(B\\) denote the number of purchasing records in the dataset (i.e., number of rows of the dataset). Each row \\(b \\in \\{1,2,\\dots, B\\}\\) corresponds to a purchase record (i.e., who bought what at where and when ). Items and Categories To begin with, there are \\(I\\) items indexed by \\(i \\in \\{1,2,\\dots,I\\}\\) under our consideration. Further, the researcher can optionally partition the set items into \\(C\\) categories indexed by \\(c \\in \\{1,2,\\dots,C\\}\\) . Let \\(I_c\\) denote the collection of items in category \\(c\\) , it is easy to verify that \\[ \\bigcup_{c \\in \\{1, 2, \\dots, C\\}} I_c = \\{1, 2, \\dots I\\} \\] If the researcher does not wish to model different categories differently, the researcher can simply put all items in one single category: \\(I_1 = \\{1, 2, \\dots I\\}\\) , so that all items belong to the same category. Note : since we will be using PyTorch to train our model, we represent their identities with integer values instead of the raw human-readable names of items (e.g., Dell 24 inch LCD monitor). Raw item names can be encoded easily with sklearn.preprocessing.OrdinalEncoder . Users Each purchaing reocrd is naturally associated with an user indexed by \\(u \\in \\{1,2,\\dots,U\\}\\) ( who ) as well. Sessions Our data structure encompasses where and when using a notion called session indexed by \\(s \\in \\{1,2,\\dots, S\\}\\) . For example, when the data came from a single store over the period of a year. In this case, the notion of where does not matter that much, and session \\(s\\) is simply the date of purchase. Another example is that we have the purchase record from different stores, the session \\(s\\) can be defined as a pair of (date, store) instead. If the researcher does not wish to handle records from different sessions differently, the researcher can assign the same session ID to all rows of the dataset. To summarize, each purchasing record \\(b\\) in the dataset is characterized by a user-session-item tuple \\((u, s, i)\\) . When there are multiple items bought by the same user in the same session, there will be multiple rows in the dataset with the same \\((u, s)\\) corresponding to the same receipt. Item Availability It is not necessarily that all items are available in every session, items can get out-of-stock in particular sessions. To handle these cases, the researcher can optionally provide a boolean tensor \\(\\in \\{\\texttt{True}, \\texttt{False}\\}^{S\\times I}\\) to indicate which items are available for purchasing in each session. While predicting the purchase probabilities, the model sets the probability for these unavailable items to zero and normalizes probabilities among available items. If the item availability is not provided, the model assumes all items are available in all sessions. Observables Basic Usage Optionally, the researcher can incorporate observables of, for example, users and items. Currently, the package support the following types of observables, where \\(K_{...}\\) denote the number of observables. user_obs \\(\\in \\mathbb{R}^{U\\times K_{user}}\\) item_obs \\(\\in \\mathbb{R}^{I\\times K_{item}}\\) session_obs \\(\\in \\mathbb{R}^{S \\times K_{session}}\\) price_obs \\(\\in \\mathbb{R}^{S \\times I \\times K_{price}}\\) , price observables are values depending on both session and item. The researcher should supply them with as appropriate keyword arguments while constructing the ChoiceDataset object. Advanced Usage: Additional Observables In some cases, the researcher may wish to handle different parts of user_obs (or other observable tensors) differently. For example, the researcher wishes to model the utility for user \\(u\\) to purchase item \\(i\\) in session \\(s\\) as the following: \\[ U_{usi} = \\beta_{i} X^{(u)}_{user\\ income} + \\gamma X^{(u)}_{user\\ market\\ membership} \\] The coefficient for user income is item-specific so that it captures the nature of the product (i.e., a luxury or an essential good). Additionally, the utility representation admits an user market membership becomes shoppers with active memberships tend to purchase more, and the coefficient of this term is constant across all items. As we will cover later in the modelling section, we need to supply two user observable tensors in this case for the model to build coefficient with different levels of variations (i.e., item-specific coefficients versus constant coefficients). In this case, the researcher needs to supply two tensors user_income and user_market_membership as keyword arguments to the ChoiceDataset constructor. The ChoiceDataset handles multiple user/item/session/price observables internally, for example, every keyword arguments passed into ChoiceDataset with name starting with item_ (except for the reserved item_availability ) will be treated as item observable tensors. All keywords with names starting user_ , session_ and price_ (except for reserved names like user_index and session_index mentioned above) will be interpreted as user/session/price observable tensors. A Toy Example Suppose we have a dataset of purchase history from two stores (Store A and B) on two dates (Sep 16 and 17), both stores sell {apple, banana, orange} ( num_items=3 ) and there are three people came to those stores between Sep 16 and 17. user_index session_index item_index Amy Sep-17-2021-Store-A banana Ben Sep-17-2021-Store-B apple Ben Sep-16-2021-Store-A orange Charlie Sep-16-2021-Store-B apple Charlie Sep-16-2021-Store-B orange NOTE : For demonstration purpose, the example dataset has user_index , session_index and item_index as strings, they should be consecutive integers in actual production. One can easily convert them to integers using sklearn.preprocessing.LabelEncoder . In the example above, - user_index=[0,1,1,2,2] (with encoding 0=Amy, 1=Ben, 2=Charlie ), - session_index=[0,1,2,3,3] (with encoding 0=Sep-17-2021-Store-A, 1=Sep-17-2021-Store-B, 2=Sep-16-2021-Store-A, 3=Sep-16-2021-Store-B ), - item_index=[0,1,2,1,2] (with encoding 0=banana, 1=apple, 2=orange ). Suppose we believe people's purchasing decision depends on nutrition levels of these fruits, suppose apple has the highest nutrition level and banana has the lowest one, we can add item_obs=[[1.5], [12.0], [3.3]] \\(\\in \\mathbb{R}^{3\\times 1}\\) . The shape of this tensor is number-of-items by number-of-observable. NOTE : If someone went to one store and bought multiple items (e.g., Charlie bought both apple and orange at Store B on Sep-16), we include them as separate rows in the dataset and model them independently. # import required dependencies. import numpy as np import torch from torch_choice.data import ChoiceDataset , JointDataset # let's get a helper def print_dict_shape ( d ): for key , val in d . items (): if torch . is_tensor ( val ): print ( f 'dict. { key } .shape= { val . shape } ' ) Creating ChoiceDataset Object # Feel free to modify it as you want. num_users = 10 num_items = 4 num_sessions = 500 length_of_dataset = 10000 Step 1: Generate some random purchase records and observables We will be creating a randomly generated dataset with 10000 purchase records from 10 users, 4 items and 500 sessions. The first step is to randomly generate the purchase records using the following code. For simplicity, we assume all items are available in all sessions. # create observables/features, the number of parameters are arbitrarily chosen. # generate 128 features for each user, e.g., race, gender. user_obs = torch . randn ( num_users , 128 ) # generate 64 features for each user, e.g., quality. item_obs = torch . randn ( num_items , 64 ) # generate 10 features for each session, e.g., weekday indicator. session_obs = torch . randn ( num_sessions , 10 ) # generate 12 features for each session user pair, e.g., the budget of that user at the shopping day. price_obs = torch . randn ( num_sessions , num_items , 12 ) We then generate random observable tensors for users, items, sessions and price observables, the size of observables of each type (i.e., the last dimension in the shape) is arbitrarily chosen. item_index = torch . LongTensor ( np . random . choice ( num_items , size = length_of_dataset )) user_index = torch . LongTensor ( np . random . choice ( num_users , size = length_of_dataset )) session_index = torch . LongTensor ( np . random . choice ( num_sessions , size = length_of_dataset )) # assume all items are available in all sessions. item_availability = torch . ones ( num_sessions , num_items ) . bool () Step 2: Initialize the ChoiceDataset . You can construct a choice set using the following code, which manage all information for you. dataset = ChoiceDataset ( # pre-specified keywords of __init__ item_index = item_index , # required. # optional: user_index = user_index , session_index = session_index , item_availability = item_availability , # additional keywords of __init__ user_obs = user_obs , item_obs = item_obs , session_obs = session_obs , price_obs = price_obs ) What you can do with the ChoiceDataset ? print(dataset) and dataset.__str__ The command print(dataset) will provide a quick overview of shapes of tensors included in the object as well as where the dataset is located (i.e., host memory or GPU memory). print ( dataset ) ChoiceDataset(label=[], item_index=[10000], user_index=[10000], session_index=[10000], item_availability=[500, 4], user_obs=[10, 128], item_obs=[4, 64], session_obs=[500, 10], price_obs=[500, 4, 12], device=cpu) dataset.num_{users, items, sessions} You can use the num_{users, items, sessions} attribute to obtain the number of users, items, and sessions, they are determined automatically from the {user, item, session}_obs tensors provided while initializing the dataset object. Note : the print =: operator requires Python3.8 or higher, you can remove =: if you are using an earlier copy of Python. print ( f ' { dataset . num_users =:} ' ) print ( f ' { dataset . num_items =:} ' ) print ( f ' { dataset . num_sessions =:} ' ) print ( f ' { len ( dataset ) =:} ' ) dataset.num_users=10 dataset.num_items=4 dataset.num_sessions=500 len(dataset)=10000 dataset.clone() The ChoiceDataset offers a clone method allow you to make copy of the dataset, you can modify the cloned dataset arbitrarily without changing the original dataset. # clone print ( dataset . item_index [: 10 ]) dataset_cloned = dataset . clone () dataset_cloned . item_index = 99 * torch . ones ( num_sessions ) print ( dataset_cloned . item_index [: 10 ]) print ( dataset . item_index [: 10 ]) # does not change the original dataset. tensor([2, 2, 3, 1, 3, 2, 2, 1, 0, 1]) tensor([99., 99., 99., 99., 99., 99., 99., 99., 99., 99.]) tensor([2, 2, 3, 1, 3, 2, 2, 1, 0, 1]) dataset.to('cuda') and dataset._check_device_consistency() . One key advantage of the torch_choice and bemb is their compatibility with GPUs, you can easily move tensors in a ChoiceDataset object between host memory (i.e., cpu memory) and device memory (i.e., GPU memory) using dataset.to() method. Please note that the following code runs only if your machine has a compatible GPU and GPU-compatible version of PyTorch installed. Similarly, one can move data to host-memory using dataset.to('cpu') . The dataset also provides a dataset._check_device_consistency() method to check if all tensors are on the same device. If we only move the label to cpu without moving other tensors, this will result in an error message. # move to device print ( f ' { dataset . device =:} ' ) print ( f ' { dataset . device =:} ' ) print ( f ' { dataset . user_index . device =:} ' ) print ( f ' { dataset . session_index . device =:} ' ) dataset = dataset . to ( 'cuda' ) print ( f ' { dataset . device =:} ' ) print ( f ' { dataset . item_index . device =:} ' ) print ( f ' { dataset . user_index . device =:} ' ) print ( f ' { dataset . session_index . device =:} ' ) dataset.device=cpu dataset.device=cpu dataset.user_index.device=cpu dataset.session_index.device=cpu dataset.device=cuda:0 dataset.item_index.device=cuda:0 dataset.user_index.device=cuda:0 dataset.session_index.device=cuda:0 dataset . _check_device_consistency () # # NOTE: this cell will result errors, this is intentional. dataset . item_index = dataset . item_index . to ( 'cpu' ) dataset . _check_device_consistency () --------------------------------------------------------------------------- Exception Traceback (most recent call last) <ipython-input-56-40d626c6d436> in <module> 1 # # NOTE: this cell will result errors, this is intentional. 2 dataset.item_index = dataset.item_index.to('cpu') ----> 3 dataset._check_device_consistency() ~/Development/torch-choice/torch_choice/data/choice_dataset.py in _check_device_consistency(self) 180 devices.append(val.device) 181 if len(set(devices)) > 1: --> 182 raise Exception(f'Found tensors on different devices: {set(devices)}.', 183 'Use dataset.to() method to align devices.') 184 Exception: (\"Found tensors on different devices: {device(type='cuda', index=0), device(type='cpu')}.\", 'Use dataset.to() method to align devices.') # create dictionary inputs for model.forward() # collapse to a dictionary object. print_dict_shape ( dataset . x_dict ) dict.user_obs.shape=torch.Size([10000, 4, 128]) dict.item_obs.shape=torch.Size([10000, 4, 64]) dict.session_obs.shape=torch.Size([10000, 4, 10]) dict.price_obs.shape=torch.Size([10000, 4, 12]) Subset method One can use dataset[indices] with indices as an integer-valued tensor or array to get the corresponding rows of the dataset. The example code block below queries the 6256-th, 4119-th, 453-th, 5520-th, and 1877-th row of the dataset object. The item_index , user_index , session_index of the resulted subset will be different from the original dataset, but other tensors will be the same. # __getitem__ to get batch. # pick 5 random sessions as the mini-batch. dataset = dataset . to ( 'cpu' ) indices = torch . Tensor ( np . random . choice ( len ( dataset ), size = 5 , replace = False )) . long () print ( indices ) subset = dataset [ indices ] print ( dataset ) print ( subset ) # print_dict_shape(subset.x_dict) # assert torch.all(dataset.x_dict['price_obs'][indices, :, :] == subset.x_dict['price_obs']) # assert torch.all(dataset.item_index[indices] == subset.item_index) tensor([1118, 976, 1956, 290, 8283]) ChoiceDataset(label=[], item_index=[10000], user_index=[10000], session_index=[10000], item_availability=[500, 4], user_obs=[10, 128], item_obs=[4, 64], session_obs=[500, 10], price_obs=[500, 4, 12], device=cpu) ChoiceDataset(label=[], item_index=[5], user_index=[5], session_index=[5], item_availability=[500, 4], user_obs=[10, 128], item_obs=[4, 64], session_obs=[500, 10], price_obs=[500, 4, 12], device=cpu) The subset method internally creates a copy of the datasets so that any modification applied on the subset will not be reflected on the original dataset. The researcher can feel free to do in-place modification to the subset. print ( subset . item_index ) print ( dataset . item_index [ indices ]) subset . item_index += 1 # modifying the batch does not change the original dataset. print ( subset . item_index ) print ( dataset . item_index [ indices ]) tensor([0, 1, 0, 0, 0]) tensor([0, 1, 0, 0, 0]) tensor([1, 2, 1, 1, 1]) tensor([0, 1, 0, 0, 0]) print ( subset . item_obs [ 0 , 0 ]) print ( dataset . item_obs [ 0 , 0 ]) subset . item_obs += 1 print ( subset . item_obs [ 0 , 0 ]) print ( dataset . item_obs [ 0 , 0 ]) tensor(-1.5811) tensor(-1.5811) tensor(-0.5811) tensor(-1.5811) print ( id ( subset . item_index )) print ( id ( dataset . item_index [ indices ])) 140339656298640 140339656150528 Using Pytorch dataloader for the training loop. The ChoiceDataset object natively support batch samplers from PyTorch. For demonstration purpose, we turned off the shuffling option. from torch.utils.data.sampler import BatchSampler , SequentialSampler , RandomSampler shuffle = False # for demonstration purpose. batch_size = 32 # Create sampler. sampler = BatchSampler ( RandomSampler ( dataset ) if shuffle else SequentialSampler ( dataset ), batch_size = batch_size , drop_last = False ) dataloader = torch . utils . data . DataLoader ( dataset , sampler = sampler , num_workers = 1 , collate_fn = lambda x : x [ 0 ], pin_memory = ( dataset . device == 'cpu' )) print ( f ' { item_obs . shape =:} ' ) item_obs_all = item_obs . view ( 1 , num_items , - 1 ) . expand ( len ( dataset ), - 1 , - 1 ) item_obs_all = item_obs_all . to ( dataset . device ) item_index_all = item_index . to ( dataset . device ) print ( f ' { item_obs_all . shape =:} ' ) item_obs.shape=torch.Size([4, 64]) item_obs_all.shape=torch.Size([10000, 4, 64]) for i , batch in enumerate ( dataloader ): first , last = i * batch_size , min ( len ( dataset ), ( i + 1 ) * batch_size ) idx = torch . arange ( first , last ) assert torch . all ( item_obs_all [ idx , :, :] == batch . x_dict [ 'item_obs' ]) assert torch . all ( item_index_all [ idx ] == batch . item_index ) batch . x_dict [ 'item_obs' ] . shape torch.Size([16, 4, 64]) print_dict_shape ( dataset . x_dict ) dict.user_obs.shape=torch.Size([10000, 4, 128]) dict.item_obs.shape=torch.Size([10000, 4, 64]) dict.session_obs.shape=torch.Size([10000, 4, 10]) dict.price_obs.shape=torch.Size([10000, 4, 12]) dataset . __len__ () 10000 Chaining Multiple Datasets: JointDataset Examples dataset1 = dataset . clone () dataset2 = dataset . clone () joint_dataset = JointDataset ( the_dataset = dataset1 , another_dataset = dataset2 ) joint_dataset JointDataset with 2 sub-datasets: ( the_dataset: ChoiceDataset(label=[], item_index=[10000], user_index=[10000], session_index=[10000], item_availability=[500, 4], user_obs=[10, 128], item_obs=[4, 64], session_obs=[500, 10], price_obs=[500, 4, 12], device=cpu) another_dataset: ChoiceDataset(label=[], item_index=[10000], user_index=[10000], session_index=[10000], item_availability=[500, 4], user_obs=[10, 128], item_obs=[4, 64], session_obs=[500, 10], price_obs=[500, 4, 12], device=cpu) )","title":"Tutorial for  Data Management"},{"location":"data_management/#tutorial-data-management","text":"Author: Tianyu Du (tianyudu@stanford.edu) This notebook aims to help users understand the functionality of ChoiceDataset object. The ChoiceDataset is an instance of the more general PyTorch dataset object holding information of consumer choices. The ChoiceDataset offers easy, clean and efficient data management. Note : since this package was initially proposed for modelling consumer choices, attribute names of ChoiceDataset are borrowed from the consumer choice literature. The BEMB model was initially designed for predicting consumers\u2019 purchasing choices from the supermarket purchase dataset, we use the same setup in this tutorial as a running example. However, one can easily adopt the ChoiceDataset data structure to other use cases. Note : the Jupyter-notebook version of this tutorial can be found here .","title":"Tutorial: Data Management"},{"location":"data_management/#components-of-the-consumer-choice-modelling-problem","text":"We begin with essential component of the consumer choice modelling problem. Walking through these components should help you understand what kind of data our models are working on.","title":"Components of the Consumer Choice Modelling Problem"},{"location":"data_management/#purchasing-record","text":"Each row (record) of the dataset is called a purchasing record , which includes who bought what at when and where . Let \\(B\\) denote the number of purchasing records in the dataset (i.e., number of rows of the dataset). Each row \\(b \\in \\{1,2,\\dots, B\\}\\) corresponds to a purchase record (i.e., who bought what at where and when ).","title":"Purchasing Record"},{"location":"data_management/#items-and-categories","text":"To begin with, there are \\(I\\) items indexed by \\(i \\in \\{1,2,\\dots,I\\}\\) under our consideration. Further, the researcher can optionally partition the set items into \\(C\\) categories indexed by \\(c \\in \\{1,2,\\dots,C\\}\\) . Let \\(I_c\\) denote the collection of items in category \\(c\\) , it is easy to verify that \\[ \\bigcup_{c \\in \\{1, 2, \\dots, C\\}} I_c = \\{1, 2, \\dots I\\} \\] If the researcher does not wish to model different categories differently, the researcher can simply put all items in one single category: \\(I_1 = \\{1, 2, \\dots I\\}\\) , so that all items belong to the same category. Note : since we will be using PyTorch to train our model, we represent their identities with integer values instead of the raw human-readable names of items (e.g., Dell 24 inch LCD monitor). Raw item names can be encoded easily with sklearn.preprocessing.OrdinalEncoder .","title":"Items and Categories"},{"location":"data_management/#users","text":"Each purchaing reocrd is naturally associated with an user indexed by \\(u \\in \\{1,2,\\dots,U\\}\\) ( who ) as well.","title":"Users"},{"location":"data_management/#sessions","text":"Our data structure encompasses where and when using a notion called session indexed by \\(s \\in \\{1,2,\\dots, S\\}\\) . For example, when the data came from a single store over the period of a year. In this case, the notion of where does not matter that much, and session \\(s\\) is simply the date of purchase. Another example is that we have the purchase record from different stores, the session \\(s\\) can be defined as a pair of (date, store) instead. If the researcher does not wish to handle records from different sessions differently, the researcher can assign the same session ID to all rows of the dataset. To summarize, each purchasing record \\(b\\) in the dataset is characterized by a user-session-item tuple \\((u, s, i)\\) . When there are multiple items bought by the same user in the same session, there will be multiple rows in the dataset with the same \\((u, s)\\) corresponding to the same receipt.","title":"Sessions"},{"location":"data_management/#item-availability","text":"It is not necessarily that all items are available in every session, items can get out-of-stock in particular sessions. To handle these cases, the researcher can optionally provide a boolean tensor \\(\\in \\{\\texttt{True}, \\texttt{False}\\}^{S\\times I}\\) to indicate which items are available for purchasing in each session. While predicting the purchase probabilities, the model sets the probability for these unavailable items to zero and normalizes probabilities among available items. If the item availability is not provided, the model assumes all items are available in all sessions.","title":"Item Availability"},{"location":"data_management/#observables","text":"","title":"Observables"},{"location":"data_management/#basic-usage","text":"Optionally, the researcher can incorporate observables of, for example, users and items. Currently, the package support the following types of observables, where \\(K_{...}\\) denote the number of observables. user_obs \\(\\in \\mathbb{R}^{U\\times K_{user}}\\) item_obs \\(\\in \\mathbb{R}^{I\\times K_{item}}\\) session_obs \\(\\in \\mathbb{R}^{S \\times K_{session}}\\) price_obs \\(\\in \\mathbb{R}^{S \\times I \\times K_{price}}\\) , price observables are values depending on both session and item. The researcher should supply them with as appropriate keyword arguments while constructing the ChoiceDataset object.","title":"Basic Usage"},{"location":"data_management/#advanced-usage-additional-observables","text":"In some cases, the researcher may wish to handle different parts of user_obs (or other observable tensors) differently. For example, the researcher wishes to model the utility for user \\(u\\) to purchase item \\(i\\) in session \\(s\\) as the following: \\[ U_{usi} = \\beta_{i} X^{(u)}_{user\\ income} + \\gamma X^{(u)}_{user\\ market\\ membership} \\] The coefficient for user income is item-specific so that it captures the nature of the product (i.e., a luxury or an essential good). Additionally, the utility representation admits an user market membership becomes shoppers with active memberships tend to purchase more, and the coefficient of this term is constant across all items. As we will cover later in the modelling section, we need to supply two user observable tensors in this case for the model to build coefficient with different levels of variations (i.e., item-specific coefficients versus constant coefficients). In this case, the researcher needs to supply two tensors user_income and user_market_membership as keyword arguments to the ChoiceDataset constructor. The ChoiceDataset handles multiple user/item/session/price observables internally, for example, every keyword arguments passed into ChoiceDataset with name starting with item_ (except for the reserved item_availability ) will be treated as item observable tensors. All keywords with names starting user_ , session_ and price_ (except for reserved names like user_index and session_index mentioned above) will be interpreted as user/session/price observable tensors.","title":"Advanced Usage: Additional Observables"},{"location":"data_management/#a-toy-example","text":"Suppose we have a dataset of purchase history from two stores (Store A and B) on two dates (Sep 16 and 17), both stores sell {apple, banana, orange} ( num_items=3 ) and there are three people came to those stores between Sep 16 and 17. user_index session_index item_index Amy Sep-17-2021-Store-A banana Ben Sep-17-2021-Store-B apple Ben Sep-16-2021-Store-A orange Charlie Sep-16-2021-Store-B apple Charlie Sep-16-2021-Store-B orange NOTE : For demonstration purpose, the example dataset has user_index , session_index and item_index as strings, they should be consecutive integers in actual production. One can easily convert them to integers using sklearn.preprocessing.LabelEncoder . In the example above, - user_index=[0,1,1,2,2] (with encoding 0=Amy, 1=Ben, 2=Charlie ), - session_index=[0,1,2,3,3] (with encoding 0=Sep-17-2021-Store-A, 1=Sep-17-2021-Store-B, 2=Sep-16-2021-Store-A, 3=Sep-16-2021-Store-B ), - item_index=[0,1,2,1,2] (with encoding 0=banana, 1=apple, 2=orange ). Suppose we believe people's purchasing decision depends on nutrition levels of these fruits, suppose apple has the highest nutrition level and banana has the lowest one, we can add item_obs=[[1.5], [12.0], [3.3]] \\(\\in \\mathbb{R}^{3\\times 1}\\) . The shape of this tensor is number-of-items by number-of-observable. NOTE : If someone went to one store and bought multiple items (e.g., Charlie bought both apple and orange at Store B on Sep-16), we include them as separate rows in the dataset and model them independently. # import required dependencies. import numpy as np import torch from torch_choice.data import ChoiceDataset , JointDataset # let's get a helper def print_dict_shape ( d ): for key , val in d . items (): if torch . is_tensor ( val ): print ( f 'dict. { key } .shape= { val . shape } ' )","title":"A Toy Example"},{"location":"data_management/#creating-choicedataset-object","text":"# Feel free to modify it as you want. num_users = 10 num_items = 4 num_sessions = 500 length_of_dataset = 10000","title":"Creating  ChoiceDataset Object"},{"location":"data_management/#step-1-generate-some-random-purchase-records-and-observables","text":"We will be creating a randomly generated dataset with 10000 purchase records from 10 users, 4 items and 500 sessions. The first step is to randomly generate the purchase records using the following code. For simplicity, we assume all items are available in all sessions. # create observables/features, the number of parameters are arbitrarily chosen. # generate 128 features for each user, e.g., race, gender. user_obs = torch . randn ( num_users , 128 ) # generate 64 features for each user, e.g., quality. item_obs = torch . randn ( num_items , 64 ) # generate 10 features for each session, e.g., weekday indicator. session_obs = torch . randn ( num_sessions , 10 ) # generate 12 features for each session user pair, e.g., the budget of that user at the shopping day. price_obs = torch . randn ( num_sessions , num_items , 12 ) We then generate random observable tensors for users, items, sessions and price observables, the size of observables of each type (i.e., the last dimension in the shape) is arbitrarily chosen. item_index = torch . LongTensor ( np . random . choice ( num_items , size = length_of_dataset )) user_index = torch . LongTensor ( np . random . choice ( num_users , size = length_of_dataset )) session_index = torch . LongTensor ( np . random . choice ( num_sessions , size = length_of_dataset )) # assume all items are available in all sessions. item_availability = torch . ones ( num_sessions , num_items ) . bool ()","title":"Step 1: Generate some random purchase records and observables"},{"location":"data_management/#step-2-initialize-the-choicedataset","text":"You can construct a choice set using the following code, which manage all information for you. dataset = ChoiceDataset ( # pre-specified keywords of __init__ item_index = item_index , # required. # optional: user_index = user_index , session_index = session_index , item_availability = item_availability , # additional keywords of __init__ user_obs = user_obs , item_obs = item_obs , session_obs = session_obs , price_obs = price_obs )","title":"Step 2: Initialize the ChoiceDataset."},{"location":"data_management/#what-you-can-do-with-the-choicedataset","text":"","title":"What you can do with the ChoiceDataset?"},{"location":"data_management/#printdataset-and-dataset__str__","text":"The command print(dataset) will provide a quick overview of shapes of tensors included in the object as well as where the dataset is located (i.e., host memory or GPU memory). print ( dataset ) ChoiceDataset(label=[], item_index=[10000], user_index=[10000], session_index=[10000], item_availability=[500, 4], user_obs=[10, 128], item_obs=[4, 64], session_obs=[500, 10], price_obs=[500, 4, 12], device=cpu)","title":"print(dataset) and dataset.__str__"},{"location":"data_management/#datasetnum_users-items-sessions","text":"You can use the num_{users, items, sessions} attribute to obtain the number of users, items, and sessions, they are determined automatically from the {user, item, session}_obs tensors provided while initializing the dataset object. Note : the print =: operator requires Python3.8 or higher, you can remove =: if you are using an earlier copy of Python. print ( f ' { dataset . num_users =:} ' ) print ( f ' { dataset . num_items =:} ' ) print ( f ' { dataset . num_sessions =:} ' ) print ( f ' { len ( dataset ) =:} ' ) dataset.num_users=10 dataset.num_items=4 dataset.num_sessions=500 len(dataset)=10000","title":"dataset.num_{users, items, sessions}"},{"location":"data_management/#datasetclone","text":"The ChoiceDataset offers a clone method allow you to make copy of the dataset, you can modify the cloned dataset arbitrarily without changing the original dataset. # clone print ( dataset . item_index [: 10 ]) dataset_cloned = dataset . clone () dataset_cloned . item_index = 99 * torch . ones ( num_sessions ) print ( dataset_cloned . item_index [: 10 ]) print ( dataset . item_index [: 10 ]) # does not change the original dataset. tensor([2, 2, 3, 1, 3, 2, 2, 1, 0, 1]) tensor([99., 99., 99., 99., 99., 99., 99., 99., 99., 99.]) tensor([2, 2, 3, 1, 3, 2, 2, 1, 0, 1])","title":"dataset.clone()"},{"location":"data_management/#datasettocuda-and-dataset_check_device_consistency","text":"One key advantage of the torch_choice and bemb is their compatibility with GPUs, you can easily move tensors in a ChoiceDataset object between host memory (i.e., cpu memory) and device memory (i.e., GPU memory) using dataset.to() method. Please note that the following code runs only if your machine has a compatible GPU and GPU-compatible version of PyTorch installed. Similarly, one can move data to host-memory using dataset.to('cpu') . The dataset also provides a dataset._check_device_consistency() method to check if all tensors are on the same device. If we only move the label to cpu without moving other tensors, this will result in an error message. # move to device print ( f ' { dataset . device =:} ' ) print ( f ' { dataset . device =:} ' ) print ( f ' { dataset . user_index . device =:} ' ) print ( f ' { dataset . session_index . device =:} ' ) dataset = dataset . to ( 'cuda' ) print ( f ' { dataset . device =:} ' ) print ( f ' { dataset . item_index . device =:} ' ) print ( f ' { dataset . user_index . device =:} ' ) print ( f ' { dataset . session_index . device =:} ' ) dataset.device=cpu dataset.device=cpu dataset.user_index.device=cpu dataset.session_index.device=cpu dataset.device=cuda:0 dataset.item_index.device=cuda:0 dataset.user_index.device=cuda:0 dataset.session_index.device=cuda:0 dataset . _check_device_consistency () # # NOTE: this cell will result errors, this is intentional. dataset . item_index = dataset . item_index . to ( 'cpu' ) dataset . _check_device_consistency () --------------------------------------------------------------------------- Exception Traceback (most recent call last) <ipython-input-56-40d626c6d436> in <module> 1 # # NOTE: this cell will result errors, this is intentional. 2 dataset.item_index = dataset.item_index.to('cpu') ----> 3 dataset._check_device_consistency() ~/Development/torch-choice/torch_choice/data/choice_dataset.py in _check_device_consistency(self) 180 devices.append(val.device) 181 if len(set(devices)) > 1: --> 182 raise Exception(f'Found tensors on different devices: {set(devices)}.', 183 'Use dataset.to() method to align devices.') 184 Exception: (\"Found tensors on different devices: {device(type='cuda', index=0), device(type='cpu')}.\", 'Use dataset.to() method to align devices.') # create dictionary inputs for model.forward() # collapse to a dictionary object. print_dict_shape ( dataset . x_dict ) dict.user_obs.shape=torch.Size([10000, 4, 128]) dict.item_obs.shape=torch.Size([10000, 4, 64]) dict.session_obs.shape=torch.Size([10000, 4, 10]) dict.price_obs.shape=torch.Size([10000, 4, 12])","title":"dataset.to('cuda') and dataset._check_device_consistency()."},{"location":"data_management/#subset-method","text":"One can use dataset[indices] with indices as an integer-valued tensor or array to get the corresponding rows of the dataset. The example code block below queries the 6256-th, 4119-th, 453-th, 5520-th, and 1877-th row of the dataset object. The item_index , user_index , session_index of the resulted subset will be different from the original dataset, but other tensors will be the same. # __getitem__ to get batch. # pick 5 random sessions as the mini-batch. dataset = dataset . to ( 'cpu' ) indices = torch . Tensor ( np . random . choice ( len ( dataset ), size = 5 , replace = False )) . long () print ( indices ) subset = dataset [ indices ] print ( dataset ) print ( subset ) # print_dict_shape(subset.x_dict) # assert torch.all(dataset.x_dict['price_obs'][indices, :, :] == subset.x_dict['price_obs']) # assert torch.all(dataset.item_index[indices] == subset.item_index) tensor([1118, 976, 1956, 290, 8283]) ChoiceDataset(label=[], item_index=[10000], user_index=[10000], session_index=[10000], item_availability=[500, 4], user_obs=[10, 128], item_obs=[4, 64], session_obs=[500, 10], price_obs=[500, 4, 12], device=cpu) ChoiceDataset(label=[], item_index=[5], user_index=[5], session_index=[5], item_availability=[500, 4], user_obs=[10, 128], item_obs=[4, 64], session_obs=[500, 10], price_obs=[500, 4, 12], device=cpu) The subset method internally creates a copy of the datasets so that any modification applied on the subset will not be reflected on the original dataset. The researcher can feel free to do in-place modification to the subset. print ( subset . item_index ) print ( dataset . item_index [ indices ]) subset . item_index += 1 # modifying the batch does not change the original dataset. print ( subset . item_index ) print ( dataset . item_index [ indices ]) tensor([0, 1, 0, 0, 0]) tensor([0, 1, 0, 0, 0]) tensor([1, 2, 1, 1, 1]) tensor([0, 1, 0, 0, 0]) print ( subset . item_obs [ 0 , 0 ]) print ( dataset . item_obs [ 0 , 0 ]) subset . item_obs += 1 print ( subset . item_obs [ 0 , 0 ]) print ( dataset . item_obs [ 0 , 0 ]) tensor(-1.5811) tensor(-1.5811) tensor(-0.5811) tensor(-1.5811) print ( id ( subset . item_index )) print ( id ( dataset . item_index [ indices ])) 140339656298640 140339656150528","title":"Subset method"},{"location":"data_management/#using-pytorch-dataloader-for-the-training-loop","text":"The ChoiceDataset object natively support batch samplers from PyTorch. For demonstration purpose, we turned off the shuffling option. from torch.utils.data.sampler import BatchSampler , SequentialSampler , RandomSampler shuffle = False # for demonstration purpose. batch_size = 32 # Create sampler. sampler = BatchSampler ( RandomSampler ( dataset ) if shuffle else SequentialSampler ( dataset ), batch_size = batch_size , drop_last = False ) dataloader = torch . utils . data . DataLoader ( dataset , sampler = sampler , num_workers = 1 , collate_fn = lambda x : x [ 0 ], pin_memory = ( dataset . device == 'cpu' )) print ( f ' { item_obs . shape =:} ' ) item_obs_all = item_obs . view ( 1 , num_items , - 1 ) . expand ( len ( dataset ), - 1 , - 1 ) item_obs_all = item_obs_all . to ( dataset . device ) item_index_all = item_index . to ( dataset . device ) print ( f ' { item_obs_all . shape =:} ' ) item_obs.shape=torch.Size([4, 64]) item_obs_all.shape=torch.Size([10000, 4, 64]) for i , batch in enumerate ( dataloader ): first , last = i * batch_size , min ( len ( dataset ), ( i + 1 ) * batch_size ) idx = torch . arange ( first , last ) assert torch . all ( item_obs_all [ idx , :, :] == batch . x_dict [ 'item_obs' ]) assert torch . all ( item_index_all [ idx ] == batch . item_index ) batch . x_dict [ 'item_obs' ] . shape torch.Size([16, 4, 64]) print_dict_shape ( dataset . x_dict ) dict.user_obs.shape=torch.Size([10000, 4, 128]) dict.item_obs.shape=torch.Size([10000, 4, 64]) dict.session_obs.shape=torch.Size([10000, 4, 10]) dict.price_obs.shape=torch.Size([10000, 4, 12]) dataset . __len__ () 10000","title":"Using Pytorch dataloader for the training loop."},{"location":"data_management/#chaining-multiple-datasets-jointdataset-examples","text":"dataset1 = dataset . clone () dataset2 = dataset . clone () joint_dataset = JointDataset ( the_dataset = dataset1 , another_dataset = dataset2 ) joint_dataset JointDataset with 2 sub-datasets: ( the_dataset: ChoiceDataset(label=[], item_index=[10000], user_index=[10000], session_index=[10000], item_availability=[500, 4], user_obs=[10, 128], item_obs=[4, 64], session_obs=[500, 10], price_obs=[500, 4, 12], device=cpu) another_dataset: ChoiceDataset(label=[], item_index=[10000], user_index=[10000], session_index=[10000], item_availability=[500, 4], user_obs=[10, 128], item_obs=[4, 64], session_obs=[500, 10], price_obs=[500, 4, 12], device=cpu) )","title":"Chaining Multiple Datasets: JointDataset Examples"},{"location":"education_data/","text":"Tutorial for Bayesian Embedding (BEMB) with Educational Data Author: Tianyu Du Date: May. 7, 2022 This tutorial helps lab members to deploy the BEMB model on educational question-answering (QA) datasets. We will be using the 17Zuoye data, which is available on Sherlock, throughout this tutorial. However, this tutorial generalizes to any QA datasets in which each row of the dataset corresponds to a triple (student, question, label). Equivalently, each row of these QA datasets is about a student answering a question correctly/incorrectly. You can find the executable Jupyter notebook for this tutorial here import os import numpy as np import pandas as pd import torch from bemb.model import LitBEMBFlex from bemb.utils.run_helper import run from sklearn import preprocessing from torch_choice.data import ChoiceDataset Load Data We build some helper functions especially for the Zuoye data for demonstration, you can skip this part if you have your own data ready. Please see below for the formats data. def get_all_unique_fields ( column , field = 'id' ): unique_fields = set () for tag_list in column : for entry in tag_list : unique_fields . add ( entry [ field ]) return list ( unique_fields ) def convert_tag_list_into_binary_vector ( tag_list , encoder , vec_len ): index = encoder . transform ([ x [ 'id' ] for x in tag_list ]) out = torch . zeros ([ vec_len ], dtype = torch . float64 ) out [ index ] = 1 return out def convert_column_to_binary_vectors ( column ): all_elements = get_all_unique_fields ( column ) my_encoder = preprocessing . LabelEncoder () my_encoder . fit ( all_elements ) out = column . apply ( lambda x : convert_tag_list_into_binary_vector ( x , my_encoder , len ( all_elements ))) return out If you wish to try this tutorial on the 17Zuoye dataset, which is located at data_path on Sherlock. Please make sure the data_path is correct if you are running on your local machine. Henry prepared these datasets in the feather format. Feather is a portable file format for storing Arrow tables or data frames (from languages like Python or R) that utilizes the Arrow IPC format internally. Feather was created early in the Arrow project as a proof of concept for fast, language-agnostic data frame storage for Python (pandas) and R (see here for more information about Feather data format). You can easily load the data using pandas. data_path = '/oak/stanford/groups/athey/17Zuoye/bayesian_measurement_17zy/bayes' response_path = os . path . join ( data_path , 'exam_response_with_attrib.feather' ) attribute_path = os . path . join ( data_path , 'exam_response_ques_attrib.feather' ) The User-Item and Label Dataset (i.e., The Response Dataset) For the student response use case, the response dataset contains at least three columns: {user_id, item_id, label} . Where user_id is typically the student's ID, item_id is the question's ID, and label is the student's response to the question, which is a binary variable indicating whether the student answered the question correctly. In the df_resp dataset loaded below, the student_id column corresponds to the user_id , the question_id column corresponds to the item_id , and the correct column corresponds to the label . The length of the df_resp dataset is the total number of times students answer questions, this corresponds to the number of purchasing records following our terminology in the data management tutorial. df_resp = pd . read_feather ( response_path ) print ( 'Number of student-question response pairs:' , len ( df_resp )) df_resp Number of student-question response pairs: 8621720 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } student_id question_id correct subject grade 0 90368 409 0 CHINESE 2 1 90368 409 0 CHINESE 2 2 90368 409 0 CHINESE 2 3 93193 409 0 CHINESE 2 4 93193 409 0 CHINESE 2 ... ... ... ... ... ... 8621715 115131 2080 0 MATH 2 8621716 83680 2561 1 ENGLISH 3 8621717 83680 2564 1 ENGLISH 3 8621718 83680 2563 1 ENGLISH 3 8621719 83680 2562 1 ENGLISH 3 8621720 rows \u00d7 5 columns The dataset contains 261,756 students and 3,604 questions. Student IDs are already encoded as integers ranging from 0 to 261,755 , and question IDs are already encoded as integers ranging from 0 to 3,603 . print ( df_resp [ 'student_id' ] . nunique ()) print ( df_resp [ 'question_id' ] . nunique ()) 261756 3604 print ( df_resp [ 'student_id' ] . max ()) print ( df_resp [ 'question_id' ] . max ()) 261755 3603 The Attribute Dataset Researchers can optionally supply a separate attribute dataset including observables of users (i.e., students) and items (i.e., questions). Here we load the df_attr dataset, which has length equal to the number of questions. Each row of df_attr contains attributes/observables of each question. Specifically, df_attr contains a column called question_id and several other columns of attributes. For each question, we have two attribute as known as capability and knowledge . df_attr = pd . read_feather ( attribute_path ) . sort_values ( 'question_id' ) . reset_index ( drop = True ) df_attr .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } question_id capability knowledge kp 0 0 [{'id': 'TAG_10100001553832', 'type': 0}, {'id... [{'id': '0101001', 'type': 0.0}, {'id': '01020... [{'id': 'KP_10100071064944'}, {'id': 'KP_10100... 1 1 [{'id': 'TAG_10100001553832', 'type': 0}, {'id... [{'id': '0101001', 'type': 0.0}, {'id': '01020... [{'id': 'KP_10100050863402'}, {'id': 'KP_10100... 2 2 [{'id': 'TAG_10100001553832', 'type': 0}, {'id... [{'id': '0101001', 'type': 0.0}, {'id': '01020... [{'id': 'KP_10100050866393'}] 3 3 [{'id': 'TAG_10100001553832', 'type': 0}, {'id... [{'id': '0101001', 'type': 0.0}, {'id': '01020... [{'id': 'KP_10100125674593'}, {'id': 'KP_10100... 4 4 [{'id': 'TAG_10100001553832', 'type': 0}, {'id... [{'id': '0101001', 'type': 0.0}, {'id': '01020... [{'id': 'KP_10100077305590'}, {'id': 'KP_10100... ... ... ... ... ... 3599 3599 [{'id': 'TAG_10300000827653', 'type': 0}, {'id... [{'id': '0301001', 'type': 0.0}, {'id': '03020... [{'id': 'KP_10300117105040'}] 3600 3600 [{'id': 'TAG_10300000827653', 'type': 0}, {'id... [{'id': '0301001', 'type': 0.0}, {'id': '03020... [{'id': 'KP_10300212870515'}] 3601 3601 [{'id': 'TAG_10300000827653', 'type': 0}, {'id... [{'id': '0301001', 'type': 0.0}, {'id': '03020... [{'id': 'KP_10300111435423'}] 3602 3602 [{'id': 'TAG_10300000827653', 'type': 0}, {'id... [{'id': '0301001', 'type': 0.0}, {'id': '03020... [{'id': 'KP_10300213265389'}] 3603 3603 [{'id': 'TAG_10300000827653', 'type': 0}, {'id... [{'id': '0301001', 'type': 0.0}, {'id': '03020... [{'id': 'KP_10300111316448'}] 3604 rows \u00d7 4 columns There are 90 types of capabilities and 34 types of knowledge required by different questions in ths dataset. We convert these attributes into two binary vectors named capability_vec and knowledge_vec . The capability_vec vector has shape (number_of_questions, 90) and the knowledge_vec vector has shape (number_of_questions, 34) . For example, knowledge_vec[i, j] = 1 indicates answering question i correctly requires type j of knowledge. def f ( z ): # extract knowledge domain. return z [ - 1 ][ 'id' ] knowledge_domain = [ f ( x ) for x in df_attr [ 'knowledge' ] . values ] df_attr [ 'capability_vec' ] = convert_column_to_binary_vectors ( df_attr [ 'capability' ]) df_attr [ 'knowledge_vec' ] = convert_column_to_binary_vectors ( df_attr [ 'knowledge' ]) capability_vec = torch . stack ( df_attr [ 'capability_vec' ] . to_list (), dim = 0 ) . float () knowledge_vec = torch . stack ( df_attr [ 'knowledge_vec' ] . to_list (), dim = 0 ) . float () print ( f \" { knowledge_vec . shape =:} \" ) print ( f \" { capability_vec . shape =:} \" ) knowledge_vec.shape=torch.Size([3604, 34]) capability_vec.shape=torch.Size([3604, 90]) Lastly, we concatenate the capability_vec and knowledge_vec vectors into a single vector called item_obs with shape (number_of_questions, 124) . This vector encompasses all attributes/observables of items (i.e., questions in this context). item_obs = torch . cat ([ capability_vec , knowledge_vec ], dim = 1 ) print ( f \" { item_obs . shape =:} \" ) item_obs.shape=torch.Size([3604, 124]) Construct the ChoiceDataset Object The last step is to construct the ChoiceDataset object. The item_index ( user_index ) keyword argument holds the identify of question answered (student answering the question) in each student-question response pair respectively. The label argument is a binary tensor indicating whether the student answered the question correctly. Lastly, we put the item_obs to capture observables of questions to the dataset. In this tutorial, we don't have any user observables (i.e., observables of students). choice_dataset = ChoiceDataset ( item_index = torch . LongTensor ( df_resp [ 'question_id' ] . values ), user_index = torch . LongTensor ( df_resp [ 'student_id' ] . values ), label = torch . LongTensor ( df_resp [ 'correct' ] . values ), item_obs = item_obs ) No `session_index` is provided, assume each choice instance is in its own session. You can print the choice_dataset to see information about tensors encompassed. print ( choice_dataset ) ChoiceDataset(label=[8621720], item_index=[8621720], user_index=[8621720], session_index=[8621720], item_availability=[], item_obs=[3604, 124], device=cpu) num_users = len ( torch . unique ( choice_dataset . user_index )) num_items = len ( torch . unique ( choice_dataset . item_index )) num_item_obs = choice_dataset . item_obs . shape [ - 1 ] Splitting Data into Training, Validation, and Testing Sets To test the generalizability of the model, we split the data into training, validation, and testing sets. Specifically, we randomly take 80% of student-question pairs as the training set, 10% as the validation set, and the rest 10% as the testing set. # randomly permutate the index ranging from (0, 1, ..., len(choice_Dataset) - 1). idx = np . random . permutation ( len ( choice_dataset )) # take the first 80% from the random permutation as indices for the training set. train_size = int ( 0.8 * len ( choice_dataset )) val_size = int ( 0.1 * len ( choice_dataset )) train_idx = idx [: train_size ] val_idx = idx [ train_size : train_size + val_size ] test_idx = idx [ train_size + val_size :] # we put train/validation/test datasets into a list. dataset_list = [ choice_dataset [ train_idx ], choice_dataset [ val_idx ], choice_dataset [ test_idx ]] print ( '[Training dataset]' , dataset_list [ 0 ]) print ( '[Validation dataset]' , dataset_list [ 1 ]) print ( '[Testing dataset]' , dataset_list [ 2 ]) [Training dataset] ChoiceDataset(label=[6897376], item_index=[6897376], user_index=[6897376], session_index=[6897376], item_availability=[], item_obs=[3604, 124], device=cpu) [Validation dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu) [Testing dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu) Fitting the Model One Basic Model Now let's fit a basic BEMB model to the data. Recall that an user \\(u\\) corresponds to a student and an item \\(i\\) corresponds to question in this tutorial. The basic model we will be fitting has utility representation \\[ U_{ui} = \\lambda_i + \\theta_u^\\top \\alpha_i \\] where \\[ \\theta_u, \\alpha_i \\in \\mathbb{R}^{10} \\] The predicted probability for student \\(u\\) to correctly answer question \\(i\\) is \\[ \\frac{1}{1 + e^{-U_{ui}}} \\] Important : be sure to set pred_item=False below since the model is predicting choice_dataset.label instead of choice_dataset.item as in traditional consumer choice modeling. obs2prior_dict = { 'lambda_item' : False , 'theta_user' : False , 'alpha_item' : False } LATENT_DIM = 10 coef_dim_dict = { 'lambda_item' : 1 , 'theta_user' : LATENT_DIM , 'alpha_item' : LATENT_DIM } bemb = LitBEMBFlex ( learning_rate = 0.1 , pred_item = False , num_seeds = 4 , utility_formula = 'lambda_item + theta_user * alpha_item' , num_users = num_users , num_items = num_items , obs2prior_dict = obs2prior_dict , coef_dim_dict = coef_dim_dict , trace_log_q = True , num_item_obs = num_item_obs , prior_variance = 1 ) if torch . cuda . is_available (): bemb = bemb . to ( 'cuda' ) bemb = run ( bemb , dataset_list , batch_size = len ( choice_dataset ) // 20 , num_epochs = 10 ) BEMB: utility formula parsed: [{'coefficient': ['lambda_item'], 'observable': None}, {'coefficient': ['theta_user', 'alpha_item'], 'observable': None}] GPU available: True, used: True TPU available: False, using: 0 TPU cores IPU available: False, using: 0 IPUs HPU available: False, using: 0 HPUs LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params ----------------------------------- 0 | model | BEMBFlex | 5.3 M ----------------------------------- 5.3 M Trainable params 0 Non-trainable params 5.3 M Total params 21.258 Total estimated model params size (MB) ==================== model received ==================== Bayesian EMBedding Model with U[user, item, session] = lambda_item + theta_user * alpha_item Total number of parameters: 5314408. With the following coefficients: ModuleDict( (lambda_item): BayesianCoefficient(num_classes=3604, dimension=1, prior=N(0, I)) (theta_user): BayesianCoefficient(num_classes=261756, dimension=10, prior=N(0, I)) (alpha_item): BayesianCoefficient(num_classes=3604, dimension=10, prior=N(0, I)) ) [] ==================== data set received ==================== [Training dataset] ChoiceDataset(label=[6897376], item_index=[6897376], user_index=[6897376], session_index=[6897376], item_availability=[], item_obs=[3604, 124], device=cpu) [Validation dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu) [Testing dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu) ==================== train the model ==================== Sanity Checking: 0it [00:00, ?it/s] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] time taken: 89.43709015846252 ==================== test performance ==================== Testing: 0it [00:00, ?it/s] \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Test metric DataLoader 0 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 test_acc 0.8308121813280877 test_ll -0.3618064307005444 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Leveraging More Complex Utility Representations Let's add the item-observable measuring capacities and knowledge required by answering each question to the utility representation. \\[ U_{ui} = \\lambda_i + \\theta_u^\\top \\alpha_i + \\eta_u^\\top X^{(item\\_obs)}_i \\] where \\[ \\theta_u, \\alpha_i \\in \\mathbb{R}^{10} \\] and \\[ \\eta_u, X^{(item\\_obs)}_i \\in \\mathbb{R}^{124} \\] obs2prior_dict = { 'lambda_item' : False , 'theta_user' : False , 'alpha_item' : False , 'eta_user' : False } LATENT_DIM = 10 coef_dim_dict = { 'lambda_item' : 1 , 'theta_user' : LATENT_DIM , 'alpha_item' : LATENT_DIM , 'eta_user' : num_item_obs } bemb = LitBEMBFlex ( # trainings args. learning_rate = 0.1 , pred_item = False , num_seeds = 4 , # model args, will be passed to BEMB constructor. utility_formula = 'lambda_item + theta_user * alpha_item + eta_user * item_obs' , num_users = num_users , num_items = num_items , obs2prior_dict = obs2prior_dict , coef_dim_dict = coef_dim_dict , trace_log_q = True , num_item_obs = num_item_obs , prior_variance = 1 ) if torch . cuda . is_available (): bemb = bemb . to ( 'cuda' ) bemb = run ( bemb , dataset_list , batch_size = len ( choice_dataset ) // 20 , num_epochs = 10 ) BEMB: utility formula parsed: [{'coefficient': ['lambda_item'], 'observable': None}, {'coefficient': ['theta_user', 'alpha_item'], 'observable': None}, {'coefficient': ['eta_user'], 'observable': 'item_obs'}] GPU available: True, used: True TPU available: False, using: 0 TPU cores IPU available: False, using: 0 IPUs HPU available: False, using: 0 HPUs LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params ----------------------------------- 0 | model | BEMBFlex | 70.2 M ----------------------------------- 70.2 M Trainable params 0 Non-trainable params 70.2 M Total params 280.920 Total estimated model params size (MB) ==================== model received ==================== Bayesian EMBedding Model with U[user, item, session] = lambda_item + theta_user * alpha_item + eta_user * item_obs Total number of parameters: 70229896. With the following coefficients: ModuleDict( (lambda_item): BayesianCoefficient(num_classes=3604, dimension=1, prior=N(0, I)) (theta_user): BayesianCoefficient(num_classes=261756, dimension=10, prior=N(0, I)) (alpha_item): BayesianCoefficient(num_classes=3604, dimension=10, prior=N(0, I)) (eta_user): BayesianCoefficient(num_classes=261756, dimension=124, prior=N(0, I)) ) [] ==================== data set received ==================== [Training dataset] ChoiceDataset(label=[6897376], item_index=[6897376], user_index=[6897376], session_index=[6897376], item_availability=[], item_obs=[3604, 124], device=cpu) [Validation dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu) [Testing dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu) ==================== train the model ==================== LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] time taken: 185.29189801216125 ==================== test performance ==================== Testing: 0it [00:00, ?it/s] \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Test metric DataLoader 0 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 test_acc 0.852068960717815 test_ll -0.3408827750695644 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Leveraging obs2prior In both examples above, the prior of all coefficients were standard Gaussian distributions. We can improve the model by incorporating the obs2prior option and let the mean of prior distribution of item-specific coefficients (i.e., \\(\\lambda_i\\) and \\(\\alpha_i\\) ) depend on item observables. One can turn on the obs2prior option easily by setting obs2prior_dict['lambda_item'] = True and obs2prior_dict['alpha_item'] = True . Important : we recommend to set a small prior_variance to make obs2prior more effective. For example, if one set prior_variance= \\(\\infty\\) , prior distributions do not matter at all to the optimization, and the obs2prior will be ineffectively as a result. \\[ U_{ui} = \\lambda_i + \\theta_u^\\top \\alpha_i \\] where \\[ \\theta_u, \\alpha_i \\in \\mathbb{R}^{10} \\] obs2prior_dict = { 'lambda_item' : True , 'theta_user' : False , 'alpha_item' : True , 'eta_user' : False } LATENT_DIM = 10 coef_dim_dict = { 'lambda_user' : 1 , 'lambda_item' : 1 , 'theta_user' : LATENT_DIM , 'alpha_item' : LATENT_DIM , 'eta_user' : num_item_obs } bemb = LitBEMBFlex ( # trainings args. learning_rate = 0.1 , pred_item = False , num_seeds = 4 , # model args, will be passed to BEMB constructor. utility_formula = 'lambda_item + theta_user * alpha_item + eta_user * item_obs' , num_users = num_users , num_items = num_items , obs2prior_dict = obs2prior_dict , coef_dim_dict = coef_dim_dict , trace_log_q = True , num_item_obs = num_item_obs , prior_variance = 0.01 ) if torch . cuda . is_available (): bemb = bemb . to ( 'cuda' ) bemb = run ( bemb , dataset_list , batch_size = len ( choice_dataset ) // 20 , num_epochs = 50 ) BEMB: utility formula parsed: [{'coefficient': ['lambda_item'], 'observable': None}, {'coefficient': ['theta_user', 'alpha_item'], 'observable': None}, {'coefficient': ['eta_user'], 'observable': 'item_obs'}] GPU available: True, used: True TPU available: False, using: 0 TPU cores IPU available: False, using: 0 IPUs HPU available: False, using: 0 HPUs LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params ----------------------------------- 0 | model | BEMBFlex | 70.2 M ----------------------------------- 70.2 M Trainable params 0 Non-trainable params 70.2 M Total params 280.930 Total estimated model params size (MB) ==================== model received ==================== Bayesian EMBedding Model with U[user, item, session] = lambda_item + theta_user * alpha_item + eta_user * item_obs Total number of parameters: 70232624. With the following coefficients: ModuleDict( (lambda_item): BayesianCoefficient(num_classes=3604, dimension=1, prior=N(H*X_obs(H shape=torch.Size([1, 124]), X_obs shape=124), Ix0.01)) (theta_user): BayesianCoefficient(num_classes=261756, dimension=10, prior=N(0, I)) (alpha_item): BayesianCoefficient(num_classes=3604, dimension=10, prior=N(H*X_obs(H shape=torch.Size([10, 124]), X_obs shape=124), Ix0.01)) (eta_user): BayesianCoefficient(num_classes=261756, dimension=124, prior=N(0, I)) ) [] ==================== data set received ==================== [Training dataset] ChoiceDataset(label=[6897376], item_index=[6897376], user_index=[6897376], session_index=[6897376], item_availability=[], item_obs=[3604, 124], device=cpu) [Validation dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu) [Testing dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu) ==================== train the model ==================== Sanity Checking: 0it [00:00, ?it/s] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] time taken: 941.1486117839813 ==================== test performance ==================== Testing: 0it [00:00, ?it/s] \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Test metric DataLoader 0 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 test_acc 0.8209313222883601 test_ll -0.3934649652798017 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Tuning the Model There are tons of parameters in models above, for example, we choose LATENT_DIM = 10 based on our own experience. However, these choices of hyper-parameters can be sub-optimal. We recommend researchers to try out different combinations of hyper-parameters before sticking with a particular hyper-parameter configuration. We will be providing a script for effectively parameter tuning though the learning-tool-competition project.","title":"Tutorial for Bayesian Embedding (BEMB) with Educational Data"},{"location":"education_data/#tutorial-for-bayesian-embedding-bemb-with-educational-data","text":"Author: Tianyu Du Date: May. 7, 2022 This tutorial helps lab members to deploy the BEMB model on educational question-answering (QA) datasets. We will be using the 17Zuoye data, which is available on Sherlock, throughout this tutorial. However, this tutorial generalizes to any QA datasets in which each row of the dataset corresponds to a triple (student, question, label). Equivalently, each row of these QA datasets is about a student answering a question correctly/incorrectly. You can find the executable Jupyter notebook for this tutorial here import os import numpy as np import pandas as pd import torch from bemb.model import LitBEMBFlex from bemb.utils.run_helper import run from sklearn import preprocessing from torch_choice.data import ChoiceDataset","title":"Tutorial for Bayesian Embedding (BEMB) with Educational Data"},{"location":"education_data/#load-data","text":"We build some helper functions especially for the Zuoye data for demonstration, you can skip this part if you have your own data ready. Please see below for the formats data. def get_all_unique_fields ( column , field = 'id' ): unique_fields = set () for tag_list in column : for entry in tag_list : unique_fields . add ( entry [ field ]) return list ( unique_fields ) def convert_tag_list_into_binary_vector ( tag_list , encoder , vec_len ): index = encoder . transform ([ x [ 'id' ] for x in tag_list ]) out = torch . zeros ([ vec_len ], dtype = torch . float64 ) out [ index ] = 1 return out def convert_column_to_binary_vectors ( column ): all_elements = get_all_unique_fields ( column ) my_encoder = preprocessing . LabelEncoder () my_encoder . fit ( all_elements ) out = column . apply ( lambda x : convert_tag_list_into_binary_vector ( x , my_encoder , len ( all_elements ))) return out If you wish to try this tutorial on the 17Zuoye dataset, which is located at data_path on Sherlock. Please make sure the data_path is correct if you are running on your local machine. Henry prepared these datasets in the feather format. Feather is a portable file format for storing Arrow tables or data frames (from languages like Python or R) that utilizes the Arrow IPC format internally. Feather was created early in the Arrow project as a proof of concept for fast, language-agnostic data frame storage for Python (pandas) and R (see here for more information about Feather data format). You can easily load the data using pandas. data_path = '/oak/stanford/groups/athey/17Zuoye/bayesian_measurement_17zy/bayes' response_path = os . path . join ( data_path , 'exam_response_with_attrib.feather' ) attribute_path = os . path . join ( data_path , 'exam_response_ques_attrib.feather' )","title":"Load Data"},{"location":"education_data/#the-user-item-and-label-dataset-ie-the-response-dataset","text":"For the student response use case, the response dataset contains at least three columns: {user_id, item_id, label} . Where user_id is typically the student's ID, item_id is the question's ID, and label is the student's response to the question, which is a binary variable indicating whether the student answered the question correctly. In the df_resp dataset loaded below, the student_id column corresponds to the user_id , the question_id column corresponds to the item_id , and the correct column corresponds to the label . The length of the df_resp dataset is the total number of times students answer questions, this corresponds to the number of purchasing records following our terminology in the data management tutorial. df_resp = pd . read_feather ( response_path ) print ( 'Number of student-question response pairs:' , len ( df_resp )) df_resp Number of student-question response pairs: 8621720 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } student_id question_id correct subject grade 0 90368 409 0 CHINESE 2 1 90368 409 0 CHINESE 2 2 90368 409 0 CHINESE 2 3 93193 409 0 CHINESE 2 4 93193 409 0 CHINESE 2 ... ... ... ... ... ... 8621715 115131 2080 0 MATH 2 8621716 83680 2561 1 ENGLISH 3 8621717 83680 2564 1 ENGLISH 3 8621718 83680 2563 1 ENGLISH 3 8621719 83680 2562 1 ENGLISH 3 8621720 rows \u00d7 5 columns The dataset contains 261,756 students and 3,604 questions. Student IDs are already encoded as integers ranging from 0 to 261,755 , and question IDs are already encoded as integers ranging from 0 to 3,603 . print ( df_resp [ 'student_id' ] . nunique ()) print ( df_resp [ 'question_id' ] . nunique ()) 261756 3604 print ( df_resp [ 'student_id' ] . max ()) print ( df_resp [ 'question_id' ] . max ()) 261755 3603","title":"The User-Item and Label Dataset (i.e., The Response Dataset)"},{"location":"education_data/#the-attribute-dataset","text":"Researchers can optionally supply a separate attribute dataset including observables of users (i.e., students) and items (i.e., questions). Here we load the df_attr dataset, which has length equal to the number of questions. Each row of df_attr contains attributes/observables of each question. Specifically, df_attr contains a column called question_id and several other columns of attributes. For each question, we have two attribute as known as capability and knowledge . df_attr = pd . read_feather ( attribute_path ) . sort_values ( 'question_id' ) . reset_index ( drop = True ) df_attr .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } question_id capability knowledge kp 0 0 [{'id': 'TAG_10100001553832', 'type': 0}, {'id... [{'id': '0101001', 'type': 0.0}, {'id': '01020... [{'id': 'KP_10100071064944'}, {'id': 'KP_10100... 1 1 [{'id': 'TAG_10100001553832', 'type': 0}, {'id... [{'id': '0101001', 'type': 0.0}, {'id': '01020... [{'id': 'KP_10100050863402'}, {'id': 'KP_10100... 2 2 [{'id': 'TAG_10100001553832', 'type': 0}, {'id... [{'id': '0101001', 'type': 0.0}, {'id': '01020... [{'id': 'KP_10100050866393'}] 3 3 [{'id': 'TAG_10100001553832', 'type': 0}, {'id... [{'id': '0101001', 'type': 0.0}, {'id': '01020... [{'id': 'KP_10100125674593'}, {'id': 'KP_10100... 4 4 [{'id': 'TAG_10100001553832', 'type': 0}, {'id... [{'id': '0101001', 'type': 0.0}, {'id': '01020... [{'id': 'KP_10100077305590'}, {'id': 'KP_10100... ... ... ... ... ... 3599 3599 [{'id': 'TAG_10300000827653', 'type': 0}, {'id... [{'id': '0301001', 'type': 0.0}, {'id': '03020... [{'id': 'KP_10300117105040'}] 3600 3600 [{'id': 'TAG_10300000827653', 'type': 0}, {'id... [{'id': '0301001', 'type': 0.0}, {'id': '03020... [{'id': 'KP_10300212870515'}] 3601 3601 [{'id': 'TAG_10300000827653', 'type': 0}, {'id... [{'id': '0301001', 'type': 0.0}, {'id': '03020... [{'id': 'KP_10300111435423'}] 3602 3602 [{'id': 'TAG_10300000827653', 'type': 0}, {'id... [{'id': '0301001', 'type': 0.0}, {'id': '03020... [{'id': 'KP_10300213265389'}] 3603 3603 [{'id': 'TAG_10300000827653', 'type': 0}, {'id... [{'id': '0301001', 'type': 0.0}, {'id': '03020... [{'id': 'KP_10300111316448'}] 3604 rows \u00d7 4 columns There are 90 types of capabilities and 34 types of knowledge required by different questions in ths dataset. We convert these attributes into two binary vectors named capability_vec and knowledge_vec . The capability_vec vector has shape (number_of_questions, 90) and the knowledge_vec vector has shape (number_of_questions, 34) . For example, knowledge_vec[i, j] = 1 indicates answering question i correctly requires type j of knowledge. def f ( z ): # extract knowledge domain. return z [ - 1 ][ 'id' ] knowledge_domain = [ f ( x ) for x in df_attr [ 'knowledge' ] . values ] df_attr [ 'capability_vec' ] = convert_column_to_binary_vectors ( df_attr [ 'capability' ]) df_attr [ 'knowledge_vec' ] = convert_column_to_binary_vectors ( df_attr [ 'knowledge' ]) capability_vec = torch . stack ( df_attr [ 'capability_vec' ] . to_list (), dim = 0 ) . float () knowledge_vec = torch . stack ( df_attr [ 'knowledge_vec' ] . to_list (), dim = 0 ) . float () print ( f \" { knowledge_vec . shape =:} \" ) print ( f \" { capability_vec . shape =:} \" ) knowledge_vec.shape=torch.Size([3604, 34]) capability_vec.shape=torch.Size([3604, 90]) Lastly, we concatenate the capability_vec and knowledge_vec vectors into a single vector called item_obs with shape (number_of_questions, 124) . This vector encompasses all attributes/observables of items (i.e., questions in this context). item_obs = torch . cat ([ capability_vec , knowledge_vec ], dim = 1 ) print ( f \" { item_obs . shape =:} \" ) item_obs.shape=torch.Size([3604, 124])","title":"The Attribute Dataset"},{"location":"education_data/#construct-the-choicedataset-object","text":"The last step is to construct the ChoiceDataset object. The item_index ( user_index ) keyword argument holds the identify of question answered (student answering the question) in each student-question response pair respectively. The label argument is a binary tensor indicating whether the student answered the question correctly. Lastly, we put the item_obs to capture observables of questions to the dataset. In this tutorial, we don't have any user observables (i.e., observables of students). choice_dataset = ChoiceDataset ( item_index = torch . LongTensor ( df_resp [ 'question_id' ] . values ), user_index = torch . LongTensor ( df_resp [ 'student_id' ] . values ), label = torch . LongTensor ( df_resp [ 'correct' ] . values ), item_obs = item_obs ) No `session_index` is provided, assume each choice instance is in its own session. You can print the choice_dataset to see information about tensors encompassed. print ( choice_dataset ) ChoiceDataset(label=[8621720], item_index=[8621720], user_index=[8621720], session_index=[8621720], item_availability=[], item_obs=[3604, 124], device=cpu) num_users = len ( torch . unique ( choice_dataset . user_index )) num_items = len ( torch . unique ( choice_dataset . item_index )) num_item_obs = choice_dataset . item_obs . shape [ - 1 ]","title":"Construct the ChoiceDataset Object"},{"location":"education_data/#splitting-data-into-training-validation-and-testing-sets","text":"To test the generalizability of the model, we split the data into training, validation, and testing sets. Specifically, we randomly take 80% of student-question pairs as the training set, 10% as the validation set, and the rest 10% as the testing set. # randomly permutate the index ranging from (0, 1, ..., len(choice_Dataset) - 1). idx = np . random . permutation ( len ( choice_dataset )) # take the first 80% from the random permutation as indices for the training set. train_size = int ( 0.8 * len ( choice_dataset )) val_size = int ( 0.1 * len ( choice_dataset )) train_idx = idx [: train_size ] val_idx = idx [ train_size : train_size + val_size ] test_idx = idx [ train_size + val_size :] # we put train/validation/test datasets into a list. dataset_list = [ choice_dataset [ train_idx ], choice_dataset [ val_idx ], choice_dataset [ test_idx ]] print ( '[Training dataset]' , dataset_list [ 0 ]) print ( '[Validation dataset]' , dataset_list [ 1 ]) print ( '[Testing dataset]' , dataset_list [ 2 ]) [Training dataset] ChoiceDataset(label=[6897376], item_index=[6897376], user_index=[6897376], session_index=[6897376], item_availability=[], item_obs=[3604, 124], device=cpu) [Validation dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu) [Testing dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu)","title":"Splitting Data into Training, Validation, and Testing Sets"},{"location":"education_data/#fitting-the-model","text":"","title":"Fitting the Model"},{"location":"education_data/#one-basic-model","text":"Now let's fit a basic BEMB model to the data. Recall that an user \\(u\\) corresponds to a student and an item \\(i\\) corresponds to question in this tutorial. The basic model we will be fitting has utility representation \\[ U_{ui} = \\lambda_i + \\theta_u^\\top \\alpha_i \\] where \\[ \\theta_u, \\alpha_i \\in \\mathbb{R}^{10} \\] The predicted probability for student \\(u\\) to correctly answer question \\(i\\) is \\[ \\frac{1}{1 + e^{-U_{ui}}} \\] Important : be sure to set pred_item=False below since the model is predicting choice_dataset.label instead of choice_dataset.item as in traditional consumer choice modeling. obs2prior_dict = { 'lambda_item' : False , 'theta_user' : False , 'alpha_item' : False } LATENT_DIM = 10 coef_dim_dict = { 'lambda_item' : 1 , 'theta_user' : LATENT_DIM , 'alpha_item' : LATENT_DIM } bemb = LitBEMBFlex ( learning_rate = 0.1 , pred_item = False , num_seeds = 4 , utility_formula = 'lambda_item + theta_user * alpha_item' , num_users = num_users , num_items = num_items , obs2prior_dict = obs2prior_dict , coef_dim_dict = coef_dim_dict , trace_log_q = True , num_item_obs = num_item_obs , prior_variance = 1 ) if torch . cuda . is_available (): bemb = bemb . to ( 'cuda' ) bemb = run ( bemb , dataset_list , batch_size = len ( choice_dataset ) // 20 , num_epochs = 10 ) BEMB: utility formula parsed: [{'coefficient': ['lambda_item'], 'observable': None}, {'coefficient': ['theta_user', 'alpha_item'], 'observable': None}] GPU available: True, used: True TPU available: False, using: 0 TPU cores IPU available: False, using: 0 IPUs HPU available: False, using: 0 HPUs LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params ----------------------------------- 0 | model | BEMBFlex | 5.3 M ----------------------------------- 5.3 M Trainable params 0 Non-trainable params 5.3 M Total params 21.258 Total estimated model params size (MB) ==================== model received ==================== Bayesian EMBedding Model with U[user, item, session] = lambda_item + theta_user * alpha_item Total number of parameters: 5314408. With the following coefficients: ModuleDict( (lambda_item): BayesianCoefficient(num_classes=3604, dimension=1, prior=N(0, I)) (theta_user): BayesianCoefficient(num_classes=261756, dimension=10, prior=N(0, I)) (alpha_item): BayesianCoefficient(num_classes=3604, dimension=10, prior=N(0, I)) ) [] ==================== data set received ==================== [Training dataset] ChoiceDataset(label=[6897376], item_index=[6897376], user_index=[6897376], session_index=[6897376], item_availability=[], item_obs=[3604, 124], device=cpu) [Validation dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu) [Testing dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu) ==================== train the model ==================== Sanity Checking: 0it [00:00, ?it/s] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] time taken: 89.43709015846252 ==================== test performance ==================== Testing: 0it [00:00, ?it/s] \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Test metric DataLoader 0 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 test_acc 0.8308121813280877 test_ll -0.3618064307005444 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500","title":"One Basic Model"},{"location":"education_data/#leveraging-more-complex-utility-representations","text":"Let's add the item-observable measuring capacities and knowledge required by answering each question to the utility representation. \\[ U_{ui} = \\lambda_i + \\theta_u^\\top \\alpha_i + \\eta_u^\\top X^{(item\\_obs)}_i \\] where \\[ \\theta_u, \\alpha_i \\in \\mathbb{R}^{10} \\] and \\[ \\eta_u, X^{(item\\_obs)}_i \\in \\mathbb{R}^{124} \\] obs2prior_dict = { 'lambda_item' : False , 'theta_user' : False , 'alpha_item' : False , 'eta_user' : False } LATENT_DIM = 10 coef_dim_dict = { 'lambda_item' : 1 , 'theta_user' : LATENT_DIM , 'alpha_item' : LATENT_DIM , 'eta_user' : num_item_obs } bemb = LitBEMBFlex ( # trainings args. learning_rate = 0.1 , pred_item = False , num_seeds = 4 , # model args, will be passed to BEMB constructor. utility_formula = 'lambda_item + theta_user * alpha_item + eta_user * item_obs' , num_users = num_users , num_items = num_items , obs2prior_dict = obs2prior_dict , coef_dim_dict = coef_dim_dict , trace_log_q = True , num_item_obs = num_item_obs , prior_variance = 1 ) if torch . cuda . is_available (): bemb = bemb . to ( 'cuda' ) bemb = run ( bemb , dataset_list , batch_size = len ( choice_dataset ) // 20 , num_epochs = 10 ) BEMB: utility formula parsed: [{'coefficient': ['lambda_item'], 'observable': None}, {'coefficient': ['theta_user', 'alpha_item'], 'observable': None}, {'coefficient': ['eta_user'], 'observable': 'item_obs'}] GPU available: True, used: True TPU available: False, using: 0 TPU cores IPU available: False, using: 0 IPUs HPU available: False, using: 0 HPUs LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params ----------------------------------- 0 | model | BEMBFlex | 70.2 M ----------------------------------- 70.2 M Trainable params 0 Non-trainable params 70.2 M Total params 280.920 Total estimated model params size (MB) ==================== model received ==================== Bayesian EMBedding Model with U[user, item, session] = lambda_item + theta_user * alpha_item + eta_user * item_obs Total number of parameters: 70229896. With the following coefficients: ModuleDict( (lambda_item): BayesianCoefficient(num_classes=3604, dimension=1, prior=N(0, I)) (theta_user): BayesianCoefficient(num_classes=261756, dimension=10, prior=N(0, I)) (alpha_item): BayesianCoefficient(num_classes=3604, dimension=10, prior=N(0, I)) (eta_user): BayesianCoefficient(num_classes=261756, dimension=124, prior=N(0, I)) ) [] ==================== data set received ==================== [Training dataset] ChoiceDataset(label=[6897376], item_index=[6897376], user_index=[6897376], session_index=[6897376], item_availability=[], item_obs=[3604, 124], device=cpu) [Validation dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu) [Testing dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu) ==================== train the model ==================== LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] time taken: 185.29189801216125 ==================== test performance ==================== Testing: 0it [00:00, ?it/s] \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Test metric DataLoader 0 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 test_acc 0.852068960717815 test_ll -0.3408827750695644 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500","title":"Leveraging More Complex Utility Representations"},{"location":"education_data/#leveraging-obs2prior","text":"In both examples above, the prior of all coefficients were standard Gaussian distributions. We can improve the model by incorporating the obs2prior option and let the mean of prior distribution of item-specific coefficients (i.e., \\(\\lambda_i\\) and \\(\\alpha_i\\) ) depend on item observables. One can turn on the obs2prior option easily by setting obs2prior_dict['lambda_item'] = True and obs2prior_dict['alpha_item'] = True . Important : we recommend to set a small prior_variance to make obs2prior more effective. For example, if one set prior_variance= \\(\\infty\\) , prior distributions do not matter at all to the optimization, and the obs2prior will be ineffectively as a result. \\[ U_{ui} = \\lambda_i + \\theta_u^\\top \\alpha_i \\] where \\[ \\theta_u, \\alpha_i \\in \\mathbb{R}^{10} \\] obs2prior_dict = { 'lambda_item' : True , 'theta_user' : False , 'alpha_item' : True , 'eta_user' : False } LATENT_DIM = 10 coef_dim_dict = { 'lambda_user' : 1 , 'lambda_item' : 1 , 'theta_user' : LATENT_DIM , 'alpha_item' : LATENT_DIM , 'eta_user' : num_item_obs } bemb = LitBEMBFlex ( # trainings args. learning_rate = 0.1 , pred_item = False , num_seeds = 4 , # model args, will be passed to BEMB constructor. utility_formula = 'lambda_item + theta_user * alpha_item + eta_user * item_obs' , num_users = num_users , num_items = num_items , obs2prior_dict = obs2prior_dict , coef_dim_dict = coef_dim_dict , trace_log_q = True , num_item_obs = num_item_obs , prior_variance = 0.01 ) if torch . cuda . is_available (): bemb = bemb . to ( 'cuda' ) bemb = run ( bemb , dataset_list , batch_size = len ( choice_dataset ) // 20 , num_epochs = 50 ) BEMB: utility formula parsed: [{'coefficient': ['lambda_item'], 'observable': None}, {'coefficient': ['theta_user', 'alpha_item'], 'observable': None}, {'coefficient': ['eta_user'], 'observable': 'item_obs'}] GPU available: True, used: True TPU available: False, using: 0 TPU cores IPU available: False, using: 0 IPUs HPU available: False, using: 0 HPUs LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params ----------------------------------- 0 | model | BEMBFlex | 70.2 M ----------------------------------- 70.2 M Trainable params 0 Non-trainable params 70.2 M Total params 280.930 Total estimated model params size (MB) ==================== model received ==================== Bayesian EMBedding Model with U[user, item, session] = lambda_item + theta_user * alpha_item + eta_user * item_obs Total number of parameters: 70232624. With the following coefficients: ModuleDict( (lambda_item): BayesianCoefficient(num_classes=3604, dimension=1, prior=N(H*X_obs(H shape=torch.Size([1, 124]), X_obs shape=124), Ix0.01)) (theta_user): BayesianCoefficient(num_classes=261756, dimension=10, prior=N(0, I)) (alpha_item): BayesianCoefficient(num_classes=3604, dimension=10, prior=N(H*X_obs(H shape=torch.Size([10, 124]), X_obs shape=124), Ix0.01)) (eta_user): BayesianCoefficient(num_classes=261756, dimension=124, prior=N(0, I)) ) [] ==================== data set received ==================== [Training dataset] ChoiceDataset(label=[6897376], item_index=[6897376], user_index=[6897376], session_index=[6897376], item_availability=[], item_obs=[3604, 124], device=cpu) [Validation dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu) [Testing dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu) ==================== train the model ==================== Sanity Checking: 0it [00:00, ?it/s] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] time taken: 941.1486117839813 ==================== test performance ==================== Testing: 0it [00:00, ?it/s] \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Test metric DataLoader 0 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 test_acc 0.8209313222883601 test_ll -0.3934649652798017 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500","title":"Leveraging obs2prior"},{"location":"education_data/#tuning-the-model","text":"There are tons of parameters in models above, for example, we choose LATENT_DIM = 10 based on our own experience. However, these choices of hyper-parameters can be sub-optimal. We recommend researchers to try out different combinations of hyper-parameters before sticking with a particular hyper-parameter configuration. We will be providing a script for effectively parameter tuning though the learning-tool-competition project.","title":"Tuning the Model"},{"location":"install/","text":"Installation This page will guide you through the installation procedure of torch-choice and bemb . There are two parts of this project: the torch_choice library consisting of data management modules, logit and nested-logit models for consumer choice modelling. For researchers wish to use the Bayesian Embedding (BEMB) model, they need to install an additional bemb package, which was built on the top of torch_choice . Note Since this project is still on its pre-release stage and subject to changes, we have not uploaded our packages to PIP or CONDA. Researchers need to install these packages from Github source code. Option 1: Install using Source Code from Github Repository To install torch_choice and bemb from source, 1. Clone the repositories of both torch_choice and bemb to your local machine. 2. Install required dependencies (e.g., PyTorch and PyTorch-Lightning). 3. For each of repositories, run python3 ./setup.py develop to add the package to your Python environment. 4. Check installation by running python3 -c \"import torch_choice; print(torch_choice.__version__)\" . 5. Check installation by running python3 -c \"import bemb; print(bemb.__version__)\" . Option 2: Install using Pip The torch-choice is available on PIP now here ! You can use pip install torch-choice to install it. Note : We are working on publishing BEMB to PIP.","title":"Get Started"},{"location":"install/#installation","text":"This page will guide you through the installation procedure of torch-choice and bemb . There are two parts of this project: the torch_choice library consisting of data management modules, logit and nested-logit models for consumer choice modelling. For researchers wish to use the Bayesian Embedding (BEMB) model, they need to install an additional bemb package, which was built on the top of torch_choice . Note Since this project is still on its pre-release stage and subject to changes, we have not uploaded our packages to PIP or CONDA. Researchers need to install these packages from Github source code.","title":"Installation"},{"location":"install/#option-1-install-using-source-code-from-github-repository","text":"To install torch_choice and bemb from source, 1. Clone the repositories of both torch_choice and bemb to your local machine. 2. Install required dependencies (e.g., PyTorch and PyTorch-Lightning). 3. For each of repositories, run python3 ./setup.py develop to add the package to your Python environment. 4. Check installation by running python3 -c \"import torch_choice; print(torch_choice.__version__)\" . 5. Check installation by running python3 -c \"import bemb; print(bemb.__version__)\" .","title":"Option 1: Install using Source Code from Github Repository"},{"location":"install/#option-2-install-using-pip","text":"The torch-choice is available on PIP now here ! You can use pip install torch-choice to install it. Note : We are working on publishing BEMB to PIP.","title":"Option 2: Install using Pip"},{"location":"intro/","text":"Introduction This document provides a short introduction to the consumer choice model we aim to solve. In short, all models in the package aim to predict which item an user will purchase while facing the shelves in a supermarket. More specifically, for each user \\(u\\) and item \\(i\\) , models compute a value \\(U_{ui}\\) predicting the utility user \\(u\\) will get from purchasing item \\(i\\) , then user \\(u\\) is predicted to purchase the item \\(i\\) generating the maximum utility. However, the usage of our models is not limited to this supermarket context, researchers can adjust the definition of user and item to fit any choice modelling context. The related project page overviews some extensions of our models to other context. Components of the Consumer Choice Modelling Problem We begin with essential component of the consumer choice modelling problem. Walking through these components should help you understand what kind of data our models are working on. Purchasing Record Each row (record) of the dataset is called a purchasing record , which includes who bought what at when and where . Let \\(B\\) denote the number of purchasing records in the dataset (i.e., number of rows of the dataset). Each row \\(b \\in \\{1,2,\\dots, B\\}\\) corresponds to a purchase record (i.e., who bought what at where and when ). Items and Categories To begin with, there are \\(I\\) items indexed by \\(i \\in \\{1,2,\\dots,I\\}\\) under our consideration. Further, the researcher can optionally partition the set items into \\(C\\) categories indexed by \\(c \\in \\{1,2,\\dots,C\\}\\) . Let \\(I_c\\) denote the collection of items in category \\(c\\) , it is easy to verify that $ \\bigcup_{c \\in {1, 2, \\dots, C}} I_c = {1, 2, \\dots I} $ If the researcher does not wish to model different categories differently, the researcher can simply put all items in one single category: \\(I_1 = \\{1, 2, \\dots I\\}\\) , so that all items belong to the same category. Note : since we will be using PyTorch to train our model, we represent their identities with integer values instead of the raw human-readable names of items (e.g., Dell 24 inch LCD monitor). Raw item names can be encoded easily with sklearn.preprocessing.OrdinalEncoder Users Each purchaing reocrd is naturally associated with an user indexed by \\(u \\in \\{1,2,\\dots,U\\}\\) ( who ) as well. Sessions Our data structure encompasses where and when using a notion called session indexed by \\(s \\in \\{1,2,\\dots, S\\}\\) . For example, when the data came from a single store over the period of a year. In this case, the notion of where does not matter that much, and session \\(s\\) is simply the date of purchase. Another example is that we have the purchase record from different stores, the session \\(s\\) can be defined as a pair of (date, store) instead. If the researcher does not wish to handle records from different sessions differently, the researcher can assign the same session ID to all rows of the dataset. To summarize, each purchasing record \\(b\\) in the dataset is characterized by a user-session-item tuple \\((u, s, i)\\) . When there are multiple items bought by the same user in the same session, there will be multiple rows in the dataset with the same \\((u, s)\\) corresponding to the same receipt. Item Availability It is not necessarily that all items are available in every session, items can get out-of-stock in particular sessions. To handle these cases, the researcher can optionally provide a boolean tensor \\(\\in \\{\\texttt{True}, \\texttt{False}\\}^{S\\times I}\\) to indicate which items are available for purchasing in each session. While predicting the purchase probabilities, the model sets the probability for these unavailable items to zero and normalizes probabilities among available items. If the item availability is not provided, the model assumes all items are available in all sessions. Available Models","title":"About"},{"location":"intro/#introduction","text":"This document provides a short introduction to the consumer choice model we aim to solve. In short, all models in the package aim to predict which item an user will purchase while facing the shelves in a supermarket. More specifically, for each user \\(u\\) and item \\(i\\) , models compute a value \\(U_{ui}\\) predicting the utility user \\(u\\) will get from purchasing item \\(i\\) , then user \\(u\\) is predicted to purchase the item \\(i\\) generating the maximum utility. However, the usage of our models is not limited to this supermarket context, researchers can adjust the definition of user and item to fit any choice modelling context. The related project page overviews some extensions of our models to other context.","title":"Introduction"},{"location":"intro/#components-of-the-consumer-choice-modelling-problem","text":"We begin with essential component of the consumer choice modelling problem. Walking through these components should help you understand what kind of data our models are working on.","title":"Components of the Consumer Choice Modelling Problem"},{"location":"intro/#purchasing-record","text":"Each row (record) of the dataset is called a purchasing record , which includes who bought what at when and where . Let \\(B\\) denote the number of purchasing records in the dataset (i.e., number of rows of the dataset). Each row \\(b \\in \\{1,2,\\dots, B\\}\\) corresponds to a purchase record (i.e., who bought what at where and when ).","title":"Purchasing Record"},{"location":"intro/#items-and-categories","text":"To begin with, there are \\(I\\) items indexed by \\(i \\in \\{1,2,\\dots,I\\}\\) under our consideration. Further, the researcher can optionally partition the set items into \\(C\\) categories indexed by \\(c \\in \\{1,2,\\dots,C\\}\\) . Let \\(I_c\\) denote the collection of items in category \\(c\\) , it is easy to verify that $ \\bigcup_{c \\in {1, 2, \\dots, C}} I_c = {1, 2, \\dots I} $ If the researcher does not wish to model different categories differently, the researcher can simply put all items in one single category: \\(I_1 = \\{1, 2, \\dots I\\}\\) , so that all items belong to the same category. Note : since we will be using PyTorch to train our model, we represent their identities with integer values instead of the raw human-readable names of items (e.g., Dell 24 inch LCD monitor). Raw item names can be encoded easily with sklearn.preprocessing.OrdinalEncoder","title":"Items and Categories"},{"location":"intro/#users","text":"Each purchaing reocrd is naturally associated with an user indexed by \\(u \\in \\{1,2,\\dots,U\\}\\) ( who ) as well.","title":"Users"},{"location":"intro/#sessions","text":"Our data structure encompasses where and when using a notion called session indexed by \\(s \\in \\{1,2,\\dots, S\\}\\) . For example, when the data came from a single store over the period of a year. In this case, the notion of where does not matter that much, and session \\(s\\) is simply the date of purchase. Another example is that we have the purchase record from different stores, the session \\(s\\) can be defined as a pair of (date, store) instead. If the researcher does not wish to handle records from different sessions differently, the researcher can assign the same session ID to all rows of the dataset. To summarize, each purchasing record \\(b\\) in the dataset is characterized by a user-session-item tuple \\((u, s, i)\\) . When there are multiple items bought by the same user in the same session, there will be multiple rows in the dataset with the same \\((u, s)\\) corresponding to the same receipt.","title":"Sessions"},{"location":"intro/#item-availability","text":"It is not necessarily that all items are available in every session, items can get out-of-stock in particular sessions. To handle these cases, the researcher can optionally provide a boolean tensor \\(\\in \\{\\texttt{True}, \\texttt{False}\\}^{S\\times I}\\) to indicate which items are available for purchasing in each session. While predicting the purchase probabilities, the model sets the probability for these unavailable items to zero and normalizes probabilities among available items. If the item availability is not provided, the model assumes all items are available in all sessions.","title":"Item Availability"},{"location":"intro/#available-models","text":"","title":"Available Models"},{"location":"nested_logit_model_house_cooling/","text":"Random Utility Model (RUM) Part II: Nested Logit Model Author: Tianyu Du The package implements the nested logit model as well, which allows researchers to model choices as a two-stage process: the user first picks a category of purchase and then picks the item from the chosen category that generates the most utility. Examples here are modified from Exercise 2: Nested logit model by Kenneth Train and Yves Croissant . The House Cooling (HC) dataset from mlogit contains data in R format on the choice of heating and central cooling system for 250 single-family, newly built houses in California. The dataset is small and serve as a demonstration of the nested logit model. The alternatives are: Gas central heat with cooling gcc , Electric central resistence heat with cooling ecc , Electric room resistence heat with cooling erc , Electric heat pump, which provides cooling also hpc , Gas central heat without cooling gc , Electric central resistence heat without cooling ec , Electric room resistence heat without cooling er . Heat pumps necessarily provide both heating and cooling such that heat pump without cooling is not an alternative. The variables are: depvar gives the name of the chosen alternative, ich.alt are the installation cost for the heating portion of the system, icca is the installation cost for cooling och.alt are the operating cost for the heating portion of the system occa is the operating cost for cooling income is the annual income of the household Note that the full installation cost of alternative gcc is ich.gcc+icca, and similarly for the operating cost and for the other alternatives with cooling. Nested Logit Model: Background The following code block provides an example initialization of the NestedLogitModel (please refer to examples below for details). model = NestedLogitModel ( category_to_item = category_to_item , category_coef_variation_dict = {}, category_num_param_dict = {}, item_coef_variation_dict = { 'price_obs' : 'constant' }, item_num_param_dict = { 'price_obs' : 7 }, shared_lambda = True ) The nested logit model decompose the utility of choosing item \\(i\\) into the (1) item-specific values and (2) category specify values. For simplicity, suppose item \\(i\\) belongs to category \\(k \\in \\{1, \\dots, K\\}\\) : \\(i \\in B_k\\) . \\[ U_{uit} = W_{ukt} + Y_{uit} \\] Where both \\(W\\) and \\(Y\\) are estimated using linear models from as in the conditional logit model. The log-likelihood for user \\(u\\) to choose item \\(i\\) at time/session \\(t\\) decomposes into the item-level likelihood and category-level likelihood. \\[ \\log P(i \\mid u, t) = \\log P(i \\mid u, t, B_k) + \\log P(k \\mid u, t) \\\\ = \\log \\left(\\frac{\\exp(Y_{uit}/\\lambda_k)}{\\sum_{j \\in B_k} \\exp(Y_{ujt}/\\lambda_k)}\\right) + \\log \\left( \\frac{\\exp(W_{ukt} + \\lambda_k I_{ukt})}{\\sum_{\\ell=1}^K \\exp(W_{u\\ell t} + \\lambda_\\ell I_{u\\ell t})}\\right) \\] The inclusive value of category \\(k\\) , \\(I_{ukt}\\) is defined as \\(\\log \\sum_{j \\in B_k} \\exp(Y_{ujt}/\\lambda_k)\\) , which is the expected utility from choosing the best alternative from category \\(k\\) . The category_to_item keyword defines a dictionary of the mapping \\(k \\mapsto B_k\\) , where keys of category_to_item are integer \\(k\\) 's and category_to_item[k] is a list consisting of IDs of items in \\(B_k\\) . The {category, item}_coef_variation_dict provides specification to \\(W_{ukt}\\) and \\(Y_{uit}\\) respectively, torch_choice allows for empty category level models by providing an empty dictionary (in this case, \\(W_{ukt} = \\epsilon_{ukt}\\) ) since the inclusive value term \\(\\lambda_k I_{ukt}\\) will be used to model the choice over categories. However, by specifying an empty second stage model ( \\(Y_{uit} = \\epsilon_{uit}\\) ), the nested logit model reduces to a conditional logit model of choices over categories. Hence, one should never use the NestedLogitModel class with an empty item-level model. Similar to the conditional logit model, {category, item}_num_param_dict specify the dimension (number of observables to be multiplied with the coefficient) of coefficients. The above code initializes a simple model built upon item-time-specific observables \\(X_{it} \\in \\mathbb{R}^7\\) , \\[ Y_{uit} = \\beta^\\top X_{it} + \\epsilon_{uit} \\\\ W_{ukt} = \\epsilon_{ukt} \\] The research may wish to enfoce the elasiticity \\(\\lambda_k\\) to be constant across categories, setting shared_lambda=True enforces \\(\\lambda_k = \\lambda\\ \\forall k \\in [K]\\) . Load Essential Packages We firstly read essential packages for this tutorial. import argparse import pandas as pd import torch from torch_choice.data import ChoiceDataset , JointDataset , utils from torch_choice.model.nested_logit_model import NestedLogitModel from torch_choice.utils.run_helper import run We then select the appropriate device to run the model on, our package supports both CPU and GPU. if torch . cuda . is_available (): print ( f 'CUDA device used: { torch . cuda . get_device_name () } ' ) DEVICE = 'cuda' else : print ( 'Running tutorial on CPU' ) DEVICE = 'cpu' CUDA device used: NVIDIA GeForce RTX 3090 Load Datasets We firstly read the dataset for this tutorial, the csv file can be found at ./public_datasets/HC.csv . df = pd . read_csv ( './public_datasets/HC.csv' , index_col = 0 ) df = df . reset_index ( drop = True ) df . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } depvar icca occa income ich och idx.id1 idx.id2 inc.room inc.cooling int.cooling cooling.modes room.modes 0 False 0.00 0.00 20 24.50 4.09 1 ec 0 0 0 False False 1 False 27.28 2.95 20 7.86 4.09 1 ecc 0 20 1 True False 2 False 0.00 0.00 20 7.37 3.85 1 er 20 0 0 False True 3 True 27.28 2.95 20 8.79 3.85 1 erc 20 20 1 True True 4 False 0.00 0.00 20 24.08 2.26 1 gc 0 0 0 False False The raw dataset is in a long-format (i.e., each row contains information of one item). df [ 'idx.id2' ] . value_counts () ec 250 ecc 250 er 250 erc 250 gc 250 gcc 250 hpc 250 Name: idx.id2, dtype: int64 # what was actually chosen. item_index = df [ df [ 'depvar' ] == True ] . sort_values ( by = 'idx.id1' )[ 'idx.id2' ] . reset_index ( drop = True ) item_names = [ 'ec' , 'ecc' , 'er' , 'erc' , 'gc' , 'gcc' , 'hpc' ] num_items = df [ 'idx.id2' ] . nunique () # cardinal encoder. encoder = dict ( zip ( item_names , range ( num_items ))) item_index = item_index . map ( lambda x : encoder [ x ]) item_index = torch . LongTensor ( item_index ) Because we will be training our model with PyTorch , we need to encode item names to integers (from 0 to 6). We do this manually in this exercise given the small amount of items, for more items, one can use sklearn.preprocessing.OrdinalEncoder to encode. Raw item names will be encoded as the following. encoder {'ec': 0, 'ecc': 1, 'er': 2, 'erc': 3, 'gc': 4, 'gcc': 5, 'hpc': 6} Category Level Dataset We firstly construct the category-level dataset, however, there is no observable that is constant within the same category, so we don't need to include any observable tensor to the category_dataset . All we need to do is adding the item_index (i.e., which item is chosen) to the dataset, so that category_dataset knows the total number of choices made. # category feature: no category feature, all features are item-level. category_dataset = ChoiceDataset ( item_index = item_index . clone ()) . to ( DEVICE ) No `session_index` is provided, assume each choice instance is in its own session. Item Level Dataset For simplicity, we treat each purchasing record as its own session. Moreover, we treat all observables as price observables (i.e., varying by both session and item). Since there are 7 observables in total, the resulted price_obs has shape (250, 7, 7) corresponding to number_of_sessions by number_of_items by number_of_observables . # item feature. item_feat_cols = [ 'ich' , 'och' , 'icca' , 'occa' , 'inc.room' , 'inc.cooling' , 'int.cooling' ] price_obs = utils . pivot3d ( df , dim0 = 'idx.id1' , dim1 = 'idx.id2' , values = item_feat_cols ) price_obs . shape torch.Size([250, 7, 7]) Then, we construct the item level dataset by providing both item_index and price_obs . We move item_dataset to the appropriate device as well. This is only necessary if we are using GPU to accelerate the model. item_dataset = ChoiceDataset ( item_index = item_index , price_obs = price_obs ) . to ( DEVICE ) No `session_index` is provided, assume each choice instance is in its own session. Finally, we chain the category-level and item-level dataset into a single JointDataset . dataset = JointDataset ( category = category_dataset , item = item_dataset ) One can print the joint dataset to see its contents, and tensors contained in each of these sub-datasets. print ( dataset ) JointDataset with 2 sub-datasets: ( category: ChoiceDataset(label=[], item_index=[250], user_index=[], session_index=[250], item_availability=[], device=cuda:0) item: ChoiceDataset(label=[], item_index=[250], user_index=[], session_index=[250], item_availability=[], price_obs=[250, 7, 7], device=cuda:0) ) Examples There are multiple ways to group 7 items into categories, different classification will result in different utility functions and estimations (see the background of nested logit models). We will demonstrate the usage of our package by presenting three different categorization schemes and corresponding model estimations. Example 1 In the first example, the model is specified to have the cooling alternatives {gcc, ecc, erc, hpc} in one category and the non-cooling alternatives {gc, ec, er} in another category. We create a category_to_item dictionary to inform the model our categorization scheme. The dictionary should have keys ranging from 0 to number_of_categories - 1 , each integer corresponds to a category. The value of each key is a list of item IDs in the category, the encoding of item names should be exactly the same as in the construction of item_index . category_to_item = { 0 : [ 'gcc' , 'ecc' , 'erc' , 'hpc' ], 1 : [ 'gc' , 'ec' , 'er' ]} # encode items to integers. for k , v in category_to_item . items (): v = [ encoder [ item ] for item in v ] category_to_item [ k ] = sorted ( v ) In this example, we have item [1, 3, 5, 6] in the first category (category 0 ) and the rest of items in the second category (category 1 ). print ( category_to_item ) {0: [1, 3, 5, 6], 1: [0, 2, 4]} Next, let's create the NestedLogitModel class! The first thing to put in is the category_to_item dictionary we just built. For category_coef_variation_dict , category_num_param_dict , since we don't have any category-specific observables, we can simply put an empty dictionary there. Coefficients for all observables are constant across items, and there are 7 observables in total. As for shared_lambda=True , please refer to the background recap for nested logit model. model = NestedLogitModel ( category_to_item = category_to_item , category_coef_variation_dict = {}, category_num_param_dict = {}, item_coef_variation_dict = { 'price_obs' : 'constant' }, item_num_param_dict = { 'price_obs' : 7 }, shared_lambda = True ) model = model . to ( DEVICE ) You can print the model to get summary information of the NestedLogitModel class. print ( model ) NestedLogitModel( (category_coef_dict): ModuleDict() (item_coef_dict): ModuleDict( (price_obs): Coefficient(variation=constant, num_items=7, num_users=None, num_params=7, 7 trainable parameters in total). ) ) NOTE : We are computing the standard errors using \\(\\sqrt{\\text{diag}(H^{-1})}\\) , where \\(H\\) is the hessian of negative log-likelihood with respect to model parameters. This leads to slight different results compared with R implementation. run ( model , dataset , num_epochs = 10000 ) ==================== received model ==================== NestedLogitModel( (category_coef_dict): ModuleDict() (item_coef_dict): ModuleDict( (price_obs): Coefficient(variation=constant, num_items=7, num_users=None, num_params=7, 7 trainable parameters in total). ) ) ==================== received dataset ==================== JointDataset with 2 sub-datasets: ( category: ChoiceDataset(label=[], item_index=[250], user_index=[], session_index=[250], item_availability=[], device=cuda:0) item: ChoiceDataset(label=[], item_index=[250], user_index=[], session_index=[250], item_availability=[], price_obs=[250, 7, 7], device=cuda:0) ) ==================== training the model ==================== Epoch 1000: Log-likelihood=-187.43597412109375 Epoch 2000: Log-likelihood=-179.69964599609375 Epoch 3000: Log-likelihood=-178.70831298828125 Epoch 4000: Log-likelihood=-178.28799438476562 Epoch 5000: Log-likelihood=-178.17779541015625 Epoch 6000: Log-likelihood=-178.13650512695312 Epoch 7000: Log-likelihood=-178.12576293945312 Epoch 8000: Log-likelihood=-178.14144897460938 Epoch 9000: Log-likelihood=-178.12478637695312 Epoch 10000: Log-likelihood=-178.13674926757812 ==================== model results ==================== Training Epochs: 10000 Learning Rate: 0.01 Batch Size: 250 out of 250 observations in total Final Log-likelihood: -178.13674926757812 Coefficients: | Coefficient | Estimation | Std. Err. | |:-----------------|-------------:|------------:| | lambda_weight_0 | 0.585981 | 0.167168 | | item_price_obs_0 | -0.555577 | 0.145414 | | item_price_obs_1 | -0.85812 | 0.238405 | | item_price_obs_2 | -0.224599 | 0.111092 | | item_price_obs_3 | -1.08912 | 1.04131 | | item_price_obs_4 | -0.379067 | 0.101126 | | item_price_obs_5 | 0.250203 | 0.0522721 | | item_price_obs_6 | -5.99917 | 4.85404 | NestedLogitModel( (category_coef_dict): ModuleDict() (item_coef_dict): ModuleDict( (price_obs): Coefficient(variation=constant, num_items=7, num_users=None, num_params=7, 7 trainable parameters in total). ) ) R Output Here we provide the output from mlogit model in R for estimation reference. Coefficient names reported are slightly different in Python and R , please use the following table for comparison. Please note that the lambda_weight_0 in Python (at the top) corresponds to the iv (inclusive value) in R (at the bottom). Orderings of coefficients for observables should be the same in both languages. Coefficient (Python) Coefficient (R) lambda_weight_0 iv item_price_obs_0 ich item_price_obs_1 och item_price_obs_2 icca item_price_obs_3 occa item_price_obs_4 inc.room item_price_obs_5 inc.cooling item_price_obs_6 int.cooling ## ## Call: ## mlogit(formula = depvar ~ ich + och + icca + occa + inc.room + ## inc.cooling + int.cooling | 0, data = HC, nests = list(cooling = c(\"gcc\", ## \"ecc\", \"erc\", \"hpc\"), other = c(\"gc\", \"ec\", \"er\")), un.nest.el = TRUE) ## ## Frequencies of alternatives:choice ## ec ecc er erc gc gcc hpc ## 0.004 0.016 0.032 0.004 0.096 0.744 0.104 ## ## bfgs method ## 11 iterations, 0h:0m:0s ## g'(-H)^-1g = 7.26E-06 ## successive function values within tolerance limits ## ## Coefficients : ## Estimate Std. Error z-value Pr(>|z|) ## ich -0.554878 0.144205 -3.8478 0.0001192 *** ## och -0.857886 0.255313 -3.3601 0.0007791 *** ## icca -0.225079 0.144423 -1.5585 0.1191212 ## occa -1.089458 1.219821 -0.8931 0.3717882 ## inc.room -0.378971 0.099631 -3.8038 0.0001425 *** ## inc.cooling 0.249575 0.059213 4.2149 2.499e-05 *** ## int.cooling -6.000415 5.562423 -1.0787 0.2807030 ## iv 0.585922 0.179708 3.2604 0.0011125 ** ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ## Log-Likelihood: -178.12 Example 2 The second example is similar to the first one, but we change the way we group items into different categories. Re-estimate the model with the room alternatives in one nest and the central alternatives in another nest. (Note that a heat pump is a central system.) category_to_item = { 0 : [ 'ec' , 'ecc' , 'gc' , 'gcc' , 'hpc' ], 1 : [ 'er' , 'erc' ]} for k , v in category_to_item . items (): v = [ encoder [ item ] for item in v ] category_to_item [ k ] = sorted ( v ) model = NestedLogitModel ( category_to_item = category_to_item , category_coef_variation_dict = {}, category_num_param_dict = {}, item_coef_variation_dict = { 'price_obs' : 'constant' }, item_num_param_dict = { 'price_obs' : 7 }, shared_lambda = True ) model = model . to ( DEVICE ) run ( model , dataset , num_epochs = 5000 , learning_rate = 0.3 ) ==================== received model ==================== NestedLogitModel( (category_coef_dict): ModuleDict() (item_coef_dict): ModuleDict( (price_obs): Coefficient(variation=constant, num_items=7, num_users=None, num_params=7, 7 trainable parameters in total). ) ) ==================== received dataset ==================== JointDataset with 2 sub-datasets: ( category: ChoiceDataset(label=[], item_index=[250], user_index=[], session_index=[250], item_availability=[], device=cuda:0) item: ChoiceDataset(label=[], item_index=[250], user_index=[], session_index=[250], item_availability=[], price_obs=[250, 7, 7], device=cuda:0) ) ==================== training the model ==================== Epoch 500: Log-likelihood=-193.73406982421875 Epoch 1000: Log-likelihood=-185.25933837890625 Epoch 1500: Log-likelihood=-183.55142211914062 Epoch 2000: Log-likelihood=-181.8164825439453 Epoch 2500: Log-likelihood=-180.4320526123047 Epoch 3000: Log-likelihood=-180.04095458984375 Epoch 3500: Log-likelihood=-180.7447509765625 Epoch 4000: Log-likelihood=-180.39688110351562 Epoch 4500: Log-likelihood=-180.27947998046875 Epoch 5000: Log-likelihood=-181.1483612060547 ==================== model results ==================== Training Epochs: 5000 Learning Rate: 0.3 Batch Size: 250 out of 250 observations in total Final Log-likelihood: -181.1483612060547 Coefficients: | Coefficient | Estimation | Std. Err. | |:-----------------|-------------:|------------:| | lambda_weight_0 | 1.61072 | 0.787735 | | item_price_obs_0 | -1.34719 | 0.631206 | | item_price_obs_1 | -2.16109 | 1.0451 | | item_price_obs_2 | -0.393868 | 0.255138 | | item_price_obs_3 | -2.53253 | 2.2719 | | item_price_obs_4 | -0.884873 | 0.379626 | | item_price_obs_5 | 0.496491 | 0.248118 | | item_price_obs_6 | -15.6477 | 9.88054 | NestedLogitModel( (category_coef_dict): ModuleDict() (item_coef_dict): ModuleDict( (price_obs): Coefficient(variation=constant, num_items=7, num_users=None, num_params=7, 7 trainable parameters in total). ) ) R Output You can use the table for converting coefficient names reported by Python and R : Coefficient (Python) Coefficient (R) lambda_weight_0 iv item_price_obs_0 ich item_price_obs_1 och item_price_obs_2 icca item_price_obs_3 occa item_price_obs_4 inc.room item_price_obs_5 inc.cooling item_price_obs_6 int.cooling ## ## Call: ## mlogit(formula = depvar ~ ich + och + icca + occa + inc.room + ## inc.cooling + int.cooling | 0, data = HC, nests = list(central = c(\"ec\", ## \"ecc\", \"gc\", \"gcc\", \"hpc\"), room = c(\"er\", \"erc\")), un.nest.el = TRUE) ## ## Frequencies of alternatives:choice ## ec ecc er erc gc gcc hpc ## 0.004 0.016 0.032 0.004 0.096 0.744 0.104 ## ## bfgs method ## 10 iterations, 0h:0m:0s ## g'(-H)^-1g = 5.87E-07 ## gradient close to zero ## ## Coefficients : ## Estimate Std. Error z-value Pr(>|z|) ## ich -1.13818 0.54216 -2.0993 0.03579 * ## och -1.82532 0.93228 -1.9579 0.05024 . ## icca -0.33746 0.26934 -1.2529 0.21024 ## occa -2.06328 1.89726 -1.0875 0.27681 ## inc.room -0.75722 0.34292 -2.2081 0.02723 * ## inc.cooling 0.41689 0.20742 2.0099 0.04444 * ## int.cooling -13.82487 7.94031 -1.7411 0.08167 . ## iv 1.36201 0.65393 2.0828 0.03727 * ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ## Log-Likelihood: -180.02 Example 3 For the third example, we now group items into three categories. Specifically, we have items gcc , ecc and erc in the first category (category 0 in the category_to_item dictionary), hpc in a category (category 1 ) alone, and items gc , ec and er in the last category (category 2 ). category_to_item = { 0 : [ 'gcc' , 'ecc' , 'erc' ], 1 : [ 'hpc' ], 2 : [ 'gc' , 'ec' , 'er' ]} for k , v in category_to_item . items (): v = [ encoder [ item ] for item in v ] category_to_item [ k ] = sorted ( v ) model = NestedLogitModel ( category_to_item = category_to_item , category_coef_variation_dict = {}, category_num_param_dict = {}, item_coef_variation_dict = { 'price_obs' : 'constant' }, item_num_param_dict = { 'price_obs' : 7 }, shared_lambda = True ) model = model . to ( DEVICE ) run ( model , dataset ) ==================== received model ==================== NestedLogitModel( (category_coef_dict): ModuleDict() (item_coef_dict): ModuleDict( (price_obs): Coefficient(variation=constant, num_items=7, num_users=None, num_params=7, 7 trainable parameters in total). ) ) ==================== received dataset ==================== JointDataset with 2 sub-datasets: ( category: ChoiceDataset(label=[], item_index=[250], user_index=[], session_index=[250], item_availability=[], device=cuda:0) item: ChoiceDataset(label=[], item_index=[250], user_index=[], session_index=[250], item_availability=[], price_obs=[250, 7, 7], device=cuda:0) ) ==================== training the model ==================== Epoch 500: Log-likelihood=-187.12100219726562 Epoch 1000: Log-likelihood=-182.98468017578125 Epoch 1500: Log-likelihood=-181.72171020507812 Epoch 2000: Log-likelihood=-181.3906707763672 Epoch 2500: Log-likelihood=-181.2037353515625 Epoch 3000: Log-likelihood=-181.0186767578125 Epoch 3500: Log-likelihood=-180.83331298828125 Epoch 4000: Log-likelihood=-180.6610107421875 Epoch 4500: Log-likelihood=-180.51480102539062 Epoch 5000: Log-likelihood=-180.40383911132812 ==================== model results ==================== Training Epochs: 5000 Learning Rate: 0.01 Batch Size: 250 out of 250 observations in total Final Log-likelihood: -180.40383911132812 Coefficients: | Coefficient | Estimation | Std. Err. | |:-----------------|-------------:|------------:| | lambda_weight_0 | 0.939528 | 0.193704 | | item_price_obs_0 | -0.823672 | 0.0973065 | | item_price_obs_1 | -1.31387 | 0.182701 | | item_price_obs_2 | -0.305365 | 0.12726 | | item_price_obs_3 | -1.89104 | 1.14781 | | item_price_obs_4 | -0.559503 | 0.0734163 | | item_price_obs_5 | 0.310081 | 0.0551569 | | item_price_obs_6 | -7.68508 | 5.09592 | NestedLogitModel( (category_coef_dict): ModuleDict() (item_coef_dict): ModuleDict( (price_obs): Coefficient(variation=constant, num_items=7, num_users=None, num_params=7, 7 trainable parameters in total). ) ) R Output You can use the table for converting coefficient names reported by Python and R : Coefficient (Python) Coefficient (R) lambda_weight_0 iv item_price_obs_0 ich item_price_obs_1 och item_price_obs_2 icca item_price_obs_3 occa item_price_obs_4 inc.room item_price_obs_5 inc.cooling item_price_obs_6 int.cooling ## ## Call: ## mlogit(formula = depvar ~ ich + och + icca + occa + inc.room + ## inc.cooling + int.cooling | 0, data = HC, nests = list(n1 = c(\"gcc\", ## \"ecc\", \"erc\"), n2 = c(\"hpc\"), n3 = c(\"gc\", \"ec\", \"er\")), ## un.nest.el = TRUE) ## ## Frequencies of alternatives:choice ## ec ecc er erc gc gcc hpc ## 0.004 0.016 0.032 0.004 0.096 0.744 0.104 ## ## bfgs method ## 8 iterations, 0h:0m:0s ## g'(-H)^-1g = 3.71E-08 ## gradient close to zero ## ## Coefficients : ## Estimate Std. Error z-value Pr(>|z|) ## ich -0.838394 0.100546 -8.3384 < 2.2e-16 *** ## och -1.331598 0.252069 -5.2827 1.273e-07 *** ## icca -0.256131 0.145564 -1.7596 0.07848 . ## occa -1.405656 1.207281 -1.1643 0.24430 ## inc.room -0.571352 0.077950 -7.3297 2.307e-13 *** ## inc.cooling 0.311355 0.056357 5.5247 3.301e-08 *** ## int.cooling -10.413384 5.612445 -1.8554 0.06354 . ## iv 0.956544 0.180722 5.2929 1.204e-07 *** ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ## Log-Likelihood: -180.26","title":"Tutorial for Nested Logit Model"},{"location":"nested_logit_model_house_cooling/#random-utility-model-rum-part-ii-nested-logit-model","text":"Author: Tianyu Du The package implements the nested logit model as well, which allows researchers to model choices as a two-stage process: the user first picks a category of purchase and then picks the item from the chosen category that generates the most utility. Examples here are modified from Exercise 2: Nested logit model by Kenneth Train and Yves Croissant . The House Cooling (HC) dataset from mlogit contains data in R format on the choice of heating and central cooling system for 250 single-family, newly built houses in California. The dataset is small and serve as a demonstration of the nested logit model. The alternatives are: Gas central heat with cooling gcc , Electric central resistence heat with cooling ecc , Electric room resistence heat with cooling erc , Electric heat pump, which provides cooling also hpc , Gas central heat without cooling gc , Electric central resistence heat without cooling ec , Electric room resistence heat without cooling er . Heat pumps necessarily provide both heating and cooling such that heat pump without cooling is not an alternative. The variables are: depvar gives the name of the chosen alternative, ich.alt are the installation cost for the heating portion of the system, icca is the installation cost for cooling och.alt are the operating cost for the heating portion of the system occa is the operating cost for cooling income is the annual income of the household Note that the full installation cost of alternative gcc is ich.gcc+icca, and similarly for the operating cost and for the other alternatives with cooling.","title":"Random Utility Model (RUM) Part II: Nested Logit Model"},{"location":"nested_logit_model_house_cooling/#nested-logit-model-background","text":"The following code block provides an example initialization of the NestedLogitModel (please refer to examples below for details). model = NestedLogitModel ( category_to_item = category_to_item , category_coef_variation_dict = {}, category_num_param_dict = {}, item_coef_variation_dict = { 'price_obs' : 'constant' }, item_num_param_dict = { 'price_obs' : 7 }, shared_lambda = True ) The nested logit model decompose the utility of choosing item \\(i\\) into the (1) item-specific values and (2) category specify values. For simplicity, suppose item \\(i\\) belongs to category \\(k \\in \\{1, \\dots, K\\}\\) : \\(i \\in B_k\\) . \\[ U_{uit} = W_{ukt} + Y_{uit} \\] Where both \\(W\\) and \\(Y\\) are estimated using linear models from as in the conditional logit model. The log-likelihood for user \\(u\\) to choose item \\(i\\) at time/session \\(t\\) decomposes into the item-level likelihood and category-level likelihood. \\[ \\log P(i \\mid u, t) = \\log P(i \\mid u, t, B_k) + \\log P(k \\mid u, t) \\\\ = \\log \\left(\\frac{\\exp(Y_{uit}/\\lambda_k)}{\\sum_{j \\in B_k} \\exp(Y_{ujt}/\\lambda_k)}\\right) + \\log \\left( \\frac{\\exp(W_{ukt} + \\lambda_k I_{ukt})}{\\sum_{\\ell=1}^K \\exp(W_{u\\ell t} + \\lambda_\\ell I_{u\\ell t})}\\right) \\] The inclusive value of category \\(k\\) , \\(I_{ukt}\\) is defined as \\(\\log \\sum_{j \\in B_k} \\exp(Y_{ujt}/\\lambda_k)\\) , which is the expected utility from choosing the best alternative from category \\(k\\) . The category_to_item keyword defines a dictionary of the mapping \\(k \\mapsto B_k\\) , where keys of category_to_item are integer \\(k\\) 's and category_to_item[k] is a list consisting of IDs of items in \\(B_k\\) . The {category, item}_coef_variation_dict provides specification to \\(W_{ukt}\\) and \\(Y_{uit}\\) respectively, torch_choice allows for empty category level models by providing an empty dictionary (in this case, \\(W_{ukt} = \\epsilon_{ukt}\\) ) since the inclusive value term \\(\\lambda_k I_{ukt}\\) will be used to model the choice over categories. However, by specifying an empty second stage model ( \\(Y_{uit} = \\epsilon_{uit}\\) ), the nested logit model reduces to a conditional logit model of choices over categories. Hence, one should never use the NestedLogitModel class with an empty item-level model. Similar to the conditional logit model, {category, item}_num_param_dict specify the dimension (number of observables to be multiplied with the coefficient) of coefficients. The above code initializes a simple model built upon item-time-specific observables \\(X_{it} \\in \\mathbb{R}^7\\) , \\[ Y_{uit} = \\beta^\\top X_{it} + \\epsilon_{uit} \\\\ W_{ukt} = \\epsilon_{ukt} \\] The research may wish to enfoce the elasiticity \\(\\lambda_k\\) to be constant across categories, setting shared_lambda=True enforces \\(\\lambda_k = \\lambda\\ \\forall k \\in [K]\\) .","title":"Nested Logit Model: Background"},{"location":"nested_logit_model_house_cooling/#load-essential-packages","text":"We firstly read essential packages for this tutorial. import argparse import pandas as pd import torch from torch_choice.data import ChoiceDataset , JointDataset , utils from torch_choice.model.nested_logit_model import NestedLogitModel from torch_choice.utils.run_helper import run We then select the appropriate device to run the model on, our package supports both CPU and GPU. if torch . cuda . is_available (): print ( f 'CUDA device used: { torch . cuda . get_device_name () } ' ) DEVICE = 'cuda' else : print ( 'Running tutorial on CPU' ) DEVICE = 'cpu' CUDA device used: NVIDIA GeForce RTX 3090","title":"Load Essential Packages"},{"location":"nested_logit_model_house_cooling/#load-datasets","text":"We firstly read the dataset for this tutorial, the csv file can be found at ./public_datasets/HC.csv . df = pd . read_csv ( './public_datasets/HC.csv' , index_col = 0 ) df = df . reset_index ( drop = True ) df . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } depvar icca occa income ich och idx.id1 idx.id2 inc.room inc.cooling int.cooling cooling.modes room.modes 0 False 0.00 0.00 20 24.50 4.09 1 ec 0 0 0 False False 1 False 27.28 2.95 20 7.86 4.09 1 ecc 0 20 1 True False 2 False 0.00 0.00 20 7.37 3.85 1 er 20 0 0 False True 3 True 27.28 2.95 20 8.79 3.85 1 erc 20 20 1 True True 4 False 0.00 0.00 20 24.08 2.26 1 gc 0 0 0 False False The raw dataset is in a long-format (i.e., each row contains information of one item). df [ 'idx.id2' ] . value_counts () ec 250 ecc 250 er 250 erc 250 gc 250 gcc 250 hpc 250 Name: idx.id2, dtype: int64 # what was actually chosen. item_index = df [ df [ 'depvar' ] == True ] . sort_values ( by = 'idx.id1' )[ 'idx.id2' ] . reset_index ( drop = True ) item_names = [ 'ec' , 'ecc' , 'er' , 'erc' , 'gc' , 'gcc' , 'hpc' ] num_items = df [ 'idx.id2' ] . nunique () # cardinal encoder. encoder = dict ( zip ( item_names , range ( num_items ))) item_index = item_index . map ( lambda x : encoder [ x ]) item_index = torch . LongTensor ( item_index ) Because we will be training our model with PyTorch , we need to encode item names to integers (from 0 to 6). We do this manually in this exercise given the small amount of items, for more items, one can use sklearn.preprocessing.OrdinalEncoder to encode. Raw item names will be encoded as the following. encoder {'ec': 0, 'ecc': 1, 'er': 2, 'erc': 3, 'gc': 4, 'gcc': 5, 'hpc': 6}","title":"Load Datasets"},{"location":"nested_logit_model_house_cooling/#category-level-dataset","text":"We firstly construct the category-level dataset, however, there is no observable that is constant within the same category, so we don't need to include any observable tensor to the category_dataset . All we need to do is adding the item_index (i.e., which item is chosen) to the dataset, so that category_dataset knows the total number of choices made. # category feature: no category feature, all features are item-level. category_dataset = ChoiceDataset ( item_index = item_index . clone ()) . to ( DEVICE ) No `session_index` is provided, assume each choice instance is in its own session.","title":"Category Level Dataset"},{"location":"nested_logit_model_house_cooling/#item-level-dataset","text":"For simplicity, we treat each purchasing record as its own session. Moreover, we treat all observables as price observables (i.e., varying by both session and item). Since there are 7 observables in total, the resulted price_obs has shape (250, 7, 7) corresponding to number_of_sessions by number_of_items by number_of_observables . # item feature. item_feat_cols = [ 'ich' , 'och' , 'icca' , 'occa' , 'inc.room' , 'inc.cooling' , 'int.cooling' ] price_obs = utils . pivot3d ( df , dim0 = 'idx.id1' , dim1 = 'idx.id2' , values = item_feat_cols ) price_obs . shape torch.Size([250, 7, 7]) Then, we construct the item level dataset by providing both item_index and price_obs . We move item_dataset to the appropriate device as well. This is only necessary if we are using GPU to accelerate the model. item_dataset = ChoiceDataset ( item_index = item_index , price_obs = price_obs ) . to ( DEVICE ) No `session_index` is provided, assume each choice instance is in its own session. Finally, we chain the category-level and item-level dataset into a single JointDataset . dataset = JointDataset ( category = category_dataset , item = item_dataset ) One can print the joint dataset to see its contents, and tensors contained in each of these sub-datasets. print ( dataset ) JointDataset with 2 sub-datasets: ( category: ChoiceDataset(label=[], item_index=[250], user_index=[], session_index=[250], item_availability=[], device=cuda:0) item: ChoiceDataset(label=[], item_index=[250], user_index=[], session_index=[250], item_availability=[], price_obs=[250, 7, 7], device=cuda:0) )","title":"Item Level Dataset"},{"location":"nested_logit_model_house_cooling/#examples","text":"There are multiple ways to group 7 items into categories, different classification will result in different utility functions and estimations (see the background of nested logit models). We will demonstrate the usage of our package by presenting three different categorization schemes and corresponding model estimations.","title":"Examples"},{"location":"nested_logit_model_house_cooling/#example-1","text":"In the first example, the model is specified to have the cooling alternatives {gcc, ecc, erc, hpc} in one category and the non-cooling alternatives {gc, ec, er} in another category. We create a category_to_item dictionary to inform the model our categorization scheme. The dictionary should have keys ranging from 0 to number_of_categories - 1 , each integer corresponds to a category. The value of each key is a list of item IDs in the category, the encoding of item names should be exactly the same as in the construction of item_index . category_to_item = { 0 : [ 'gcc' , 'ecc' , 'erc' , 'hpc' ], 1 : [ 'gc' , 'ec' , 'er' ]} # encode items to integers. for k , v in category_to_item . items (): v = [ encoder [ item ] for item in v ] category_to_item [ k ] = sorted ( v ) In this example, we have item [1, 3, 5, 6] in the first category (category 0 ) and the rest of items in the second category (category 1 ). print ( category_to_item ) {0: [1, 3, 5, 6], 1: [0, 2, 4]} Next, let's create the NestedLogitModel class! The first thing to put in is the category_to_item dictionary we just built. For category_coef_variation_dict , category_num_param_dict , since we don't have any category-specific observables, we can simply put an empty dictionary there. Coefficients for all observables are constant across items, and there are 7 observables in total. As for shared_lambda=True , please refer to the background recap for nested logit model. model = NestedLogitModel ( category_to_item = category_to_item , category_coef_variation_dict = {}, category_num_param_dict = {}, item_coef_variation_dict = { 'price_obs' : 'constant' }, item_num_param_dict = { 'price_obs' : 7 }, shared_lambda = True ) model = model . to ( DEVICE ) You can print the model to get summary information of the NestedLogitModel class. print ( model ) NestedLogitModel( (category_coef_dict): ModuleDict() (item_coef_dict): ModuleDict( (price_obs): Coefficient(variation=constant, num_items=7, num_users=None, num_params=7, 7 trainable parameters in total). ) ) NOTE : We are computing the standard errors using \\(\\sqrt{\\text{diag}(H^{-1})}\\) , where \\(H\\) is the hessian of negative log-likelihood with respect to model parameters. This leads to slight different results compared with R implementation. run ( model , dataset , num_epochs = 10000 ) ==================== received model ==================== NestedLogitModel( (category_coef_dict): ModuleDict() (item_coef_dict): ModuleDict( (price_obs): Coefficient(variation=constant, num_items=7, num_users=None, num_params=7, 7 trainable parameters in total). ) ) ==================== received dataset ==================== JointDataset with 2 sub-datasets: ( category: ChoiceDataset(label=[], item_index=[250], user_index=[], session_index=[250], item_availability=[], device=cuda:0) item: ChoiceDataset(label=[], item_index=[250], user_index=[], session_index=[250], item_availability=[], price_obs=[250, 7, 7], device=cuda:0) ) ==================== training the model ==================== Epoch 1000: Log-likelihood=-187.43597412109375 Epoch 2000: Log-likelihood=-179.69964599609375 Epoch 3000: Log-likelihood=-178.70831298828125 Epoch 4000: Log-likelihood=-178.28799438476562 Epoch 5000: Log-likelihood=-178.17779541015625 Epoch 6000: Log-likelihood=-178.13650512695312 Epoch 7000: Log-likelihood=-178.12576293945312 Epoch 8000: Log-likelihood=-178.14144897460938 Epoch 9000: Log-likelihood=-178.12478637695312 Epoch 10000: Log-likelihood=-178.13674926757812 ==================== model results ==================== Training Epochs: 10000 Learning Rate: 0.01 Batch Size: 250 out of 250 observations in total Final Log-likelihood: -178.13674926757812 Coefficients: | Coefficient | Estimation | Std. Err. | |:-----------------|-------------:|------------:| | lambda_weight_0 | 0.585981 | 0.167168 | | item_price_obs_0 | -0.555577 | 0.145414 | | item_price_obs_1 | -0.85812 | 0.238405 | | item_price_obs_2 | -0.224599 | 0.111092 | | item_price_obs_3 | -1.08912 | 1.04131 | | item_price_obs_4 | -0.379067 | 0.101126 | | item_price_obs_5 | 0.250203 | 0.0522721 | | item_price_obs_6 | -5.99917 | 4.85404 | NestedLogitModel( (category_coef_dict): ModuleDict() (item_coef_dict): ModuleDict( (price_obs): Coefficient(variation=constant, num_items=7, num_users=None, num_params=7, 7 trainable parameters in total). ) )","title":"Example 1"},{"location":"nested_logit_model_house_cooling/#r-output","text":"Here we provide the output from mlogit model in R for estimation reference. Coefficient names reported are slightly different in Python and R , please use the following table for comparison. Please note that the lambda_weight_0 in Python (at the top) corresponds to the iv (inclusive value) in R (at the bottom). Orderings of coefficients for observables should be the same in both languages. Coefficient (Python) Coefficient (R) lambda_weight_0 iv item_price_obs_0 ich item_price_obs_1 och item_price_obs_2 icca item_price_obs_3 occa item_price_obs_4 inc.room item_price_obs_5 inc.cooling item_price_obs_6 int.cooling ## ## Call: ## mlogit(formula = depvar ~ ich + och + icca + occa + inc.room + ## inc.cooling + int.cooling | 0, data = HC, nests = list(cooling = c(\"gcc\", ## \"ecc\", \"erc\", \"hpc\"), other = c(\"gc\", \"ec\", \"er\")), un.nest.el = TRUE) ## ## Frequencies of alternatives:choice ## ec ecc er erc gc gcc hpc ## 0.004 0.016 0.032 0.004 0.096 0.744 0.104 ## ## bfgs method ## 11 iterations, 0h:0m:0s ## g'(-H)^-1g = 7.26E-06 ## successive function values within tolerance limits ## ## Coefficients : ## Estimate Std. Error z-value Pr(>|z|) ## ich -0.554878 0.144205 -3.8478 0.0001192 *** ## och -0.857886 0.255313 -3.3601 0.0007791 *** ## icca -0.225079 0.144423 -1.5585 0.1191212 ## occa -1.089458 1.219821 -0.8931 0.3717882 ## inc.room -0.378971 0.099631 -3.8038 0.0001425 *** ## inc.cooling 0.249575 0.059213 4.2149 2.499e-05 *** ## int.cooling -6.000415 5.562423 -1.0787 0.2807030 ## iv 0.585922 0.179708 3.2604 0.0011125 ** ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ## Log-Likelihood: -178.12","title":"R Output"},{"location":"nested_logit_model_house_cooling/#example-2","text":"The second example is similar to the first one, but we change the way we group items into different categories. Re-estimate the model with the room alternatives in one nest and the central alternatives in another nest. (Note that a heat pump is a central system.) category_to_item = { 0 : [ 'ec' , 'ecc' , 'gc' , 'gcc' , 'hpc' ], 1 : [ 'er' , 'erc' ]} for k , v in category_to_item . items (): v = [ encoder [ item ] for item in v ] category_to_item [ k ] = sorted ( v ) model = NestedLogitModel ( category_to_item = category_to_item , category_coef_variation_dict = {}, category_num_param_dict = {}, item_coef_variation_dict = { 'price_obs' : 'constant' }, item_num_param_dict = { 'price_obs' : 7 }, shared_lambda = True ) model = model . to ( DEVICE ) run ( model , dataset , num_epochs = 5000 , learning_rate = 0.3 ) ==================== received model ==================== NestedLogitModel( (category_coef_dict): ModuleDict() (item_coef_dict): ModuleDict( (price_obs): Coefficient(variation=constant, num_items=7, num_users=None, num_params=7, 7 trainable parameters in total). ) ) ==================== received dataset ==================== JointDataset with 2 sub-datasets: ( category: ChoiceDataset(label=[], item_index=[250], user_index=[], session_index=[250], item_availability=[], device=cuda:0) item: ChoiceDataset(label=[], item_index=[250], user_index=[], session_index=[250], item_availability=[], price_obs=[250, 7, 7], device=cuda:0) ) ==================== training the model ==================== Epoch 500: Log-likelihood=-193.73406982421875 Epoch 1000: Log-likelihood=-185.25933837890625 Epoch 1500: Log-likelihood=-183.55142211914062 Epoch 2000: Log-likelihood=-181.8164825439453 Epoch 2500: Log-likelihood=-180.4320526123047 Epoch 3000: Log-likelihood=-180.04095458984375 Epoch 3500: Log-likelihood=-180.7447509765625 Epoch 4000: Log-likelihood=-180.39688110351562 Epoch 4500: Log-likelihood=-180.27947998046875 Epoch 5000: Log-likelihood=-181.1483612060547 ==================== model results ==================== Training Epochs: 5000 Learning Rate: 0.3 Batch Size: 250 out of 250 observations in total Final Log-likelihood: -181.1483612060547 Coefficients: | Coefficient | Estimation | Std. Err. | |:-----------------|-------------:|------------:| | lambda_weight_0 | 1.61072 | 0.787735 | | item_price_obs_0 | -1.34719 | 0.631206 | | item_price_obs_1 | -2.16109 | 1.0451 | | item_price_obs_2 | -0.393868 | 0.255138 | | item_price_obs_3 | -2.53253 | 2.2719 | | item_price_obs_4 | -0.884873 | 0.379626 | | item_price_obs_5 | 0.496491 | 0.248118 | | item_price_obs_6 | -15.6477 | 9.88054 | NestedLogitModel( (category_coef_dict): ModuleDict() (item_coef_dict): ModuleDict( (price_obs): Coefficient(variation=constant, num_items=7, num_users=None, num_params=7, 7 trainable parameters in total). ) )","title":"Example 2"},{"location":"nested_logit_model_house_cooling/#r-output_1","text":"You can use the table for converting coefficient names reported by Python and R : Coefficient (Python) Coefficient (R) lambda_weight_0 iv item_price_obs_0 ich item_price_obs_1 och item_price_obs_2 icca item_price_obs_3 occa item_price_obs_4 inc.room item_price_obs_5 inc.cooling item_price_obs_6 int.cooling ## ## Call: ## mlogit(formula = depvar ~ ich + och + icca + occa + inc.room + ## inc.cooling + int.cooling | 0, data = HC, nests = list(central = c(\"ec\", ## \"ecc\", \"gc\", \"gcc\", \"hpc\"), room = c(\"er\", \"erc\")), un.nest.el = TRUE) ## ## Frequencies of alternatives:choice ## ec ecc er erc gc gcc hpc ## 0.004 0.016 0.032 0.004 0.096 0.744 0.104 ## ## bfgs method ## 10 iterations, 0h:0m:0s ## g'(-H)^-1g = 5.87E-07 ## gradient close to zero ## ## Coefficients : ## Estimate Std. Error z-value Pr(>|z|) ## ich -1.13818 0.54216 -2.0993 0.03579 * ## och -1.82532 0.93228 -1.9579 0.05024 . ## icca -0.33746 0.26934 -1.2529 0.21024 ## occa -2.06328 1.89726 -1.0875 0.27681 ## inc.room -0.75722 0.34292 -2.2081 0.02723 * ## inc.cooling 0.41689 0.20742 2.0099 0.04444 * ## int.cooling -13.82487 7.94031 -1.7411 0.08167 . ## iv 1.36201 0.65393 2.0828 0.03727 * ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ## Log-Likelihood: -180.02","title":"R Output"},{"location":"nested_logit_model_house_cooling/#example-3","text":"For the third example, we now group items into three categories. Specifically, we have items gcc , ecc and erc in the first category (category 0 in the category_to_item dictionary), hpc in a category (category 1 ) alone, and items gc , ec and er in the last category (category 2 ). category_to_item = { 0 : [ 'gcc' , 'ecc' , 'erc' ], 1 : [ 'hpc' ], 2 : [ 'gc' , 'ec' , 'er' ]} for k , v in category_to_item . items (): v = [ encoder [ item ] for item in v ] category_to_item [ k ] = sorted ( v ) model = NestedLogitModel ( category_to_item = category_to_item , category_coef_variation_dict = {}, category_num_param_dict = {}, item_coef_variation_dict = { 'price_obs' : 'constant' }, item_num_param_dict = { 'price_obs' : 7 }, shared_lambda = True ) model = model . to ( DEVICE ) run ( model , dataset ) ==================== received model ==================== NestedLogitModel( (category_coef_dict): ModuleDict() (item_coef_dict): ModuleDict( (price_obs): Coefficient(variation=constant, num_items=7, num_users=None, num_params=7, 7 trainable parameters in total). ) ) ==================== received dataset ==================== JointDataset with 2 sub-datasets: ( category: ChoiceDataset(label=[], item_index=[250], user_index=[], session_index=[250], item_availability=[], device=cuda:0) item: ChoiceDataset(label=[], item_index=[250], user_index=[], session_index=[250], item_availability=[], price_obs=[250, 7, 7], device=cuda:0) ) ==================== training the model ==================== Epoch 500: Log-likelihood=-187.12100219726562 Epoch 1000: Log-likelihood=-182.98468017578125 Epoch 1500: Log-likelihood=-181.72171020507812 Epoch 2000: Log-likelihood=-181.3906707763672 Epoch 2500: Log-likelihood=-181.2037353515625 Epoch 3000: Log-likelihood=-181.0186767578125 Epoch 3500: Log-likelihood=-180.83331298828125 Epoch 4000: Log-likelihood=-180.6610107421875 Epoch 4500: Log-likelihood=-180.51480102539062 Epoch 5000: Log-likelihood=-180.40383911132812 ==================== model results ==================== Training Epochs: 5000 Learning Rate: 0.01 Batch Size: 250 out of 250 observations in total Final Log-likelihood: -180.40383911132812 Coefficients: | Coefficient | Estimation | Std. Err. | |:-----------------|-------------:|------------:| | lambda_weight_0 | 0.939528 | 0.193704 | | item_price_obs_0 | -0.823672 | 0.0973065 | | item_price_obs_1 | -1.31387 | 0.182701 | | item_price_obs_2 | -0.305365 | 0.12726 | | item_price_obs_3 | -1.89104 | 1.14781 | | item_price_obs_4 | -0.559503 | 0.0734163 | | item_price_obs_5 | 0.310081 | 0.0551569 | | item_price_obs_6 | -7.68508 | 5.09592 | NestedLogitModel( (category_coef_dict): ModuleDict() (item_coef_dict): ModuleDict( (price_obs): Coefficient(variation=constant, num_items=7, num_users=None, num_params=7, 7 trainable parameters in total). ) )","title":"Example 3"},{"location":"nested_logit_model_house_cooling/#r-output_2","text":"You can use the table for converting coefficient names reported by Python and R : Coefficient (Python) Coefficient (R) lambda_weight_0 iv item_price_obs_0 ich item_price_obs_1 och item_price_obs_2 icca item_price_obs_3 occa item_price_obs_4 inc.room item_price_obs_5 inc.cooling item_price_obs_6 int.cooling ## ## Call: ## mlogit(formula = depvar ~ ich + och + icca + occa + inc.room + ## inc.cooling + int.cooling | 0, data = HC, nests = list(n1 = c(\"gcc\", ## \"ecc\", \"erc\"), n2 = c(\"hpc\"), n3 = c(\"gc\", \"ec\", \"er\")), ## un.nest.el = TRUE) ## ## Frequencies of alternatives:choice ## ec ecc er erc gc gcc hpc ## 0.004 0.016 0.032 0.004 0.096 0.744 0.104 ## ## bfgs method ## 8 iterations, 0h:0m:0s ## g'(-H)^-1g = 3.71E-08 ## gradient close to zero ## ## Coefficients : ## Estimate Std. Error z-value Pr(>|z|) ## ich -0.838394 0.100546 -8.3384 < 2.2e-16 *** ## och -1.331598 0.252069 -5.2827 1.273e-07 *** ## icca -0.256131 0.145564 -1.7596 0.07848 . ## occa -1.405656 1.207281 -1.1643 0.24430 ## inc.room -0.571352 0.077950 -7.3297 2.307e-13 *** ## inc.cooling 0.311355 0.056357 5.5247 3.301e-08 *** ## int.cooling -10.413384 5.612445 -1.8554 0.06354 . ## iv 0.956544 0.180722 5.2929 1.204e-07 *** ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ## Log-Likelihood: -180.26","title":"R Output"},{"location":"projects/","text":"Research Projects using this Package Question-Answering Data for Educational Applications Tutorial on Educational Question-Answering","title":"Related Projects"},{"location":"projects/#research-projects-using-this-package","text":"","title":"Research Projects using this Package"},{"location":"projects/#question-answering-data-for-educational-applications","text":"Tutorial on Educational Question-Answering","title":"Question-Answering Data for Educational Applications"},{"location":"test/","text":"Compatibility Check List We have tested the tutorials using the following environments, please let us know if there is any issue with our packages on other systems. Tutorial Platform Versions CPU GPU Device Tested Data Management MacOS 12.2 Python 3.9.7 PyTorch 1.10.0 M1 Max N/A cpu Data Management Ubuntu 20.04 Python 3.8.10 PyTorch 1.10.1 CUDA 11.3 11700F RTX3090 cpu and cuda Conditional Logit Model MacOS 12.2 Python 3.9 PyTorch 1.10.0 M1 Max N/A cpu Conditional Logit Model Ubuntu 20.04 Python 3.8.10 PyTorch 1.10.1 CUDA 11.3 11700F RTX3090 cpu and cuda Nested Logit Model MacOS 12.2 Python 3.9.7 PyTorch 1.10.0 M1 Max N/A cpu Nested Logit Model Ubuntu 20.04 Python 3.8.10 PyTorch 1.10.1 CUDA 11.3 11700F RTX3090 cpu and cuda","title":"Compatibility Tests"},{"location":"test/#compatibility-check-list","text":"We have tested the tutorials using the following environments, please let us know if there is any issue with our packages on other systems. Tutorial Platform Versions CPU GPU Device Tested Data Management MacOS 12.2 Python 3.9.7 PyTorch 1.10.0 M1 Max N/A cpu Data Management Ubuntu 20.04 Python 3.8.10 PyTorch 1.10.1 CUDA 11.3 11700F RTX3090 cpu and cuda Conditional Logit Model MacOS 12.2 Python 3.9 PyTorch 1.10.0 M1 Max N/A cpu Conditional Logit Model Ubuntu 20.04 Python 3.8.10 PyTorch 1.10.1 CUDA 11.3 11700F RTX3090 cpu and cuda Nested Logit Model MacOS 12.2 Python 3.9.7 PyTorch 1.10.0 M1 Max N/A cpu Nested Logit Model Ubuntu 20.04 Python 3.8.10 PyTorch 1.10.1 CUDA 11.3 11700F RTX3090 cpu and cuda","title":"Compatibility Check List"},{"location":"tutorials/","text":"Tutorials The following tutorials demonstrates how to use our packages for modelling consumer choices. Data Management We begin with creating the ChoiceDataset data strcuture holding all purchasing records. Please navigate to data data managment tutorial . The executable Jupyter notebook for this tutorial is located at data management tutorial . Random Utility Model (RUM) 1: Conditional Logit Model The executable Jupyter notebook for this tutorial is located at Random Utility Model (RUM) 1: Conditional Logit Model Random Utility Model (RUM) 2: Nested Logit Model The executable Jupyter notebook for this tutorial is located at Random Utility Model (RUM) 2: Nested Logit Model Bayesian Embedding Model (BEMB) Bayesian Embedding Model (BEMB)","title":"Tutorials"},{"location":"tutorials/#tutorials","text":"The following tutorials demonstrates how to use our packages for modelling consumer choices.","title":"Tutorials"},{"location":"tutorials/#data-management","text":"We begin with creating the ChoiceDataset data strcuture holding all purchasing records. Please navigate to data data managment tutorial . The executable Jupyter notebook for this tutorial is located at data management tutorial .","title":"Data Management"},{"location":"tutorials/#random-utility-model-rum-1-conditional-logit-model","text":"The executable Jupyter notebook for this tutorial is located at Random Utility Model (RUM) 1: Conditional Logit Model","title":"Random Utility Model (RUM) 1: Conditional Logit Model"},{"location":"tutorials/#random-utility-model-rum-2-nested-logit-model","text":"The executable Jupyter notebook for this tutorial is located at Random Utility Model (RUM) 2: Nested Logit Model","title":"Random Utility Model (RUM) 2: Nested Logit Model"},{"location":"tutorials/#bayesian-embedding-model-bemb","text":"Bayesian Embedding Model (BEMB)","title":"Bayesian Embedding Model (BEMB)"}]}