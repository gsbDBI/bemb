{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Bayesian Embedding (BEMB) Authors: Tianyu Du and Ayush Kanodia; PI: Susan Athey; Contact: tianyudu@stanford.edu BEMB is a flexible, fast Bayesian embedding model for modelling choice problems. The bemb package is built upon the torch_choice library. Installation Install torch-choice following steps here . Run the following script to install it. # Clone the repository to your local machine or server for tutorials. git clone \"git@github.com:gsbDBI/bemb.git\" # Install required dependencies. pip3 install -r requirements.txt # Install bemb from the Pip. pip3 install bemb # Check installation. python3 -c 'import torch_choice; print(bemb.__version__)' Example Usage of BEMB Here is a simulation exercise of using bemb .","title":"Home"},{"location":"#bayesian-embedding-bemb","text":"Authors: Tianyu Du and Ayush Kanodia; PI: Susan Athey; Contact: tianyudu@stanford.edu BEMB is a flexible, fast Bayesian embedding model for modelling choice problems. The bemb package is built upon the torch_choice library.","title":"Bayesian Embedding (BEMB)"},{"location":"#installation","text":"Install torch-choice following steps here . Run the following script to install it. # Clone the repository to your local machine or server for tutorials. git clone \"git@github.com:gsbDBI/bemb.git\" # Install required dependencies. pip3 install -r requirements.txt # Install bemb from the Pip. pip3 install bemb # Check installation. python3 -c 'import torch_choice; print(bemb.__version__)'","title":"Installation"},{"location":"#example-usage-of-bemb","text":"Here is a simulation exercise of using bemb .","title":"Example Usage of BEMB"},{"location":"api_bemb/","text":"API Reference: BEMB model special bayesian_coefficient Bayesian Coefficient is the building block for the BEMB model. Author: Tianyu Du Update: Apr. 28, 2022 BayesianCoefficient ( Module ) Source code in bemb/model/bayesian_coefficient.py class BayesianCoefficient ( nn . Module ): def __init__ ( self , variation : str , num_classes : int , obs2prior : bool , num_obs : Optional [ int ] = None , dim : int = 1 , prior_mean : float = 0.0 , prior_variance : float = 1.0 ) -> None : \"\"\"The Bayesian coefficient object represents a learnable tensor mu_i in R^k, where i is from a family (e.g., user, item) so there are num_classes * num_obs learnable weights in total. The prior distribution of mu_i is N(0, I) or N(H*X_obs(H shape=num_obs, X_obs shape=dim), Ix1). The posterior(i.e., variational) distribution of mu_i is a Gaussian distribution with learnable mean mu_i and unit covariance. The mean of the variational distribution consists of two parts: 1. The fixed part, which is not learnable. This part is particularly useful when the researcher want to impose some structure on the variational distribution. For example, the research might have some variational mean learned from another model and wish to use BEMB to polish the learned mean. 2. The flexible part, which is the main learnable part of the variational mean. Args: variation (str): the variation # TODO: this will be removed in the next version, after we have a complete test pipline. num_classes (int): number of classes in the coefficient. For example, if we have user-specific coefficients, `theta_user`, the `num_classes` should be the number of users. If we have item-specific coefficients, the the `num_classes` should be the number of items. obs2prior (bool): whether the mean of coefficient prior depends on the observable or not. num_obs (int, optional): the number of observables associated with each class. For example, if the coefficient if item-specific, and we have `obs2prior` set to True, the `num_obs` should be the number of observables for each item. Defaults to None. dim (int, optional): the dimension of the coefficient. Defaults to 1. prior_mean (float): the mean of the prior distribution of coefficient. Defaults to 0.0. prior_variance (float): the variance of the prior distribution of coefficient. Defaults to 1.0. \"\"\" super ( BayesianCoefficient , self ) . __init__ () # do we use this at all? TODO: drop self.variation. assert variation in [ 'item' , 'user' , 'constant' , 'category' ] self . variation = variation self . obs2prior = obs2prior if variation == 'constant' or variation == 'category' : if obs2prior : raise NotImplementedError ( 'obs2prior is not supported for constant and category variation at present.' ) self . num_classes = num_classes self . num_obs = num_obs self . dim = dim # the dimension of greek letter parameter. self . prior_mean = prior_mean self . prior_variance = prior_variance # assert self.prior_variance > 0 # create prior distribution. if self . obs2prior : # the mean of prior distribution depends on observables. # initiate a Bayesian Coefficient with shape (dim, num_obs) standard Gaussian. self . prior_H = BayesianCoefficient ( variation = 'constant' , num_classes = dim , obs2prior = False , dim = num_obs , prior_variance = 1.0 ) else : self . register_buffer ( 'prior_zero_mean' , torch . zeros ( num_classes , dim ) + ( self . prior_mean )) # self.prior_cov_factor = nn.Parameter(torch.zeros(num_classes, dim, 1), requires_grad=False) # self.prior_cov_diag = nn.Parameter(torch.ones(num_classes, dim), requires_grad=False) self . register_buffer ( 'prior_cov_factor' , torch . zeros ( num_classes , dim , 1 )) self . register_buffer ( 'prior_cov_diag' , torch . ones ( num_classes , dim ) * self . prior_variance ) # create variational distribution. self . variational_mean_flexible = nn . Parameter ( torch . randn ( num_classes , dim ), requires_grad = True ) self . variational_logstd = nn . Parameter ( torch . randn ( num_classes , dim ), requires_grad = True ) self . register_buffer ( 'variational_cov_factor' , torch . zeros ( num_classes , dim , 1 )) self . variational_mean_fixed = None def __repr__ ( self ) -> str : \"\"\"Constructs a string representation of the Bayesian coefficient object. Returns: str: the string representation of the Bayesian coefficient object. \"\"\" if self . obs2prior : prior_str = f 'prior=N(H*X_obs(H shape= { self . prior_H . prior_zero_mean . shape } , X_obs shape= { self . prior_H . dim } ), Ix { self . prior_variance } )' else : prior_str = f 'prior=N(0, I)' return f 'BayesianCoefficient(num_classes= { self . num_classes } , dimension= { self . dim } , { prior_str } )' def update_variational_mean_fixed ( self , new_value : torch . Tensor ) -> None : \"\"\"Updates the fixed part of the mean of the variational distribution. Args: new_value (torch.Tensor): the new value of the fixed part of the mean of the variational distribution. \"\"\" assert new_value . shape == self . variational_mean_flexible . shape del self . variational_mean_fixed self . register_buffer ( 'variational_mean_fixed' , new_value ) @property def variational_mean ( self ) -> torch . Tensor : \"\"\"Returns the mean of the variational distribution. Returns: torch.Tensor: the current mean of the variational distribution with shape (num_classes, dim). \"\"\" if self . variational_mean_fixed is None : return self . variational_mean_flexible else : return self . variational_mean_fixed + self . variational_mean_flexible def log_prior ( self , sample : torch . Tensor , H_sample : Optional [ torch . Tensor ] = None , x_obs : Optional [ torch . Tensor ] = None ) -> torch . Tensor : \"\"\" Computes the logP_{Prior}(Coefficient Sample) for provided samples of the coefficient. The prior will either be a zero-mean Gaussian (if `obs2prior` is False) or a Gaussian with a learnable mean (if `obs2prior` is True). Args: sample (torch.Tensor): Monte Carlo samples of the variable with shape (num_seeds, num_classes, dim), where sample[i, :, :] corresponds to one sample of the coefficient. # arguments required only if `obs2prior == True`: H_sample (Optional[torch.Tensor], optional): Monte Carlo samples of the weight in obs2prior term, with shape (num_seeds, dim, self.num_obs), this is required if and only if obs2prior == True. Defaults to None. x_obs (Optional[torch.Tensor], optional): observables for obs2prior with shape (num_classes, num_obs), only required if and only if obs2prior == True. Defaults to None. Returns: torch.Tensor: the log prior of the variable with shape (num_seeds, num_classes). \"\"\" # p(sample) num_seeds , num_classes , dim = sample . shape # shape (num_seeds, num_classes) if self . obs2prior : assert H_sample . shape == ( num_seeds , dim , self . num_obs ) assert x_obs . shape == ( num_classes , self . num_obs ) x_obs = x_obs . view ( 1 , num_classes , self . num_obs ) . expand ( num_seeds , - 1 , - 1 ) H_sample = torch . transpose ( H_sample , 1 , 2 ) assert H_sample . shape == ( num_seeds , self . num_obs , dim ) mu = torch . bmm ( x_obs , H_sample ) assert mu . shape == ( num_seeds , num_classes , dim ) else : mu = self . prior_zero_mean out = LowRankMultivariateNormal ( loc = mu , cov_factor = self . prior_cov_factor , cov_diag = self . prior_cov_diag ) . log_prob ( sample ) assert out . shape == ( num_seeds , num_classes ) return out def log_variational ( self , sample : torch . Tensor ) -> torch . Tensor : \"\"\"Given a set of sampled values of coefficients, with shape (num_seeds, num_classes, dim), computes the the log probability of these sampled values of coefficients under the current variational distribution. Args: sample (torch.Tensor): a tensor of shape (num_seeds, num_classes, dim) containing sampled values of coefficients, where sample[i, :, :] corresponds to one sample of the coefficient. Returns: torch.Tensor: a tensor of shape (num_seeds, num_classes) containing the log probability of provided samples under the variational distribution. The output is splitted by random seeds and classes, you can sum along the second axis (i.e., the num_classes axis) to get the total log probability. \"\"\" num_seeds , num_classes , dim = sample . shape out = self . variational_distribution . log_prob ( sample ) assert out . shape == ( num_seeds , num_classes ) return out def rsample ( self , num_seeds : int = 1 ) -> Union [ torch . Tensor , Tuple [ torch . Tensor ]]: \"\"\"Samples values of the coefficient from the variational distribution using re-parameterization trick. Args: num_seeds (int, optional): number of values to be sampled. Defaults to 1. Returns: Union[torch.Tensor, Tuple[torch.Tensor]]: if `obs2prior` is disabled, returns a tensor of shape (num_seeds, num_classes, dim) where each output[i, :, :] corresponds to one sample of the coefficient. If `obs2prior` is enabled, returns a tuple of samples: (1) a tensor of shape (num_seeds, num_classes, dim) containing sampled values of coefficient, and (2) a tensor o shape (num_seeds, dim, num_obs) containing samples of the H weight in the prior distribution. \"\"\" value_sample = self . variational_distribution . rsample ( torch . Size ([ num_seeds ])) if self . obs2prior : # sample obs2prior H as well. H_sample = self . prior_H . rsample ( num_seeds = num_seeds ) return ( value_sample , H_sample ) else : return value_sample @property def variational_distribution ( self ) -> LowRankMultivariateNormal : \"\"\"Constructs the current variational distribution of the coefficient from current variational mean and covariance. \"\"\" return LowRankMultivariateNormal ( loc = self . variational_mean , cov_factor = self . variational_cov_factor , cov_diag = torch . exp ( self . variational_logstd )) @property def device ( self ) -> torch . device : \"\"\"Returns the device of tensors contained in this module.\"\"\" return self . variational_mean . device device : device property readonly Returns the device of tensors contained in this module. variational_distribution : LowRankMultivariateNormal property readonly Constructs the current variational distribution of the coefficient from current variational mean and covariance. variational_mean : Tensor property readonly Returns the mean of the variational distribution. Returns: Type Description torch.Tensor the current mean of the variational distribution with shape (num_classes, dim). __init__ ( self , variation , num_classes , obs2prior , num_obs = None , dim = 1 , prior_mean = 0.0 , prior_variance = 1.0 ) special The Bayesian coefficient object represents a learnable tensor mu_i in R^k, where i is from a family (e.g., user, item) so there are num_classes * num_obs learnable weights in total. The prior distribution of mu_i is N(0, I) or N(H*X_obs(H shape=num_obs, X_obs shape=dim), Ix1). The posterior(i.e., variational) distribution of mu_i is a Gaussian distribution with learnable mean mu_i and unit covariance. The mean of the variational distribution consists of two parts: 1. The fixed part, which is not learnable. This part is particularly useful when the researcher want to impose some structure on the variational distribution. For example, the research might have some variational mean learned from another model and wish to use BEMB to polish the learned mean. 2. The flexible part, which is the main learnable part of the variational mean. Parameters: Name Type Description Default variation str the variation # TODO: this will be removed in the next version, after we have a complete test pipline. required num_classes int number of classes in the coefficient. For example, if we have user-specific coefficients, theta_user , the num_classes should be the number of users. If we have item-specific coefficients, the the num_classes should be the number of items. required obs2prior bool whether the mean of coefficient prior depends on the observable or not. required num_obs int the number of observables associated with each class. For example, if the coefficient if item-specific, and we have obs2prior set to True, the num_obs should be the number of observables for each item. Defaults to None. None dim int the dimension of the coefficient. Defaults to 1. 1 prior_mean float the mean of the prior distribution of coefficient. Defaults to 0.0. 0.0 prior_variance float the variance of the prior distribution of coefficient. Defaults to 1.0. 1.0 Source code in bemb/model/bayesian_coefficient.py def __init__ ( self , variation : str , num_classes : int , obs2prior : bool , num_obs : Optional [ int ] = None , dim : int = 1 , prior_mean : float = 0.0 , prior_variance : float = 1.0 ) -> None : \"\"\"The Bayesian coefficient object represents a learnable tensor mu_i in R^k, where i is from a family (e.g., user, item) so there are num_classes * num_obs learnable weights in total. The prior distribution of mu_i is N(0, I) or N(H*X_obs(H shape=num_obs, X_obs shape=dim), Ix1). The posterior(i.e., variational) distribution of mu_i is a Gaussian distribution with learnable mean mu_i and unit covariance. The mean of the variational distribution consists of two parts: 1. The fixed part, which is not learnable. This part is particularly useful when the researcher want to impose some structure on the variational distribution. For example, the research might have some variational mean learned from another model and wish to use BEMB to polish the learned mean. 2. The flexible part, which is the main learnable part of the variational mean. Args: variation (str): the variation # TODO: this will be removed in the next version, after we have a complete test pipline. num_classes (int): number of classes in the coefficient. For example, if we have user-specific coefficients, `theta_user`, the `num_classes` should be the number of users. If we have item-specific coefficients, the the `num_classes` should be the number of items. obs2prior (bool): whether the mean of coefficient prior depends on the observable or not. num_obs (int, optional): the number of observables associated with each class. For example, if the coefficient if item-specific, and we have `obs2prior` set to True, the `num_obs` should be the number of observables for each item. Defaults to None. dim (int, optional): the dimension of the coefficient. Defaults to 1. prior_mean (float): the mean of the prior distribution of coefficient. Defaults to 0.0. prior_variance (float): the variance of the prior distribution of coefficient. Defaults to 1.0. \"\"\" super ( BayesianCoefficient , self ) . __init__ () # do we use this at all? TODO: drop self.variation. assert variation in [ 'item' , 'user' , 'constant' , 'category' ] self . variation = variation self . obs2prior = obs2prior if variation == 'constant' or variation == 'category' : if obs2prior : raise NotImplementedError ( 'obs2prior is not supported for constant and category variation at present.' ) self . num_classes = num_classes self . num_obs = num_obs self . dim = dim # the dimension of greek letter parameter. self . prior_mean = prior_mean self . prior_variance = prior_variance # assert self.prior_variance > 0 # create prior distribution. if self . obs2prior : # the mean of prior distribution depends on observables. # initiate a Bayesian Coefficient with shape (dim, num_obs) standard Gaussian. self . prior_H = BayesianCoefficient ( variation = 'constant' , num_classes = dim , obs2prior = False , dim = num_obs , prior_variance = 1.0 ) else : self . register_buffer ( 'prior_zero_mean' , torch . zeros ( num_classes , dim ) + ( self . prior_mean )) # self.prior_cov_factor = nn.Parameter(torch.zeros(num_classes, dim, 1), requires_grad=False) # self.prior_cov_diag = nn.Parameter(torch.ones(num_classes, dim), requires_grad=False) self . register_buffer ( 'prior_cov_factor' , torch . zeros ( num_classes , dim , 1 )) self . register_buffer ( 'prior_cov_diag' , torch . ones ( num_classes , dim ) * self . prior_variance ) # create variational distribution. self . variational_mean_flexible = nn . Parameter ( torch . randn ( num_classes , dim ), requires_grad = True ) self . variational_logstd = nn . Parameter ( torch . randn ( num_classes , dim ), requires_grad = True ) self . register_buffer ( 'variational_cov_factor' , torch . zeros ( num_classes , dim , 1 )) self . variational_mean_fixed = None __repr__ ( self ) special Constructs a string representation of the Bayesian coefficient object. Returns: Type Description str the string representation of the Bayesian coefficient object. Source code in bemb/model/bayesian_coefficient.py def __repr__ ( self ) -> str : \"\"\"Constructs a string representation of the Bayesian coefficient object. Returns: str: the string representation of the Bayesian coefficient object. \"\"\" if self . obs2prior : prior_str = f 'prior=N(H*X_obs(H shape= { self . prior_H . prior_zero_mean . shape } , X_obs shape= { self . prior_H . dim } ), Ix { self . prior_variance } )' else : prior_str = f 'prior=N(0, I)' return f 'BayesianCoefficient(num_classes= { self . num_classes } , dimension= { self . dim } , { prior_str } )' log_prior ( self , sample , H_sample = None , x_obs = None ) Computes the logP_{Prior}(Coefficient Sample) for provided samples of the coefficient. The prior will either be a zero-mean Gaussian (if obs2prior is False) or a Gaussian with a learnable mean (if obs2prior is True). Parameters: Name Type Description Default sample torch.Tensor Monte Carlo samples of the variable with shape (num_seeds, num_classes, dim), where sample[i, :, :] corresponds to one sample of the coefficient. required # arguments required only if `obs2prior == True` required H_sample Optional[torch.Tensor] Monte Carlo samples of the weight in obs2prior term, with shape (num_seeds, dim, self.num_obs), this is required if and only if obs2prior == True. Defaults to None. None x_obs Optional[torch.Tensor] observables for obs2prior with shape (num_classes, num_obs), only required if and only if obs2prior == True. Defaults to None. None Returns: Type Description torch.Tensor the log prior of the variable with shape (num_seeds, num_classes). Source code in bemb/model/bayesian_coefficient.py def log_prior ( self , sample : torch . Tensor , H_sample : Optional [ torch . Tensor ] = None , x_obs : Optional [ torch . Tensor ] = None ) -> torch . Tensor : \"\"\" Computes the logP_{Prior}(Coefficient Sample) for provided samples of the coefficient. The prior will either be a zero-mean Gaussian (if `obs2prior` is False) or a Gaussian with a learnable mean (if `obs2prior` is True). Args: sample (torch.Tensor): Monte Carlo samples of the variable with shape (num_seeds, num_classes, dim), where sample[i, :, :] corresponds to one sample of the coefficient. # arguments required only if `obs2prior == True`: H_sample (Optional[torch.Tensor], optional): Monte Carlo samples of the weight in obs2prior term, with shape (num_seeds, dim, self.num_obs), this is required if and only if obs2prior == True. Defaults to None. x_obs (Optional[torch.Tensor], optional): observables for obs2prior with shape (num_classes, num_obs), only required if and only if obs2prior == True. Defaults to None. Returns: torch.Tensor: the log prior of the variable with shape (num_seeds, num_classes). \"\"\" # p(sample) num_seeds , num_classes , dim = sample . shape # shape (num_seeds, num_classes) if self . obs2prior : assert H_sample . shape == ( num_seeds , dim , self . num_obs ) assert x_obs . shape == ( num_classes , self . num_obs ) x_obs = x_obs . view ( 1 , num_classes , self . num_obs ) . expand ( num_seeds , - 1 , - 1 ) H_sample = torch . transpose ( H_sample , 1 , 2 ) assert H_sample . shape == ( num_seeds , self . num_obs , dim ) mu = torch . bmm ( x_obs , H_sample ) assert mu . shape == ( num_seeds , num_classes , dim ) else : mu = self . prior_zero_mean out = LowRankMultivariateNormal ( loc = mu , cov_factor = self . prior_cov_factor , cov_diag = self . prior_cov_diag ) . log_prob ( sample ) assert out . shape == ( num_seeds , num_classes ) return out log_variational ( self , sample ) Given a set of sampled values of coefficients, with shape (num_seeds, num_classes, dim), computes the the log probability of these sampled values of coefficients under the current variational distribution. Parameters: Name Type Description Default sample torch.Tensor a tensor of shape (num_seeds, num_classes, dim) containing sampled values of coefficients, where sample[i, :, :] corresponds to one sample of the coefficient. required Returns: Type Description torch.Tensor a tensor of shape (num_seeds, num_classes) containing the log probability of provided samples under the variational distribution. The output is splitted by random seeds and classes, you can sum along the second axis (i.e., the num_classes axis) to get the total log probability. Source code in bemb/model/bayesian_coefficient.py def log_variational ( self , sample : torch . Tensor ) -> torch . Tensor : \"\"\"Given a set of sampled values of coefficients, with shape (num_seeds, num_classes, dim), computes the the log probability of these sampled values of coefficients under the current variational distribution. Args: sample (torch.Tensor): a tensor of shape (num_seeds, num_classes, dim) containing sampled values of coefficients, where sample[i, :, :] corresponds to one sample of the coefficient. Returns: torch.Tensor: a tensor of shape (num_seeds, num_classes) containing the log probability of provided samples under the variational distribution. The output is splitted by random seeds and classes, you can sum along the second axis (i.e., the num_classes axis) to get the total log probability. \"\"\" num_seeds , num_classes , dim = sample . shape out = self . variational_distribution . log_prob ( sample ) assert out . shape == ( num_seeds , num_classes ) return out rsample ( self , num_seeds = 1 ) Samples values of the coefficient from the variational distribution using re-parameterization trick. Parameters: Name Type Description Default num_seeds int number of values to be sampled. Defaults to 1. 1 Returns: Type Description Union[torch.Tensor, Tuple[torch.Tensor]] if obs2prior is disabled, returns a tensor of shape (num_seeds, num_classes, dim) where each output[i, :, :] corresponds to one sample of the coefficient. If obs2prior is enabled, returns a tuple of samples: (1) a tensor of shape (num_seeds, num_classes, dim) containing sampled values of coefficient, and (2) a tensor o shape (num_seeds, dim, num_obs) containing samples of the H weight in the prior distribution. Source code in bemb/model/bayesian_coefficient.py def rsample ( self , num_seeds : int = 1 ) -> Union [ torch . Tensor , Tuple [ torch . Tensor ]]: \"\"\"Samples values of the coefficient from the variational distribution using re-parameterization trick. Args: num_seeds (int, optional): number of values to be sampled. Defaults to 1. Returns: Union[torch.Tensor, Tuple[torch.Tensor]]: if `obs2prior` is disabled, returns a tensor of shape (num_seeds, num_classes, dim) where each output[i, :, :] corresponds to one sample of the coefficient. If `obs2prior` is enabled, returns a tuple of samples: (1) a tensor of shape (num_seeds, num_classes, dim) containing sampled values of coefficient, and (2) a tensor o shape (num_seeds, dim, num_obs) containing samples of the H weight in the prior distribution. \"\"\" value_sample = self . variational_distribution . rsample ( torch . Size ([ num_seeds ])) if self . obs2prior : # sample obs2prior H as well. H_sample = self . prior_H . rsample ( num_seeds = num_seeds ) return ( value_sample , H_sample ) else : return value_sample update_variational_mean_fixed ( self , new_value ) Updates the fixed part of the mean of the variational distribution. Parameters: Name Type Description Default new_value torch.Tensor the new value of the fixed part of the mean of the variational distribution. required Source code in bemb/model/bayesian_coefficient.py def update_variational_mean_fixed ( self , new_value : torch . Tensor ) -> None : \"\"\"Updates the fixed part of the mean of the variational distribution. Args: new_value (torch.Tensor): the new value of the fixed part of the mean of the variational distribution. \"\"\" assert new_value . shape == self . variational_mean_flexible . shape del self . variational_mean_fixed self . register_buffer ( 'variational_mean_fixed' , new_value ) bayesian_linear Bayesian tensor object. BayesianLinear ( Module ) Source code in bemb/model/bayesian_linear.py class BayesianLinear ( nn . Module ): def __init__ ( self , in_features : int , out_features : int , bias : bool = True , W_variational_mean_fixed : Optional [ torch . Tensor ] = None , device = None , dtype = None , W_prior_variance : float = 1.0 , b_prior_variance : float = 1.0 ): \"\"\"Linear layer where weight and bias are modelled as distributions. \"\"\" super () . __init__ () if dtype is not None : raise NotImplementedError ( 'dtype is not Supported yet.' ) self . in_features = in_features # the same as number of classes before. self . out_features = out_features # the same as latent dimension before. self . bias = bias # ============================================================================================================== # prior distributions for mean and bias. # ============================================================================================================== # the prior of weights are gausssian distributions independent across in_feature dimensions. self . register_buffer ( 'W_prior_mean' , torch . zeros ( in_features , out_features )) self . register_buffer ( 'W_prior_logstd' , torch . ones ( in_features , out_features ) * np . log ( W_prior_variance )) if self . bias : self . register_buffer ( 'b_prior_mean' , torch . zeros ( in_features , out_features )) self . register_buffer ( 'b_prior_logstd' , torch . ones ( in_features , out_features ) * np . log ( b_prior_variance )) # ============================================================================================================== # variational distributions for weight and bias. # ============================================================================================================== if W_variational_mean_fixed is None : self . W_variational_mean_fixed = None else : assert W_variational_mean_fixed . shape == ( in_features , out_features ), \\ f 'W_variational_mean_fixed tensor should have shape (in_features, out_features), got { W_variational_mean_fixed . shape } ' self . register_buffer ( 'W_variational_mean_fixed' , W_variational_mean_fixed ) # TODO: optionally add customizable initialization here. self . W_variational_mean_flexible = nn . Parameter ( torch . randn ( in_features , out_features ), requires_grad = True ) self . W_variational_logstd = nn . Parameter ( torch . randn ( in_features , out_features ), requires_grad = True ) if self . bias : self . b_variational_mean = nn . Parameter ( torch . randn ( out_features ), requires_grad = True ) self . b_variational_logstd = nn . Parameter ( torch . randn ( out_features ), requires_grad = True ) if device is not None : self . to ( device ) self . W_sample = None self . b_sample = None self . num_seeds = None @property def W_variational_mean ( self ): if self . W_variational_mean_fixed is None : return self . W_variational_mean_flexible else : return self . W_variational_mean_fixed + self . W_variational_mean_flexible def rsample ( self , num_seeds : int = 1 ) -> Optional [ Tuple [ torch . Tensor , Optional [ torch . Tensor ]]]: \"\"\"sample all parameters using re-parameterization trick. \"\"\" self . num_seeds = num_seeds self . W_sample = self . W_variational_distribution . rsample ( torch . Size ([ num_seeds ])) if self . bias : self . b_sample = self . b_variational_distribution . rsample ( torch . Size ([ num_seeds ])) return self . W_sample , self . b_sample def dsample ( self ): \"\"\"Deterministic sample method, set (W, b) sample to the mean of variational distribution.\"\"\" self . num_seeds = 1 self . W_sample = self . W_variational_mean . unsqueeze ( dim = 0 ) if self . bias : self . b_sample = self . b_variational_mean . unsqueeze ( dim = 0 ) return self . W_sample , self . b_sample def forward ( self , x , mode : str = 'multiply' ): \"\"\" Forward with weight sampling. Forward does out = XW + b, for forward() method behaves like the embedding layer in PyTorch, use the lookup() method. To have determinstic results, call self.dsample() before executing. To have stochastic results, call self.rsample() before executing. mode in ['multiply', 'lookup'] output shape: (num_seeds, batch_size, out_features). \"\"\" assert self . num_seeds is not None , 'run BayesianLinear.rsample() or dsample() first to sample weight and bias.' # if determinstic, num_seeds is set to 1. # w: (num_seeds, in_features=num_classes, out_features) # b: (num_seeds, out_features) # x: (N, in_features) if multiply and (N,) if lookup. # output: (num_seeds, N, out_features) if mode == 'multiply' : x = x . view ( 1 , - 1 , self . in_features ) . expand ( self . num_seeds , - 1 , - 1 ) # (num_seeds, N, in_features) out = x . bmm ( self . W_sample ) # (num_seeds, N, out_features) elif mode == 'lookup' : out = self . W_sample [:, x , :] # (num_seeds, N, out_features) else : raise ValueError ( f 'mode= { mode } is not allowed.' ) if self . bias : out += self . b_sample . view ( self . num_seeds , 1 , self . out_features ) # (num_seeds, N, out_features) return out @property def W_variational_distribution ( self ): \"\"\"the weight variational distribution.\"\"\" return Normal ( loc = self . W_variational_mean , scale = torch . exp ( self . W_variational_logstd )) @property def b_variational_distribution ( self ): return Normal ( loc = self . b_variational_mean , scale = torch . exp ( self . b_variational_logstd )) @property def device ( self ) -> torch . device : return self . W_variational_mean . device def log_prior ( self ): \"\"\"Evaluate the likelihood of the provided samples of parameter under the current prior distribution.\"\"\" assert self . num_seeds is not None , 'run BayesianLinear.rsample() or dsample() first to sample weight and bias.' num_seeds = self . W_sample . shape [ 0 ] total_log_prob = torch . zeros ( num_seeds , device = self . device ) # log P(W_sample). shape = (num_seeds,) W_prior = Normal ( loc = self . W_prior_mean , scale = torch . exp ( self . W_prior_logstd )) total_log_prob += W_prior . log_prob ( self . W_sample ) . sum ( dim = [ 1 , 2 ]) # log P(b_sample) if applicable. if self . bias : b_prior = Normal ( loc = self . b_prior_mean , scale = torch . exp ( self . b_prior_logstd )) total_log_prob += b_prior . log_prob ( self . b_sample ) . sum ( dim = 1 ) assert total_log_prob . shape == ( num_seeds ,) return total_log_prob def log_variational ( self ): \"\"\"Evaluate the likelihood of the provided samples of parameter under the current variational distribution.\"\"\" assert self . num_seeds is not None , 'run BayesianLinear.rsample() or dsample() first to sample weight and bias.' num_seeds = self . W_sample . shape [ 0 ] total_log_prob = torch . zeros ( num_seeds , device = self . device ) total_log_prob += self . W_variational_distribution . log_prob ( self . W_sample ) . sum ( dim = [ 1 , 2 ]) if self . bias : total_log_prob += self . b_variational_distribution . log_prob ( self . b_sample ) . sum ( dim = 1 ) assert total_log_prob . shape == ( num_seeds ,) return total_log_prob def __repr__ ( self ): prior_info = f 'W_prior ~ N(mu= { self . W_prior_mean } , logstd= { self . W_prior_logstd } )' if self . bias : prior_info += f 'b_prior ~ N(mu= { self . b_prior_mean } , logstd= { self . b_prior_logstd } )' return f \"BayesianLinear(in_features= { self . in_features } , out_features= { self . out_features } , bias= { self . bias } , { prior_info } )\" W_variational_distribution property readonly the weight variational distribution. __init__ ( self , in_features , out_features , bias = True , W_variational_mean_fixed = None , device = None , dtype = None , W_prior_variance = 1.0 , b_prior_variance = 1.0 ) special Linear layer where weight and bias are modelled as distributions. Source code in bemb/model/bayesian_linear.py def __init__ ( self , in_features : int , out_features : int , bias : bool = True , W_variational_mean_fixed : Optional [ torch . Tensor ] = None , device = None , dtype = None , W_prior_variance : float = 1.0 , b_prior_variance : float = 1.0 ): \"\"\"Linear layer where weight and bias are modelled as distributions. \"\"\" super () . __init__ () if dtype is not None : raise NotImplementedError ( 'dtype is not Supported yet.' ) self . in_features = in_features # the same as number of classes before. self . out_features = out_features # the same as latent dimension before. self . bias = bias # ============================================================================================================== # prior distributions for mean and bias. # ============================================================================================================== # the prior of weights are gausssian distributions independent across in_feature dimensions. self . register_buffer ( 'W_prior_mean' , torch . zeros ( in_features , out_features )) self . register_buffer ( 'W_prior_logstd' , torch . ones ( in_features , out_features ) * np . log ( W_prior_variance )) if self . bias : self . register_buffer ( 'b_prior_mean' , torch . zeros ( in_features , out_features )) self . register_buffer ( 'b_prior_logstd' , torch . ones ( in_features , out_features ) * np . log ( b_prior_variance )) # ============================================================================================================== # variational distributions for weight and bias. # ============================================================================================================== if W_variational_mean_fixed is None : self . W_variational_mean_fixed = None else : assert W_variational_mean_fixed . shape == ( in_features , out_features ), \\ f 'W_variational_mean_fixed tensor should have shape (in_features, out_features), got { W_variational_mean_fixed . shape } ' self . register_buffer ( 'W_variational_mean_fixed' , W_variational_mean_fixed ) # TODO: optionally add customizable initialization here. self . W_variational_mean_flexible = nn . Parameter ( torch . randn ( in_features , out_features ), requires_grad = True ) self . W_variational_logstd = nn . Parameter ( torch . randn ( in_features , out_features ), requires_grad = True ) if self . bias : self . b_variational_mean = nn . Parameter ( torch . randn ( out_features ), requires_grad = True ) self . b_variational_logstd = nn . Parameter ( torch . randn ( out_features ), requires_grad = True ) if device is not None : self . to ( device ) self . W_sample = None self . b_sample = None self . num_seeds = None dsample ( self ) Deterministic sample method, set (W, b) sample to the mean of variational distribution. Source code in bemb/model/bayesian_linear.py def dsample ( self ): \"\"\"Deterministic sample method, set (W, b) sample to the mean of variational distribution.\"\"\" self . num_seeds = 1 self . W_sample = self . W_variational_mean . unsqueeze ( dim = 0 ) if self . bias : self . b_sample = self . b_variational_mean . unsqueeze ( dim = 0 ) return self . W_sample , self . b_sample forward ( self , x , mode = 'multiply' ) Forward with weight sampling. Forward does out = XW + b, for forward() method behaves like the embedding layer in PyTorch, use the lookup() method. To have determinstic results, call self.dsample() before executing. To have stochastic results, call self.rsample() before executing. mode in ['multiply', 'lookup'] output shape: (num_seeds, batch_size, out_features). Source code in bemb/model/bayesian_linear.py def forward ( self , x , mode : str = 'multiply' ): \"\"\" Forward with weight sampling. Forward does out = XW + b, for forward() method behaves like the embedding layer in PyTorch, use the lookup() method. To have determinstic results, call self.dsample() before executing. To have stochastic results, call self.rsample() before executing. mode in ['multiply', 'lookup'] output shape: (num_seeds, batch_size, out_features). \"\"\" assert self . num_seeds is not None , 'run BayesianLinear.rsample() or dsample() first to sample weight and bias.' # if determinstic, num_seeds is set to 1. # w: (num_seeds, in_features=num_classes, out_features) # b: (num_seeds, out_features) # x: (N, in_features) if multiply and (N,) if lookup. # output: (num_seeds, N, out_features) if mode == 'multiply' : x = x . view ( 1 , - 1 , self . in_features ) . expand ( self . num_seeds , - 1 , - 1 ) # (num_seeds, N, in_features) out = x . bmm ( self . W_sample ) # (num_seeds, N, out_features) elif mode == 'lookup' : out = self . W_sample [:, x , :] # (num_seeds, N, out_features) else : raise ValueError ( f 'mode= { mode } is not allowed.' ) if self . bias : out += self . b_sample . view ( self . num_seeds , 1 , self . out_features ) # (num_seeds, N, out_features) return out log_prior ( self ) Evaluate the likelihood of the provided samples of parameter under the current prior distribution. Source code in bemb/model/bayesian_linear.py def log_prior ( self ): \"\"\"Evaluate the likelihood of the provided samples of parameter under the current prior distribution.\"\"\" assert self . num_seeds is not None , 'run BayesianLinear.rsample() or dsample() first to sample weight and bias.' num_seeds = self . W_sample . shape [ 0 ] total_log_prob = torch . zeros ( num_seeds , device = self . device ) # log P(W_sample). shape = (num_seeds,) W_prior = Normal ( loc = self . W_prior_mean , scale = torch . exp ( self . W_prior_logstd )) total_log_prob += W_prior . log_prob ( self . W_sample ) . sum ( dim = [ 1 , 2 ]) # log P(b_sample) if applicable. if self . bias : b_prior = Normal ( loc = self . b_prior_mean , scale = torch . exp ( self . b_prior_logstd )) total_log_prob += b_prior . log_prob ( self . b_sample ) . sum ( dim = 1 ) assert total_log_prob . shape == ( num_seeds ,) return total_log_prob log_variational ( self ) Evaluate the likelihood of the provided samples of parameter under the current variational distribution. Source code in bemb/model/bayesian_linear.py def log_variational ( self ): \"\"\"Evaluate the likelihood of the provided samples of parameter under the current variational distribution.\"\"\" assert self . num_seeds is not None , 'run BayesianLinear.rsample() or dsample() first to sample weight and bias.' num_seeds = self . W_sample . shape [ 0 ] total_log_prob = torch . zeros ( num_seeds , device = self . device ) total_log_prob += self . W_variational_distribution . log_prob ( self . W_sample ) . sum ( dim = [ 1 , 2 ]) if self . bias : total_log_prob += self . b_variational_distribution . log_prob ( self . b_sample ) . sum ( dim = 1 ) assert total_log_prob . shape == ( num_seeds ,) return total_log_prob rsample ( self , num_seeds = 1 ) sample all parameters using re-parameterization trick. Source code in bemb/model/bayesian_linear.py def rsample ( self , num_seeds : int = 1 ) -> Optional [ Tuple [ torch . Tensor , Optional [ torch . Tensor ]]]: \"\"\"sample all parameters using re-parameterization trick. \"\"\" self . num_seeds = num_seeds self . W_sample = self . W_variational_distribution . rsample ( torch . Size ([ num_seeds ])) if self . bias : self . b_sample = self . b_variational_distribution . rsample ( torch . Size ([ num_seeds ])) return self . W_sample , self . b_sample bemb The core class of the Bayesian EMBedding (BEMB) model. Author: Tianyu Du Update: Apr. 28, 2022 BEMBFlex ( Module ) Source code in bemb/model/bemb.py class BEMBFlex ( nn . Module ): # ================================================================================================================== # core function as a PyTorch module. # ================================================================================================================== def __init__ ( self , utility_formula : str , obs2prior_dict : Dict [ str , bool ], coef_dim_dict : Dict [ str , int ], num_items : int , pred_item : bool , prior_mean : Union [ float , Dict [ str , float ]] = 0.0 , default_prior_mean : float = 0.0 , prior_variance : Union [ float , Dict [ str , float ]] = 1.0 , num_users : Optional [ int ] = None , num_sessions : Optional [ int ] = None , trace_log_q : bool = False , category_to_item : Dict [ int , List [ int ]] = None , # number of observables. num_user_obs : Optional [ int ] = None , num_item_obs : Optional [ int ] = None , num_session_obs : Optional [ int ] = None , num_price_obs : Optional [ int ] = None , num_taste_obs : Optional [ int ] = None , # additional modules. additional_modules : Optional [ List [ nn . Module ]] = None ) -> None : \"\"\" Args: utility_formula (str): a string representing the utility function U[user, item, session]. See documentation for more details in the documentation for the format of formula. Examples: lambda_item lambda_item + theta_user * alpha_item + zeta_user * item_obs lambda_item + theta_user * alpha_item + gamma_user * beta_item * price_obs See the doc-string of parse_utility for an example. obs2prior_dict (Dict[str, bool]): a dictionary maps coefficient name (e.g., 'lambda_item') to a boolean indicating if observable (e.g., item_obs) enters the prior of the coefficient. coef_dim_dict (Dict[str, int]): a dictionary maps coefficient name (e.g., 'lambda_item') to an integer indicating the dimension of coefficient. For standalone coefficients like U = lambda_item, the dim should be 1. For factorized coefficients like U = theta_user * alpha_item, the dim should be the latent dimension of theta and alpha. For coefficients multiplied with observables like U = zeta_user * item_obs, the dim should be the number of observables in item_obs. For factorized coefficient multiplied with observables like U = gamma_user * beta_item * price_obs, the dim should be the latent dim multiplied by number of observables in price_obs. num_items (int): number of items. pred_item (bool): there are two use cases of this model, suppose we have `user_index[i]` and `item_index[i]` for the i-th observation in the dataset. Case 1: which item among all items user `user_index[i]` is going to purchase, the prediction label is therefore `item_index[i]`. Equivalently, we can ask what's the likelihood for user `user_index[i]` to purchase `item_index[i]`. Case 2: what rating would user `user_index[i]` assign to item `item_index[i]`? In this case, the dataset object needs to contain a separate label. NOTE: for now, we only support binary labels. default_prior_mean (float): the default prior mean for coefficients, if it is not specified in the prior_mean; defaults to 0.0. prior_mean (Union[float, Dict[str, float]]): the mean of prior distribution for coefficients. If a float is provided, all prior mean will be diagonal matrix with the provided value. If a dictionary is provided, keys of prior_mean should be coefficient names, and the mean of prior of coef_name would the provided value Defaults to 0.0, which means all prior means are initalized to 0.0 prior_variance (Union[float, Dict[str, float]]): the variance of prior distribution for coefficients. If a float is provided, all priors will be diagonal matrix with prior_variance along the diagonal. If a dictionary is provided, keys of prior_variance should be coefficient names, and the variance of prior of coef_name would be a diagonal matrix with prior_variance[coef_name] along the diagonal. Defaults to 1.0, which means all prior have identity matrix as the covariance matrix. num_users (int, optional): number of users, required only if coefficient or observable depending on user is in utility. Defaults to None. num_sessions (int, optional): number of sessions, required only if coefficient or observable depending on session is in utility. Defaults to None. trace_log_q (bool, optional): whether to trace the derivative of variational likelihood logQ with respect to variational parameters in the ELBO while conducting gradient update. Defaults to False. category_to_item (Dict[str, List[int]], optional): a dictionary with category id or name as keys, and category_to_item[C] contains the list of item ids belonging to category C. If None is provided, all items are assumed to be in the same category. Defaults to None. num_{user, item, session, price, taste}_obs (int, optional): number of observables of each type of features, only required if observable enters prior. NOTE: currently we only allow coefficient to depend on either user or item, thus only user and item observables can enter the prior of coefficient. Hence session, price, and taste observables are never required, we include it here for completeness. \"\"\" super ( BEMBFlex , self ) . __init__ () self . utility_formula = utility_formula self . obs2prior_dict = obs2prior_dict self . coef_dim_dict = coef_dim_dict self . prior_variance = prior_variance self . default_prior_mean = default_prior_mean self . prior_mean = prior_mean self . pred_item = pred_item self . num_items = num_items self . num_users = num_users self . num_sessions = num_sessions self . trace_log_q = trace_log_q self . category_to_item = category_to_item # ============================================================================================================== # Category ID to Item ID mapping. # Category ID to Category Size mapping. # Item ID to Category ID mapping. # ============================================================================================================== if self . category_to_item is None : if self . pred_item : # assign all items to the same category if predicting items. self . category_to_item = { 0 : list ( np . arange ( self . num_items ))} else : # otherwise, for the j-th observation in the dataset, the label[j] # only depends on user_index[j] and item_index[j], so we put each # item to its own category. self . category_to_item = { i : [ i ] for i in range ( self . num_items )} self . num_categories = len ( self . category_to_item ) max_category_size = max ( len ( x ) for x in self . category_to_item . values ()) category_to_item_tensor = torch . full ( ( self . num_categories , max_category_size ), - 1 ) category_to_size_tensor = torch . empty ( self . num_categories ) for c , item_in_c in self . category_to_item . items (): category_to_item_tensor [ c , : len ( item_in_c )] = torch . LongTensor ( item_in_c ) category_to_size_tensor [ c ] = torch . scalar_tensor ( len ( item_in_c )) self . register_buffer ( 'category_to_item_tensor' , category_to_item_tensor . long ()) self . register_buffer ( 'category_to_size_tensor' , category_to_size_tensor . long ()) item_to_category_tensor = torch . zeros ( self . num_items ) for c , items_in_c in self . category_to_item . items (): item_to_category_tensor [ items_in_c ] = c self . register_buffer ( 'item_to_category_tensor' , item_to_category_tensor . long ()) # ============================================================================================================== # Create Bayesian Coefficient Objects # ============================================================================================================== # model configuration. self . formula = parse_utility ( utility_formula ) print ( 'BEMB: utility formula parsed:' ) pprint ( self . formula ) self . raw_formula = utility_formula self . obs2prior_dict = obs2prior_dict # dimension of each observable, this one is used only for obs2prior. self . num_obs_dict = { 'user' : num_user_obs , 'item' : num_item_obs , 'category' : 0 , 'session' : num_session_obs , 'price' : num_price_obs , 'taste' : num_taste_obs , 'constant' : 1 # not really used, for dummy variables. } # how many classes for the variational distribution. # for example, beta_item would be `num_items` 10-dimensional gaussian if latent dim = 10. variation_to_num_classes = { 'user' : self . num_users , 'item' : self . num_items , 'constant' : 1 , 'category' : self . num_categories , } coef_dict = dict () for additive_term in self . formula : for coef_name in additive_term [ 'coefficient' ]: variation = coef_name . split ( '_' )[ - 1 ] mean = self . prior_mean [ coef_name ] if isinstance ( self . prior_mean , dict ) else self . default_prior_mean s2 = self . prior_variance [ coef_name ] if isinstance ( self . prior_variance , dict ) else self . prior_variance coef_dict [ coef_name ] = BayesianCoefficient ( variation = variation , num_classes = variation_to_num_classes [ variation ], obs2prior = self . obs2prior_dict [ coef_name ], num_obs = self . num_obs_dict [ variation ], dim = self . coef_dim_dict [ coef_name ], prior_mean = mean , prior_variance = s2 ) self . coef_dict = nn . ModuleDict ( coef_dict ) # ============================================================================================================== # Optional: register additional modules. # ============================================================================================================== if additional_modules is None : self . additional_modules = [] else : raise NotImplementedError ( 'Additional modules are temporarily disabled for further development.' ) self . additional_modules = nn . ModuleList ( additional_modules ) def __str__ ( self ): return f 'Bayesian EMBedding Model with U[user, item, session] = { self . raw_formula } \\n ' \\ + f 'Total number of parameters: { self . num_params } . \\n ' \\ + 'With the following coefficients: \\n ' \\ + str ( self . coef_dict ) + ' \\n ' \\ + str ( self . additional_modules ) def posterior_mean ( self , coef_name : str ) -> torch . Tensor : \"\"\"Returns the mean of estimated posterior distribution of coefficient `coef_name`. Args: coef_name (str): name of the coefficient to query. Returns: torch.Tensor: mean of the estimated posterior distribution of `coef_name`. \"\"\" if coef_name in self . coef_dict . keys (): return self . coef_dict [ coef_name ] . variational_mean else : raise KeyError ( f ' { coef_name } is not a valid coefficient name in { self . utility_formula } .' ) def ivs ( self , batch ) -> torch . Tensor : \"\"\"The combined method of computing utilities and log probability. Args: batch (dict): a batch of data. Returns: torch.Tensor: the combined utility and log probability. \"\"\" # Use the means of variational distributions as the sole MC sample. sample_dict = dict () for coef_name , coef in self . coef_dict . items (): sample_dict [ coef_name ] = coef . variational_distribution . mean . unsqueeze ( dim = 0 ) # (1, num_*, dim) # there is 1 random seed in this case. # (num_seeds=1, len(batch), num_items) out = self . log_likelihood_all_items ( batch , return_logit = True , sample_dict = sample_dict ) out = out . squeeze ( 0 ) # import pdb; pdb.set_trace() ivs = scatter_logsumexp ( out , self . item_to_category_tensor , dim =- 1 ) return ivs # (len(batch), num_categories) def sample_choices ( self , batch : ChoiceDataset , debug : bool = False , num_seeds : int = 1 , ** kwargs ) -> Tuple [ torch . Tensor ]: \"\"\"Samples choices given model paramaters and trips Args: batch(ChoiceDataset): batch data containing trip information; item choice information is discarded debug(bool): whether to print debug information Returns: Tuple[torch.Tensor]: sampled choices; shape: (batch_size, num_categories) \"\"\" # Use the means of variational distributions as the sole MC sample. sample_dict = dict () for coef_name , coef in self . coef_dict . items (): sample_dict [ coef_name ] = coef . variational_distribution . mean . unsqueeze ( dim = 0 ) # (1, num_*, dim) # sample_dict = self.sample_coefficient_dictionary(num_seeds) maxes , out = self . sample_log_likelihoods ( batch , sample_dict ) return maxes . squeeze (), out . squeeze () def sample_log_likelihoods ( self , batch : ChoiceDataset , sample_dict : Dict [ str , torch . Tensor ]) -> Tuple [ torch . Tensor , torch . Tensor ]: \"\"\"Samples log likelihoods given model paramaters and trips Args: batch(ChoiceDataset): batch data containing trip information; item choice information is discarded sample_dict(Dict[str, torch.Tensor]): sampled coefficient values Returns: Tuple[torch.Tensor]: sampled log likelihoods; shape: (batch_size, num_categories) \"\"\" # get the log likelihoods for all items for all categories utility = self . log_likelihood_all_items ( batch , return_logit = True , sample_dict = sample_dict ) mu_gumbel = 0.0 beta_gumbel = 1.0 EUL_MAS_CONST = 0.5772156649 mean_gumbel = torch . tensor ([ mu_gumbel + beta_gumbel * EUL_MAS_CONST ], device = self . device ) m = torch . distributions . gumbel . Gumbel ( torch . tensor ([ 0.0 ], device = self . device ), torch . tensor ([ 1.0 ], device = self . device )) # m = torch.distributions.gumbel.Gumbel(0.0, 1.0) gumbel_samples = m . sample ( utility . shape ) . squeeze ( - 1 ) gumbel_samples -= mean_gumbel utility += gumbel_samples max_by_category , argmax_by_category = scatter_max ( utility , self . item_to_category_tensor , dim =- 1 ) return max_by_category , argmax_by_category log_likelihoods = self . sample_log_likelihoods_per_category ( batch , sample_dict ) # sum over all categories. log_likelihoods = log_likelihoods . sum ( dim = 1 ) return log_likelihoods , log_likelihoods def forward ( self , batch : ChoiceDataset , return_type : str , return_scope : str , deterministic : bool = True , sample_dict : Optional [ Dict [ str , torch . Tensor ]] = None , num_seeds : Optional [ int ] = None ) -> torch . Tensor : \"\"\"A combined method for inference with the model. Args: batch (ChoiceDataset): batch data containing choice information. return_type (str): either 'log_prob' or 'utility'. 'log_prob': return the log-probability (by within-category log-softmax) for items 'utility': return the utility value of items. return_scope (str): either 'item_index' or 'all_items'. 'item_index': for each observation i, return log-prob/utility for the chosen item batch.item_index[i] only. 'all_items': for each observation i, return log-prob/utility for all items. deterministic (bool, optional): True: expectations of parameter variational distributions are used for inference. False: the user needs to supply a dictionary of sampled parameters for inference. Defaults to True. sample_dict (Optional[Dict[str, torch.Tensor]], optional): sampled parameters for inference task. This is not needed when `deterministic` is True. When `deterministic` is False, the user can supply a `sample_dict`. If `sample_dict` is not provided, this method will create `num_seeds` samples. Defaults to None. num_seeds (Optional[int]): the number of random samples of parameters to construct. This is only required if `deterministic` is False (i.e., stochastic mode) and `sample_dict` is not provided. Defaults to None. Returns: torch.Tensor: a tensor of log-probabilities or utilities, depending on `return_type`. The shape of the returned tensor depends on `return_scope` and `deterministic`. ------------------------------------------------------------------------- | `return_scope` | `deterministic` | Output shape | ------------------------------------------------------------------------- | 'item_index` | True | (len(batch),) | ------------------------------------------------------------------------- | 'all_items' | True | (len(batch), num_items) | ------------------------------------------------------------------------- | 'item_index' | False | (num_seeds, len(batch)) | ------------------------------------------------------------------------- | 'all_items' | False | (num_seeds, len(batch), num_items) | ------------------------------------------------------------------------- \"\"\" # ============================================================================================================== # check arguments. # ============================================================================================================== assert return_type in [ 'log_prob' , 'utility' ], \"return_type must be either 'log_prob' or 'utility'.\" assert return_scope in [ 'item_index' , 'all_items' ], \"return_scope must be either 'item_index' or 'all_items'.\" assert deterministic in [ True , False ] if ( not deterministic ) and ( sample_dict is None ): assert num_seeds >= 1 , \"A positive interger `num_seeds` is required if `deterministic` is False and no `sample_dict` is provided.\" # when pred_item is true, the model is predicting which item is bought (specified by item_index). if self . pred_item : batch . label = batch . item_index # ============================================================================================================== # get sample_dict ready. # ============================================================================================================== if deterministic : num_seeds = 1 # Use the means of variational distributions as the sole deterministic MC sample. # NOTE: here we don't need to sample the obs2prior weight H since we only compute the log-likelihood. # TODO: is this correct? sample_dict = dict () for coef_name , coef in self . coef_dict . items (): sample_dict [ coef_name ] = coef . variational_distribution . mean . unsqueeze ( dim = 0 ) # (1, num_*, dim) else : if sample_dict is None : # sample stochastic parameters. sample_dict = self . sample_coefficient_dictionary ( num_seeds ) else : # use the provided sample_dict. num_seeds = list ( sample_dict . values ())[ 0 ] . shape [ 0 ] # ============================================================================================================== # call the sampling method of additional modules. # ============================================================================================================== for module in self . additional_modules : # deterministic sample. if deterministic : module . dsample () else : module . rsample ( num_seeds = num_seeds ) # if utility is requested, don't run log-softmax, simply return logit. return_logit = ( return_type == 'utility' ) if return_scope == 'all_items' : # (num_seeds, len(batch), num_items) out = self . log_likelihood_all_items ( batch = batch , sample_dict = sample_dict , return_logit = return_logit ) elif return_scope == 'item_index' : # (num_seeds, len(batch)) out = self . log_likelihood_item_index ( batch = batch , sample_dict = sample_dict , return_logit = return_logit ) if deterministic : # drop the first dimension, which has size of `num_seeds` (equals 1 in the deterministic case). # (len(batch), num_items) or (len(batch),) return out . squeeze ( dim = 0 ) return out @property def num_params ( self ) -> int : return sum ([ p . numel () for p in self . parameters ()]) @property def device ( self ) -> torch . device : for coef in self . coef_dict . values (): return coef . device # ================================================================================================================== # helper functions. # ================================================================================================================== def sample_coefficient_dictionary ( self , num_seeds : int ) -> Dict [ str , torch . Tensor ]: \"\"\"A helper function to sample parameters from coefficients. Args: num_seeds (int): number of random samples. Returns: Dict[str, torch.Tensor]: a dictionary maps coefficient names to tensor of sampled coefficient parameters, where the first dimension of the sampled tensor has size `num_seeds`. Each sample tensor has shape (num_seeds, num_classes, dim). \"\"\" sample_dict = dict () for coef_name , coef in self . coef_dict . items (): s = coef . rsample ( num_seeds ) if coef . obs2prior : # sample both obs2prior weight and realization of variable. assert isinstance ( s , tuple ) and len ( s ) == 2 sample_dict [ coef_name ] = s [ 0 ] sample_dict [ coef_name + '.H' ] = s [ 1 ] else : # only sample the realization of variable. assert torch . is_tensor ( s ) sample_dict [ coef_name ] = s return sample_dict @torch . no_grad () def get_within_category_accuracy ( self , log_p_all_items : torch . Tensor , label : torch . LongTensor ) -> Dict [ str , float ]: \"\"\"A helper function for computing prediction accuracy (i.e., all non-differential metrics) within category. In particular, this method calculates the accuracy, precision, recall and F1 score. This method has the same functionality as the following peusodcode: for C in categories: # get sessions in which item in category C was purchased. T <- (t for t in {0,1,..., len(label)-1} if label[t] is in C) Y <- label[T] predictions = list() for t in T: # get the prediction within category for this session. y_pred = argmax_{items in C} log prob computed before. predictions.append(y_pred) accuracy = mean(Y == predictions) Similarly, this function computes precision, recall and f1score as well. Args: log_p_all_items (torch.Tensor): shape (num_sessions, num_items) the log probability of choosing each item in each session. label (torch.LongTensor): shape (num_sessions,), the IDs of items purchased in each session. Returns: [Dict[str, float]]: A dictionary containing performance metrics. \"\"\" # argmax: (num_sessions, num_categories), within category argmax. # item IDs are consecutive, thus argmax is the same as IDs of the item with highest P. _ , argmax_by_category = scatter_max ( log_p_all_items , self . item_to_category_tensor , dim =- 1 ) # category_purchased[t] = the category of item label[t]. # (num_sessions,) category_purchased = self . item_to_category_tensor [ label ] # pred[t] = the item with highest utility from the category item label[t] belongs to. # (num_sessions,) pred_from_category = argmax_by_category [ torch . arange ( len ( label )), category_purchased ] within_category_accuracy = ( pred_from_category == label ) . float () . mean () . item () # precision precision = list () recall = list () for i in range ( self . num_items ): correct_i = torch . sum ( ( torch . logical_and ( pred_from_category == i , label == i )) . float ()) precision_i = correct_i / \\ torch . sum (( pred_from_category == i ) . float ()) recall_i = correct_i / torch . sum (( label == i ) . float ()) # do not add if divided by zero. if torch . any ( pred_from_category == i ): precision . append ( precision_i . cpu () . item ()) if torch . any ( label == i ): recall . append ( recall_i . cpu () . item ()) precision = float ( np . mean ( precision )) recall = float ( np . mean ( recall )) if precision == recall == 0 : f1 = 0 else : f1 = 2 * precision * recall / ( precision + recall ) return { 'accuracy' : within_category_accuracy , 'precision' : precision , 'recall' : recall , 'f1score' : f1 } # ================================================================================================================== # Methods for terms in the ELBO: prior, likelihood, and variational. # ================================================================================================================== def log_likelihood_all_items ( self , batch : ChoiceDataset , return_logit : bool , sample_dict : Dict [ str , torch . Tensor ]) -> torch . Tensor : \"\"\" NOTE to developers: NOTE (akanodia to tianyudu): Is this really slow; even with log_likelihood you need log_prob which depends on logits of all items? This method computes utilities for all items available, which is a relatively slow operation. For training the model, you only need the utility/log-prob for the chosen/relevant item (i.e., item_index[i] for each i-th observation). Use this method for inference only. Use self.log_likelihood_item_index() for training instead. Computes the log probability of choosing `each` item in each session based on current model parameters. NOTE (akanodiadu to tianyudu): What does the next line mean? I think it just says its allowing for samples instead of posterior mean. This method allows for specifying {user, item}_latent_value for Monte Carlo estimation in ELBO. For actual prediction tasks, use the forward() function, which will use means of variational distributions for user and item latents. Args: batch (ChoiceDataset): a ChoiceDataset object containing relevant information. return_logit(bool): if set to True, return the log-probability, otherwise return the logit/utility. sample_dict(Dict[str, torch.Tensor]): Monte Carlo samples for model coefficients (i.e., those Greek letters). sample_dict.keys() should be the same as keys of self.obs2prior_dict, i.e., those greek letters actually enter the functional form of utility. The value of sample_dict should be tensors of shape (num_seeds, num_classes, dim) where num_classes in {num_users, num_items, 1} and dim in {latent_dim(K), num_item_obs, num_user_obs, 1}. Returns: torch.Tensor: a tensor of shape (num_seeds, len(batch), self.num_items), where out[x, y, z] is the probability of choosing item z in session y conditioned on latents to be the x-th Monte Carlo sample. \"\"\" num_seeds = next ( iter ( sample_dict . values ())) . shape [ 0 ] # avoid repeated work when user purchased several items in the same session. user_session_index = torch . stack ( [ batch . user_index , batch . session_index ]) assert user_session_index . shape == ( 2 , len ( batch )) unique_user_sess , inverse_indices = torch . unique ( user_session_index , dim = 1 , return_inverse = True ) user_index = unique_user_sess [ 0 , :] session_index = unique_user_sess [ 1 , :] assert len ( user_index ) == len ( session_index ) # short-hands for easier shape check. R = num_seeds # P = len(batch) # num_purchases. P = unique_user_sess . shape [ 1 ] S = self . num_sessions U = self . num_users I = self . num_items NC = self . num_categories # ============================================================================================================== # Helper Functions for Reshaping. # ============================================================================================================== def reshape_user_coef_sample ( C ): # input shape (R, U, *) C = C . view ( R , U , 1 , - 1 ) . expand ( - 1 , - 1 , I , - 1 ) # (R, U, I, *) C = C [:, user_index , :, :] assert C . shape == ( R , P , I , positive_integer ) return C def reshape_item_coef_sample ( C ): # input shape (R, I, *) C = C . view ( R , 1 , I , - 1 ) . expand ( - 1 , P , - 1 , - 1 ) assert C . shape == ( R , P , I , positive_integer ) return C def reshape_category_coef_sample ( C ): # input shape (R, NC, *) C = torch . repeat_interleave ( C , self . category_to_size_tensor , dim = 1 ) # input shape (R, I, *) C = C . view ( R , 1 , I , - 1 ) . expand ( - 1 , P , - 1 , - 1 ) assert C . shape == ( R , P , I , positive_integer ) return C def reshape_constant_coef_sample ( C ): # input shape (R, *) C = C . view ( R , 1 , 1 , - 1 ) . expand ( - 1 , P , I , - 1 ) assert C . shape == ( R , P , I , positive_integer ) return C def reshape_coef_sample ( sample , name ): # reshape the monte carlo sample of coefficients to (R, P, I, *). if name . endswith ( '_user' ): # (R, U, *) --> (R, P, I, *) return reshape_user_coef_sample ( sample ) elif name . endswith ( '_item' ): # (R, I, *) --> (R, P, I, *) return reshape_item_coef_sample ( sample ) elif name . endswith ( '_category' ): # (R, NC, *) --> (R, P, NC, *) return reshape_category_coef_sample ( sample ) elif name . endswith ( '_constant' ): # (R, *) --> (R, P, I, *) return reshape_constant_coef_sample ( sample ) else : raise ValueError def reshape_observable ( obs , name ): # reshape observable to (R, P, I, *) so that it can be multiplied with monte carlo # samples of coefficients. O = obs . shape [ - 1 ] # number of observables. assert O == positive_integer if name . startswith ( 'item_' ): assert obs . shape == ( I , O ) obs = obs . view ( 1 , 1 , I , O ) . expand ( R , P , - 1 , - 1 ) elif name . startswith ( 'user_' ): assert obs . shape == ( U , O ) obs = obs [ user_index , :] # (P, O) obs = obs . view ( 1 , P , 1 , O ) . expand ( R , - 1 , I , - 1 ) elif name . startswith ( 'session_' ): assert obs . shape == ( S , O ) obs = obs [ session_index , :] # (P, O) return obs . view ( 1 , P , 1 , O ) . expand ( R , - 1 , I , - 1 ) elif name . startswith ( 'price_' ): assert obs . shape == ( S , I , O ) obs = obs [ session_index , :, :] # (P, I, O) return obs . view ( 1 , P , I , O ) . expand ( R , - 1 , - 1 , - 1 ) elif name . startswith ( 'taste_' ): assert obs . shape == ( U , I , O ) obs = obs [ user_index , :, :] # (P, I, O) return obs . view ( 1 , P , I , O ) . expand ( R , - 1 , - 1 , - 1 ) else : raise ValueError assert obs . shape == ( R , P , I , O ) return obs # ============================================================================================================== # Copmute the Utility Term by Term. # ============================================================================================================== # P is the number of unique (user, session) pairs. # (random_seeds, P, num_items). utility = torch . zeros ( R , P , I , device = self . device ) # loop over additive term to utility for term in self . formula : # Type I: single coefficient, e.g., lambda_item or lambda_user. if len ( term [ 'coefficient' ]) == 1 and term [ 'observable' ] is None : # E.g., lambda_item or lambda_user coef_name = term [ 'coefficient' ][ 0 ] coef_sample = reshape_coef_sample ( sample_dict [ coef_name ], coef_name ) assert coef_sample . shape == ( R , P , I , 1 ) additive_term = coef_sample . view ( R , P , I ) # Type II: factorized coefficient, e.g., <theta_user, lambda_item>. elif len ( term [ 'coefficient' ]) == 2 and term [ 'observable' ] is None : coef_name_0 = term [ 'coefficient' ][ 0 ] coef_name_1 = term [ 'coefficient' ][ 1 ] coef_sample_0 = reshape_coef_sample ( sample_dict [ coef_name_0 ], coef_name_0 ) coef_sample_1 = reshape_coef_sample ( sample_dict [ coef_name_1 ], coef_name_1 ) assert coef_sample_0 . shape == coef_sample_1 . shape == ( R , P , I , positive_integer ) additive_term = ( coef_sample_0 * coef_sample_1 ) . sum ( dim =- 1 ) # Type III: single coefficient multiplied by observable, e.g., theta_user * x_obs_item. elif len ( term [ 'coefficient' ]) == 1 and term [ 'observable' ] is not None : coef_name = term [ 'coefficient' ][ 0 ] coef_sample = reshape_coef_sample ( sample_dict [ coef_name ], coef_name ) assert coef_sample . shape == ( R , P , I , positive_integer ) obs_name = term [ 'observable' ] obs = reshape_observable ( getattr ( batch , obs_name ), obs_name ) assert obs . shape == ( R , P , I , positive_integer ) additive_term = ( coef_sample * obs ) . sum ( dim =- 1 ) # Type IV: factorized coefficient multiplied by observable. # e.g., gamma_user * beta_item * price_obs. elif len ( term [ 'coefficient' ]) == 2 and term [ 'observable' ] is not None : coef_name_0 , coef_name_1 = term [ 'coefficient' ][ 0 ], term [ 'coefficient' ][ 1 ] coef_sample_0 = reshape_coef_sample ( sample_dict [ coef_name_0 ], coef_name_0 ) coef_sample_1 = reshape_coef_sample ( sample_dict [ coef_name_1 ], coef_name_1 ) assert coef_sample_0 . shape == coef_sample_1 . shape == ( R , P , I , positive_integer ) num_obs_times_latent_dim = coef_sample_0 . shape [ - 1 ] obs_name = term [ 'observable' ] obs = reshape_observable ( getattr ( batch , obs_name ), obs_name ) assert obs . shape == ( R , P , I , positive_integer ) num_obs = obs . shape [ - 1 ] # number of observables. assert ( num_obs_times_latent_dim % num_obs ) == 0 latent_dim = num_obs_times_latent_dim // num_obs coef_sample_0 = coef_sample_0 . view ( R , P , I , num_obs , latent_dim ) coef_sample_1 = coef_sample_1 . view ( R , P , I , num_obs , latent_dim ) # compute the factorized coefficient with shape (R, P, I, O). coef = ( coef_sample_0 * coef_sample_1 ) . sum ( dim =- 1 ) additive_term = ( coef * obs ) . sum ( dim =- 1 ) else : raise ValueError ( f 'Undefined term type: { term } ' ) assert additive_term . shape == ( R , P , I ) utility += additive_term # ============================================================================================================== # Mask Out Unavailable Items in Each Session. # ============================================================================================================== if batch . item_availability is not None : # expand to the Monte Carlo sample dimension. # (S, I) -> (P, I) -> (1, P, I) -> (R, P, I) A = batch . item_availability [ session_index , :] . unsqueeze ( dim = 0 ) . expand ( R , - 1 , - 1 ) utility [ ~ A ] = - ( torch . finfo ( utility . dtype ) . max / 2 ) utility = utility [:, inverse_indices , :] assert utility . shape == ( R , len ( batch ), I ) for module in self . additional_modules : additive_term = module ( batch ) assert additive_term . shape == ( R , len ( batch ), 1 ) utility += additive_term . expand ( - 1 , - 1 , I ) if return_logit : # output shape: (num_seeds, len(batch), num_items) return utility else : # compute log likelihood log p(choosing item i | user, item latents) # compute log softmax separately within each category. if self . pred_item : # output shape: (num_seeds, len(batch), num_items) log_p = scatter_log_softmax ( utility , self . item_to_category_tensor , dim =- 1 ) else : log_p = torch . nn . functional . logsigmoid ( utility ) return log_p def log_likelihood_item_index ( self , batch : ChoiceDataset , return_logit : bool , sample_dict : Dict [ str , torch . Tensor ]) -> torch . Tensor : \"\"\" NOTE for developers: This method is more efficient and only computes log-likelihood/logit(utility) for item in item_index[i] for each i-th observation. Developers should use use `log_likelihood_all_items` for inference purpose and to computes log-likelihoods/utilities for ALL items for the i-th observation. Computes the log probability of choosing item_index[i] in each session based on current model parameters. This method allows for specifying {user, item}_latent_value for Monte Carlo estimation in ELBO. For actual prediction tasks, use the forward() function, which will use means of variational distributions for user and item latents. Args: batch (ChoiceDataset): a ChoiceDataset object containing relevant information. return_logit(bool): if set to True, return the log-probability, otherwise return the logit/utility. sample_dict(Dict[str, torch.Tensor]): Monte Carlo samples for model coefficients (i.e., those Greek letters). sample_dict.keys() should be the same as keys of self.obs2prior_dict, i.e., those greek letters actually enter the functional form of utility. The value of sample_dict should be tensors of shape (num_seeds, num_classes, dim) where num_classes in {num_users, num_items, 1} and dim in {latent_dim(K), num_item_obs, num_user_obs, 1}. Returns: torch.Tensor: a tensor of shape (num_seeds, len(batch)), where out[x, y] is the probabilities of choosing item batch.item[y] in session y conditioned on latents to be the x-th Monte Carlo sample. \"\"\" num_seeds = next ( iter ( sample_dict . values ())) . shape [ 0 ] # get category id of the item bought in each row of batch. cate_index = self . item_to_category_tensor [ batch . item_index ] # get item ids of all items from the same category of each item bought. relevant_item_index = self . category_to_item_tensor [ cate_index , :] relevant_item_index = relevant_item_index . view ( - 1 ,) # index were padded with -1's, drop those dummy entries. relevant_item_index = relevant_item_index [ relevant_item_index != - 1 ] # the first repeats[0] entries in relevant_item_index are for the category of item_index[0] repeats = self . category_to_size_tensor [ cate_index ] # argwhere(reverse_indices == k) are positions in relevant_item_index for the category of item_index[k]. reverse_indices = torch . repeat_interleave ( torch . arange ( len ( batch ), device = self . device ), repeats ) # expand the user_index and session_index. user_index = torch . repeat_interleave ( batch . user_index , repeats ) repeat_category_index = torch . repeat_interleave ( cate_index , repeats ) session_index = torch . repeat_interleave ( batch . session_index , repeats ) # duplicate the item focused to match. item_index_expanded = torch . repeat_interleave ( batch . item_index , repeats ) # short-hands for easier shape check. R = num_seeds # total number of relevant items. total_computation = len ( session_index ) S = self . num_sessions U = self . num_users I = self . num_items NC = self . num_categories # ========================================================================================== # Helper Functions for Reshaping. # ========================================================================================== def reshape_coef_sample ( sample , name ): # reshape the monte carlo sample of coefficients to (R, P, I, *). if name . endswith ( '_user' ): # (R, U, *) --> (R, total_computation, *) return sample [:, user_index , :] elif name . endswith ( '_item' ): # (R, I, *) --> (R, total_computation, *) return sample [:, relevant_item_index , :] elif name . endswith ( '_category' ): # (R, NC, *) --> (R, total_computation, *) return sample [:, repeat_category_index , :] elif name . endswith ( '_constant' ): # (R, *) --> (R, total_computation, *) return sample . view ( R , 1 , - 1 ) . expand ( - 1 , total_computation , - 1 ) else : raise ValueError def reshape_observable ( obs , name ): # reshape observable to (R, P, I, *) so that it can be multiplied with monte carlo # samples of coefficients. O = obs . shape [ - 1 ] # number of observables. assert O == positive_integer if name . startswith ( 'item_' ): assert obs . shape == ( I , O ) obs = obs [ relevant_item_index , :] elif name . startswith ( 'user_' ): assert obs . shape == ( U , O ) obs = obs [ user_index , :] elif name . startswith ( 'session_' ): assert obs . shape == ( S , O ) obs = obs [ session_index , :] elif name . startswith ( 'price_' ): assert obs . shape == ( S , I , O ) obs = obs [ session_index , relevant_item_index , :] elif name . startswith ( 'taste_' ): assert obs . shape == ( U , I , O ) obs = obs [ user_index , relevant_item_index , :] else : raise ValueError assert obs . shape == ( total_computation , O ) return obs . unsqueeze ( dim = 0 ) . expand ( R , - 1 , - 1 ) # ========================================================================================== # Compute Components related to users and items only. # ========================================================================================== utility = torch . zeros ( R , total_computation , device = self . device ) # loop over additive term to utility for term in self . formula : # Type I: single coefficient, e.g., lambda_item or lambda_user. if len ( term [ 'coefficient' ]) == 1 and term [ 'observable' ] is None : # E.g., lambda_item or lambda_user coef_name = term [ 'coefficient' ][ 0 ] coef_sample = reshape_coef_sample ( sample_dict [ coef_name ], coef_name ) assert coef_sample . shape == ( R , total_computation , 1 ) additive_term = coef_sample . view ( R , total_computation ) # Type II: factorized coefficient, e.g., <theta_user, lambda_item>. elif len ( term [ 'coefficient' ]) == 2 and term [ 'observable' ] is None : coef_name_0 = term [ 'coefficient' ][ 0 ] coef_name_1 = term [ 'coefficient' ][ 1 ] coef_sample_0 = reshape_coef_sample ( sample_dict [ coef_name_0 ], coef_name_0 ) coef_sample_1 = reshape_coef_sample ( sample_dict [ coef_name_1 ], coef_name_1 ) assert coef_sample_0 . shape == coef_sample_1 . shape == ( R , total_computation , positive_integer ) additive_term = ( coef_sample_0 * coef_sample_1 ) . sum ( dim =- 1 ) # Type III: single coefficient multiplied by observable, e.g., theta_user * x_obs_item. elif len ( term [ 'coefficient' ]) == 1 and term [ 'observable' ] is not None : coef_name = term [ 'coefficient' ][ 0 ] coef_sample = reshape_coef_sample ( sample_dict [ coef_name ], coef_name ) assert coef_sample . shape == ( R , total_computation , positive_integer ) obs_name = term [ 'observable' ] obs = reshape_observable ( getattr ( batch , obs_name ), obs_name ) assert obs . shape == ( R , total_computation , positive_integer ) additive_term = ( coef_sample * obs ) . sum ( dim =- 1 ) # Type IV: factorized coefficient multiplied by observable. # e.g., gamma_user * beta_item * price_obs. elif len ( term [ 'coefficient' ]) == 2 and term [ 'observable' ] is not None : coef_name_0 , coef_name_1 = term [ 'coefficient' ][ 0 ], term [ 'coefficient' ][ 1 ] coef_sample_0 = reshape_coef_sample ( sample_dict [ coef_name_0 ], coef_name_0 ) coef_sample_1 = reshape_coef_sample ( sample_dict [ coef_name_1 ], coef_name_1 ) assert coef_sample_0 . shape == coef_sample_1 . shape == ( R , total_computation , positive_integer ) num_obs_times_latent_dim = coef_sample_0 . shape [ - 1 ] obs_name = term [ 'observable' ] obs = reshape_observable ( getattr ( batch , obs_name ), obs_name ) assert obs . shape == ( R , total_computation , positive_integer ) num_obs = obs . shape [ - 1 ] # number of observables. assert ( num_obs_times_latent_dim % num_obs ) == 0 latent_dim = num_obs_times_latent_dim // num_obs coef_sample_0 = coef_sample_0 . view ( R , total_computation , num_obs , latent_dim ) coef_sample_1 = coef_sample_1 . view ( R , total_computation , num_obs , latent_dim ) # compute the factorized coefficient with shape (R, P, I, O). coef = ( coef_sample_0 * coef_sample_1 ) . sum ( dim =- 1 ) additive_term = ( coef * obs ) . sum ( dim =- 1 ) else : raise ValueError ( f 'Undefined term type: { term } ' ) assert additive_term . shape == ( R , total_computation ) utility += additive_term # ========================================================================================== # Mask Out Unavailable Items in Each Session. # ========================================================================================== if batch . item_availability is not None : # expand to the Monte Carlo sample dimension. A = batch . item_availability [ session_index , relevant_item_index ] . unsqueeze ( dim = 0 ) . expand ( R , - 1 ) utility [ ~ A ] = - ( torch . finfo ( utility . dtype ) . max / 2 ) for module in self . additional_modules : # current utility shape: (R, total_computation) additive_term = module ( batch ) assert additive_term . shape == ( R , len ( batch )) or additive_term . shape == ( R , len ( batch ), 1 ) if additive_term . shape == ( R , len ( batch ), 1 ): # TODO: need to make this consistent with log_likelihood_all. # be tolerant for some customized module with BayesianLinear that returns (R, len(batch), 1). additive_term = additive_term . view ( R , len ( batch )) # expand to total number of computation, query by reverse_indices. # reverse_indices has length total_computation, and reverse_indices[i] correspond to the row-id that this # computation is responsible for. additive_term = additive_term [:, reverse_indices ] assert additive_term . shape == ( R , total_computation ) # compute log likelihood log p(choosing item i | user, item latents) if return_logit : log_p = utility else : if self . pred_item : # compute the log probability from logits/utilities. # output shape: (num_seeds, len(batch), num_items) log_p = scatter_log_softmax ( utility , reverse_indices , dim =- 1 ) # select the log-P of the item actually bought. log_p = log_p [:, item_index_expanded == relevant_item_index ] else : # This is the binomial choice situation in which case we just report sigmoid log likelihood bce = nn . BCELoss ( reduction = 'none' ) log_p = - bce ( torch . sigmoid ( utility . view ( - 1 )), batch . label . to ( torch . float32 )) return log_p def log_prior ( self , batch : ChoiceDataset , sample_dict : Dict [ str , torch . Tensor ]) -> torch . Tensor : \"\"\"Calculates the log-likelihood of Monte Carlo samples of Bayesian coefficients under their prior distribution. This method assume coefficients are statistically independent. Args: batch (ChoiceDataset): a dataset object contains observables for computing the prior distribution if obs2prior is True. sample_dict (Dict[str, torch.Tensor]): a dictionary coefficient names to Monte Carlo samples. Raises: ValueError: [description] Returns: torch.scalar_tensor: a tensor with shape (num_seeds,) of [ log P_{prior_distribution}(param[i]) ], where param[i] is the i-th Monte Carlo sample. \"\"\" # assert sample_dict.keys() == self.coef_dict.keys() num_seeds = next ( iter ( sample_dict . values ())) . shape [ 0 ] total = torch . zeros ( num_seeds , device = self . device ) for coef_name , coef in self . coef_dict . items (): if self . obs2prior_dict [ coef_name ]: if coef_name . endswith ( '_item' ): x_obs = batch . item_obs elif coef_name . endswith ( '_user' ): x_obs = batch . user_obs else : raise ValueError ( f 'No observable found to support obs2prior for { coef_name } .' ) total += coef . log_prior ( sample = sample_dict [ coef_name ], H_sample = sample_dict [ coef_name + '.H' ], x_obs = x_obs ) . sum ( dim =- 1 ) else : # log_prob outputs (num_seeds, num_{items, users}), sum to (num_seeds). total += coef . log_prior ( sample = sample_dict [ coef_name ], H_sample = None , x_obs = None ) . sum ( dim =- 1 ) for module in self . additional_modules : raise NotImplementedError () total += module . log_prior () return total def log_variational ( self , sample_dict : Dict [ str , torch . Tensor ]) -> torch . Tensor : \"\"\"Calculate the log-likelihood of samples in sample_dict under the current variational distribution. Args: sample_dict (Dict[str, torch.Tensor]): a dictionary coefficient names to Monte Carlo samples. Returns: torch.Tensor: a tensor of shape (num_seeds) of [ log P_{variational_distribution}(param[i]) ], where param[i] is the i-th Monte Carlo sample. \"\"\" num_seeds = list ( sample_dict . values ())[ 0 ] . shape [ 0 ] total = torch . zeros ( num_seeds , device = self . device ) for coef_name , coef in self . coef_dict . items (): # log_prob outputs (num_seeds, num_{items, users}), sum to (num_seeds). total += coef . log_variational ( sample_dict [ coef_name ]) . sum ( dim =- 1 ) for module in self . additional_modules : raise NotImplementedError () # with shape (num_seeds,) total += module . log_variational () . sum () return total def elbo ( self , batch : ChoiceDataset , num_seeds : int = 1 ) -> torch . Tensor : \"\"\"A combined method to computes the current ELBO given a batch, this method is used for training the model. Args: batch (ChoiceDataset): a ChoiceDataset containing necessary information. num_seeds (int, optional): the number of Monte Carlo samples from variational distributions to evaluate the expectation in ELBO. Defaults to 1. Returns: torch.Tensor: a scalar tensor of the ELBO estimated from num_seeds Monte Carlo samples. \"\"\" # ============================================================================================================== # 1. sample latent variables from their variational distributions. # ============================================================================================================== sample_dict = self . sample_coefficient_dictionary ( num_seeds ) # ============================================================================================================== # 2. compute log p(latent) prior. # (num_seeds,) --mean--> scalar. elbo = self . log_prior ( batch , sample_dict ) . mean ( dim = 0 ) # ============================================================================================================== # ============================================================================================================== # 3. compute the log likelihood log p(obs|latent). # sum over independent purchase decision for individual observations, mean over MC seeds. # the forward() function calls module.rsample(num_seeds) for module in self.additional_modules. # ============================================================================================================== if self . pred_item : # the prediction target is item_index. elbo += self . forward ( batch , return_type = 'log_prob' , return_scope = 'item_index' , deterministic = False , sample_dict = sample_dict ) . sum ( dim = 1 ) . mean ( dim = 0 ) # (num_seeds, len(batch)) --> scalar. else : # the prediction target is binary. # TODO: update the prediction function. utility = self . forward ( batch , return_type = 'utility' , return_scope = 'item_index' , deterministic = False , sample_dict = sample_dict ) # (num_seeds, len(batch)) # compute the log-likelihood for binary label. # (num_seeds, len(batch)) y_stacked = torch . stack ([ batch . label ] * num_seeds ) . float () assert y_stacked . shape == utility . shape bce = nn . BCELoss ( reduction = 'none' ) # scalar. ll = - bce ( torch . sigmoid ( utility ), y_stacked ) . sum ( dim = 1 ) . mean ( dim = 0 ) elbo += ll # ============================================================================================================== # 4. optionally add log likelihood under variational distributions q(latent). # ============================================================================================================== if self . trace_log_q : elbo -= self . log_variational ( sample_dict ) . mean ( dim = 0 ) return elbo __init__ ( self , utility_formula , obs2prior_dict , coef_dim_dict , num_items , pred_item , prior_mean = 0.0 , default_prior_mean = 0.0 , prior_variance = 1.0 , num_users = None , num_sessions = None , trace_log_q = False , category_to_item = None , num_user_obs = None , num_item_obs = None , num_session_obs = None , num_price_obs = None , num_taste_obs = None , additional_modules = None ) special Parameters: Name Type Description Default utility_formula str a string representing the utility function U[user, item, session]. See documentation for more details in the documentation for the format of formula. Examples: lambda_item lambda_item + theta_user * alpha_item + zeta_user * item_obs lambda_item + theta_user * alpha_item + gamma_user * beta_item * price_obs See the doc-string of parse_utility for an example. required obs2prior_dict Dict[str, bool] a dictionary maps coefficient name (e.g., 'lambda_item') to a boolean indicating if observable (e.g., item_obs) enters the prior of the coefficient. required coef_dim_dict Dict[str, int] a dictionary maps coefficient name (e.g., 'lambda_item') to an integer indicating the dimension of coefficient. For standalone coefficients like U = lambda_item, the dim should be 1. For factorized coefficients like U = theta_user * alpha_item, the dim should be the latent dimension of theta and alpha. For coefficients multiplied with observables like U = zeta_user * item_obs, the dim should be the number of observables in item_obs. For factorized coefficient multiplied with observables like U = gamma_user * beta_item * price_obs, the dim should be the latent dim multiplied by number of observables in price_obs. required num_items int number of items. required pred_item bool there are two use cases of this model, suppose we have user_index[i] and item_index[i] for the i-th observation in the dataset. Case 1: which item among all items user user_index[i] is going to purchase, the prediction label is therefore item_index[i] . Equivalently, we can ask what's the likelihood for user user_index[i] to purchase item_index[i] . Case 2: what rating would user user_index[i] assign to item item_index[i] ? In this case, the dataset object needs to contain a separate label. NOTE: for now, we only support binary labels. required default_prior_mean float the default prior mean for coefficients, 0.0 prior_mean Union[float, Dict[str, float]] the mean of prior distribution for coefficients. If a float is provided, all prior mean will be diagonal matrix with the provided value. If a dictionary is provided, keys of prior_mean should be coefficient names, and the mean of prior of coef_name would the provided value Defaults to 0.0, which means all prior means are initalized to 0.0 0.0 prior_variance Union[float, Dict[str, float]] the variance of prior distribution for coefficients. If a float is provided, all priors will be diagonal matrix with prior_variance along the diagonal. If a dictionary is provided, keys of prior_variance should be coefficient names, and the variance of prior of coef_name would be a diagonal matrix with prior_variance[coef_name] along the diagonal. Defaults to 1.0, which means all prior have identity matrix as the covariance matrix. 1.0 num_users int number of users, required only if coefficient or observable depending on user is in utility. Defaults to None. None num_sessions int number of sessions, required only if coefficient or observable depending on session is in utility. Defaults to None. None trace_log_q bool whether to trace the derivative of variational likelihood logQ with respect to variational parameters in the ELBO while conducting gradient update. Defaults to False. False category_to_item Dict[str, List[int]] a dictionary with category id or name as keys, and category_to_item[C] contains the list of item ids belonging to category C. If None is provided, all items are assumed to be in the same category. Defaults to None. None num_{user, item, session, price, taste}_obs (int number of observables of each type of features, only required if observable enters prior. NOTE: currently we only allow coefficient to depend on either user or item, thus only user and item observables can enter the prior of coefficient. Hence session, price, and taste observables are never required, we include it here for completeness. required Source code in bemb/model/bemb.py def __init__ ( self , utility_formula : str , obs2prior_dict : Dict [ str , bool ], coef_dim_dict : Dict [ str , int ], num_items : int , pred_item : bool , prior_mean : Union [ float , Dict [ str , float ]] = 0.0 , default_prior_mean : float = 0.0 , prior_variance : Union [ float , Dict [ str , float ]] = 1.0 , num_users : Optional [ int ] = None , num_sessions : Optional [ int ] = None , trace_log_q : bool = False , category_to_item : Dict [ int , List [ int ]] = None , # number of observables. num_user_obs : Optional [ int ] = None , num_item_obs : Optional [ int ] = None , num_session_obs : Optional [ int ] = None , num_price_obs : Optional [ int ] = None , num_taste_obs : Optional [ int ] = None , # additional modules. additional_modules : Optional [ List [ nn . Module ]] = None ) -> None : \"\"\" Args: utility_formula (str): a string representing the utility function U[user, item, session]. See documentation for more details in the documentation for the format of formula. Examples: lambda_item lambda_item + theta_user * alpha_item + zeta_user * item_obs lambda_item + theta_user * alpha_item + gamma_user * beta_item * price_obs See the doc-string of parse_utility for an example. obs2prior_dict (Dict[str, bool]): a dictionary maps coefficient name (e.g., 'lambda_item') to a boolean indicating if observable (e.g., item_obs) enters the prior of the coefficient. coef_dim_dict (Dict[str, int]): a dictionary maps coefficient name (e.g., 'lambda_item') to an integer indicating the dimension of coefficient. For standalone coefficients like U = lambda_item, the dim should be 1. For factorized coefficients like U = theta_user * alpha_item, the dim should be the latent dimension of theta and alpha. For coefficients multiplied with observables like U = zeta_user * item_obs, the dim should be the number of observables in item_obs. For factorized coefficient multiplied with observables like U = gamma_user * beta_item * price_obs, the dim should be the latent dim multiplied by number of observables in price_obs. num_items (int): number of items. pred_item (bool): there are two use cases of this model, suppose we have `user_index[i]` and `item_index[i]` for the i-th observation in the dataset. Case 1: which item among all items user `user_index[i]` is going to purchase, the prediction label is therefore `item_index[i]`. Equivalently, we can ask what's the likelihood for user `user_index[i]` to purchase `item_index[i]`. Case 2: what rating would user `user_index[i]` assign to item `item_index[i]`? In this case, the dataset object needs to contain a separate label. NOTE: for now, we only support binary labels. default_prior_mean (float): the default prior mean for coefficients, if it is not specified in the prior_mean; defaults to 0.0. prior_mean (Union[float, Dict[str, float]]): the mean of prior distribution for coefficients. If a float is provided, all prior mean will be diagonal matrix with the provided value. If a dictionary is provided, keys of prior_mean should be coefficient names, and the mean of prior of coef_name would the provided value Defaults to 0.0, which means all prior means are initalized to 0.0 prior_variance (Union[float, Dict[str, float]]): the variance of prior distribution for coefficients. If a float is provided, all priors will be diagonal matrix with prior_variance along the diagonal. If a dictionary is provided, keys of prior_variance should be coefficient names, and the variance of prior of coef_name would be a diagonal matrix with prior_variance[coef_name] along the diagonal. Defaults to 1.0, which means all prior have identity matrix as the covariance matrix. num_users (int, optional): number of users, required only if coefficient or observable depending on user is in utility. Defaults to None. num_sessions (int, optional): number of sessions, required only if coefficient or observable depending on session is in utility. Defaults to None. trace_log_q (bool, optional): whether to trace the derivative of variational likelihood logQ with respect to variational parameters in the ELBO while conducting gradient update. Defaults to False. category_to_item (Dict[str, List[int]], optional): a dictionary with category id or name as keys, and category_to_item[C] contains the list of item ids belonging to category C. If None is provided, all items are assumed to be in the same category. Defaults to None. num_{user, item, session, price, taste}_obs (int, optional): number of observables of each type of features, only required if observable enters prior. NOTE: currently we only allow coefficient to depend on either user or item, thus only user and item observables can enter the prior of coefficient. Hence session, price, and taste observables are never required, we include it here for completeness. \"\"\" super ( BEMBFlex , self ) . __init__ () self . utility_formula = utility_formula self . obs2prior_dict = obs2prior_dict self . coef_dim_dict = coef_dim_dict self . prior_variance = prior_variance self . default_prior_mean = default_prior_mean self . prior_mean = prior_mean self . pred_item = pred_item self . num_items = num_items self . num_users = num_users self . num_sessions = num_sessions self . trace_log_q = trace_log_q self . category_to_item = category_to_item # ============================================================================================================== # Category ID to Item ID mapping. # Category ID to Category Size mapping. # Item ID to Category ID mapping. # ============================================================================================================== if self . category_to_item is None : if self . pred_item : # assign all items to the same category if predicting items. self . category_to_item = { 0 : list ( np . arange ( self . num_items ))} else : # otherwise, for the j-th observation in the dataset, the label[j] # only depends on user_index[j] and item_index[j], so we put each # item to its own category. self . category_to_item = { i : [ i ] for i in range ( self . num_items )} self . num_categories = len ( self . category_to_item ) max_category_size = max ( len ( x ) for x in self . category_to_item . values ()) category_to_item_tensor = torch . full ( ( self . num_categories , max_category_size ), - 1 ) category_to_size_tensor = torch . empty ( self . num_categories ) for c , item_in_c in self . category_to_item . items (): category_to_item_tensor [ c , : len ( item_in_c )] = torch . LongTensor ( item_in_c ) category_to_size_tensor [ c ] = torch . scalar_tensor ( len ( item_in_c )) self . register_buffer ( 'category_to_item_tensor' , category_to_item_tensor . long ()) self . register_buffer ( 'category_to_size_tensor' , category_to_size_tensor . long ()) item_to_category_tensor = torch . zeros ( self . num_items ) for c , items_in_c in self . category_to_item . items (): item_to_category_tensor [ items_in_c ] = c self . register_buffer ( 'item_to_category_tensor' , item_to_category_tensor . long ()) # ============================================================================================================== # Create Bayesian Coefficient Objects # ============================================================================================================== # model configuration. self . formula = parse_utility ( utility_formula ) print ( 'BEMB: utility formula parsed:' ) pprint ( self . formula ) self . raw_formula = utility_formula self . obs2prior_dict = obs2prior_dict # dimension of each observable, this one is used only for obs2prior. self . num_obs_dict = { 'user' : num_user_obs , 'item' : num_item_obs , 'category' : 0 , 'session' : num_session_obs , 'price' : num_price_obs , 'taste' : num_taste_obs , 'constant' : 1 # not really used, for dummy variables. } # how many classes for the variational distribution. # for example, beta_item would be `num_items` 10-dimensional gaussian if latent dim = 10. variation_to_num_classes = { 'user' : self . num_users , 'item' : self . num_items , 'constant' : 1 , 'category' : self . num_categories , } coef_dict = dict () for additive_term in self . formula : for coef_name in additive_term [ 'coefficient' ]: variation = coef_name . split ( '_' )[ - 1 ] mean = self . prior_mean [ coef_name ] if isinstance ( self . prior_mean , dict ) else self . default_prior_mean s2 = self . prior_variance [ coef_name ] if isinstance ( self . prior_variance , dict ) else self . prior_variance coef_dict [ coef_name ] = BayesianCoefficient ( variation = variation , num_classes = variation_to_num_classes [ variation ], obs2prior = self . obs2prior_dict [ coef_name ], num_obs = self . num_obs_dict [ variation ], dim = self . coef_dim_dict [ coef_name ], prior_mean = mean , prior_variance = s2 ) self . coef_dict = nn . ModuleDict ( coef_dict ) # ============================================================================================================== # Optional: register additional modules. # ============================================================================================================== if additional_modules is None : self . additional_modules = [] else : raise NotImplementedError ( 'Additional modules are temporarily disabled for further development.' ) self . additional_modules = nn . ModuleList ( additional_modules ) elbo ( self , batch , num_seeds = 1 ) A combined method to computes the current ELBO given a batch, this method is used for training the model. Parameters: Name Type Description Default batch ChoiceDataset a ChoiceDataset containing necessary information. required num_seeds int the number of Monte Carlo samples from variational distributions to evaluate the expectation in ELBO. Defaults to 1. 1 Returns: Type Description torch.Tensor a scalar tensor of the ELBO estimated from num_seeds Monte Carlo samples. Source code in bemb/model/bemb.py def elbo ( self , batch : ChoiceDataset , num_seeds : int = 1 ) -> torch . Tensor : \"\"\"A combined method to computes the current ELBO given a batch, this method is used for training the model. Args: batch (ChoiceDataset): a ChoiceDataset containing necessary information. num_seeds (int, optional): the number of Monte Carlo samples from variational distributions to evaluate the expectation in ELBO. Defaults to 1. Returns: torch.Tensor: a scalar tensor of the ELBO estimated from num_seeds Monte Carlo samples. \"\"\" # ============================================================================================================== # 1. sample latent variables from their variational distributions. # ============================================================================================================== sample_dict = self . sample_coefficient_dictionary ( num_seeds ) # ============================================================================================================== # 2. compute log p(latent) prior. # (num_seeds,) --mean--> scalar. elbo = self . log_prior ( batch , sample_dict ) . mean ( dim = 0 ) # ============================================================================================================== # ============================================================================================================== # 3. compute the log likelihood log p(obs|latent). # sum over independent purchase decision for individual observations, mean over MC seeds. # the forward() function calls module.rsample(num_seeds) for module in self.additional_modules. # ============================================================================================================== if self . pred_item : # the prediction target is item_index. elbo += self . forward ( batch , return_type = 'log_prob' , return_scope = 'item_index' , deterministic = False , sample_dict = sample_dict ) . sum ( dim = 1 ) . mean ( dim = 0 ) # (num_seeds, len(batch)) --> scalar. else : # the prediction target is binary. # TODO: update the prediction function. utility = self . forward ( batch , return_type = 'utility' , return_scope = 'item_index' , deterministic = False , sample_dict = sample_dict ) # (num_seeds, len(batch)) # compute the log-likelihood for binary label. # (num_seeds, len(batch)) y_stacked = torch . stack ([ batch . label ] * num_seeds ) . float () assert y_stacked . shape == utility . shape bce = nn . BCELoss ( reduction = 'none' ) # scalar. ll = - bce ( torch . sigmoid ( utility ), y_stacked ) . sum ( dim = 1 ) . mean ( dim = 0 ) elbo += ll # ============================================================================================================== # 4. optionally add log likelihood under variational distributions q(latent). # ============================================================================================================== if self . trace_log_q : elbo -= self . log_variational ( sample_dict ) . mean ( dim = 0 ) return elbo forward ( self , batch , return_type , return_scope , deterministic = True , sample_dict = None , num_seeds = None ) A combined method for inference with the model. Parameters: Name Type Description Default batch ChoiceDataset batch data containing choice information. required return_type str either 'log_prob' or 'utility'. 'log_prob': return the log-probability (by within-category log-softmax) for items 'utility': return the utility value of items. required return_scope str either 'item_index' or 'all_items'. 'item_index': for each observation i, return log-prob/utility for the chosen item batch.item_index[i] only. 'all_items': for each observation i, return log-prob/utility for all items. required deterministic bool True: expectations of parameter variational distributions are used for inference. False: the user needs to supply a dictionary of sampled parameters for inference. Defaults to True. True sample_dict Optional[Dict[str, torch.Tensor]] sampled parameters for inference task. This is not needed when deterministic is True. When deterministic is False, the user can supply a sample_dict . If sample_dict is not provided, this method will create num_seeds samples. Defaults to None. None num_seeds Optional[int] the number of random samples of parameters to construct. This is only required if deterministic is False (i.e., stochastic mode) and sample_dict is not provided. Defaults to None. None Returns: Type Description torch.Tensor a tensor of log-probabilities or utilities, depending on return_type . The shape of the returned tensor depends on return_scope and deterministic . ------------------------------------------------------------------------- | return_scope | deterministic | Output shape | ------------------------------------------------------------------------- | 'item_index` | True | (len(batch),) | ------------------------------------------------------------------------- | 'all_items' | True | (len(batch), num_items) | ------------------------------------------------------------------------- | 'item_index' | False | (num_seeds, len(batch)) | ------------------------------------------------------------------------- | 'all_items' | False | (num_seeds, len(batch), num_items) | ------------------------------------------------------------------------- Source code in bemb/model/bemb.py def forward ( self , batch : ChoiceDataset , return_type : str , return_scope : str , deterministic : bool = True , sample_dict : Optional [ Dict [ str , torch . Tensor ]] = None , num_seeds : Optional [ int ] = None ) -> torch . Tensor : \"\"\"A combined method for inference with the model. Args: batch (ChoiceDataset): batch data containing choice information. return_type (str): either 'log_prob' or 'utility'. 'log_prob': return the log-probability (by within-category log-softmax) for items 'utility': return the utility value of items. return_scope (str): either 'item_index' or 'all_items'. 'item_index': for each observation i, return log-prob/utility for the chosen item batch.item_index[i] only. 'all_items': for each observation i, return log-prob/utility for all items. deterministic (bool, optional): True: expectations of parameter variational distributions are used for inference. False: the user needs to supply a dictionary of sampled parameters for inference. Defaults to True. sample_dict (Optional[Dict[str, torch.Tensor]], optional): sampled parameters for inference task. This is not needed when `deterministic` is True. When `deterministic` is False, the user can supply a `sample_dict`. If `sample_dict` is not provided, this method will create `num_seeds` samples. Defaults to None. num_seeds (Optional[int]): the number of random samples of parameters to construct. This is only required if `deterministic` is False (i.e., stochastic mode) and `sample_dict` is not provided. Defaults to None. Returns: torch.Tensor: a tensor of log-probabilities or utilities, depending on `return_type`. The shape of the returned tensor depends on `return_scope` and `deterministic`. ------------------------------------------------------------------------- | `return_scope` | `deterministic` | Output shape | ------------------------------------------------------------------------- | 'item_index` | True | (len(batch),) | ------------------------------------------------------------------------- | 'all_items' | True | (len(batch), num_items) | ------------------------------------------------------------------------- | 'item_index' | False | (num_seeds, len(batch)) | ------------------------------------------------------------------------- | 'all_items' | False | (num_seeds, len(batch), num_items) | ------------------------------------------------------------------------- \"\"\" # ============================================================================================================== # check arguments. # ============================================================================================================== assert return_type in [ 'log_prob' , 'utility' ], \"return_type must be either 'log_prob' or 'utility'.\" assert return_scope in [ 'item_index' , 'all_items' ], \"return_scope must be either 'item_index' or 'all_items'.\" assert deterministic in [ True , False ] if ( not deterministic ) and ( sample_dict is None ): assert num_seeds >= 1 , \"A positive interger `num_seeds` is required if `deterministic` is False and no `sample_dict` is provided.\" # when pred_item is true, the model is predicting which item is bought (specified by item_index). if self . pred_item : batch . label = batch . item_index # ============================================================================================================== # get sample_dict ready. # ============================================================================================================== if deterministic : num_seeds = 1 # Use the means of variational distributions as the sole deterministic MC sample. # NOTE: here we don't need to sample the obs2prior weight H since we only compute the log-likelihood. # TODO: is this correct? sample_dict = dict () for coef_name , coef in self . coef_dict . items (): sample_dict [ coef_name ] = coef . variational_distribution . mean . unsqueeze ( dim = 0 ) # (1, num_*, dim) else : if sample_dict is None : # sample stochastic parameters. sample_dict = self . sample_coefficient_dictionary ( num_seeds ) else : # use the provided sample_dict. num_seeds = list ( sample_dict . values ())[ 0 ] . shape [ 0 ] # ============================================================================================================== # call the sampling method of additional modules. # ============================================================================================================== for module in self . additional_modules : # deterministic sample. if deterministic : module . dsample () else : module . rsample ( num_seeds = num_seeds ) # if utility is requested, don't run log-softmax, simply return logit. return_logit = ( return_type == 'utility' ) if return_scope == 'all_items' : # (num_seeds, len(batch), num_items) out = self . log_likelihood_all_items ( batch = batch , sample_dict = sample_dict , return_logit = return_logit ) elif return_scope == 'item_index' : # (num_seeds, len(batch)) out = self . log_likelihood_item_index ( batch = batch , sample_dict = sample_dict , return_logit = return_logit ) if deterministic : # drop the first dimension, which has size of `num_seeds` (equals 1 in the deterministic case). # (len(batch), num_items) or (len(batch),) return out . squeeze ( dim = 0 ) return out get_within_category_accuracy ( self , log_p_all_items , label ) A helper function for computing prediction accuracy (i.e., all non-differential metrics) within category. In particular, this method calculates the accuracy, precision, recall and F1 score. This method has the same functionality as the following peusodcode: for C in categories: # get sessions in which item in category C was purchased. T <- (t for t in {0,1,..., len(label)-1} if label[t] is in C) Y <- label[T] predictions = list() for t in T: # get the prediction within category for this session. y_pred = argmax_{items in C} log prob computed before. predictions.append(y_pred) accuracy = mean(Y == predictions) Similarly, this function computes precision, recall and f1score as well. Parameters: Name Type Description Default log_p_all_items torch.Tensor shape (num_sessions, num_items) the log probability of choosing each item in each session. required label torch.LongTensor shape (num_sessions,), the IDs of items purchased in each session. required Returns: Type Description [Dict[str, float]] A dictionary containing performance metrics. Source code in bemb/model/bemb.py @torch . no_grad () def get_within_category_accuracy ( self , log_p_all_items : torch . Tensor , label : torch . LongTensor ) -> Dict [ str , float ]: \"\"\"A helper function for computing prediction accuracy (i.e., all non-differential metrics) within category. In particular, this method calculates the accuracy, precision, recall and F1 score. This method has the same functionality as the following peusodcode: for C in categories: # get sessions in which item in category C was purchased. T <- (t for t in {0,1,..., len(label)-1} if label[t] is in C) Y <- label[T] predictions = list() for t in T: # get the prediction within category for this session. y_pred = argmax_{items in C} log prob computed before. predictions.append(y_pred) accuracy = mean(Y == predictions) Similarly, this function computes precision, recall and f1score as well. Args: log_p_all_items (torch.Tensor): shape (num_sessions, num_items) the log probability of choosing each item in each session. label (torch.LongTensor): shape (num_sessions,), the IDs of items purchased in each session. Returns: [Dict[str, float]]: A dictionary containing performance metrics. \"\"\" # argmax: (num_sessions, num_categories), within category argmax. # item IDs are consecutive, thus argmax is the same as IDs of the item with highest P. _ , argmax_by_category = scatter_max ( log_p_all_items , self . item_to_category_tensor , dim =- 1 ) # category_purchased[t] = the category of item label[t]. # (num_sessions,) category_purchased = self . item_to_category_tensor [ label ] # pred[t] = the item with highest utility from the category item label[t] belongs to. # (num_sessions,) pred_from_category = argmax_by_category [ torch . arange ( len ( label )), category_purchased ] within_category_accuracy = ( pred_from_category == label ) . float () . mean () . item () # precision precision = list () recall = list () for i in range ( self . num_items ): correct_i = torch . sum ( ( torch . logical_and ( pred_from_category == i , label == i )) . float ()) precision_i = correct_i / \\ torch . sum (( pred_from_category == i ) . float ()) recall_i = correct_i / torch . sum (( label == i ) . float ()) # do not add if divided by zero. if torch . any ( pred_from_category == i ): precision . append ( precision_i . cpu () . item ()) if torch . any ( label == i ): recall . append ( recall_i . cpu () . item ()) precision = float ( np . mean ( precision )) recall = float ( np . mean ( recall )) if precision == recall == 0 : f1 = 0 else : f1 = 2 * precision * recall / ( precision + recall ) return { 'accuracy' : within_category_accuracy , 'precision' : precision , 'recall' : recall , 'f1score' : f1 } ivs ( self , batch ) The combined method of computing utilities and log probability. Parameters: Name Type Description Default batch dict a batch of data. required Returns: Type Description torch.Tensor the combined utility and log probability. Source code in bemb/model/bemb.py def ivs ( self , batch ) -> torch . Tensor : \"\"\"The combined method of computing utilities and log probability. Args: batch (dict): a batch of data. Returns: torch.Tensor: the combined utility and log probability. \"\"\" # Use the means of variational distributions as the sole MC sample. sample_dict = dict () for coef_name , coef in self . coef_dict . items (): sample_dict [ coef_name ] = coef . variational_distribution . mean . unsqueeze ( dim = 0 ) # (1, num_*, dim) # there is 1 random seed in this case. # (num_seeds=1, len(batch), num_items) out = self . log_likelihood_all_items ( batch , return_logit = True , sample_dict = sample_dict ) out = out . squeeze ( 0 ) # import pdb; pdb.set_trace() ivs = scatter_logsumexp ( out , self . item_to_category_tensor , dim =- 1 ) return ivs # (len(batch), num_categories) log_likelihood_all_items ( self , batch , return_logit , sample_dict ) NOTE to developers: NOTE (akanodia to tianyudu): Is this really slow; even with log_likelihood you need log_prob which depends on logits of all items? This method computes utilities for all items available, which is a relatively slow operation. For training the model, you only need the utility/log-prob for the chosen/relevant item (i.e., item_index[i] for each i-th observation). Use this method for inference only. Use self.log_likelihood_item_index() for training instead. Computes the log probability of choosing each item in each session based on current model parameters. NOTE (akanodiadu to tianyudu): What does the next line mean? I think it just says its allowing for samples instead of posterior mean. This method allows for specifying {user, item}_latent_value for Monte Carlo estimation in ELBO. For actual prediction tasks, use the forward() function, which will use means of variational distributions for user and item latents. Parameters: Name Type Description Default batch ChoiceDataset a ChoiceDataset object containing relevant information. required return_logit(bool) if set to True, return the log-probability, otherwise return the logit/utility. required sample_dict(Dict[str, torch.Tensor] Monte Carlo samples for model coefficients (i.e., those Greek letters). sample_dict.keys() should be the same as keys of self.obs2prior_dict, i.e., those greek letters actually enter the functional form of utility. The value of sample_dict should be tensors of shape (num_seeds, num_classes, dim) where num_classes in {num_users, num_items, 1} and dim in {latent_dim(K), num_item_obs, num_user_obs, 1}. required Returns: Type Description torch.Tensor a tensor of shape (num_seeds, len(batch), self.num_items), where out[x, y, z] is the probability of choosing item z in session y conditioned on latents to be the x-th Monte Carlo sample. Source code in bemb/model/bemb.py def log_likelihood_all_items ( self , batch : ChoiceDataset , return_logit : bool , sample_dict : Dict [ str , torch . Tensor ]) -> torch . Tensor : \"\"\" NOTE to developers: NOTE (akanodia to tianyudu): Is this really slow; even with log_likelihood you need log_prob which depends on logits of all items? This method computes utilities for all items available, which is a relatively slow operation. For training the model, you only need the utility/log-prob for the chosen/relevant item (i.e., item_index[i] for each i-th observation). Use this method for inference only. Use self.log_likelihood_item_index() for training instead. Computes the log probability of choosing `each` item in each session based on current model parameters. NOTE (akanodiadu to tianyudu): What does the next line mean? I think it just says its allowing for samples instead of posterior mean. This method allows for specifying {user, item}_latent_value for Monte Carlo estimation in ELBO. For actual prediction tasks, use the forward() function, which will use means of variational distributions for user and item latents. Args: batch (ChoiceDataset): a ChoiceDataset object containing relevant information. return_logit(bool): if set to True, return the log-probability, otherwise return the logit/utility. sample_dict(Dict[str, torch.Tensor]): Monte Carlo samples for model coefficients (i.e., those Greek letters). sample_dict.keys() should be the same as keys of self.obs2prior_dict, i.e., those greek letters actually enter the functional form of utility. The value of sample_dict should be tensors of shape (num_seeds, num_classes, dim) where num_classes in {num_users, num_items, 1} and dim in {latent_dim(K), num_item_obs, num_user_obs, 1}. Returns: torch.Tensor: a tensor of shape (num_seeds, len(batch), self.num_items), where out[x, y, z] is the probability of choosing item z in session y conditioned on latents to be the x-th Monte Carlo sample. \"\"\" num_seeds = next ( iter ( sample_dict . values ())) . shape [ 0 ] # avoid repeated work when user purchased several items in the same session. user_session_index = torch . stack ( [ batch . user_index , batch . session_index ]) assert user_session_index . shape == ( 2 , len ( batch )) unique_user_sess , inverse_indices = torch . unique ( user_session_index , dim = 1 , return_inverse = True ) user_index = unique_user_sess [ 0 , :] session_index = unique_user_sess [ 1 , :] assert len ( user_index ) == len ( session_index ) # short-hands for easier shape check. R = num_seeds # P = len(batch) # num_purchases. P = unique_user_sess . shape [ 1 ] S = self . num_sessions U = self . num_users I = self . num_items NC = self . num_categories # ============================================================================================================== # Helper Functions for Reshaping. # ============================================================================================================== def reshape_user_coef_sample ( C ): # input shape (R, U, *) C = C . view ( R , U , 1 , - 1 ) . expand ( - 1 , - 1 , I , - 1 ) # (R, U, I, *) C = C [:, user_index , :, :] assert C . shape == ( R , P , I , positive_integer ) return C def reshape_item_coef_sample ( C ): # input shape (R, I, *) C = C . view ( R , 1 , I , - 1 ) . expand ( - 1 , P , - 1 , - 1 ) assert C . shape == ( R , P , I , positive_integer ) return C def reshape_category_coef_sample ( C ): # input shape (R, NC, *) C = torch . repeat_interleave ( C , self . category_to_size_tensor , dim = 1 ) # input shape (R, I, *) C = C . view ( R , 1 , I , - 1 ) . expand ( - 1 , P , - 1 , - 1 ) assert C . shape == ( R , P , I , positive_integer ) return C def reshape_constant_coef_sample ( C ): # input shape (R, *) C = C . view ( R , 1 , 1 , - 1 ) . expand ( - 1 , P , I , - 1 ) assert C . shape == ( R , P , I , positive_integer ) return C def reshape_coef_sample ( sample , name ): # reshape the monte carlo sample of coefficients to (R, P, I, *). if name . endswith ( '_user' ): # (R, U, *) --> (R, P, I, *) return reshape_user_coef_sample ( sample ) elif name . endswith ( '_item' ): # (R, I, *) --> (R, P, I, *) return reshape_item_coef_sample ( sample ) elif name . endswith ( '_category' ): # (R, NC, *) --> (R, P, NC, *) return reshape_category_coef_sample ( sample ) elif name . endswith ( '_constant' ): # (R, *) --> (R, P, I, *) return reshape_constant_coef_sample ( sample ) else : raise ValueError def reshape_observable ( obs , name ): # reshape observable to (R, P, I, *) so that it can be multiplied with monte carlo # samples of coefficients. O = obs . shape [ - 1 ] # number of observables. assert O == positive_integer if name . startswith ( 'item_' ): assert obs . shape == ( I , O ) obs = obs . view ( 1 , 1 , I , O ) . expand ( R , P , - 1 , - 1 ) elif name . startswith ( 'user_' ): assert obs . shape == ( U , O ) obs = obs [ user_index , :] # (P, O) obs = obs . view ( 1 , P , 1 , O ) . expand ( R , - 1 , I , - 1 ) elif name . startswith ( 'session_' ): assert obs . shape == ( S , O ) obs = obs [ session_index , :] # (P, O) return obs . view ( 1 , P , 1 , O ) . expand ( R , - 1 , I , - 1 ) elif name . startswith ( 'price_' ): assert obs . shape == ( S , I , O ) obs = obs [ session_index , :, :] # (P, I, O) return obs . view ( 1 , P , I , O ) . expand ( R , - 1 , - 1 , - 1 ) elif name . startswith ( 'taste_' ): assert obs . shape == ( U , I , O ) obs = obs [ user_index , :, :] # (P, I, O) return obs . view ( 1 , P , I , O ) . expand ( R , - 1 , - 1 , - 1 ) else : raise ValueError assert obs . shape == ( R , P , I , O ) return obs # ============================================================================================================== # Copmute the Utility Term by Term. # ============================================================================================================== # P is the number of unique (user, session) pairs. # (random_seeds, P, num_items). utility = torch . zeros ( R , P , I , device = self . device ) # loop over additive term to utility for term in self . formula : # Type I: single coefficient, e.g., lambda_item or lambda_user. if len ( term [ 'coefficient' ]) == 1 and term [ 'observable' ] is None : # E.g., lambda_item or lambda_user coef_name = term [ 'coefficient' ][ 0 ] coef_sample = reshape_coef_sample ( sample_dict [ coef_name ], coef_name ) assert coef_sample . shape == ( R , P , I , 1 ) additive_term = coef_sample . view ( R , P , I ) # Type II: factorized coefficient, e.g., <theta_user, lambda_item>. elif len ( term [ 'coefficient' ]) == 2 and term [ 'observable' ] is None : coef_name_0 = term [ 'coefficient' ][ 0 ] coef_name_1 = term [ 'coefficient' ][ 1 ] coef_sample_0 = reshape_coef_sample ( sample_dict [ coef_name_0 ], coef_name_0 ) coef_sample_1 = reshape_coef_sample ( sample_dict [ coef_name_1 ], coef_name_1 ) assert coef_sample_0 . shape == coef_sample_1 . shape == ( R , P , I , positive_integer ) additive_term = ( coef_sample_0 * coef_sample_1 ) . sum ( dim =- 1 ) # Type III: single coefficient multiplied by observable, e.g., theta_user * x_obs_item. elif len ( term [ 'coefficient' ]) == 1 and term [ 'observable' ] is not None : coef_name = term [ 'coefficient' ][ 0 ] coef_sample = reshape_coef_sample ( sample_dict [ coef_name ], coef_name ) assert coef_sample . shape == ( R , P , I , positive_integer ) obs_name = term [ 'observable' ] obs = reshape_observable ( getattr ( batch , obs_name ), obs_name ) assert obs . shape == ( R , P , I , positive_integer ) additive_term = ( coef_sample * obs ) . sum ( dim =- 1 ) # Type IV: factorized coefficient multiplied by observable. # e.g., gamma_user * beta_item * price_obs. elif len ( term [ 'coefficient' ]) == 2 and term [ 'observable' ] is not None : coef_name_0 , coef_name_1 = term [ 'coefficient' ][ 0 ], term [ 'coefficient' ][ 1 ] coef_sample_0 = reshape_coef_sample ( sample_dict [ coef_name_0 ], coef_name_0 ) coef_sample_1 = reshape_coef_sample ( sample_dict [ coef_name_1 ], coef_name_1 ) assert coef_sample_0 . shape == coef_sample_1 . shape == ( R , P , I , positive_integer ) num_obs_times_latent_dim = coef_sample_0 . shape [ - 1 ] obs_name = term [ 'observable' ] obs = reshape_observable ( getattr ( batch , obs_name ), obs_name ) assert obs . shape == ( R , P , I , positive_integer ) num_obs = obs . shape [ - 1 ] # number of observables. assert ( num_obs_times_latent_dim % num_obs ) == 0 latent_dim = num_obs_times_latent_dim // num_obs coef_sample_0 = coef_sample_0 . view ( R , P , I , num_obs , latent_dim ) coef_sample_1 = coef_sample_1 . view ( R , P , I , num_obs , latent_dim ) # compute the factorized coefficient with shape (R, P, I, O). coef = ( coef_sample_0 * coef_sample_1 ) . sum ( dim =- 1 ) additive_term = ( coef * obs ) . sum ( dim =- 1 ) else : raise ValueError ( f 'Undefined term type: { term } ' ) assert additive_term . shape == ( R , P , I ) utility += additive_term # ============================================================================================================== # Mask Out Unavailable Items in Each Session. # ============================================================================================================== if batch . item_availability is not None : # expand to the Monte Carlo sample dimension. # (S, I) -> (P, I) -> (1, P, I) -> (R, P, I) A = batch . item_availability [ session_index , :] . unsqueeze ( dim = 0 ) . expand ( R , - 1 , - 1 ) utility [ ~ A ] = - ( torch . finfo ( utility . dtype ) . max / 2 ) utility = utility [:, inverse_indices , :] assert utility . shape == ( R , len ( batch ), I ) for module in self . additional_modules : additive_term = module ( batch ) assert additive_term . shape == ( R , len ( batch ), 1 ) utility += additive_term . expand ( - 1 , - 1 , I ) if return_logit : # output shape: (num_seeds, len(batch), num_items) return utility else : # compute log likelihood log p(choosing item i | user, item latents) # compute log softmax separately within each category. if self . pred_item : # output shape: (num_seeds, len(batch), num_items) log_p = scatter_log_softmax ( utility , self . item_to_category_tensor , dim =- 1 ) else : log_p = torch . nn . functional . logsigmoid ( utility ) return log_p log_likelihood_item_index ( self , batch , return_logit , sample_dict ) NOTE for developers: This method is more efficient and only computes log-likelihood/logit(utility) for item in item_index[i] for each i-th observation. Developers should use use log_likelihood_all_items for inference purpose and to computes log-likelihoods/utilities for ALL items for the i-th observation. Computes the log probability of choosing item_index[i] in each session based on current model parameters. This method allows for specifying {user, item}_latent_value for Monte Carlo estimation in ELBO. For actual prediction tasks, use the forward() function, which will use means of variational distributions for user and item latents. Parameters: Name Type Description Default batch ChoiceDataset a ChoiceDataset object containing relevant information. required return_logit(bool) if set to True, return the log-probability, otherwise return the logit/utility. required sample_dict(Dict[str, torch.Tensor] Monte Carlo samples for model coefficients (i.e., those Greek letters). sample_dict.keys() should be the same as keys of self.obs2prior_dict, i.e., those greek letters actually enter the functional form of utility. The value of sample_dict should be tensors of shape (num_seeds, num_classes, dim) where num_classes in {num_users, num_items, 1} and dim in {latent_dim(K), num_item_obs, num_user_obs, 1}. required Returns: Type Description torch.Tensor a tensor of shape (num_seeds, len(batch)), where out[x, y] is the probabilities of choosing item batch.item[y] in session y conditioned on latents to be the x-th Monte Carlo sample. Source code in bemb/model/bemb.py def log_likelihood_item_index ( self , batch : ChoiceDataset , return_logit : bool , sample_dict : Dict [ str , torch . Tensor ]) -> torch . Tensor : \"\"\" NOTE for developers: This method is more efficient and only computes log-likelihood/logit(utility) for item in item_index[i] for each i-th observation. Developers should use use `log_likelihood_all_items` for inference purpose and to computes log-likelihoods/utilities for ALL items for the i-th observation. Computes the log probability of choosing item_index[i] in each session based on current model parameters. This method allows for specifying {user, item}_latent_value for Monte Carlo estimation in ELBO. For actual prediction tasks, use the forward() function, which will use means of variational distributions for user and item latents. Args: batch (ChoiceDataset): a ChoiceDataset object containing relevant information. return_logit(bool): if set to True, return the log-probability, otherwise return the logit/utility. sample_dict(Dict[str, torch.Tensor]): Monte Carlo samples for model coefficients (i.e., those Greek letters). sample_dict.keys() should be the same as keys of self.obs2prior_dict, i.e., those greek letters actually enter the functional form of utility. The value of sample_dict should be tensors of shape (num_seeds, num_classes, dim) where num_classes in {num_users, num_items, 1} and dim in {latent_dim(K), num_item_obs, num_user_obs, 1}. Returns: torch.Tensor: a tensor of shape (num_seeds, len(batch)), where out[x, y] is the probabilities of choosing item batch.item[y] in session y conditioned on latents to be the x-th Monte Carlo sample. \"\"\" num_seeds = next ( iter ( sample_dict . values ())) . shape [ 0 ] # get category id of the item bought in each row of batch. cate_index = self . item_to_category_tensor [ batch . item_index ] # get item ids of all items from the same category of each item bought. relevant_item_index = self . category_to_item_tensor [ cate_index , :] relevant_item_index = relevant_item_index . view ( - 1 ,) # index were padded with -1's, drop those dummy entries. relevant_item_index = relevant_item_index [ relevant_item_index != - 1 ] # the first repeats[0] entries in relevant_item_index are for the category of item_index[0] repeats = self . category_to_size_tensor [ cate_index ] # argwhere(reverse_indices == k) are positions in relevant_item_index for the category of item_index[k]. reverse_indices = torch . repeat_interleave ( torch . arange ( len ( batch ), device = self . device ), repeats ) # expand the user_index and session_index. user_index = torch . repeat_interleave ( batch . user_index , repeats ) repeat_category_index = torch . repeat_interleave ( cate_index , repeats ) session_index = torch . repeat_interleave ( batch . session_index , repeats ) # duplicate the item focused to match. item_index_expanded = torch . repeat_interleave ( batch . item_index , repeats ) # short-hands for easier shape check. R = num_seeds # total number of relevant items. total_computation = len ( session_index ) S = self . num_sessions U = self . num_users I = self . num_items NC = self . num_categories # ========================================================================================== # Helper Functions for Reshaping. # ========================================================================================== def reshape_coef_sample ( sample , name ): # reshape the monte carlo sample of coefficients to (R, P, I, *). if name . endswith ( '_user' ): # (R, U, *) --> (R, total_computation, *) return sample [:, user_index , :] elif name . endswith ( '_item' ): # (R, I, *) --> (R, total_computation, *) return sample [:, relevant_item_index , :] elif name . endswith ( '_category' ): # (R, NC, *) --> (R, total_computation, *) return sample [:, repeat_category_index , :] elif name . endswith ( '_constant' ): # (R, *) --> (R, total_computation, *) return sample . view ( R , 1 , - 1 ) . expand ( - 1 , total_computation , - 1 ) else : raise ValueError def reshape_observable ( obs , name ): # reshape observable to (R, P, I, *) so that it can be multiplied with monte carlo # samples of coefficients. O = obs . shape [ - 1 ] # number of observables. assert O == positive_integer if name . startswith ( 'item_' ): assert obs . shape == ( I , O ) obs = obs [ relevant_item_index , :] elif name . startswith ( 'user_' ): assert obs . shape == ( U , O ) obs = obs [ user_index , :] elif name . startswith ( 'session_' ): assert obs . shape == ( S , O ) obs = obs [ session_index , :] elif name . startswith ( 'price_' ): assert obs . shape == ( S , I , O ) obs = obs [ session_index , relevant_item_index , :] elif name . startswith ( 'taste_' ): assert obs . shape == ( U , I , O ) obs = obs [ user_index , relevant_item_index , :] else : raise ValueError assert obs . shape == ( total_computation , O ) return obs . unsqueeze ( dim = 0 ) . expand ( R , - 1 , - 1 ) # ========================================================================================== # Compute Components related to users and items only. # ========================================================================================== utility = torch . zeros ( R , total_computation , device = self . device ) # loop over additive term to utility for term in self . formula : # Type I: single coefficient, e.g., lambda_item or lambda_user. if len ( term [ 'coefficient' ]) == 1 and term [ 'observable' ] is None : # E.g., lambda_item or lambda_user coef_name = term [ 'coefficient' ][ 0 ] coef_sample = reshape_coef_sample ( sample_dict [ coef_name ], coef_name ) assert coef_sample . shape == ( R , total_computation , 1 ) additive_term = coef_sample . view ( R , total_computation ) # Type II: factorized coefficient, e.g., <theta_user, lambda_item>. elif len ( term [ 'coefficient' ]) == 2 and term [ 'observable' ] is None : coef_name_0 = term [ 'coefficient' ][ 0 ] coef_name_1 = term [ 'coefficient' ][ 1 ] coef_sample_0 = reshape_coef_sample ( sample_dict [ coef_name_0 ], coef_name_0 ) coef_sample_1 = reshape_coef_sample ( sample_dict [ coef_name_1 ], coef_name_1 ) assert coef_sample_0 . shape == coef_sample_1 . shape == ( R , total_computation , positive_integer ) additive_term = ( coef_sample_0 * coef_sample_1 ) . sum ( dim =- 1 ) # Type III: single coefficient multiplied by observable, e.g., theta_user * x_obs_item. elif len ( term [ 'coefficient' ]) == 1 and term [ 'observable' ] is not None : coef_name = term [ 'coefficient' ][ 0 ] coef_sample = reshape_coef_sample ( sample_dict [ coef_name ], coef_name ) assert coef_sample . shape == ( R , total_computation , positive_integer ) obs_name = term [ 'observable' ] obs = reshape_observable ( getattr ( batch , obs_name ), obs_name ) assert obs . shape == ( R , total_computation , positive_integer ) additive_term = ( coef_sample * obs ) . sum ( dim =- 1 ) # Type IV: factorized coefficient multiplied by observable. # e.g., gamma_user * beta_item * price_obs. elif len ( term [ 'coefficient' ]) == 2 and term [ 'observable' ] is not None : coef_name_0 , coef_name_1 = term [ 'coefficient' ][ 0 ], term [ 'coefficient' ][ 1 ] coef_sample_0 = reshape_coef_sample ( sample_dict [ coef_name_0 ], coef_name_0 ) coef_sample_1 = reshape_coef_sample ( sample_dict [ coef_name_1 ], coef_name_1 ) assert coef_sample_0 . shape == coef_sample_1 . shape == ( R , total_computation , positive_integer ) num_obs_times_latent_dim = coef_sample_0 . shape [ - 1 ] obs_name = term [ 'observable' ] obs = reshape_observable ( getattr ( batch , obs_name ), obs_name ) assert obs . shape == ( R , total_computation , positive_integer ) num_obs = obs . shape [ - 1 ] # number of observables. assert ( num_obs_times_latent_dim % num_obs ) == 0 latent_dim = num_obs_times_latent_dim // num_obs coef_sample_0 = coef_sample_0 . view ( R , total_computation , num_obs , latent_dim ) coef_sample_1 = coef_sample_1 . view ( R , total_computation , num_obs , latent_dim ) # compute the factorized coefficient with shape (R, P, I, O). coef = ( coef_sample_0 * coef_sample_1 ) . sum ( dim =- 1 ) additive_term = ( coef * obs ) . sum ( dim =- 1 ) else : raise ValueError ( f 'Undefined term type: { term } ' ) assert additive_term . shape == ( R , total_computation ) utility += additive_term # ========================================================================================== # Mask Out Unavailable Items in Each Session. # ========================================================================================== if batch . item_availability is not None : # expand to the Monte Carlo sample dimension. A = batch . item_availability [ session_index , relevant_item_index ] . unsqueeze ( dim = 0 ) . expand ( R , - 1 ) utility [ ~ A ] = - ( torch . finfo ( utility . dtype ) . max / 2 ) for module in self . additional_modules : # current utility shape: (R, total_computation) additive_term = module ( batch ) assert additive_term . shape == ( R , len ( batch )) or additive_term . shape == ( R , len ( batch ), 1 ) if additive_term . shape == ( R , len ( batch ), 1 ): # TODO: need to make this consistent with log_likelihood_all. # be tolerant for some customized module with BayesianLinear that returns (R, len(batch), 1). additive_term = additive_term . view ( R , len ( batch )) # expand to total number of computation, query by reverse_indices. # reverse_indices has length total_computation, and reverse_indices[i] correspond to the row-id that this # computation is responsible for. additive_term = additive_term [:, reverse_indices ] assert additive_term . shape == ( R , total_computation ) # compute log likelihood log p(choosing item i | user, item latents) if return_logit : log_p = utility else : if self . pred_item : # compute the log probability from logits/utilities. # output shape: (num_seeds, len(batch), num_items) log_p = scatter_log_softmax ( utility , reverse_indices , dim =- 1 ) # select the log-P of the item actually bought. log_p = log_p [:, item_index_expanded == relevant_item_index ] else : # This is the binomial choice situation in which case we just report sigmoid log likelihood bce = nn . BCELoss ( reduction = 'none' ) log_p = - bce ( torch . sigmoid ( utility . view ( - 1 )), batch . label . to ( torch . float32 )) return log_p log_prior ( self , batch , sample_dict ) Calculates the log-likelihood of Monte Carlo samples of Bayesian coefficients under their prior distribution. This method assume coefficients are statistically independent. Parameters: Name Type Description Default batch ChoiceDataset a dataset object contains observables for computing the prior distribution if obs2prior is True. required sample_dict Dict[str, torch.Tensor] a dictionary coefficient names to Monte Carlo samples. required Exceptions: Type Description ValueError [description] Returns: Type Description torch.scalar_tensor a tensor with shape (num_seeds,) of [ log P_{prior_distribution}(param[i]) ], where param[i] is the i-th Monte Carlo sample. Source code in bemb/model/bemb.py def log_prior ( self , batch : ChoiceDataset , sample_dict : Dict [ str , torch . Tensor ]) -> torch . Tensor : \"\"\"Calculates the log-likelihood of Monte Carlo samples of Bayesian coefficients under their prior distribution. This method assume coefficients are statistically independent. Args: batch (ChoiceDataset): a dataset object contains observables for computing the prior distribution if obs2prior is True. sample_dict (Dict[str, torch.Tensor]): a dictionary coefficient names to Monte Carlo samples. Raises: ValueError: [description] Returns: torch.scalar_tensor: a tensor with shape (num_seeds,) of [ log P_{prior_distribution}(param[i]) ], where param[i] is the i-th Monte Carlo sample. \"\"\" # assert sample_dict.keys() == self.coef_dict.keys() num_seeds = next ( iter ( sample_dict . values ())) . shape [ 0 ] total = torch . zeros ( num_seeds , device = self . device ) for coef_name , coef in self . coef_dict . items (): if self . obs2prior_dict [ coef_name ]: if coef_name . endswith ( '_item' ): x_obs = batch . item_obs elif coef_name . endswith ( '_user' ): x_obs = batch . user_obs else : raise ValueError ( f 'No observable found to support obs2prior for { coef_name } .' ) total += coef . log_prior ( sample = sample_dict [ coef_name ], H_sample = sample_dict [ coef_name + '.H' ], x_obs = x_obs ) . sum ( dim =- 1 ) else : # log_prob outputs (num_seeds, num_{items, users}), sum to (num_seeds). total += coef . log_prior ( sample = sample_dict [ coef_name ], H_sample = None , x_obs = None ) . sum ( dim =- 1 ) for module in self . additional_modules : raise NotImplementedError () total += module . log_prior () return total log_variational ( self , sample_dict ) Calculate the log-likelihood of samples in sample_dict under the current variational distribution. Parameters: Name Type Description Default sample_dict Dict[str, torch.Tensor] a dictionary coefficient names to Monte Carlo samples. required Returns: Type Description torch.Tensor a tensor of shape (num_seeds) of [ log P_{variational_distribution}(param[i]) ], where param[i] is the i-th Monte Carlo sample. Source code in bemb/model/bemb.py def log_variational ( self , sample_dict : Dict [ str , torch . Tensor ]) -> torch . Tensor : \"\"\"Calculate the log-likelihood of samples in sample_dict under the current variational distribution. Args: sample_dict (Dict[str, torch.Tensor]): a dictionary coefficient names to Monte Carlo samples. Returns: torch.Tensor: a tensor of shape (num_seeds) of [ log P_{variational_distribution}(param[i]) ], where param[i] is the i-th Monte Carlo sample. \"\"\" num_seeds = list ( sample_dict . values ())[ 0 ] . shape [ 0 ] total = torch . zeros ( num_seeds , device = self . device ) for coef_name , coef in self . coef_dict . items (): # log_prob outputs (num_seeds, num_{items, users}), sum to (num_seeds). total += coef . log_variational ( sample_dict [ coef_name ]) . sum ( dim =- 1 ) for module in self . additional_modules : raise NotImplementedError () # with shape (num_seeds,) total += module . log_variational () . sum () return total posterior_mean ( self , coef_name ) Returns the mean of estimated posterior distribution of coefficient coef_name . Parameters: Name Type Description Default coef_name str name of the coefficient to query. required Returns: Type Description torch.Tensor mean of the estimated posterior distribution of coef_name . Source code in bemb/model/bemb.py def posterior_mean ( self , coef_name : str ) -> torch . Tensor : \"\"\"Returns the mean of estimated posterior distribution of coefficient `coef_name`. Args: coef_name (str): name of the coefficient to query. Returns: torch.Tensor: mean of the estimated posterior distribution of `coef_name`. \"\"\" if coef_name in self . coef_dict . keys (): return self . coef_dict [ coef_name ] . variational_mean else : raise KeyError ( f ' { coef_name } is not a valid coefficient name in { self . utility_formula } .' ) sample_choices ( self , batch , debug = False , num_seeds = 1 , ** kwargs ) Samples choices given model paramaters and trips batch(ChoiceDataset): batch data containing trip information; item choice information is discarded debug(bool): whether to print debug information Tuple[torch.Tensor]: sampled choices; shape: (batch_size, num_categories) Source code in bemb/model/bemb.py def sample_choices ( self , batch : ChoiceDataset , debug : bool = False , num_seeds : int = 1 , ** kwargs ) -> Tuple [ torch . Tensor ]: \"\"\"Samples choices given model paramaters and trips Args: batch(ChoiceDataset): batch data containing trip information; item choice information is discarded debug(bool): whether to print debug information Returns: Tuple[torch.Tensor]: sampled choices; shape: (batch_size, num_categories) \"\"\" # Use the means of variational distributions as the sole MC sample. sample_dict = dict () for coef_name , coef in self . coef_dict . items (): sample_dict [ coef_name ] = coef . variational_distribution . mean . unsqueeze ( dim = 0 ) # (1, num_*, dim) # sample_dict = self.sample_coefficient_dictionary(num_seeds) maxes , out = self . sample_log_likelihoods ( batch , sample_dict ) return maxes . squeeze (), out . squeeze () sample_coefficient_dictionary ( self , num_seeds ) A helper function to sample parameters from coefficients. Parameters: Name Type Description Default num_seeds int number of random samples. required Returns: Type Description Dict[str, torch.Tensor] a dictionary maps coefficient names to tensor of sampled coefficient parameters, where the first dimension of the sampled tensor has size num_seeds . Each sample tensor has shape (num_seeds, num_classes, dim). Source code in bemb/model/bemb.py def sample_coefficient_dictionary ( self , num_seeds : int ) -> Dict [ str , torch . Tensor ]: \"\"\"A helper function to sample parameters from coefficients. Args: num_seeds (int): number of random samples. Returns: Dict[str, torch.Tensor]: a dictionary maps coefficient names to tensor of sampled coefficient parameters, where the first dimension of the sampled tensor has size `num_seeds`. Each sample tensor has shape (num_seeds, num_classes, dim). \"\"\" sample_dict = dict () for coef_name , coef in self . coef_dict . items (): s = coef . rsample ( num_seeds ) if coef . obs2prior : # sample both obs2prior weight and realization of variable. assert isinstance ( s , tuple ) and len ( s ) == 2 sample_dict [ coef_name ] = s [ 0 ] sample_dict [ coef_name + '.H' ] = s [ 1 ] else : # only sample the realization of variable. assert torch . is_tensor ( s ) sample_dict [ coef_name ] = s return sample_dict sample_log_likelihoods ( self , batch , sample_dict ) Samples log likelihoods given model paramaters and trips batch(ChoiceDataset): batch data containing trip information; item choice information is discarded sample_dict(Dict[str, torch.Tensor]): sampled coefficient values Tuple[torch.Tensor]: sampled log likelihoods; shape: (batch_size, num_categories) Source code in bemb/model/bemb.py def sample_log_likelihoods ( self , batch : ChoiceDataset , sample_dict : Dict [ str , torch . Tensor ]) -> Tuple [ torch . Tensor , torch . Tensor ]: \"\"\"Samples log likelihoods given model paramaters and trips Args: batch(ChoiceDataset): batch data containing trip information; item choice information is discarded sample_dict(Dict[str, torch.Tensor]): sampled coefficient values Returns: Tuple[torch.Tensor]: sampled log likelihoods; shape: (batch_size, num_categories) \"\"\" # get the log likelihoods for all items for all categories utility = self . log_likelihood_all_items ( batch , return_logit = True , sample_dict = sample_dict ) mu_gumbel = 0.0 beta_gumbel = 1.0 EUL_MAS_CONST = 0.5772156649 mean_gumbel = torch . tensor ([ mu_gumbel + beta_gumbel * EUL_MAS_CONST ], device = self . device ) m = torch . distributions . gumbel . Gumbel ( torch . tensor ([ 0.0 ], device = self . device ), torch . tensor ([ 1.0 ], device = self . device )) # m = torch.distributions.gumbel.Gumbel(0.0, 1.0) gumbel_samples = m . sample ( utility . shape ) . squeeze ( - 1 ) gumbel_samples -= mean_gumbel utility += gumbel_samples max_by_category , argmax_by_category = scatter_max ( utility , self . item_to_category_tensor , dim =- 1 ) return max_by_category , argmax_by_category log_likelihoods = self . sample_log_likelihoods_per_category ( batch , sample_dict ) # sum over all categories. log_likelihoods = log_likelihoods . sum ( dim = 1 ) return log_likelihoods , log_likelihoods parse_utility ( utility_string ) A helper function parse utility string into a list of additive terms. Examples: utility_string = 'lambda_item + theta_user * alpha_item + gamma_user * beta_item * price_obs' output = [ { 'coefficient': ['lambda_item'], 'observable': None }, { 'coefficient': ['theta_user', 'alpha_item'], 'observable': None }, { 'coefficient': ['gamma_user', 'beta_item'], 'observable': 'price_obs' } ] Source code in bemb/model/bemb.py def parse_utility ( utility_string : str ) -> List [ Dict [ str , Union [ List [ str ], None ]]]: \"\"\" A helper function parse utility string into a list of additive terms. Example: utility_string = 'lambda_item + theta_user * alpha_item + gamma_user * beta_item * price_obs' output = [ { 'coefficient': ['lambda_item'], 'observable': None }, { 'coefficient': ['theta_user', 'alpha_item'], 'observable': None }, { 'coefficient': ['gamma_user', 'beta_item'], 'observable': 'price_obs' } ] \"\"\" # split additive terms coefficient_suffix = ( '_item' , '_user' , '_constant' , '_category' ) observable_prefix = ( 'item_' , 'user_' , 'session_' , 'price_' , 'taste_' ) def is_coefficient ( name : str ) -> bool : return any ( name . endswith ( suffix ) for suffix in coefficient_suffix ) def is_observable ( name : str ) -> bool : return any ( name . startswith ( prefix ) for prefix in observable_prefix ) additive_terms = utility_string . split ( ' + ' ) additive_decomposition = list () for term in additive_terms : atom = { 'coefficient' : [], 'observable' : None } # split multiplicative terms. for x in term . split ( ' * ' ): if is_coefficient ( x ): atom [ 'coefficient' ] . append ( x ) elif is_observable ( x ): atom [ 'observable' ] = x else : raise ValueError ( f ' { x } term cannot be classified.' ) additive_decomposition . append ( atom ) return additive_decomposition bemb_flex_lightning PyTorch lightning wrapper for the BEMB Flex model, allows for more smooth model training and inference. You can still use this package without using LitBEMBFlex. Author: Tianyu Du Update: Apr. 29, 2022 LitBEMBFlex ( LightningModule ) Source code in bemb/model/bemb_flex_lightning.py class LitBEMBFlex ( pl . LightningModule ): def __init__ ( self , learning_rate : float = 0.3 , num_seeds : int = 1 , ** kwargs ): \"\"\"The initialization method of the wrapper model. Args: learning_rate (float, optional): the learning rate of optimization. Defaults to 0.3. num_seeds (int, optional): number of random seeds for the Monte Carlo estimation in the variational inference. Defaults to 1. **kwargs: all keyword arguments used for constructing the wrapped BEMB model. \"\"\" # use kwargs to pass parameter to BEMB Torch. super () . __init__ () self . model = BEMBFlex ( ** kwargs ) self . num_needs = num_seeds self . learning_rate = learning_rate def __str__ ( self ) -> str : return str ( self . model ) def forward ( self , args , kwargs ): \"\"\"Calls the forward method of the wrapped BEMB model, please refer to the documentaton of the BEMB class for detailed definitions of the arguments. Args: args (_type_): arguments passed to the forward method of the wrapped BEMB model. kwargs (_type_): keyword arguments passed to the forward method of the wrapped BEMB model. Returns: _type_: returns whatever the wrapped BEMB model returns. \"\"\" return self . model ( * args , ** kwargs ) def training_step ( self , batch , batch_idx ): elbo = self . model . elbo ( batch , num_seeds = self . num_needs ) self . log ( 'train_elbo' , elbo ) loss = - elbo return loss def _get_performance_dict ( self , batch ): if self . model . pred_item : log_p = self . model ( batch , return_type = 'log_prob' , return_scope = 'all_items' , deterministic = True ) . cpu () . numpy () num_classes = log_p . shape [ 1 ] y_pred = np . argmax ( log_p , axis = 1 ) y_true = batch . item_index . cpu () . numpy () performance = { 'acc' : metrics . accuracy_score ( y_true = y_true , y_pred = y_pred ), 'll' : - metrics . log_loss ( y_true = y_true , y_pred = np . exp ( log_p ), labels = np . arange ( num_classes ))} else : # making binary station. pred = self . model ( batch , return_type = 'utility' , return_scope = 'item_index' , deterministic = True ) y_pred = torch . sigmoid ( pred ) . cpu () . numpy () y_true = batch . label . cpu () . numpy () performance = { 'acc' : metrics . accuracy_score ( y_true = y_true , y_pred = ( y_pred >= 0.5 ) . astype ( int )), 'll' : - metrics . log_loss ( y_true = y_true , y_pred = y_pred , eps = 1E-5 , labels = [ 0 , 1 ]), # 'auc': metrics.roc_auc_score(y_true=y_true, y_score=y_pred), # 'f1': metrics.f1_score(y_true=y_true, y_pred=(y_pred >= 0.5).astype(int)) } return performance def validation_step ( self , batch , batch_idx ): # LL = self.model.forward(batch, return_type='log_prob', return_scope='item_index', deterministic=True).mean() # self.log('val_log_likelihood', LL, prog_bar=True) # pred = self.model(batch) # performance = self.model.get_within_category_accuracy(pred, batch.label) # utility. for key , val in self . _get_performance_dict ( batch ) . items (): self . log ( 'val_' + key , val , prog_bar = True , batch_size = len ( batch )) def test_step ( self , batch , batch_idx ): # LL = self.model.forward(batch, return_logit=False, all_items=False).mean() # self.log('test_log_likelihood', LL) # pred = self.model(batch, return_type='utility', return_scope='item_index', deterministic=True) # y_pred = torch.sigmoid(pred).cpu().numpy() # y_true = batch.label.cpu().numpy() # performance = {'acc': metrics.accuracy_score(y_true=y_true, y_pred=(y_pred >= 0.5).astype(int)), # 'll': - metrics.log_loss(y_true=y_true, y_pred=y_pred, eps=1E-5, labels=[0, 1]), # # 'auc': metrics.roc_auc_score(y_true=y_true, y_score=y_pred), # # 'f1': metrics.f1_score(y_true=y_true, y_pred=(y_pred >= 0.5).astype(int)) # } # pred = self.model(batch) # performance = self.model.get_within_category_accuracy(pred, batch.label) for key , val in self . _get_performance_dict ( batch ) . items (): self . log ( 'test_' + key , val , prog_bar = True , batch_size = len ( batch )) def configure_optimizers ( self ): optimizer = torch . optim . Adam ( self . parameters (), lr = self . learning_rate ) return optimizer def fit_model ( self , dataset_list : List [ ChoiceDataset ], batch_size : int =- 1 , num_epochs : int = 10 , num_workers : int = 8 , ** kwargs ) -> \"LitBEMBFlex\" : \"\"\"A standard pipeline of model training and evaluation. Args: dataset_list (List[ChoiceDataset]): train_dataset, validation_test, and test_dataset in a list of length 3. batch_size (int, optional): batch_size for training and evaluation. Defaults to -1, which indicates full-batch training. num_epochs (int, optional): number of epochs for training. Defaults to 10. **kwargs: additional keyword argument for the pytorch-lightning Trainer. Returns: LitBEMBFlex: the trained bemb model. \"\"\" def section_print ( input_text ): \"\"\"Helper function for printing\"\"\" print ( '=' * 20 , input_text , '=' * 20 ) # present a summary of the model received. section_print ( 'model received' ) print ( self ) # present a summary of datasets received. section_print ( 'data set received' ) print ( '[Training dataset]' , dataset_list [ 0 ]) print ( '[Validation dataset]' , dataset_list [ 1 ]) print ( '[Testing dataset]' , dataset_list [ 2 ]) # create pytorch dataloader objects. train = create_data_loader ( dataset_list [ 0 ], batch_size = batch_size , shuffle = True , num_workers = num_workers ) validation = create_data_loader ( dataset_list [ 1 ], batch_size = batch_size , shuffle = False , num_workers = num_workers ) # WARNING: the test step takes extensive memory cost since it computes likelihood for all items. # we run the test step with a much smaller batch_size. test = create_data_loader ( dataset_list [ 2 ], batch_size = batch_size // 10 , shuffle = False , num_workers = num_workers ) section_print ( 'train the model' ) trainer = pl . Trainer ( gpus = 1 if ( 'cuda' in str ( self )) else 0 , # use GPU if the model is currently on the GPU. max_epochs = num_epochs , check_val_every_n_epoch = 1 , log_every_n_steps = 1 , ** kwargs ) start_time = time . time () trainer . fit ( self , train_dataloaders = train , val_dataloaders = validation ) print ( f 'time taken: { time . time () - start_time } ' ) section_print ( 'test performance' ) trainer . test ( self , dataloaders = test ) return self __init__ ( self , learning_rate = 0.3 , num_seeds = 1 , ** kwargs ) special The initialization method of the wrapper model. Parameters: Name Type Description Default learning_rate float the learning rate of optimization. Defaults to 0.3. 0.3 num_seeds int number of random seeds for the Monte Carlo estimation in the variational inference. Defaults to 1. 1 **kwargs all keyword arguments used for constructing the wrapped BEMB model. {} Source code in bemb/model/bemb_flex_lightning.py def __init__ ( self , learning_rate : float = 0.3 , num_seeds : int = 1 , ** kwargs ): \"\"\"The initialization method of the wrapper model. Args: learning_rate (float, optional): the learning rate of optimization. Defaults to 0.3. num_seeds (int, optional): number of random seeds for the Monte Carlo estimation in the variational inference. Defaults to 1. **kwargs: all keyword arguments used for constructing the wrapped BEMB model. \"\"\" # use kwargs to pass parameter to BEMB Torch. super () . __init__ () self . model = BEMBFlex ( ** kwargs ) self . num_needs = num_seeds self . learning_rate = learning_rate configure_optimizers ( self ) Choose what optimizers and learning-rate schedulers to use in your optimization. Normally you'd need one. But in the case of GANs or similar you might have multiple. Returns: Type Description Any of these 6 options. Single optimizer . List or Tuple of optimizers. Two lists - The first list has multiple optimizers, and the second has multiple LR schedulers (or multiple lr_scheduler_config ). Dictionary , with an \"optimizer\" key, and (optionally) a \"lr_scheduler\" key whose value is a single LR scheduler or lr_scheduler_config . Tuple of dictionaries as described above, with an optional \"frequency\" key. None - Fit will run without any optimizer. The lr_scheduler_config is a dictionary which contains the scheduler and its associated configuration. The default configuration is shown below. .. code-block:: python lr_scheduler_config = { # REQUIRED: The scheduler instance \"scheduler\": lr_scheduler, # The unit of the scheduler's step size, could also be 'step'. # 'epoch' updates the scheduler on epoch end whereas 'step' # updates it after a optimizer update. \"interval\": \"epoch\", # How many epochs/steps should pass between calls to # `scheduler.step()`. 1 corresponds to updating the learning # rate after every epoch/step. \"frequency\": 1, # Metric to to monitor for schedulers like `ReduceLROnPlateau` \"monitor\": \"val_loss\", # If set to `True`, will enforce that the value specified 'monitor' # is available when the scheduler is updated, thus stopping # training if not found. If set to `False`, it will only produce a warning \"strict\": True, # If using the `LearningRateMonitor` callback to monitor the # learning rate progress, this keyword can be used to specify # a custom logged name \"name\": None, } When there are schedulers in which the .step() method is conditioned on a value, such as the :class: torch.optim.lr_scheduler.ReduceLROnPlateau scheduler, Lightning requires that the lr_scheduler_config contains the keyword \"monitor\" set to the metric name that the scheduler should be conditioned on. .. testcode:: # The ReduceLROnPlateau scheduler requires a monitor def configure_optimizers(self): optimizer = Adam(...) return { \"optimizer\": optimizer, \"lr_scheduler\": { \"scheduler\": ReduceLROnPlateau(optimizer, ...), \"monitor\": \"metric_to_track\", \"frequency\": \"indicates how often the metric is updated\" # If \"monitor\" references validation metrics, then \"frequency\" should be set to a # multiple of \"trainer.check_val_every_n_epoch\". }, } # In the case of two optimizers, only one using the ReduceLROnPlateau scheduler def configure_optimizers(self): optimizer1 = Adam(...) optimizer2 = SGD(...) scheduler1 = ReduceLROnPlateau(optimizer1, ...) scheduler2 = LambdaLR(optimizer2, ...) return ( { \"optimizer\": optimizer1, \"lr_scheduler\": { \"scheduler\": scheduler1, \"monitor\": \"metric_to_track\", }, }, {\"optimizer\": optimizer2, \"lr_scheduler\": scheduler2}, ) Metrics can be made available to monitor by simply logging it using self.log('metric_to_track', metric_val) in your :class: ~pytorch_lightning.core.lightning.LightningModule . !!! note The frequency value specified in a dict along with the optimizer key is an int corresponding to the number of sequential batches optimized with the specific optimizer. It should be given to none or to all of the optimizers. There is a difference between passing multiple optimizers in a list, and passing multiple optimizers in dictionaries with a frequency of 1: - In the former case, all optimizers will operate on the given batch in each optimization step. - In the latter, only one optimizer will operate on the given batch at every step. This is different from the ``frequency`` value specified in the ``lr_scheduler_config`` mentioned above. .. code-block:: python def configure_optimizers(self): optimizer_one = torch.optim.SGD(self.model.parameters(), lr=0.01) optimizer_two = torch.optim.SGD(self.model.parameters(), lr=0.01) return [ {\"optimizer\": optimizer_one, \"frequency\": 5}, {\"optimizer\": optimizer_two, \"frequency\": 10}, ] In this example, the first optimizer will be used for the first 5 steps, the second optimizer for the next 10 steps and that cycle will continue. If an LR scheduler is specified for an optimizer using the ``lr_scheduler`` key in the above dict, the scheduler will only be updated when its optimizer is being used. Examples:: # most cases. no learning rate scheduler def configure_optimizers(self): return Adam(self.parameters(), lr=1e-3) # multiple optimizer case (e.g.: GAN) def configure_optimizers(self): gen_opt = Adam(self.model_gen.parameters(), lr=0.01) dis_opt = Adam(self.model_dis.parameters(), lr=0.02) return gen_opt, dis_opt # example with learning rate schedulers def configure_optimizers(self): gen_opt = Adam(self.model_gen.parameters(), lr=0.01) dis_opt = Adam(self.model_dis.parameters(), lr=0.02) dis_sch = CosineAnnealing(dis_opt, T_max=10) return [gen_opt, dis_opt], [dis_sch] # example with step-based learning rate schedulers # each optimizer has its own scheduler def configure_optimizers(self): gen_opt = Adam(self.model_gen.parameters(), lr=0.01) dis_opt = Adam(self.model_dis.parameters(), lr=0.02) gen_sch = { 'scheduler': ExponentialLR(gen_opt, 0.99), 'interval': 'step' # called after each training step } dis_sch = CosineAnnealing(dis_opt, T_max=10) # called every epoch return [gen_opt, dis_opt], [gen_sch, dis_sch] # example with optimizer frequencies # see training procedure in `Improved Training of Wasserstein GANs`, Algorithm 1 # https://arxiv.org/abs/1704.00028 def configure_optimizers(self): gen_opt = Adam(self.model_gen.parameters(), lr=0.01) dis_opt = Adam(self.model_dis.parameters(), lr=0.02) n_critic = 5 return ( {'optimizer': dis_opt, 'frequency': n_critic}, {'optimizer': gen_opt, 'frequency': 1} ) !!! note Some things to know: - Lightning calls ``.backward()`` and ``.step()`` on each optimizer and learning rate scheduler as needed. - If you use 16-bit precision (``precision=16``), Lightning will automatically handle the optimizers. - If you use multiple optimizers, :meth:`training_step` will have an additional ``optimizer_idx`` parameter. - If you use :class:`torch.optim.LBFGS`, Lightning handles the closure function automatically for you. - If you use multiple optimizers, gradients will be calculated only for the parameters of current optimizer at each training step. - If you need to control how often those optimizers step or override the default ``.step()`` schedule, override the :meth:`optimizer_step` hook. Source code in bemb/model/bemb_flex_lightning.py def configure_optimizers ( self ): optimizer = torch . optim . Adam ( self . parameters (), lr = self . learning_rate ) return optimizer fit_model ( self , dataset_list , batch_size =- 1 , num_epochs = 10 , num_workers = 8 , ** kwargs ) A standard pipeline of model training and evaluation. Parameters: Name Type Description Default dataset_list List[ChoiceDataset] train_dataset, validation_test, and test_dataset in a list of length 3. required batch_size int batch_size for training and evaluation. Defaults to -1, which indicates full-batch training. -1 num_epochs int number of epochs for training. Defaults to 10. 10 **kwargs additional keyword argument for the pytorch-lightning Trainer. {} Returns: Type Description LitBEMBFlex the trained bemb model. Source code in bemb/model/bemb_flex_lightning.py def fit_model ( self , dataset_list : List [ ChoiceDataset ], batch_size : int =- 1 , num_epochs : int = 10 , num_workers : int = 8 , ** kwargs ) -> \"LitBEMBFlex\" : \"\"\"A standard pipeline of model training and evaluation. Args: dataset_list (List[ChoiceDataset]): train_dataset, validation_test, and test_dataset in a list of length 3. batch_size (int, optional): batch_size for training and evaluation. Defaults to -1, which indicates full-batch training. num_epochs (int, optional): number of epochs for training. Defaults to 10. **kwargs: additional keyword argument for the pytorch-lightning Trainer. Returns: LitBEMBFlex: the trained bemb model. \"\"\" def section_print ( input_text ): \"\"\"Helper function for printing\"\"\" print ( '=' * 20 , input_text , '=' * 20 ) # present a summary of the model received. section_print ( 'model received' ) print ( self ) # present a summary of datasets received. section_print ( 'data set received' ) print ( '[Training dataset]' , dataset_list [ 0 ]) print ( '[Validation dataset]' , dataset_list [ 1 ]) print ( '[Testing dataset]' , dataset_list [ 2 ]) # create pytorch dataloader objects. train = create_data_loader ( dataset_list [ 0 ], batch_size = batch_size , shuffle = True , num_workers = num_workers ) validation = create_data_loader ( dataset_list [ 1 ], batch_size = batch_size , shuffle = False , num_workers = num_workers ) # WARNING: the test step takes extensive memory cost since it computes likelihood for all items. # we run the test step with a much smaller batch_size. test = create_data_loader ( dataset_list [ 2 ], batch_size = batch_size // 10 , shuffle = False , num_workers = num_workers ) section_print ( 'train the model' ) trainer = pl . Trainer ( gpus = 1 if ( 'cuda' in str ( self )) else 0 , # use GPU if the model is currently on the GPU. max_epochs = num_epochs , check_val_every_n_epoch = 1 , log_every_n_steps = 1 , ** kwargs ) start_time = time . time () trainer . fit ( self , train_dataloaders = train , val_dataloaders = validation ) print ( f 'time taken: { time . time () - start_time } ' ) section_print ( 'test performance' ) trainer . test ( self , dataloaders = test ) return self forward ( self , args , kwargs ) Calls the forward method of the wrapped BEMB model, please refer to the documentaton of the BEMB class for detailed definitions of the arguments. Parameters: Name Type Description Default args _type_ arguments passed to the forward method of the wrapped BEMB model. required kwargs _type_ keyword arguments passed to the forward method of the wrapped BEMB model. required Returns: Type Description _type_ returns whatever the wrapped BEMB model returns. Source code in bemb/model/bemb_flex_lightning.py def forward ( self , args , kwargs ): \"\"\"Calls the forward method of the wrapped BEMB model, please refer to the documentaton of the BEMB class for detailed definitions of the arguments. Args: args (_type_): arguments passed to the forward method of the wrapped BEMB model. kwargs (_type_): keyword arguments passed to the forward method of the wrapped BEMB model. Returns: _type_: returns whatever the wrapped BEMB model returns. \"\"\" return self . model ( * args , ** kwargs ) test_step ( self , batch , batch_idx ) Operates on a single batch of data from the test set. In this step you'd normally generate examples or calculate anything of interest such as accuracy. .. code-block:: python # the pseudocode for these calls test_outs = [] for test_batch in test_data: out = test_step(test_batch) test_outs.append(out) test_epoch_end(test_outs) Parameters: Name Type Description Default batch The output of your :class: ~torch.utils.data.DataLoader . required batch_idx The index of this batch. required dataloader_id The index of the dataloader that produced this batch. (only if multiple test dataloaders used). required Returns: Type Description Any of. Any object or value None - Testing will skip to the next batch .. code-block:: python # if you have one test dataloader: def test_step(self, batch, batch_idx): ... # if you have multiple test dataloaders: def test_step(self, batch, batch_idx, dataloader_idx=0): ... Examples:: # CASE 1: A single test dataset def test_step(self, batch, batch_idx): x, y = batch # implement your own out = self(x) loss = self.loss(out, y) # log 6 example images # or generated text... or whatever sample_imgs = x[:6] grid = torchvision.utils.make_grid(sample_imgs) self.logger.experiment.add_image('example_images', grid, 0) # calculate acc labels_hat = torch.argmax(out, dim=1) test_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0) # log the outputs! self.log_dict({'test_loss': loss, 'test_acc': test_acc}) If you pass in multiple test dataloaders, :meth: test_step will have an additional argument. We recommend setting the default value of 0 so that you can quickly switch between single and multiple dataloaders. .. code-block:: python # CASE 2: multiple test dataloaders def test_step(self, batch, batch_idx, dataloader_idx=0): # dataloader_idx tells you which dataset this is. ... !!! note If you don't need to test you don't need to implement this method. !!! note When the :meth: test_step is called, the model has been put in eval mode and PyTorch gradients have been disabled. At the end of the test epoch, the model goes back to training mode and gradients are enabled. Source code in bemb/model/bemb_flex_lightning.py def test_step ( self , batch , batch_idx ): # LL = self.model.forward(batch, return_logit=False, all_items=False).mean() # self.log('test_log_likelihood', LL) # pred = self.model(batch, return_type='utility', return_scope='item_index', deterministic=True) # y_pred = torch.sigmoid(pred).cpu().numpy() # y_true = batch.label.cpu().numpy() # performance = {'acc': metrics.accuracy_score(y_true=y_true, y_pred=(y_pred >= 0.5).astype(int)), # 'll': - metrics.log_loss(y_true=y_true, y_pred=y_pred, eps=1E-5, labels=[0, 1]), # # 'auc': metrics.roc_auc_score(y_true=y_true, y_score=y_pred), # # 'f1': metrics.f1_score(y_true=y_true, y_pred=(y_pred >= 0.5).astype(int)) # } # pred = self.model(batch) # performance = self.model.get_within_category_accuracy(pred, batch.label) for key , val in self . _get_performance_dict ( batch ) . items (): self . log ( 'test_' + key , val , prog_bar = True , batch_size = len ( batch )) training_step ( self , batch , batch_idx ) Here you compute and return the training loss and some additional metrics for e.g. the progress bar or logger. Parameters: Name Type Description Default batch class: ~torch.Tensor | (:class: ~torch.Tensor , ...) | [:class: ~torch.Tensor , ...]): The output of your :class: ~torch.utils.data.DataLoader . A tensor, tuple or list. required batch_idx ``int`` Integer displaying index of this batch required optimizer_idx ``int`` When using multiple optimizers, this argument will also be present. required hiddens ``Any`` Passed in if :paramref: ~pytorch_lightning.core.lightning.LightningModule.truncated_bptt_steps > 0. required Returns: Type Description Any of. - class: ~torch.Tensor - The loss tensor - dict - A dictionary. Can include any keys, but must include the key 'loss' - None - Training will skip to the next batch. This is only for automatic optimization. This is not supported for multi-GPU, TPU, IPU, or DeepSpeed. In this step you'd normally do the forward pass and calculate the loss for a batch. You can also do fancier things like multiple forward passes or something model specific. Example:: def training_step(self, batch, batch_idx): x, y, z = batch out = self.encoder(x) loss = self.loss(out, x) return loss If you define multiple optimizers, this step will be called with an additional optimizer_idx parameter. .. code-block:: python # Multiple optimizers (e.g.: GANs) def training_step(self, batch, batch_idx, optimizer_idx): if optimizer_idx == 0: # do training_step with encoder ... if optimizer_idx == 1: # do training_step with decoder ... If you add truncated back propagation through time you will also get an additional argument with the hidden states of the previous step. .. code-block:: python # Truncated back-propagation through time def training_step(self, batch, batch_idx, hiddens): # hiddens are the hidden states from the previous truncated backprop step out, hiddens = self.lstm(data, hiddens) loss = ... return {\"loss\": loss, \"hiddens\": hiddens} !!! note The loss value shown in the progress bar is smoothed (averaged) over the last values, so it differs from the actual loss returned in train/validation step. Source code in bemb/model/bemb_flex_lightning.py def training_step ( self , batch , batch_idx ): elbo = self . model . elbo ( batch , num_seeds = self . num_needs ) self . log ( 'train_elbo' , elbo ) loss = - elbo return loss validation_step ( self , batch , batch_idx ) Operates on a single batch of data from the validation set. In this step you'd might generate examples or calculate anything of interest like accuracy. .. code-block:: python # the pseudocode for these calls val_outs = [] for val_batch in val_data: out = validation_step(val_batch) val_outs.append(out) validation_epoch_end(val_outs) Parameters: Name Type Description Default batch The output of your :class: ~torch.utils.data.DataLoader . required batch_idx The index of this batch. required dataloader_idx The index of the dataloader that produced this batch. (only if multiple val dataloaders used) required Returns: Type Description Any object or value None - Validation will skip to the next batch .. code-block:: python # pseudocode of order val_outs = [] for val_batch in val_data: out = validation_step(val_batch) if defined(\"validation_step_end\"): out = validation_step_end(out) val_outs.append(out) val_outs = validation_epoch_end(val_outs) .. code-block:: python # if you have one val dataloader: def validation_step(self, batch, batch_idx): ... # if you have multiple val dataloaders: def validation_step(self, batch, batch_idx, dataloader_idx=0): ... Examples:: # CASE 1: A single validation dataset def validation_step(self, batch, batch_idx): x, y = batch # implement your own out = self(x) loss = self.loss(out, y) # log 6 example images # or generated text... or whatever sample_imgs = x[:6] grid = torchvision.utils.make_grid(sample_imgs) self.logger.experiment.add_image('example_images', grid, 0) # calculate acc labels_hat = torch.argmax(out, dim=1) val_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0) # log the outputs! self.log_dict({'val_loss': loss, 'val_acc': val_acc}) If you pass in multiple val dataloaders, :meth: validation_step will have an additional argument. We recommend setting the default value of 0 so that you can quickly switch between single and multiple dataloaders. .. code-block:: python # CASE 2: multiple validation dataloaders def validation_step(self, batch, batch_idx, dataloader_idx=0): # dataloader_idx tells you which dataset this is. ... !!! note If you don't need to validate you don't need to implement this method. !!! note When the :meth: validation_step is called, the model has been put in eval mode and PyTorch gradients have been disabled. At the end of validation, the model goes back to training mode and gradients are enabled. Source code in bemb/model/bemb_flex_lightning.py def validation_step ( self , batch , batch_idx ): # LL = self.model.forward(batch, return_type='log_prob', return_scope='item_index', deterministic=True).mean() # self.log('val_log_likelihood', LL, prog_bar=True) # pred = self.model(batch) # performance = self.model.get_within_category_accuracy(pred, batch.label) # utility. for key , val in self . _get_performance_dict ( batch ) . items (): self . log ( 'val_' + key , val , prog_bar = True , batch_size = len ( batch )) utils special run_helper This script contains a helper function for training and testing the BEMB model. The helper function here serves as a template for the training procedure, we encourage users to make a copy of this function and modify it to fully leverage the potential of pytorch lightning (e.g., early stopping and checkpointing). run ( model , dataset_list , batch_size =- 1 , num_epochs = 10 , num_workers = 8 , ** kwargs ) A standard pipeline of model training and evaluation. Parameters: Name Type Description Default model LitBEMBFlex the initialized pytorch-lightning wrapper of bemb. required dataset_list List[ChoiceDataset] train_dataset, validation_test, and test_dataset in a list of length 3. required batch_size int batch_size for training and evaluation. Defaults to -1, which indicates full-batch training. -1 num_epochs int number of epochs for training. Defaults to 10. 10 **kwargs additional keyword argument for the pytorch-lightning Trainer. {} Returns: Type Description LitBEMBFlex the trained bemb model. Source code in bemb/utils/run_helper.py def run ( model : LitBEMBFlex , dataset_list : List [ ChoiceDataset ], batch_size : int =- 1 , num_epochs : int = 10 , num_workers : int = 8 , ** kwargs ) -> LitBEMBFlex : \"\"\"A standard pipeline of model training and evaluation. Args: model (LitBEMBFlex): the initialized pytorch-lightning wrapper of bemb. dataset_list (List[ChoiceDataset]): train_dataset, validation_test, and test_dataset in a list of length 3. batch_size (int, optional): batch_size for training and evaluation. Defaults to -1, which indicates full-batch training. num_epochs (int, optional): number of epochs for training. Defaults to 10. **kwargs: additional keyword argument for the pytorch-lightning Trainer. Returns: LitBEMBFlex: the trained bemb model. \"\"\" # present a summary of the model received. section_print ( 'model received' ) print ( model ) # present a summary of datasets received. section_print ( 'data set received' ) print ( '[Training dataset]' , dataset_list [ 0 ]) print ( '[Validation dataset]' , dataset_list [ 1 ]) print ( '[Testing dataset]' , dataset_list [ 2 ]) # create pytorch dataloader objects. train = create_data_loader ( dataset_list [ 0 ], batch_size = batch_size , shuffle = True , num_workers = num_workers ) validation = create_data_loader ( dataset_list [ 1 ], batch_size = batch_size , shuffle = False , num_workers = num_workers ) # WARNING: the test step takes extensive memory cost since it computes likelihood for all items. # we run the test step with a much smaller batch_size. test = create_data_loader ( dataset_list [ 2 ], batch_size = batch_size // 10 , shuffle = False , num_workers = num_workers ) section_print ( 'train the model' ) trainer = pl . Trainer ( gpus = 1 if ( 'cuda' in str ( model . device )) else 0 , # use GPU if the model is currently on the GPU. max_epochs = num_epochs , check_val_every_n_epoch = 1 , log_every_n_steps = 1 , ** kwargs ) start_time = time . time () trainer . fit ( model , train_dataloaders = train , val_dataloaders = validation ) print ( f 'time taken: { time . time () - start_time } ' ) section_print ( 'test performance' ) trainer . test ( model , dataloaders = test ) return model section_print ( input_text ) Helper function for printing Source code in bemb/utils/run_helper.py def section_print ( input_text ): \"\"\"Helper function for printing\"\"\" print ( '=' * 20 , input_text , '=' * 20 )","title":"API Reference BEMB"},{"location":"api_bemb/#api-reference-bemb","text":"","title":"API Reference: BEMB"},{"location":"api_bemb/#bemb.model","text":"","title":"model"},{"location":"api_bemb/#bemb.model.bayesian_coefficient","text":"Bayesian Coefficient is the building block for the BEMB model. Author: Tianyu Du Update: Apr. 28, 2022","title":"bayesian_coefficient"},{"location":"api_bemb/#bemb.model.bayesian_coefficient.BayesianCoefficient","text":"Source code in bemb/model/bayesian_coefficient.py class BayesianCoefficient ( nn . Module ): def __init__ ( self , variation : str , num_classes : int , obs2prior : bool , num_obs : Optional [ int ] = None , dim : int = 1 , prior_mean : float = 0.0 , prior_variance : float = 1.0 ) -> None : \"\"\"The Bayesian coefficient object represents a learnable tensor mu_i in R^k, where i is from a family (e.g., user, item) so there are num_classes * num_obs learnable weights in total. The prior distribution of mu_i is N(0, I) or N(H*X_obs(H shape=num_obs, X_obs shape=dim), Ix1). The posterior(i.e., variational) distribution of mu_i is a Gaussian distribution with learnable mean mu_i and unit covariance. The mean of the variational distribution consists of two parts: 1. The fixed part, which is not learnable. This part is particularly useful when the researcher want to impose some structure on the variational distribution. For example, the research might have some variational mean learned from another model and wish to use BEMB to polish the learned mean. 2. The flexible part, which is the main learnable part of the variational mean. Args: variation (str): the variation # TODO: this will be removed in the next version, after we have a complete test pipline. num_classes (int): number of classes in the coefficient. For example, if we have user-specific coefficients, `theta_user`, the `num_classes` should be the number of users. If we have item-specific coefficients, the the `num_classes` should be the number of items. obs2prior (bool): whether the mean of coefficient prior depends on the observable or not. num_obs (int, optional): the number of observables associated with each class. For example, if the coefficient if item-specific, and we have `obs2prior` set to True, the `num_obs` should be the number of observables for each item. Defaults to None. dim (int, optional): the dimension of the coefficient. Defaults to 1. prior_mean (float): the mean of the prior distribution of coefficient. Defaults to 0.0. prior_variance (float): the variance of the prior distribution of coefficient. Defaults to 1.0. \"\"\" super ( BayesianCoefficient , self ) . __init__ () # do we use this at all? TODO: drop self.variation. assert variation in [ 'item' , 'user' , 'constant' , 'category' ] self . variation = variation self . obs2prior = obs2prior if variation == 'constant' or variation == 'category' : if obs2prior : raise NotImplementedError ( 'obs2prior is not supported for constant and category variation at present.' ) self . num_classes = num_classes self . num_obs = num_obs self . dim = dim # the dimension of greek letter parameter. self . prior_mean = prior_mean self . prior_variance = prior_variance # assert self.prior_variance > 0 # create prior distribution. if self . obs2prior : # the mean of prior distribution depends on observables. # initiate a Bayesian Coefficient with shape (dim, num_obs) standard Gaussian. self . prior_H = BayesianCoefficient ( variation = 'constant' , num_classes = dim , obs2prior = False , dim = num_obs , prior_variance = 1.0 ) else : self . register_buffer ( 'prior_zero_mean' , torch . zeros ( num_classes , dim ) + ( self . prior_mean )) # self.prior_cov_factor = nn.Parameter(torch.zeros(num_classes, dim, 1), requires_grad=False) # self.prior_cov_diag = nn.Parameter(torch.ones(num_classes, dim), requires_grad=False) self . register_buffer ( 'prior_cov_factor' , torch . zeros ( num_classes , dim , 1 )) self . register_buffer ( 'prior_cov_diag' , torch . ones ( num_classes , dim ) * self . prior_variance ) # create variational distribution. self . variational_mean_flexible = nn . Parameter ( torch . randn ( num_classes , dim ), requires_grad = True ) self . variational_logstd = nn . Parameter ( torch . randn ( num_classes , dim ), requires_grad = True ) self . register_buffer ( 'variational_cov_factor' , torch . zeros ( num_classes , dim , 1 )) self . variational_mean_fixed = None def __repr__ ( self ) -> str : \"\"\"Constructs a string representation of the Bayesian coefficient object. Returns: str: the string representation of the Bayesian coefficient object. \"\"\" if self . obs2prior : prior_str = f 'prior=N(H*X_obs(H shape= { self . prior_H . prior_zero_mean . shape } , X_obs shape= { self . prior_H . dim } ), Ix { self . prior_variance } )' else : prior_str = f 'prior=N(0, I)' return f 'BayesianCoefficient(num_classes= { self . num_classes } , dimension= { self . dim } , { prior_str } )' def update_variational_mean_fixed ( self , new_value : torch . Tensor ) -> None : \"\"\"Updates the fixed part of the mean of the variational distribution. Args: new_value (torch.Tensor): the new value of the fixed part of the mean of the variational distribution. \"\"\" assert new_value . shape == self . variational_mean_flexible . shape del self . variational_mean_fixed self . register_buffer ( 'variational_mean_fixed' , new_value ) @property def variational_mean ( self ) -> torch . Tensor : \"\"\"Returns the mean of the variational distribution. Returns: torch.Tensor: the current mean of the variational distribution with shape (num_classes, dim). \"\"\" if self . variational_mean_fixed is None : return self . variational_mean_flexible else : return self . variational_mean_fixed + self . variational_mean_flexible def log_prior ( self , sample : torch . Tensor , H_sample : Optional [ torch . Tensor ] = None , x_obs : Optional [ torch . Tensor ] = None ) -> torch . Tensor : \"\"\" Computes the logP_{Prior}(Coefficient Sample) for provided samples of the coefficient. The prior will either be a zero-mean Gaussian (if `obs2prior` is False) or a Gaussian with a learnable mean (if `obs2prior` is True). Args: sample (torch.Tensor): Monte Carlo samples of the variable with shape (num_seeds, num_classes, dim), where sample[i, :, :] corresponds to one sample of the coefficient. # arguments required only if `obs2prior == True`: H_sample (Optional[torch.Tensor], optional): Monte Carlo samples of the weight in obs2prior term, with shape (num_seeds, dim, self.num_obs), this is required if and only if obs2prior == True. Defaults to None. x_obs (Optional[torch.Tensor], optional): observables for obs2prior with shape (num_classes, num_obs), only required if and only if obs2prior == True. Defaults to None. Returns: torch.Tensor: the log prior of the variable with shape (num_seeds, num_classes). \"\"\" # p(sample) num_seeds , num_classes , dim = sample . shape # shape (num_seeds, num_classes) if self . obs2prior : assert H_sample . shape == ( num_seeds , dim , self . num_obs ) assert x_obs . shape == ( num_classes , self . num_obs ) x_obs = x_obs . view ( 1 , num_classes , self . num_obs ) . expand ( num_seeds , - 1 , - 1 ) H_sample = torch . transpose ( H_sample , 1 , 2 ) assert H_sample . shape == ( num_seeds , self . num_obs , dim ) mu = torch . bmm ( x_obs , H_sample ) assert mu . shape == ( num_seeds , num_classes , dim ) else : mu = self . prior_zero_mean out = LowRankMultivariateNormal ( loc = mu , cov_factor = self . prior_cov_factor , cov_diag = self . prior_cov_diag ) . log_prob ( sample ) assert out . shape == ( num_seeds , num_classes ) return out def log_variational ( self , sample : torch . Tensor ) -> torch . Tensor : \"\"\"Given a set of sampled values of coefficients, with shape (num_seeds, num_classes, dim), computes the the log probability of these sampled values of coefficients under the current variational distribution. Args: sample (torch.Tensor): a tensor of shape (num_seeds, num_classes, dim) containing sampled values of coefficients, where sample[i, :, :] corresponds to one sample of the coefficient. Returns: torch.Tensor: a tensor of shape (num_seeds, num_classes) containing the log probability of provided samples under the variational distribution. The output is splitted by random seeds and classes, you can sum along the second axis (i.e., the num_classes axis) to get the total log probability. \"\"\" num_seeds , num_classes , dim = sample . shape out = self . variational_distribution . log_prob ( sample ) assert out . shape == ( num_seeds , num_classes ) return out def rsample ( self , num_seeds : int = 1 ) -> Union [ torch . Tensor , Tuple [ torch . Tensor ]]: \"\"\"Samples values of the coefficient from the variational distribution using re-parameterization trick. Args: num_seeds (int, optional): number of values to be sampled. Defaults to 1. Returns: Union[torch.Tensor, Tuple[torch.Tensor]]: if `obs2prior` is disabled, returns a tensor of shape (num_seeds, num_classes, dim) where each output[i, :, :] corresponds to one sample of the coefficient. If `obs2prior` is enabled, returns a tuple of samples: (1) a tensor of shape (num_seeds, num_classes, dim) containing sampled values of coefficient, and (2) a tensor o shape (num_seeds, dim, num_obs) containing samples of the H weight in the prior distribution. \"\"\" value_sample = self . variational_distribution . rsample ( torch . Size ([ num_seeds ])) if self . obs2prior : # sample obs2prior H as well. H_sample = self . prior_H . rsample ( num_seeds = num_seeds ) return ( value_sample , H_sample ) else : return value_sample @property def variational_distribution ( self ) -> LowRankMultivariateNormal : \"\"\"Constructs the current variational distribution of the coefficient from current variational mean and covariance. \"\"\" return LowRankMultivariateNormal ( loc = self . variational_mean , cov_factor = self . variational_cov_factor , cov_diag = torch . exp ( self . variational_logstd )) @property def device ( self ) -> torch . device : \"\"\"Returns the device of tensors contained in this module.\"\"\" return self . variational_mean . device","title":"BayesianCoefficient"},{"location":"api_bemb/#bemb.model.bayesian_coefficient.BayesianCoefficient.device","text":"Returns the device of tensors contained in this module.","title":"device"},{"location":"api_bemb/#bemb.model.bayesian_coefficient.BayesianCoefficient.variational_distribution","text":"Constructs the current variational distribution of the coefficient from current variational mean and covariance.","title":"variational_distribution"},{"location":"api_bemb/#bemb.model.bayesian_coefficient.BayesianCoefficient.variational_mean","text":"Returns the mean of the variational distribution. Returns: Type Description torch.Tensor the current mean of the variational distribution with shape (num_classes, dim).","title":"variational_mean"},{"location":"api_bemb/#bemb.model.bayesian_coefficient.BayesianCoefficient.__init__","text":"The Bayesian coefficient object represents a learnable tensor mu_i in R^k, where i is from a family (e.g., user, item) so there are num_classes * num_obs learnable weights in total. The prior distribution of mu_i is N(0, I) or N(H*X_obs(H shape=num_obs, X_obs shape=dim), Ix1). The posterior(i.e., variational) distribution of mu_i is a Gaussian distribution with learnable mean mu_i and unit covariance. The mean of the variational distribution consists of two parts: 1. The fixed part, which is not learnable. This part is particularly useful when the researcher want to impose some structure on the variational distribution. For example, the research might have some variational mean learned from another model and wish to use BEMB to polish the learned mean. 2. The flexible part, which is the main learnable part of the variational mean. Parameters: Name Type Description Default variation str the variation # TODO: this will be removed in the next version, after we have a complete test pipline. required num_classes int number of classes in the coefficient. For example, if we have user-specific coefficients, theta_user , the num_classes should be the number of users. If we have item-specific coefficients, the the num_classes should be the number of items. required obs2prior bool whether the mean of coefficient prior depends on the observable or not. required num_obs int the number of observables associated with each class. For example, if the coefficient if item-specific, and we have obs2prior set to True, the num_obs should be the number of observables for each item. Defaults to None. None dim int the dimension of the coefficient. Defaults to 1. 1 prior_mean float the mean of the prior distribution of coefficient. Defaults to 0.0. 0.0 prior_variance float the variance of the prior distribution of coefficient. Defaults to 1.0. 1.0 Source code in bemb/model/bayesian_coefficient.py def __init__ ( self , variation : str , num_classes : int , obs2prior : bool , num_obs : Optional [ int ] = None , dim : int = 1 , prior_mean : float = 0.0 , prior_variance : float = 1.0 ) -> None : \"\"\"The Bayesian coefficient object represents a learnable tensor mu_i in R^k, where i is from a family (e.g., user, item) so there are num_classes * num_obs learnable weights in total. The prior distribution of mu_i is N(0, I) or N(H*X_obs(H shape=num_obs, X_obs shape=dim), Ix1). The posterior(i.e., variational) distribution of mu_i is a Gaussian distribution with learnable mean mu_i and unit covariance. The mean of the variational distribution consists of two parts: 1. The fixed part, which is not learnable. This part is particularly useful when the researcher want to impose some structure on the variational distribution. For example, the research might have some variational mean learned from another model and wish to use BEMB to polish the learned mean. 2. The flexible part, which is the main learnable part of the variational mean. Args: variation (str): the variation # TODO: this will be removed in the next version, after we have a complete test pipline. num_classes (int): number of classes in the coefficient. For example, if we have user-specific coefficients, `theta_user`, the `num_classes` should be the number of users. If we have item-specific coefficients, the the `num_classes` should be the number of items. obs2prior (bool): whether the mean of coefficient prior depends on the observable or not. num_obs (int, optional): the number of observables associated with each class. For example, if the coefficient if item-specific, and we have `obs2prior` set to True, the `num_obs` should be the number of observables for each item. Defaults to None. dim (int, optional): the dimension of the coefficient. Defaults to 1. prior_mean (float): the mean of the prior distribution of coefficient. Defaults to 0.0. prior_variance (float): the variance of the prior distribution of coefficient. Defaults to 1.0. \"\"\" super ( BayesianCoefficient , self ) . __init__ () # do we use this at all? TODO: drop self.variation. assert variation in [ 'item' , 'user' , 'constant' , 'category' ] self . variation = variation self . obs2prior = obs2prior if variation == 'constant' or variation == 'category' : if obs2prior : raise NotImplementedError ( 'obs2prior is not supported for constant and category variation at present.' ) self . num_classes = num_classes self . num_obs = num_obs self . dim = dim # the dimension of greek letter parameter. self . prior_mean = prior_mean self . prior_variance = prior_variance # assert self.prior_variance > 0 # create prior distribution. if self . obs2prior : # the mean of prior distribution depends on observables. # initiate a Bayesian Coefficient with shape (dim, num_obs) standard Gaussian. self . prior_H = BayesianCoefficient ( variation = 'constant' , num_classes = dim , obs2prior = False , dim = num_obs , prior_variance = 1.0 ) else : self . register_buffer ( 'prior_zero_mean' , torch . zeros ( num_classes , dim ) + ( self . prior_mean )) # self.prior_cov_factor = nn.Parameter(torch.zeros(num_classes, dim, 1), requires_grad=False) # self.prior_cov_diag = nn.Parameter(torch.ones(num_classes, dim), requires_grad=False) self . register_buffer ( 'prior_cov_factor' , torch . zeros ( num_classes , dim , 1 )) self . register_buffer ( 'prior_cov_diag' , torch . ones ( num_classes , dim ) * self . prior_variance ) # create variational distribution. self . variational_mean_flexible = nn . Parameter ( torch . randn ( num_classes , dim ), requires_grad = True ) self . variational_logstd = nn . Parameter ( torch . randn ( num_classes , dim ), requires_grad = True ) self . register_buffer ( 'variational_cov_factor' , torch . zeros ( num_classes , dim , 1 )) self . variational_mean_fixed = None","title":"__init__()"},{"location":"api_bemb/#bemb.model.bayesian_coefficient.BayesianCoefficient.__repr__","text":"Constructs a string representation of the Bayesian coefficient object. Returns: Type Description str the string representation of the Bayesian coefficient object. Source code in bemb/model/bayesian_coefficient.py def __repr__ ( self ) -> str : \"\"\"Constructs a string representation of the Bayesian coefficient object. Returns: str: the string representation of the Bayesian coefficient object. \"\"\" if self . obs2prior : prior_str = f 'prior=N(H*X_obs(H shape= { self . prior_H . prior_zero_mean . shape } , X_obs shape= { self . prior_H . dim } ), Ix { self . prior_variance } )' else : prior_str = f 'prior=N(0, I)' return f 'BayesianCoefficient(num_classes= { self . num_classes } , dimension= { self . dim } , { prior_str } )'","title":"__repr__()"},{"location":"api_bemb/#bemb.model.bayesian_coefficient.BayesianCoefficient.log_prior","text":"Computes the logP_{Prior}(Coefficient Sample) for provided samples of the coefficient. The prior will either be a zero-mean Gaussian (if obs2prior is False) or a Gaussian with a learnable mean (if obs2prior is True). Parameters: Name Type Description Default sample torch.Tensor Monte Carlo samples of the variable with shape (num_seeds, num_classes, dim), where sample[i, :, :] corresponds to one sample of the coefficient. required # arguments required only if `obs2prior == True` required H_sample Optional[torch.Tensor] Monte Carlo samples of the weight in obs2prior term, with shape (num_seeds, dim, self.num_obs), this is required if and only if obs2prior == True. Defaults to None. None x_obs Optional[torch.Tensor] observables for obs2prior with shape (num_classes, num_obs), only required if and only if obs2prior == True. Defaults to None. None Returns: Type Description torch.Tensor the log prior of the variable with shape (num_seeds, num_classes). Source code in bemb/model/bayesian_coefficient.py def log_prior ( self , sample : torch . Tensor , H_sample : Optional [ torch . Tensor ] = None , x_obs : Optional [ torch . Tensor ] = None ) -> torch . Tensor : \"\"\" Computes the logP_{Prior}(Coefficient Sample) for provided samples of the coefficient. The prior will either be a zero-mean Gaussian (if `obs2prior` is False) or a Gaussian with a learnable mean (if `obs2prior` is True). Args: sample (torch.Tensor): Monte Carlo samples of the variable with shape (num_seeds, num_classes, dim), where sample[i, :, :] corresponds to one sample of the coefficient. # arguments required only if `obs2prior == True`: H_sample (Optional[torch.Tensor], optional): Monte Carlo samples of the weight in obs2prior term, with shape (num_seeds, dim, self.num_obs), this is required if and only if obs2prior == True. Defaults to None. x_obs (Optional[torch.Tensor], optional): observables for obs2prior with shape (num_classes, num_obs), only required if and only if obs2prior == True. Defaults to None. Returns: torch.Tensor: the log prior of the variable with shape (num_seeds, num_classes). \"\"\" # p(sample) num_seeds , num_classes , dim = sample . shape # shape (num_seeds, num_classes) if self . obs2prior : assert H_sample . shape == ( num_seeds , dim , self . num_obs ) assert x_obs . shape == ( num_classes , self . num_obs ) x_obs = x_obs . view ( 1 , num_classes , self . num_obs ) . expand ( num_seeds , - 1 , - 1 ) H_sample = torch . transpose ( H_sample , 1 , 2 ) assert H_sample . shape == ( num_seeds , self . num_obs , dim ) mu = torch . bmm ( x_obs , H_sample ) assert mu . shape == ( num_seeds , num_classes , dim ) else : mu = self . prior_zero_mean out = LowRankMultivariateNormal ( loc = mu , cov_factor = self . prior_cov_factor , cov_diag = self . prior_cov_diag ) . log_prob ( sample ) assert out . shape == ( num_seeds , num_classes ) return out","title":"log_prior()"},{"location":"api_bemb/#bemb.model.bayesian_coefficient.BayesianCoefficient.log_variational","text":"Given a set of sampled values of coefficients, with shape (num_seeds, num_classes, dim), computes the the log probability of these sampled values of coefficients under the current variational distribution. Parameters: Name Type Description Default sample torch.Tensor a tensor of shape (num_seeds, num_classes, dim) containing sampled values of coefficients, where sample[i, :, :] corresponds to one sample of the coefficient. required Returns: Type Description torch.Tensor a tensor of shape (num_seeds, num_classes) containing the log probability of provided samples under the variational distribution. The output is splitted by random seeds and classes, you can sum along the second axis (i.e., the num_classes axis) to get the total log probability. Source code in bemb/model/bayesian_coefficient.py def log_variational ( self , sample : torch . Tensor ) -> torch . Tensor : \"\"\"Given a set of sampled values of coefficients, with shape (num_seeds, num_classes, dim), computes the the log probability of these sampled values of coefficients under the current variational distribution. Args: sample (torch.Tensor): a tensor of shape (num_seeds, num_classes, dim) containing sampled values of coefficients, where sample[i, :, :] corresponds to one sample of the coefficient. Returns: torch.Tensor: a tensor of shape (num_seeds, num_classes) containing the log probability of provided samples under the variational distribution. The output is splitted by random seeds and classes, you can sum along the second axis (i.e., the num_classes axis) to get the total log probability. \"\"\" num_seeds , num_classes , dim = sample . shape out = self . variational_distribution . log_prob ( sample ) assert out . shape == ( num_seeds , num_classes ) return out","title":"log_variational()"},{"location":"api_bemb/#bemb.model.bayesian_coefficient.BayesianCoefficient.rsample","text":"Samples values of the coefficient from the variational distribution using re-parameterization trick. Parameters: Name Type Description Default num_seeds int number of values to be sampled. Defaults to 1. 1 Returns: Type Description Union[torch.Tensor, Tuple[torch.Tensor]] if obs2prior is disabled, returns a tensor of shape (num_seeds, num_classes, dim) where each output[i, :, :] corresponds to one sample of the coefficient. If obs2prior is enabled, returns a tuple of samples: (1) a tensor of shape (num_seeds, num_classes, dim) containing sampled values of coefficient, and (2) a tensor o shape (num_seeds, dim, num_obs) containing samples of the H weight in the prior distribution. Source code in bemb/model/bayesian_coefficient.py def rsample ( self , num_seeds : int = 1 ) -> Union [ torch . Tensor , Tuple [ torch . Tensor ]]: \"\"\"Samples values of the coefficient from the variational distribution using re-parameterization trick. Args: num_seeds (int, optional): number of values to be sampled. Defaults to 1. Returns: Union[torch.Tensor, Tuple[torch.Tensor]]: if `obs2prior` is disabled, returns a tensor of shape (num_seeds, num_classes, dim) where each output[i, :, :] corresponds to one sample of the coefficient. If `obs2prior` is enabled, returns a tuple of samples: (1) a tensor of shape (num_seeds, num_classes, dim) containing sampled values of coefficient, and (2) a tensor o shape (num_seeds, dim, num_obs) containing samples of the H weight in the prior distribution. \"\"\" value_sample = self . variational_distribution . rsample ( torch . Size ([ num_seeds ])) if self . obs2prior : # sample obs2prior H as well. H_sample = self . prior_H . rsample ( num_seeds = num_seeds ) return ( value_sample , H_sample ) else : return value_sample","title":"rsample()"},{"location":"api_bemb/#bemb.model.bayesian_coefficient.BayesianCoefficient.update_variational_mean_fixed","text":"Updates the fixed part of the mean of the variational distribution. Parameters: Name Type Description Default new_value torch.Tensor the new value of the fixed part of the mean of the variational distribution. required Source code in bemb/model/bayesian_coefficient.py def update_variational_mean_fixed ( self , new_value : torch . Tensor ) -> None : \"\"\"Updates the fixed part of the mean of the variational distribution. Args: new_value (torch.Tensor): the new value of the fixed part of the mean of the variational distribution. \"\"\" assert new_value . shape == self . variational_mean_flexible . shape del self . variational_mean_fixed self . register_buffer ( 'variational_mean_fixed' , new_value )","title":"update_variational_mean_fixed()"},{"location":"api_bemb/#bemb.model.bayesian_linear","text":"Bayesian tensor object.","title":"bayesian_linear"},{"location":"api_bemb/#bemb.model.bayesian_linear.BayesianLinear","text":"Source code in bemb/model/bayesian_linear.py class BayesianLinear ( nn . Module ): def __init__ ( self , in_features : int , out_features : int , bias : bool = True , W_variational_mean_fixed : Optional [ torch . Tensor ] = None , device = None , dtype = None , W_prior_variance : float = 1.0 , b_prior_variance : float = 1.0 ): \"\"\"Linear layer where weight and bias are modelled as distributions. \"\"\" super () . __init__ () if dtype is not None : raise NotImplementedError ( 'dtype is not Supported yet.' ) self . in_features = in_features # the same as number of classes before. self . out_features = out_features # the same as latent dimension before. self . bias = bias # ============================================================================================================== # prior distributions for mean and bias. # ============================================================================================================== # the prior of weights are gausssian distributions independent across in_feature dimensions. self . register_buffer ( 'W_prior_mean' , torch . zeros ( in_features , out_features )) self . register_buffer ( 'W_prior_logstd' , torch . ones ( in_features , out_features ) * np . log ( W_prior_variance )) if self . bias : self . register_buffer ( 'b_prior_mean' , torch . zeros ( in_features , out_features )) self . register_buffer ( 'b_prior_logstd' , torch . ones ( in_features , out_features ) * np . log ( b_prior_variance )) # ============================================================================================================== # variational distributions for weight and bias. # ============================================================================================================== if W_variational_mean_fixed is None : self . W_variational_mean_fixed = None else : assert W_variational_mean_fixed . shape == ( in_features , out_features ), \\ f 'W_variational_mean_fixed tensor should have shape (in_features, out_features), got { W_variational_mean_fixed . shape } ' self . register_buffer ( 'W_variational_mean_fixed' , W_variational_mean_fixed ) # TODO: optionally add customizable initialization here. self . W_variational_mean_flexible = nn . Parameter ( torch . randn ( in_features , out_features ), requires_grad = True ) self . W_variational_logstd = nn . Parameter ( torch . randn ( in_features , out_features ), requires_grad = True ) if self . bias : self . b_variational_mean = nn . Parameter ( torch . randn ( out_features ), requires_grad = True ) self . b_variational_logstd = nn . Parameter ( torch . randn ( out_features ), requires_grad = True ) if device is not None : self . to ( device ) self . W_sample = None self . b_sample = None self . num_seeds = None @property def W_variational_mean ( self ): if self . W_variational_mean_fixed is None : return self . W_variational_mean_flexible else : return self . W_variational_mean_fixed + self . W_variational_mean_flexible def rsample ( self , num_seeds : int = 1 ) -> Optional [ Tuple [ torch . Tensor , Optional [ torch . Tensor ]]]: \"\"\"sample all parameters using re-parameterization trick. \"\"\" self . num_seeds = num_seeds self . W_sample = self . W_variational_distribution . rsample ( torch . Size ([ num_seeds ])) if self . bias : self . b_sample = self . b_variational_distribution . rsample ( torch . Size ([ num_seeds ])) return self . W_sample , self . b_sample def dsample ( self ): \"\"\"Deterministic sample method, set (W, b) sample to the mean of variational distribution.\"\"\" self . num_seeds = 1 self . W_sample = self . W_variational_mean . unsqueeze ( dim = 0 ) if self . bias : self . b_sample = self . b_variational_mean . unsqueeze ( dim = 0 ) return self . W_sample , self . b_sample def forward ( self , x , mode : str = 'multiply' ): \"\"\" Forward with weight sampling. Forward does out = XW + b, for forward() method behaves like the embedding layer in PyTorch, use the lookup() method. To have determinstic results, call self.dsample() before executing. To have stochastic results, call self.rsample() before executing. mode in ['multiply', 'lookup'] output shape: (num_seeds, batch_size, out_features). \"\"\" assert self . num_seeds is not None , 'run BayesianLinear.rsample() or dsample() first to sample weight and bias.' # if determinstic, num_seeds is set to 1. # w: (num_seeds, in_features=num_classes, out_features) # b: (num_seeds, out_features) # x: (N, in_features) if multiply and (N,) if lookup. # output: (num_seeds, N, out_features) if mode == 'multiply' : x = x . view ( 1 , - 1 , self . in_features ) . expand ( self . num_seeds , - 1 , - 1 ) # (num_seeds, N, in_features) out = x . bmm ( self . W_sample ) # (num_seeds, N, out_features) elif mode == 'lookup' : out = self . W_sample [:, x , :] # (num_seeds, N, out_features) else : raise ValueError ( f 'mode= { mode } is not allowed.' ) if self . bias : out += self . b_sample . view ( self . num_seeds , 1 , self . out_features ) # (num_seeds, N, out_features) return out @property def W_variational_distribution ( self ): \"\"\"the weight variational distribution.\"\"\" return Normal ( loc = self . W_variational_mean , scale = torch . exp ( self . W_variational_logstd )) @property def b_variational_distribution ( self ): return Normal ( loc = self . b_variational_mean , scale = torch . exp ( self . b_variational_logstd )) @property def device ( self ) -> torch . device : return self . W_variational_mean . device def log_prior ( self ): \"\"\"Evaluate the likelihood of the provided samples of parameter under the current prior distribution.\"\"\" assert self . num_seeds is not None , 'run BayesianLinear.rsample() or dsample() first to sample weight and bias.' num_seeds = self . W_sample . shape [ 0 ] total_log_prob = torch . zeros ( num_seeds , device = self . device ) # log P(W_sample). shape = (num_seeds,) W_prior = Normal ( loc = self . W_prior_mean , scale = torch . exp ( self . W_prior_logstd )) total_log_prob += W_prior . log_prob ( self . W_sample ) . sum ( dim = [ 1 , 2 ]) # log P(b_sample) if applicable. if self . bias : b_prior = Normal ( loc = self . b_prior_mean , scale = torch . exp ( self . b_prior_logstd )) total_log_prob += b_prior . log_prob ( self . b_sample ) . sum ( dim = 1 ) assert total_log_prob . shape == ( num_seeds ,) return total_log_prob def log_variational ( self ): \"\"\"Evaluate the likelihood of the provided samples of parameter under the current variational distribution.\"\"\" assert self . num_seeds is not None , 'run BayesianLinear.rsample() or dsample() first to sample weight and bias.' num_seeds = self . W_sample . shape [ 0 ] total_log_prob = torch . zeros ( num_seeds , device = self . device ) total_log_prob += self . W_variational_distribution . log_prob ( self . W_sample ) . sum ( dim = [ 1 , 2 ]) if self . bias : total_log_prob += self . b_variational_distribution . log_prob ( self . b_sample ) . sum ( dim = 1 ) assert total_log_prob . shape == ( num_seeds ,) return total_log_prob def __repr__ ( self ): prior_info = f 'W_prior ~ N(mu= { self . W_prior_mean } , logstd= { self . W_prior_logstd } )' if self . bias : prior_info += f 'b_prior ~ N(mu= { self . b_prior_mean } , logstd= { self . b_prior_logstd } )' return f \"BayesianLinear(in_features= { self . in_features } , out_features= { self . out_features } , bias= { self . bias } , { prior_info } )\"","title":"BayesianLinear"},{"location":"api_bemb/#bemb.model.bayesian_linear.BayesianLinear.W_variational_distribution","text":"the weight variational distribution.","title":"W_variational_distribution"},{"location":"api_bemb/#bemb.model.bayesian_linear.BayesianLinear.__init__","text":"Linear layer where weight and bias are modelled as distributions. Source code in bemb/model/bayesian_linear.py def __init__ ( self , in_features : int , out_features : int , bias : bool = True , W_variational_mean_fixed : Optional [ torch . Tensor ] = None , device = None , dtype = None , W_prior_variance : float = 1.0 , b_prior_variance : float = 1.0 ): \"\"\"Linear layer where weight and bias are modelled as distributions. \"\"\" super () . __init__ () if dtype is not None : raise NotImplementedError ( 'dtype is not Supported yet.' ) self . in_features = in_features # the same as number of classes before. self . out_features = out_features # the same as latent dimension before. self . bias = bias # ============================================================================================================== # prior distributions for mean and bias. # ============================================================================================================== # the prior of weights are gausssian distributions independent across in_feature dimensions. self . register_buffer ( 'W_prior_mean' , torch . zeros ( in_features , out_features )) self . register_buffer ( 'W_prior_logstd' , torch . ones ( in_features , out_features ) * np . log ( W_prior_variance )) if self . bias : self . register_buffer ( 'b_prior_mean' , torch . zeros ( in_features , out_features )) self . register_buffer ( 'b_prior_logstd' , torch . ones ( in_features , out_features ) * np . log ( b_prior_variance )) # ============================================================================================================== # variational distributions for weight and bias. # ============================================================================================================== if W_variational_mean_fixed is None : self . W_variational_mean_fixed = None else : assert W_variational_mean_fixed . shape == ( in_features , out_features ), \\ f 'W_variational_mean_fixed tensor should have shape (in_features, out_features), got { W_variational_mean_fixed . shape } ' self . register_buffer ( 'W_variational_mean_fixed' , W_variational_mean_fixed ) # TODO: optionally add customizable initialization here. self . W_variational_mean_flexible = nn . Parameter ( torch . randn ( in_features , out_features ), requires_grad = True ) self . W_variational_logstd = nn . Parameter ( torch . randn ( in_features , out_features ), requires_grad = True ) if self . bias : self . b_variational_mean = nn . Parameter ( torch . randn ( out_features ), requires_grad = True ) self . b_variational_logstd = nn . Parameter ( torch . randn ( out_features ), requires_grad = True ) if device is not None : self . to ( device ) self . W_sample = None self . b_sample = None self . num_seeds = None","title":"__init__()"},{"location":"api_bemb/#bemb.model.bayesian_linear.BayesianLinear.dsample","text":"Deterministic sample method, set (W, b) sample to the mean of variational distribution. Source code in bemb/model/bayesian_linear.py def dsample ( self ): \"\"\"Deterministic sample method, set (W, b) sample to the mean of variational distribution.\"\"\" self . num_seeds = 1 self . W_sample = self . W_variational_mean . unsqueeze ( dim = 0 ) if self . bias : self . b_sample = self . b_variational_mean . unsqueeze ( dim = 0 ) return self . W_sample , self . b_sample","title":"dsample()"},{"location":"api_bemb/#bemb.model.bayesian_linear.BayesianLinear.forward","text":"Forward with weight sampling. Forward does out = XW + b, for forward() method behaves like the embedding layer in PyTorch, use the lookup() method. To have determinstic results, call self.dsample() before executing. To have stochastic results, call self.rsample() before executing. mode in ['multiply', 'lookup'] output shape: (num_seeds, batch_size, out_features). Source code in bemb/model/bayesian_linear.py def forward ( self , x , mode : str = 'multiply' ): \"\"\" Forward with weight sampling. Forward does out = XW + b, for forward() method behaves like the embedding layer in PyTorch, use the lookup() method. To have determinstic results, call self.dsample() before executing. To have stochastic results, call self.rsample() before executing. mode in ['multiply', 'lookup'] output shape: (num_seeds, batch_size, out_features). \"\"\" assert self . num_seeds is not None , 'run BayesianLinear.rsample() or dsample() first to sample weight and bias.' # if determinstic, num_seeds is set to 1. # w: (num_seeds, in_features=num_classes, out_features) # b: (num_seeds, out_features) # x: (N, in_features) if multiply and (N,) if lookup. # output: (num_seeds, N, out_features) if mode == 'multiply' : x = x . view ( 1 , - 1 , self . in_features ) . expand ( self . num_seeds , - 1 , - 1 ) # (num_seeds, N, in_features) out = x . bmm ( self . W_sample ) # (num_seeds, N, out_features) elif mode == 'lookup' : out = self . W_sample [:, x , :] # (num_seeds, N, out_features) else : raise ValueError ( f 'mode= { mode } is not allowed.' ) if self . bias : out += self . b_sample . view ( self . num_seeds , 1 , self . out_features ) # (num_seeds, N, out_features) return out","title":"forward()"},{"location":"api_bemb/#bemb.model.bayesian_linear.BayesianLinear.log_prior","text":"Evaluate the likelihood of the provided samples of parameter under the current prior distribution. Source code in bemb/model/bayesian_linear.py def log_prior ( self ): \"\"\"Evaluate the likelihood of the provided samples of parameter under the current prior distribution.\"\"\" assert self . num_seeds is not None , 'run BayesianLinear.rsample() or dsample() first to sample weight and bias.' num_seeds = self . W_sample . shape [ 0 ] total_log_prob = torch . zeros ( num_seeds , device = self . device ) # log P(W_sample). shape = (num_seeds,) W_prior = Normal ( loc = self . W_prior_mean , scale = torch . exp ( self . W_prior_logstd )) total_log_prob += W_prior . log_prob ( self . W_sample ) . sum ( dim = [ 1 , 2 ]) # log P(b_sample) if applicable. if self . bias : b_prior = Normal ( loc = self . b_prior_mean , scale = torch . exp ( self . b_prior_logstd )) total_log_prob += b_prior . log_prob ( self . b_sample ) . sum ( dim = 1 ) assert total_log_prob . shape == ( num_seeds ,) return total_log_prob","title":"log_prior()"},{"location":"api_bemb/#bemb.model.bayesian_linear.BayesianLinear.log_variational","text":"Evaluate the likelihood of the provided samples of parameter under the current variational distribution. Source code in bemb/model/bayesian_linear.py def log_variational ( self ): \"\"\"Evaluate the likelihood of the provided samples of parameter under the current variational distribution.\"\"\" assert self . num_seeds is not None , 'run BayesianLinear.rsample() or dsample() first to sample weight and bias.' num_seeds = self . W_sample . shape [ 0 ] total_log_prob = torch . zeros ( num_seeds , device = self . device ) total_log_prob += self . W_variational_distribution . log_prob ( self . W_sample ) . sum ( dim = [ 1 , 2 ]) if self . bias : total_log_prob += self . b_variational_distribution . log_prob ( self . b_sample ) . sum ( dim = 1 ) assert total_log_prob . shape == ( num_seeds ,) return total_log_prob","title":"log_variational()"},{"location":"api_bemb/#bemb.model.bayesian_linear.BayesianLinear.rsample","text":"sample all parameters using re-parameterization trick. Source code in bemb/model/bayesian_linear.py def rsample ( self , num_seeds : int = 1 ) -> Optional [ Tuple [ torch . Tensor , Optional [ torch . Tensor ]]]: \"\"\"sample all parameters using re-parameterization trick. \"\"\" self . num_seeds = num_seeds self . W_sample = self . W_variational_distribution . rsample ( torch . Size ([ num_seeds ])) if self . bias : self . b_sample = self . b_variational_distribution . rsample ( torch . Size ([ num_seeds ])) return self . W_sample , self . b_sample","title":"rsample()"},{"location":"api_bemb/#bemb.model.bemb","text":"The core class of the Bayesian EMBedding (BEMB) model. Author: Tianyu Du Update: Apr. 28, 2022","title":"bemb"},{"location":"api_bemb/#bemb.model.bemb.BEMBFlex","text":"Source code in bemb/model/bemb.py class BEMBFlex ( nn . Module ): # ================================================================================================================== # core function as a PyTorch module. # ================================================================================================================== def __init__ ( self , utility_formula : str , obs2prior_dict : Dict [ str , bool ], coef_dim_dict : Dict [ str , int ], num_items : int , pred_item : bool , prior_mean : Union [ float , Dict [ str , float ]] = 0.0 , default_prior_mean : float = 0.0 , prior_variance : Union [ float , Dict [ str , float ]] = 1.0 , num_users : Optional [ int ] = None , num_sessions : Optional [ int ] = None , trace_log_q : bool = False , category_to_item : Dict [ int , List [ int ]] = None , # number of observables. num_user_obs : Optional [ int ] = None , num_item_obs : Optional [ int ] = None , num_session_obs : Optional [ int ] = None , num_price_obs : Optional [ int ] = None , num_taste_obs : Optional [ int ] = None , # additional modules. additional_modules : Optional [ List [ nn . Module ]] = None ) -> None : \"\"\" Args: utility_formula (str): a string representing the utility function U[user, item, session]. See documentation for more details in the documentation for the format of formula. Examples: lambda_item lambda_item + theta_user * alpha_item + zeta_user * item_obs lambda_item + theta_user * alpha_item + gamma_user * beta_item * price_obs See the doc-string of parse_utility for an example. obs2prior_dict (Dict[str, bool]): a dictionary maps coefficient name (e.g., 'lambda_item') to a boolean indicating if observable (e.g., item_obs) enters the prior of the coefficient. coef_dim_dict (Dict[str, int]): a dictionary maps coefficient name (e.g., 'lambda_item') to an integer indicating the dimension of coefficient. For standalone coefficients like U = lambda_item, the dim should be 1. For factorized coefficients like U = theta_user * alpha_item, the dim should be the latent dimension of theta and alpha. For coefficients multiplied with observables like U = zeta_user * item_obs, the dim should be the number of observables in item_obs. For factorized coefficient multiplied with observables like U = gamma_user * beta_item * price_obs, the dim should be the latent dim multiplied by number of observables in price_obs. num_items (int): number of items. pred_item (bool): there are two use cases of this model, suppose we have `user_index[i]` and `item_index[i]` for the i-th observation in the dataset. Case 1: which item among all items user `user_index[i]` is going to purchase, the prediction label is therefore `item_index[i]`. Equivalently, we can ask what's the likelihood for user `user_index[i]` to purchase `item_index[i]`. Case 2: what rating would user `user_index[i]` assign to item `item_index[i]`? In this case, the dataset object needs to contain a separate label. NOTE: for now, we only support binary labels. default_prior_mean (float): the default prior mean for coefficients, if it is not specified in the prior_mean; defaults to 0.0. prior_mean (Union[float, Dict[str, float]]): the mean of prior distribution for coefficients. If a float is provided, all prior mean will be diagonal matrix with the provided value. If a dictionary is provided, keys of prior_mean should be coefficient names, and the mean of prior of coef_name would the provided value Defaults to 0.0, which means all prior means are initalized to 0.0 prior_variance (Union[float, Dict[str, float]]): the variance of prior distribution for coefficients. If a float is provided, all priors will be diagonal matrix with prior_variance along the diagonal. If a dictionary is provided, keys of prior_variance should be coefficient names, and the variance of prior of coef_name would be a diagonal matrix with prior_variance[coef_name] along the diagonal. Defaults to 1.0, which means all prior have identity matrix as the covariance matrix. num_users (int, optional): number of users, required only if coefficient or observable depending on user is in utility. Defaults to None. num_sessions (int, optional): number of sessions, required only if coefficient or observable depending on session is in utility. Defaults to None. trace_log_q (bool, optional): whether to trace the derivative of variational likelihood logQ with respect to variational parameters in the ELBO while conducting gradient update. Defaults to False. category_to_item (Dict[str, List[int]], optional): a dictionary with category id or name as keys, and category_to_item[C] contains the list of item ids belonging to category C. If None is provided, all items are assumed to be in the same category. Defaults to None. num_{user, item, session, price, taste}_obs (int, optional): number of observables of each type of features, only required if observable enters prior. NOTE: currently we only allow coefficient to depend on either user or item, thus only user and item observables can enter the prior of coefficient. Hence session, price, and taste observables are never required, we include it here for completeness. \"\"\" super ( BEMBFlex , self ) . __init__ () self . utility_formula = utility_formula self . obs2prior_dict = obs2prior_dict self . coef_dim_dict = coef_dim_dict self . prior_variance = prior_variance self . default_prior_mean = default_prior_mean self . prior_mean = prior_mean self . pred_item = pred_item self . num_items = num_items self . num_users = num_users self . num_sessions = num_sessions self . trace_log_q = trace_log_q self . category_to_item = category_to_item # ============================================================================================================== # Category ID to Item ID mapping. # Category ID to Category Size mapping. # Item ID to Category ID mapping. # ============================================================================================================== if self . category_to_item is None : if self . pred_item : # assign all items to the same category if predicting items. self . category_to_item = { 0 : list ( np . arange ( self . num_items ))} else : # otherwise, for the j-th observation in the dataset, the label[j] # only depends on user_index[j] and item_index[j], so we put each # item to its own category. self . category_to_item = { i : [ i ] for i in range ( self . num_items )} self . num_categories = len ( self . category_to_item ) max_category_size = max ( len ( x ) for x in self . category_to_item . values ()) category_to_item_tensor = torch . full ( ( self . num_categories , max_category_size ), - 1 ) category_to_size_tensor = torch . empty ( self . num_categories ) for c , item_in_c in self . category_to_item . items (): category_to_item_tensor [ c , : len ( item_in_c )] = torch . LongTensor ( item_in_c ) category_to_size_tensor [ c ] = torch . scalar_tensor ( len ( item_in_c )) self . register_buffer ( 'category_to_item_tensor' , category_to_item_tensor . long ()) self . register_buffer ( 'category_to_size_tensor' , category_to_size_tensor . long ()) item_to_category_tensor = torch . zeros ( self . num_items ) for c , items_in_c in self . category_to_item . items (): item_to_category_tensor [ items_in_c ] = c self . register_buffer ( 'item_to_category_tensor' , item_to_category_tensor . long ()) # ============================================================================================================== # Create Bayesian Coefficient Objects # ============================================================================================================== # model configuration. self . formula = parse_utility ( utility_formula ) print ( 'BEMB: utility formula parsed:' ) pprint ( self . formula ) self . raw_formula = utility_formula self . obs2prior_dict = obs2prior_dict # dimension of each observable, this one is used only for obs2prior. self . num_obs_dict = { 'user' : num_user_obs , 'item' : num_item_obs , 'category' : 0 , 'session' : num_session_obs , 'price' : num_price_obs , 'taste' : num_taste_obs , 'constant' : 1 # not really used, for dummy variables. } # how many classes for the variational distribution. # for example, beta_item would be `num_items` 10-dimensional gaussian if latent dim = 10. variation_to_num_classes = { 'user' : self . num_users , 'item' : self . num_items , 'constant' : 1 , 'category' : self . num_categories , } coef_dict = dict () for additive_term in self . formula : for coef_name in additive_term [ 'coefficient' ]: variation = coef_name . split ( '_' )[ - 1 ] mean = self . prior_mean [ coef_name ] if isinstance ( self . prior_mean , dict ) else self . default_prior_mean s2 = self . prior_variance [ coef_name ] if isinstance ( self . prior_variance , dict ) else self . prior_variance coef_dict [ coef_name ] = BayesianCoefficient ( variation = variation , num_classes = variation_to_num_classes [ variation ], obs2prior = self . obs2prior_dict [ coef_name ], num_obs = self . num_obs_dict [ variation ], dim = self . coef_dim_dict [ coef_name ], prior_mean = mean , prior_variance = s2 ) self . coef_dict = nn . ModuleDict ( coef_dict ) # ============================================================================================================== # Optional: register additional modules. # ============================================================================================================== if additional_modules is None : self . additional_modules = [] else : raise NotImplementedError ( 'Additional modules are temporarily disabled for further development.' ) self . additional_modules = nn . ModuleList ( additional_modules ) def __str__ ( self ): return f 'Bayesian EMBedding Model with U[user, item, session] = { self . raw_formula } \\n ' \\ + f 'Total number of parameters: { self . num_params } . \\n ' \\ + 'With the following coefficients: \\n ' \\ + str ( self . coef_dict ) + ' \\n ' \\ + str ( self . additional_modules ) def posterior_mean ( self , coef_name : str ) -> torch . Tensor : \"\"\"Returns the mean of estimated posterior distribution of coefficient `coef_name`. Args: coef_name (str): name of the coefficient to query. Returns: torch.Tensor: mean of the estimated posterior distribution of `coef_name`. \"\"\" if coef_name in self . coef_dict . keys (): return self . coef_dict [ coef_name ] . variational_mean else : raise KeyError ( f ' { coef_name } is not a valid coefficient name in { self . utility_formula } .' ) def ivs ( self , batch ) -> torch . Tensor : \"\"\"The combined method of computing utilities and log probability. Args: batch (dict): a batch of data. Returns: torch.Tensor: the combined utility and log probability. \"\"\" # Use the means of variational distributions as the sole MC sample. sample_dict = dict () for coef_name , coef in self . coef_dict . items (): sample_dict [ coef_name ] = coef . variational_distribution . mean . unsqueeze ( dim = 0 ) # (1, num_*, dim) # there is 1 random seed in this case. # (num_seeds=1, len(batch), num_items) out = self . log_likelihood_all_items ( batch , return_logit = True , sample_dict = sample_dict ) out = out . squeeze ( 0 ) # import pdb; pdb.set_trace() ivs = scatter_logsumexp ( out , self . item_to_category_tensor , dim =- 1 ) return ivs # (len(batch), num_categories) def sample_choices ( self , batch : ChoiceDataset , debug : bool = False , num_seeds : int = 1 , ** kwargs ) -> Tuple [ torch . Tensor ]: \"\"\"Samples choices given model paramaters and trips Args: batch(ChoiceDataset): batch data containing trip information; item choice information is discarded debug(bool): whether to print debug information Returns: Tuple[torch.Tensor]: sampled choices; shape: (batch_size, num_categories) \"\"\" # Use the means of variational distributions as the sole MC sample. sample_dict = dict () for coef_name , coef in self . coef_dict . items (): sample_dict [ coef_name ] = coef . variational_distribution . mean . unsqueeze ( dim = 0 ) # (1, num_*, dim) # sample_dict = self.sample_coefficient_dictionary(num_seeds) maxes , out = self . sample_log_likelihoods ( batch , sample_dict ) return maxes . squeeze (), out . squeeze () def sample_log_likelihoods ( self , batch : ChoiceDataset , sample_dict : Dict [ str , torch . Tensor ]) -> Tuple [ torch . Tensor , torch . Tensor ]: \"\"\"Samples log likelihoods given model paramaters and trips Args: batch(ChoiceDataset): batch data containing trip information; item choice information is discarded sample_dict(Dict[str, torch.Tensor]): sampled coefficient values Returns: Tuple[torch.Tensor]: sampled log likelihoods; shape: (batch_size, num_categories) \"\"\" # get the log likelihoods for all items for all categories utility = self . log_likelihood_all_items ( batch , return_logit = True , sample_dict = sample_dict ) mu_gumbel = 0.0 beta_gumbel = 1.0 EUL_MAS_CONST = 0.5772156649 mean_gumbel = torch . tensor ([ mu_gumbel + beta_gumbel * EUL_MAS_CONST ], device = self . device ) m = torch . distributions . gumbel . Gumbel ( torch . tensor ([ 0.0 ], device = self . device ), torch . tensor ([ 1.0 ], device = self . device )) # m = torch.distributions.gumbel.Gumbel(0.0, 1.0) gumbel_samples = m . sample ( utility . shape ) . squeeze ( - 1 ) gumbel_samples -= mean_gumbel utility += gumbel_samples max_by_category , argmax_by_category = scatter_max ( utility , self . item_to_category_tensor , dim =- 1 ) return max_by_category , argmax_by_category log_likelihoods = self . sample_log_likelihoods_per_category ( batch , sample_dict ) # sum over all categories. log_likelihoods = log_likelihoods . sum ( dim = 1 ) return log_likelihoods , log_likelihoods def forward ( self , batch : ChoiceDataset , return_type : str , return_scope : str , deterministic : bool = True , sample_dict : Optional [ Dict [ str , torch . Tensor ]] = None , num_seeds : Optional [ int ] = None ) -> torch . Tensor : \"\"\"A combined method for inference with the model. Args: batch (ChoiceDataset): batch data containing choice information. return_type (str): either 'log_prob' or 'utility'. 'log_prob': return the log-probability (by within-category log-softmax) for items 'utility': return the utility value of items. return_scope (str): either 'item_index' or 'all_items'. 'item_index': for each observation i, return log-prob/utility for the chosen item batch.item_index[i] only. 'all_items': for each observation i, return log-prob/utility for all items. deterministic (bool, optional): True: expectations of parameter variational distributions are used for inference. False: the user needs to supply a dictionary of sampled parameters for inference. Defaults to True. sample_dict (Optional[Dict[str, torch.Tensor]], optional): sampled parameters for inference task. This is not needed when `deterministic` is True. When `deterministic` is False, the user can supply a `sample_dict`. If `sample_dict` is not provided, this method will create `num_seeds` samples. Defaults to None. num_seeds (Optional[int]): the number of random samples of parameters to construct. This is only required if `deterministic` is False (i.e., stochastic mode) and `sample_dict` is not provided. Defaults to None. Returns: torch.Tensor: a tensor of log-probabilities or utilities, depending on `return_type`. The shape of the returned tensor depends on `return_scope` and `deterministic`. ------------------------------------------------------------------------- | `return_scope` | `deterministic` | Output shape | ------------------------------------------------------------------------- | 'item_index` | True | (len(batch),) | ------------------------------------------------------------------------- | 'all_items' | True | (len(batch), num_items) | ------------------------------------------------------------------------- | 'item_index' | False | (num_seeds, len(batch)) | ------------------------------------------------------------------------- | 'all_items' | False | (num_seeds, len(batch), num_items) | ------------------------------------------------------------------------- \"\"\" # ============================================================================================================== # check arguments. # ============================================================================================================== assert return_type in [ 'log_prob' , 'utility' ], \"return_type must be either 'log_prob' or 'utility'.\" assert return_scope in [ 'item_index' , 'all_items' ], \"return_scope must be either 'item_index' or 'all_items'.\" assert deterministic in [ True , False ] if ( not deterministic ) and ( sample_dict is None ): assert num_seeds >= 1 , \"A positive interger `num_seeds` is required if `deterministic` is False and no `sample_dict` is provided.\" # when pred_item is true, the model is predicting which item is bought (specified by item_index). if self . pred_item : batch . label = batch . item_index # ============================================================================================================== # get sample_dict ready. # ============================================================================================================== if deterministic : num_seeds = 1 # Use the means of variational distributions as the sole deterministic MC sample. # NOTE: here we don't need to sample the obs2prior weight H since we only compute the log-likelihood. # TODO: is this correct? sample_dict = dict () for coef_name , coef in self . coef_dict . items (): sample_dict [ coef_name ] = coef . variational_distribution . mean . unsqueeze ( dim = 0 ) # (1, num_*, dim) else : if sample_dict is None : # sample stochastic parameters. sample_dict = self . sample_coefficient_dictionary ( num_seeds ) else : # use the provided sample_dict. num_seeds = list ( sample_dict . values ())[ 0 ] . shape [ 0 ] # ============================================================================================================== # call the sampling method of additional modules. # ============================================================================================================== for module in self . additional_modules : # deterministic sample. if deterministic : module . dsample () else : module . rsample ( num_seeds = num_seeds ) # if utility is requested, don't run log-softmax, simply return logit. return_logit = ( return_type == 'utility' ) if return_scope == 'all_items' : # (num_seeds, len(batch), num_items) out = self . log_likelihood_all_items ( batch = batch , sample_dict = sample_dict , return_logit = return_logit ) elif return_scope == 'item_index' : # (num_seeds, len(batch)) out = self . log_likelihood_item_index ( batch = batch , sample_dict = sample_dict , return_logit = return_logit ) if deterministic : # drop the first dimension, which has size of `num_seeds` (equals 1 in the deterministic case). # (len(batch), num_items) or (len(batch),) return out . squeeze ( dim = 0 ) return out @property def num_params ( self ) -> int : return sum ([ p . numel () for p in self . parameters ()]) @property def device ( self ) -> torch . device : for coef in self . coef_dict . values (): return coef . device # ================================================================================================================== # helper functions. # ================================================================================================================== def sample_coefficient_dictionary ( self , num_seeds : int ) -> Dict [ str , torch . Tensor ]: \"\"\"A helper function to sample parameters from coefficients. Args: num_seeds (int): number of random samples. Returns: Dict[str, torch.Tensor]: a dictionary maps coefficient names to tensor of sampled coefficient parameters, where the first dimension of the sampled tensor has size `num_seeds`. Each sample tensor has shape (num_seeds, num_classes, dim). \"\"\" sample_dict = dict () for coef_name , coef in self . coef_dict . items (): s = coef . rsample ( num_seeds ) if coef . obs2prior : # sample both obs2prior weight and realization of variable. assert isinstance ( s , tuple ) and len ( s ) == 2 sample_dict [ coef_name ] = s [ 0 ] sample_dict [ coef_name + '.H' ] = s [ 1 ] else : # only sample the realization of variable. assert torch . is_tensor ( s ) sample_dict [ coef_name ] = s return sample_dict @torch . no_grad () def get_within_category_accuracy ( self , log_p_all_items : torch . Tensor , label : torch . LongTensor ) -> Dict [ str , float ]: \"\"\"A helper function for computing prediction accuracy (i.e., all non-differential metrics) within category. In particular, this method calculates the accuracy, precision, recall and F1 score. This method has the same functionality as the following peusodcode: for C in categories: # get sessions in which item in category C was purchased. T <- (t for t in {0,1,..., len(label)-1} if label[t] is in C) Y <- label[T] predictions = list() for t in T: # get the prediction within category for this session. y_pred = argmax_{items in C} log prob computed before. predictions.append(y_pred) accuracy = mean(Y == predictions) Similarly, this function computes precision, recall and f1score as well. Args: log_p_all_items (torch.Tensor): shape (num_sessions, num_items) the log probability of choosing each item in each session. label (torch.LongTensor): shape (num_sessions,), the IDs of items purchased in each session. Returns: [Dict[str, float]]: A dictionary containing performance metrics. \"\"\" # argmax: (num_sessions, num_categories), within category argmax. # item IDs are consecutive, thus argmax is the same as IDs of the item with highest P. _ , argmax_by_category = scatter_max ( log_p_all_items , self . item_to_category_tensor , dim =- 1 ) # category_purchased[t] = the category of item label[t]. # (num_sessions,) category_purchased = self . item_to_category_tensor [ label ] # pred[t] = the item with highest utility from the category item label[t] belongs to. # (num_sessions,) pred_from_category = argmax_by_category [ torch . arange ( len ( label )), category_purchased ] within_category_accuracy = ( pred_from_category == label ) . float () . mean () . item () # precision precision = list () recall = list () for i in range ( self . num_items ): correct_i = torch . sum ( ( torch . logical_and ( pred_from_category == i , label == i )) . float ()) precision_i = correct_i / \\ torch . sum (( pred_from_category == i ) . float ()) recall_i = correct_i / torch . sum (( label == i ) . float ()) # do not add if divided by zero. if torch . any ( pred_from_category == i ): precision . append ( precision_i . cpu () . item ()) if torch . any ( label == i ): recall . append ( recall_i . cpu () . item ()) precision = float ( np . mean ( precision )) recall = float ( np . mean ( recall )) if precision == recall == 0 : f1 = 0 else : f1 = 2 * precision * recall / ( precision + recall ) return { 'accuracy' : within_category_accuracy , 'precision' : precision , 'recall' : recall , 'f1score' : f1 } # ================================================================================================================== # Methods for terms in the ELBO: prior, likelihood, and variational. # ================================================================================================================== def log_likelihood_all_items ( self , batch : ChoiceDataset , return_logit : bool , sample_dict : Dict [ str , torch . Tensor ]) -> torch . Tensor : \"\"\" NOTE to developers: NOTE (akanodia to tianyudu): Is this really slow; even with log_likelihood you need log_prob which depends on logits of all items? This method computes utilities for all items available, which is a relatively slow operation. For training the model, you only need the utility/log-prob for the chosen/relevant item (i.e., item_index[i] for each i-th observation). Use this method for inference only. Use self.log_likelihood_item_index() for training instead. Computes the log probability of choosing `each` item in each session based on current model parameters. NOTE (akanodiadu to tianyudu): What does the next line mean? I think it just says its allowing for samples instead of posterior mean. This method allows for specifying {user, item}_latent_value for Monte Carlo estimation in ELBO. For actual prediction tasks, use the forward() function, which will use means of variational distributions for user and item latents. Args: batch (ChoiceDataset): a ChoiceDataset object containing relevant information. return_logit(bool): if set to True, return the log-probability, otherwise return the logit/utility. sample_dict(Dict[str, torch.Tensor]): Monte Carlo samples for model coefficients (i.e., those Greek letters). sample_dict.keys() should be the same as keys of self.obs2prior_dict, i.e., those greek letters actually enter the functional form of utility. The value of sample_dict should be tensors of shape (num_seeds, num_classes, dim) where num_classes in {num_users, num_items, 1} and dim in {latent_dim(K), num_item_obs, num_user_obs, 1}. Returns: torch.Tensor: a tensor of shape (num_seeds, len(batch), self.num_items), where out[x, y, z] is the probability of choosing item z in session y conditioned on latents to be the x-th Monte Carlo sample. \"\"\" num_seeds = next ( iter ( sample_dict . values ())) . shape [ 0 ] # avoid repeated work when user purchased several items in the same session. user_session_index = torch . stack ( [ batch . user_index , batch . session_index ]) assert user_session_index . shape == ( 2 , len ( batch )) unique_user_sess , inverse_indices = torch . unique ( user_session_index , dim = 1 , return_inverse = True ) user_index = unique_user_sess [ 0 , :] session_index = unique_user_sess [ 1 , :] assert len ( user_index ) == len ( session_index ) # short-hands for easier shape check. R = num_seeds # P = len(batch) # num_purchases. P = unique_user_sess . shape [ 1 ] S = self . num_sessions U = self . num_users I = self . num_items NC = self . num_categories # ============================================================================================================== # Helper Functions for Reshaping. # ============================================================================================================== def reshape_user_coef_sample ( C ): # input shape (R, U, *) C = C . view ( R , U , 1 , - 1 ) . expand ( - 1 , - 1 , I , - 1 ) # (R, U, I, *) C = C [:, user_index , :, :] assert C . shape == ( R , P , I , positive_integer ) return C def reshape_item_coef_sample ( C ): # input shape (R, I, *) C = C . view ( R , 1 , I , - 1 ) . expand ( - 1 , P , - 1 , - 1 ) assert C . shape == ( R , P , I , positive_integer ) return C def reshape_category_coef_sample ( C ): # input shape (R, NC, *) C = torch . repeat_interleave ( C , self . category_to_size_tensor , dim = 1 ) # input shape (R, I, *) C = C . view ( R , 1 , I , - 1 ) . expand ( - 1 , P , - 1 , - 1 ) assert C . shape == ( R , P , I , positive_integer ) return C def reshape_constant_coef_sample ( C ): # input shape (R, *) C = C . view ( R , 1 , 1 , - 1 ) . expand ( - 1 , P , I , - 1 ) assert C . shape == ( R , P , I , positive_integer ) return C def reshape_coef_sample ( sample , name ): # reshape the monte carlo sample of coefficients to (R, P, I, *). if name . endswith ( '_user' ): # (R, U, *) --> (R, P, I, *) return reshape_user_coef_sample ( sample ) elif name . endswith ( '_item' ): # (R, I, *) --> (R, P, I, *) return reshape_item_coef_sample ( sample ) elif name . endswith ( '_category' ): # (R, NC, *) --> (R, P, NC, *) return reshape_category_coef_sample ( sample ) elif name . endswith ( '_constant' ): # (R, *) --> (R, P, I, *) return reshape_constant_coef_sample ( sample ) else : raise ValueError def reshape_observable ( obs , name ): # reshape observable to (R, P, I, *) so that it can be multiplied with monte carlo # samples of coefficients. O = obs . shape [ - 1 ] # number of observables. assert O == positive_integer if name . startswith ( 'item_' ): assert obs . shape == ( I , O ) obs = obs . view ( 1 , 1 , I , O ) . expand ( R , P , - 1 , - 1 ) elif name . startswith ( 'user_' ): assert obs . shape == ( U , O ) obs = obs [ user_index , :] # (P, O) obs = obs . view ( 1 , P , 1 , O ) . expand ( R , - 1 , I , - 1 ) elif name . startswith ( 'session_' ): assert obs . shape == ( S , O ) obs = obs [ session_index , :] # (P, O) return obs . view ( 1 , P , 1 , O ) . expand ( R , - 1 , I , - 1 ) elif name . startswith ( 'price_' ): assert obs . shape == ( S , I , O ) obs = obs [ session_index , :, :] # (P, I, O) return obs . view ( 1 , P , I , O ) . expand ( R , - 1 , - 1 , - 1 ) elif name . startswith ( 'taste_' ): assert obs . shape == ( U , I , O ) obs = obs [ user_index , :, :] # (P, I, O) return obs . view ( 1 , P , I , O ) . expand ( R , - 1 , - 1 , - 1 ) else : raise ValueError assert obs . shape == ( R , P , I , O ) return obs # ============================================================================================================== # Copmute the Utility Term by Term. # ============================================================================================================== # P is the number of unique (user, session) pairs. # (random_seeds, P, num_items). utility = torch . zeros ( R , P , I , device = self . device ) # loop over additive term to utility for term in self . formula : # Type I: single coefficient, e.g., lambda_item or lambda_user. if len ( term [ 'coefficient' ]) == 1 and term [ 'observable' ] is None : # E.g., lambda_item or lambda_user coef_name = term [ 'coefficient' ][ 0 ] coef_sample = reshape_coef_sample ( sample_dict [ coef_name ], coef_name ) assert coef_sample . shape == ( R , P , I , 1 ) additive_term = coef_sample . view ( R , P , I ) # Type II: factorized coefficient, e.g., <theta_user, lambda_item>. elif len ( term [ 'coefficient' ]) == 2 and term [ 'observable' ] is None : coef_name_0 = term [ 'coefficient' ][ 0 ] coef_name_1 = term [ 'coefficient' ][ 1 ] coef_sample_0 = reshape_coef_sample ( sample_dict [ coef_name_0 ], coef_name_0 ) coef_sample_1 = reshape_coef_sample ( sample_dict [ coef_name_1 ], coef_name_1 ) assert coef_sample_0 . shape == coef_sample_1 . shape == ( R , P , I , positive_integer ) additive_term = ( coef_sample_0 * coef_sample_1 ) . sum ( dim =- 1 ) # Type III: single coefficient multiplied by observable, e.g., theta_user * x_obs_item. elif len ( term [ 'coefficient' ]) == 1 and term [ 'observable' ] is not None : coef_name = term [ 'coefficient' ][ 0 ] coef_sample = reshape_coef_sample ( sample_dict [ coef_name ], coef_name ) assert coef_sample . shape == ( R , P , I , positive_integer ) obs_name = term [ 'observable' ] obs = reshape_observable ( getattr ( batch , obs_name ), obs_name ) assert obs . shape == ( R , P , I , positive_integer ) additive_term = ( coef_sample * obs ) . sum ( dim =- 1 ) # Type IV: factorized coefficient multiplied by observable. # e.g., gamma_user * beta_item * price_obs. elif len ( term [ 'coefficient' ]) == 2 and term [ 'observable' ] is not None : coef_name_0 , coef_name_1 = term [ 'coefficient' ][ 0 ], term [ 'coefficient' ][ 1 ] coef_sample_0 = reshape_coef_sample ( sample_dict [ coef_name_0 ], coef_name_0 ) coef_sample_1 = reshape_coef_sample ( sample_dict [ coef_name_1 ], coef_name_1 ) assert coef_sample_0 . shape == coef_sample_1 . shape == ( R , P , I , positive_integer ) num_obs_times_latent_dim = coef_sample_0 . shape [ - 1 ] obs_name = term [ 'observable' ] obs = reshape_observable ( getattr ( batch , obs_name ), obs_name ) assert obs . shape == ( R , P , I , positive_integer ) num_obs = obs . shape [ - 1 ] # number of observables. assert ( num_obs_times_latent_dim % num_obs ) == 0 latent_dim = num_obs_times_latent_dim // num_obs coef_sample_0 = coef_sample_0 . view ( R , P , I , num_obs , latent_dim ) coef_sample_1 = coef_sample_1 . view ( R , P , I , num_obs , latent_dim ) # compute the factorized coefficient with shape (R, P, I, O). coef = ( coef_sample_0 * coef_sample_1 ) . sum ( dim =- 1 ) additive_term = ( coef * obs ) . sum ( dim =- 1 ) else : raise ValueError ( f 'Undefined term type: { term } ' ) assert additive_term . shape == ( R , P , I ) utility += additive_term # ============================================================================================================== # Mask Out Unavailable Items in Each Session. # ============================================================================================================== if batch . item_availability is not None : # expand to the Monte Carlo sample dimension. # (S, I) -> (P, I) -> (1, P, I) -> (R, P, I) A = batch . item_availability [ session_index , :] . unsqueeze ( dim = 0 ) . expand ( R , - 1 , - 1 ) utility [ ~ A ] = - ( torch . finfo ( utility . dtype ) . max / 2 ) utility = utility [:, inverse_indices , :] assert utility . shape == ( R , len ( batch ), I ) for module in self . additional_modules : additive_term = module ( batch ) assert additive_term . shape == ( R , len ( batch ), 1 ) utility += additive_term . expand ( - 1 , - 1 , I ) if return_logit : # output shape: (num_seeds, len(batch), num_items) return utility else : # compute log likelihood log p(choosing item i | user, item latents) # compute log softmax separately within each category. if self . pred_item : # output shape: (num_seeds, len(batch), num_items) log_p = scatter_log_softmax ( utility , self . item_to_category_tensor , dim =- 1 ) else : log_p = torch . nn . functional . logsigmoid ( utility ) return log_p def log_likelihood_item_index ( self , batch : ChoiceDataset , return_logit : bool , sample_dict : Dict [ str , torch . Tensor ]) -> torch . Tensor : \"\"\" NOTE for developers: This method is more efficient and only computes log-likelihood/logit(utility) for item in item_index[i] for each i-th observation. Developers should use use `log_likelihood_all_items` for inference purpose and to computes log-likelihoods/utilities for ALL items for the i-th observation. Computes the log probability of choosing item_index[i] in each session based on current model parameters. This method allows for specifying {user, item}_latent_value for Monte Carlo estimation in ELBO. For actual prediction tasks, use the forward() function, which will use means of variational distributions for user and item latents. Args: batch (ChoiceDataset): a ChoiceDataset object containing relevant information. return_logit(bool): if set to True, return the log-probability, otherwise return the logit/utility. sample_dict(Dict[str, torch.Tensor]): Monte Carlo samples for model coefficients (i.e., those Greek letters). sample_dict.keys() should be the same as keys of self.obs2prior_dict, i.e., those greek letters actually enter the functional form of utility. The value of sample_dict should be tensors of shape (num_seeds, num_classes, dim) where num_classes in {num_users, num_items, 1} and dim in {latent_dim(K), num_item_obs, num_user_obs, 1}. Returns: torch.Tensor: a tensor of shape (num_seeds, len(batch)), where out[x, y] is the probabilities of choosing item batch.item[y] in session y conditioned on latents to be the x-th Monte Carlo sample. \"\"\" num_seeds = next ( iter ( sample_dict . values ())) . shape [ 0 ] # get category id of the item bought in each row of batch. cate_index = self . item_to_category_tensor [ batch . item_index ] # get item ids of all items from the same category of each item bought. relevant_item_index = self . category_to_item_tensor [ cate_index , :] relevant_item_index = relevant_item_index . view ( - 1 ,) # index were padded with -1's, drop those dummy entries. relevant_item_index = relevant_item_index [ relevant_item_index != - 1 ] # the first repeats[0] entries in relevant_item_index are for the category of item_index[0] repeats = self . category_to_size_tensor [ cate_index ] # argwhere(reverse_indices == k) are positions in relevant_item_index for the category of item_index[k]. reverse_indices = torch . repeat_interleave ( torch . arange ( len ( batch ), device = self . device ), repeats ) # expand the user_index and session_index. user_index = torch . repeat_interleave ( batch . user_index , repeats ) repeat_category_index = torch . repeat_interleave ( cate_index , repeats ) session_index = torch . repeat_interleave ( batch . session_index , repeats ) # duplicate the item focused to match. item_index_expanded = torch . repeat_interleave ( batch . item_index , repeats ) # short-hands for easier shape check. R = num_seeds # total number of relevant items. total_computation = len ( session_index ) S = self . num_sessions U = self . num_users I = self . num_items NC = self . num_categories # ========================================================================================== # Helper Functions for Reshaping. # ========================================================================================== def reshape_coef_sample ( sample , name ): # reshape the monte carlo sample of coefficients to (R, P, I, *). if name . endswith ( '_user' ): # (R, U, *) --> (R, total_computation, *) return sample [:, user_index , :] elif name . endswith ( '_item' ): # (R, I, *) --> (R, total_computation, *) return sample [:, relevant_item_index , :] elif name . endswith ( '_category' ): # (R, NC, *) --> (R, total_computation, *) return sample [:, repeat_category_index , :] elif name . endswith ( '_constant' ): # (R, *) --> (R, total_computation, *) return sample . view ( R , 1 , - 1 ) . expand ( - 1 , total_computation , - 1 ) else : raise ValueError def reshape_observable ( obs , name ): # reshape observable to (R, P, I, *) so that it can be multiplied with monte carlo # samples of coefficients. O = obs . shape [ - 1 ] # number of observables. assert O == positive_integer if name . startswith ( 'item_' ): assert obs . shape == ( I , O ) obs = obs [ relevant_item_index , :] elif name . startswith ( 'user_' ): assert obs . shape == ( U , O ) obs = obs [ user_index , :] elif name . startswith ( 'session_' ): assert obs . shape == ( S , O ) obs = obs [ session_index , :] elif name . startswith ( 'price_' ): assert obs . shape == ( S , I , O ) obs = obs [ session_index , relevant_item_index , :] elif name . startswith ( 'taste_' ): assert obs . shape == ( U , I , O ) obs = obs [ user_index , relevant_item_index , :] else : raise ValueError assert obs . shape == ( total_computation , O ) return obs . unsqueeze ( dim = 0 ) . expand ( R , - 1 , - 1 ) # ========================================================================================== # Compute Components related to users and items only. # ========================================================================================== utility = torch . zeros ( R , total_computation , device = self . device ) # loop over additive term to utility for term in self . formula : # Type I: single coefficient, e.g., lambda_item or lambda_user. if len ( term [ 'coefficient' ]) == 1 and term [ 'observable' ] is None : # E.g., lambda_item or lambda_user coef_name = term [ 'coefficient' ][ 0 ] coef_sample = reshape_coef_sample ( sample_dict [ coef_name ], coef_name ) assert coef_sample . shape == ( R , total_computation , 1 ) additive_term = coef_sample . view ( R , total_computation ) # Type II: factorized coefficient, e.g., <theta_user, lambda_item>. elif len ( term [ 'coefficient' ]) == 2 and term [ 'observable' ] is None : coef_name_0 = term [ 'coefficient' ][ 0 ] coef_name_1 = term [ 'coefficient' ][ 1 ] coef_sample_0 = reshape_coef_sample ( sample_dict [ coef_name_0 ], coef_name_0 ) coef_sample_1 = reshape_coef_sample ( sample_dict [ coef_name_1 ], coef_name_1 ) assert coef_sample_0 . shape == coef_sample_1 . shape == ( R , total_computation , positive_integer ) additive_term = ( coef_sample_0 * coef_sample_1 ) . sum ( dim =- 1 ) # Type III: single coefficient multiplied by observable, e.g., theta_user * x_obs_item. elif len ( term [ 'coefficient' ]) == 1 and term [ 'observable' ] is not None : coef_name = term [ 'coefficient' ][ 0 ] coef_sample = reshape_coef_sample ( sample_dict [ coef_name ], coef_name ) assert coef_sample . shape == ( R , total_computation , positive_integer ) obs_name = term [ 'observable' ] obs = reshape_observable ( getattr ( batch , obs_name ), obs_name ) assert obs . shape == ( R , total_computation , positive_integer ) additive_term = ( coef_sample * obs ) . sum ( dim =- 1 ) # Type IV: factorized coefficient multiplied by observable. # e.g., gamma_user * beta_item * price_obs. elif len ( term [ 'coefficient' ]) == 2 and term [ 'observable' ] is not None : coef_name_0 , coef_name_1 = term [ 'coefficient' ][ 0 ], term [ 'coefficient' ][ 1 ] coef_sample_0 = reshape_coef_sample ( sample_dict [ coef_name_0 ], coef_name_0 ) coef_sample_1 = reshape_coef_sample ( sample_dict [ coef_name_1 ], coef_name_1 ) assert coef_sample_0 . shape == coef_sample_1 . shape == ( R , total_computation , positive_integer ) num_obs_times_latent_dim = coef_sample_0 . shape [ - 1 ] obs_name = term [ 'observable' ] obs = reshape_observable ( getattr ( batch , obs_name ), obs_name ) assert obs . shape == ( R , total_computation , positive_integer ) num_obs = obs . shape [ - 1 ] # number of observables. assert ( num_obs_times_latent_dim % num_obs ) == 0 latent_dim = num_obs_times_latent_dim // num_obs coef_sample_0 = coef_sample_0 . view ( R , total_computation , num_obs , latent_dim ) coef_sample_1 = coef_sample_1 . view ( R , total_computation , num_obs , latent_dim ) # compute the factorized coefficient with shape (R, P, I, O). coef = ( coef_sample_0 * coef_sample_1 ) . sum ( dim =- 1 ) additive_term = ( coef * obs ) . sum ( dim =- 1 ) else : raise ValueError ( f 'Undefined term type: { term } ' ) assert additive_term . shape == ( R , total_computation ) utility += additive_term # ========================================================================================== # Mask Out Unavailable Items in Each Session. # ========================================================================================== if batch . item_availability is not None : # expand to the Monte Carlo sample dimension. A = batch . item_availability [ session_index , relevant_item_index ] . unsqueeze ( dim = 0 ) . expand ( R , - 1 ) utility [ ~ A ] = - ( torch . finfo ( utility . dtype ) . max / 2 ) for module in self . additional_modules : # current utility shape: (R, total_computation) additive_term = module ( batch ) assert additive_term . shape == ( R , len ( batch )) or additive_term . shape == ( R , len ( batch ), 1 ) if additive_term . shape == ( R , len ( batch ), 1 ): # TODO: need to make this consistent with log_likelihood_all. # be tolerant for some customized module with BayesianLinear that returns (R, len(batch), 1). additive_term = additive_term . view ( R , len ( batch )) # expand to total number of computation, query by reverse_indices. # reverse_indices has length total_computation, and reverse_indices[i] correspond to the row-id that this # computation is responsible for. additive_term = additive_term [:, reverse_indices ] assert additive_term . shape == ( R , total_computation ) # compute log likelihood log p(choosing item i | user, item latents) if return_logit : log_p = utility else : if self . pred_item : # compute the log probability from logits/utilities. # output shape: (num_seeds, len(batch), num_items) log_p = scatter_log_softmax ( utility , reverse_indices , dim =- 1 ) # select the log-P of the item actually bought. log_p = log_p [:, item_index_expanded == relevant_item_index ] else : # This is the binomial choice situation in which case we just report sigmoid log likelihood bce = nn . BCELoss ( reduction = 'none' ) log_p = - bce ( torch . sigmoid ( utility . view ( - 1 )), batch . label . to ( torch . float32 )) return log_p def log_prior ( self , batch : ChoiceDataset , sample_dict : Dict [ str , torch . Tensor ]) -> torch . Tensor : \"\"\"Calculates the log-likelihood of Monte Carlo samples of Bayesian coefficients under their prior distribution. This method assume coefficients are statistically independent. Args: batch (ChoiceDataset): a dataset object contains observables for computing the prior distribution if obs2prior is True. sample_dict (Dict[str, torch.Tensor]): a dictionary coefficient names to Monte Carlo samples. Raises: ValueError: [description] Returns: torch.scalar_tensor: a tensor with shape (num_seeds,) of [ log P_{prior_distribution}(param[i]) ], where param[i] is the i-th Monte Carlo sample. \"\"\" # assert sample_dict.keys() == self.coef_dict.keys() num_seeds = next ( iter ( sample_dict . values ())) . shape [ 0 ] total = torch . zeros ( num_seeds , device = self . device ) for coef_name , coef in self . coef_dict . items (): if self . obs2prior_dict [ coef_name ]: if coef_name . endswith ( '_item' ): x_obs = batch . item_obs elif coef_name . endswith ( '_user' ): x_obs = batch . user_obs else : raise ValueError ( f 'No observable found to support obs2prior for { coef_name } .' ) total += coef . log_prior ( sample = sample_dict [ coef_name ], H_sample = sample_dict [ coef_name + '.H' ], x_obs = x_obs ) . sum ( dim =- 1 ) else : # log_prob outputs (num_seeds, num_{items, users}), sum to (num_seeds). total += coef . log_prior ( sample = sample_dict [ coef_name ], H_sample = None , x_obs = None ) . sum ( dim =- 1 ) for module in self . additional_modules : raise NotImplementedError () total += module . log_prior () return total def log_variational ( self , sample_dict : Dict [ str , torch . Tensor ]) -> torch . Tensor : \"\"\"Calculate the log-likelihood of samples in sample_dict under the current variational distribution. Args: sample_dict (Dict[str, torch.Tensor]): a dictionary coefficient names to Monte Carlo samples. Returns: torch.Tensor: a tensor of shape (num_seeds) of [ log P_{variational_distribution}(param[i]) ], where param[i] is the i-th Monte Carlo sample. \"\"\" num_seeds = list ( sample_dict . values ())[ 0 ] . shape [ 0 ] total = torch . zeros ( num_seeds , device = self . device ) for coef_name , coef in self . coef_dict . items (): # log_prob outputs (num_seeds, num_{items, users}), sum to (num_seeds). total += coef . log_variational ( sample_dict [ coef_name ]) . sum ( dim =- 1 ) for module in self . additional_modules : raise NotImplementedError () # with shape (num_seeds,) total += module . log_variational () . sum () return total def elbo ( self , batch : ChoiceDataset , num_seeds : int = 1 ) -> torch . Tensor : \"\"\"A combined method to computes the current ELBO given a batch, this method is used for training the model. Args: batch (ChoiceDataset): a ChoiceDataset containing necessary information. num_seeds (int, optional): the number of Monte Carlo samples from variational distributions to evaluate the expectation in ELBO. Defaults to 1. Returns: torch.Tensor: a scalar tensor of the ELBO estimated from num_seeds Monte Carlo samples. \"\"\" # ============================================================================================================== # 1. sample latent variables from their variational distributions. # ============================================================================================================== sample_dict = self . sample_coefficient_dictionary ( num_seeds ) # ============================================================================================================== # 2. compute log p(latent) prior. # (num_seeds,) --mean--> scalar. elbo = self . log_prior ( batch , sample_dict ) . mean ( dim = 0 ) # ============================================================================================================== # ============================================================================================================== # 3. compute the log likelihood log p(obs|latent). # sum over independent purchase decision for individual observations, mean over MC seeds. # the forward() function calls module.rsample(num_seeds) for module in self.additional_modules. # ============================================================================================================== if self . pred_item : # the prediction target is item_index. elbo += self . forward ( batch , return_type = 'log_prob' , return_scope = 'item_index' , deterministic = False , sample_dict = sample_dict ) . sum ( dim = 1 ) . mean ( dim = 0 ) # (num_seeds, len(batch)) --> scalar. else : # the prediction target is binary. # TODO: update the prediction function. utility = self . forward ( batch , return_type = 'utility' , return_scope = 'item_index' , deterministic = False , sample_dict = sample_dict ) # (num_seeds, len(batch)) # compute the log-likelihood for binary label. # (num_seeds, len(batch)) y_stacked = torch . stack ([ batch . label ] * num_seeds ) . float () assert y_stacked . shape == utility . shape bce = nn . BCELoss ( reduction = 'none' ) # scalar. ll = - bce ( torch . sigmoid ( utility ), y_stacked ) . sum ( dim = 1 ) . mean ( dim = 0 ) elbo += ll # ============================================================================================================== # 4. optionally add log likelihood under variational distributions q(latent). # ============================================================================================================== if self . trace_log_q : elbo -= self . log_variational ( sample_dict ) . mean ( dim = 0 ) return elbo","title":"BEMBFlex"},{"location":"api_bemb/#bemb.model.bemb.BEMBFlex.__init__","text":"Parameters: Name Type Description Default utility_formula str a string representing the utility function U[user, item, session]. See documentation for more details in the documentation for the format of formula. Examples: lambda_item lambda_item + theta_user * alpha_item + zeta_user * item_obs lambda_item + theta_user * alpha_item + gamma_user * beta_item * price_obs See the doc-string of parse_utility for an example. required obs2prior_dict Dict[str, bool] a dictionary maps coefficient name (e.g., 'lambda_item') to a boolean indicating if observable (e.g., item_obs) enters the prior of the coefficient. required coef_dim_dict Dict[str, int] a dictionary maps coefficient name (e.g., 'lambda_item') to an integer indicating the dimension of coefficient. For standalone coefficients like U = lambda_item, the dim should be 1. For factorized coefficients like U = theta_user * alpha_item, the dim should be the latent dimension of theta and alpha. For coefficients multiplied with observables like U = zeta_user * item_obs, the dim should be the number of observables in item_obs. For factorized coefficient multiplied with observables like U = gamma_user * beta_item * price_obs, the dim should be the latent dim multiplied by number of observables in price_obs. required num_items int number of items. required pred_item bool there are two use cases of this model, suppose we have user_index[i] and item_index[i] for the i-th observation in the dataset. Case 1: which item among all items user user_index[i] is going to purchase, the prediction label is therefore item_index[i] . Equivalently, we can ask what's the likelihood for user user_index[i] to purchase item_index[i] . Case 2: what rating would user user_index[i] assign to item item_index[i] ? In this case, the dataset object needs to contain a separate label. NOTE: for now, we only support binary labels. required default_prior_mean float the default prior mean for coefficients, 0.0 prior_mean Union[float, Dict[str, float]] the mean of prior distribution for coefficients. If a float is provided, all prior mean will be diagonal matrix with the provided value. If a dictionary is provided, keys of prior_mean should be coefficient names, and the mean of prior of coef_name would the provided value Defaults to 0.0, which means all prior means are initalized to 0.0 0.0 prior_variance Union[float, Dict[str, float]] the variance of prior distribution for coefficients. If a float is provided, all priors will be diagonal matrix with prior_variance along the diagonal. If a dictionary is provided, keys of prior_variance should be coefficient names, and the variance of prior of coef_name would be a diagonal matrix with prior_variance[coef_name] along the diagonal. Defaults to 1.0, which means all prior have identity matrix as the covariance matrix. 1.0 num_users int number of users, required only if coefficient or observable depending on user is in utility. Defaults to None. None num_sessions int number of sessions, required only if coefficient or observable depending on session is in utility. Defaults to None. None trace_log_q bool whether to trace the derivative of variational likelihood logQ with respect to variational parameters in the ELBO while conducting gradient update. Defaults to False. False category_to_item Dict[str, List[int]] a dictionary with category id or name as keys, and category_to_item[C] contains the list of item ids belonging to category C. If None is provided, all items are assumed to be in the same category. Defaults to None. None num_{user, item, session, price, taste}_obs (int number of observables of each type of features, only required if observable enters prior. NOTE: currently we only allow coefficient to depend on either user or item, thus only user and item observables can enter the prior of coefficient. Hence session, price, and taste observables are never required, we include it here for completeness. required Source code in bemb/model/bemb.py def __init__ ( self , utility_formula : str , obs2prior_dict : Dict [ str , bool ], coef_dim_dict : Dict [ str , int ], num_items : int , pred_item : bool , prior_mean : Union [ float , Dict [ str , float ]] = 0.0 , default_prior_mean : float = 0.0 , prior_variance : Union [ float , Dict [ str , float ]] = 1.0 , num_users : Optional [ int ] = None , num_sessions : Optional [ int ] = None , trace_log_q : bool = False , category_to_item : Dict [ int , List [ int ]] = None , # number of observables. num_user_obs : Optional [ int ] = None , num_item_obs : Optional [ int ] = None , num_session_obs : Optional [ int ] = None , num_price_obs : Optional [ int ] = None , num_taste_obs : Optional [ int ] = None , # additional modules. additional_modules : Optional [ List [ nn . Module ]] = None ) -> None : \"\"\" Args: utility_formula (str): a string representing the utility function U[user, item, session]. See documentation for more details in the documentation for the format of formula. Examples: lambda_item lambda_item + theta_user * alpha_item + zeta_user * item_obs lambda_item + theta_user * alpha_item + gamma_user * beta_item * price_obs See the doc-string of parse_utility for an example. obs2prior_dict (Dict[str, bool]): a dictionary maps coefficient name (e.g., 'lambda_item') to a boolean indicating if observable (e.g., item_obs) enters the prior of the coefficient. coef_dim_dict (Dict[str, int]): a dictionary maps coefficient name (e.g., 'lambda_item') to an integer indicating the dimension of coefficient. For standalone coefficients like U = lambda_item, the dim should be 1. For factorized coefficients like U = theta_user * alpha_item, the dim should be the latent dimension of theta and alpha. For coefficients multiplied with observables like U = zeta_user * item_obs, the dim should be the number of observables in item_obs. For factorized coefficient multiplied with observables like U = gamma_user * beta_item * price_obs, the dim should be the latent dim multiplied by number of observables in price_obs. num_items (int): number of items. pred_item (bool): there are two use cases of this model, suppose we have `user_index[i]` and `item_index[i]` for the i-th observation in the dataset. Case 1: which item among all items user `user_index[i]` is going to purchase, the prediction label is therefore `item_index[i]`. Equivalently, we can ask what's the likelihood for user `user_index[i]` to purchase `item_index[i]`. Case 2: what rating would user `user_index[i]` assign to item `item_index[i]`? In this case, the dataset object needs to contain a separate label. NOTE: for now, we only support binary labels. default_prior_mean (float): the default prior mean for coefficients, if it is not specified in the prior_mean; defaults to 0.0. prior_mean (Union[float, Dict[str, float]]): the mean of prior distribution for coefficients. If a float is provided, all prior mean will be diagonal matrix with the provided value. If a dictionary is provided, keys of prior_mean should be coefficient names, and the mean of prior of coef_name would the provided value Defaults to 0.0, which means all prior means are initalized to 0.0 prior_variance (Union[float, Dict[str, float]]): the variance of prior distribution for coefficients. If a float is provided, all priors will be diagonal matrix with prior_variance along the diagonal. If a dictionary is provided, keys of prior_variance should be coefficient names, and the variance of prior of coef_name would be a diagonal matrix with prior_variance[coef_name] along the diagonal. Defaults to 1.0, which means all prior have identity matrix as the covariance matrix. num_users (int, optional): number of users, required only if coefficient or observable depending on user is in utility. Defaults to None. num_sessions (int, optional): number of sessions, required only if coefficient or observable depending on session is in utility. Defaults to None. trace_log_q (bool, optional): whether to trace the derivative of variational likelihood logQ with respect to variational parameters in the ELBO while conducting gradient update. Defaults to False. category_to_item (Dict[str, List[int]], optional): a dictionary with category id or name as keys, and category_to_item[C] contains the list of item ids belonging to category C. If None is provided, all items are assumed to be in the same category. Defaults to None. num_{user, item, session, price, taste}_obs (int, optional): number of observables of each type of features, only required if observable enters prior. NOTE: currently we only allow coefficient to depend on either user or item, thus only user and item observables can enter the prior of coefficient. Hence session, price, and taste observables are never required, we include it here for completeness. \"\"\" super ( BEMBFlex , self ) . __init__ () self . utility_formula = utility_formula self . obs2prior_dict = obs2prior_dict self . coef_dim_dict = coef_dim_dict self . prior_variance = prior_variance self . default_prior_mean = default_prior_mean self . prior_mean = prior_mean self . pred_item = pred_item self . num_items = num_items self . num_users = num_users self . num_sessions = num_sessions self . trace_log_q = trace_log_q self . category_to_item = category_to_item # ============================================================================================================== # Category ID to Item ID mapping. # Category ID to Category Size mapping. # Item ID to Category ID mapping. # ============================================================================================================== if self . category_to_item is None : if self . pred_item : # assign all items to the same category if predicting items. self . category_to_item = { 0 : list ( np . arange ( self . num_items ))} else : # otherwise, for the j-th observation in the dataset, the label[j] # only depends on user_index[j] and item_index[j], so we put each # item to its own category. self . category_to_item = { i : [ i ] for i in range ( self . num_items )} self . num_categories = len ( self . category_to_item ) max_category_size = max ( len ( x ) for x in self . category_to_item . values ()) category_to_item_tensor = torch . full ( ( self . num_categories , max_category_size ), - 1 ) category_to_size_tensor = torch . empty ( self . num_categories ) for c , item_in_c in self . category_to_item . items (): category_to_item_tensor [ c , : len ( item_in_c )] = torch . LongTensor ( item_in_c ) category_to_size_tensor [ c ] = torch . scalar_tensor ( len ( item_in_c )) self . register_buffer ( 'category_to_item_tensor' , category_to_item_tensor . long ()) self . register_buffer ( 'category_to_size_tensor' , category_to_size_tensor . long ()) item_to_category_tensor = torch . zeros ( self . num_items ) for c , items_in_c in self . category_to_item . items (): item_to_category_tensor [ items_in_c ] = c self . register_buffer ( 'item_to_category_tensor' , item_to_category_tensor . long ()) # ============================================================================================================== # Create Bayesian Coefficient Objects # ============================================================================================================== # model configuration. self . formula = parse_utility ( utility_formula ) print ( 'BEMB: utility formula parsed:' ) pprint ( self . formula ) self . raw_formula = utility_formula self . obs2prior_dict = obs2prior_dict # dimension of each observable, this one is used only for obs2prior. self . num_obs_dict = { 'user' : num_user_obs , 'item' : num_item_obs , 'category' : 0 , 'session' : num_session_obs , 'price' : num_price_obs , 'taste' : num_taste_obs , 'constant' : 1 # not really used, for dummy variables. } # how many classes for the variational distribution. # for example, beta_item would be `num_items` 10-dimensional gaussian if latent dim = 10. variation_to_num_classes = { 'user' : self . num_users , 'item' : self . num_items , 'constant' : 1 , 'category' : self . num_categories , } coef_dict = dict () for additive_term in self . formula : for coef_name in additive_term [ 'coefficient' ]: variation = coef_name . split ( '_' )[ - 1 ] mean = self . prior_mean [ coef_name ] if isinstance ( self . prior_mean , dict ) else self . default_prior_mean s2 = self . prior_variance [ coef_name ] if isinstance ( self . prior_variance , dict ) else self . prior_variance coef_dict [ coef_name ] = BayesianCoefficient ( variation = variation , num_classes = variation_to_num_classes [ variation ], obs2prior = self . obs2prior_dict [ coef_name ], num_obs = self . num_obs_dict [ variation ], dim = self . coef_dim_dict [ coef_name ], prior_mean = mean , prior_variance = s2 ) self . coef_dict = nn . ModuleDict ( coef_dict ) # ============================================================================================================== # Optional: register additional modules. # ============================================================================================================== if additional_modules is None : self . additional_modules = [] else : raise NotImplementedError ( 'Additional modules are temporarily disabled for further development.' ) self . additional_modules = nn . ModuleList ( additional_modules )","title":"__init__()"},{"location":"api_bemb/#bemb.model.bemb.BEMBFlex.elbo","text":"A combined method to computes the current ELBO given a batch, this method is used for training the model. Parameters: Name Type Description Default batch ChoiceDataset a ChoiceDataset containing necessary information. required num_seeds int the number of Monte Carlo samples from variational distributions to evaluate the expectation in ELBO. Defaults to 1. 1 Returns: Type Description torch.Tensor a scalar tensor of the ELBO estimated from num_seeds Monte Carlo samples. Source code in bemb/model/bemb.py def elbo ( self , batch : ChoiceDataset , num_seeds : int = 1 ) -> torch . Tensor : \"\"\"A combined method to computes the current ELBO given a batch, this method is used for training the model. Args: batch (ChoiceDataset): a ChoiceDataset containing necessary information. num_seeds (int, optional): the number of Monte Carlo samples from variational distributions to evaluate the expectation in ELBO. Defaults to 1. Returns: torch.Tensor: a scalar tensor of the ELBO estimated from num_seeds Monte Carlo samples. \"\"\" # ============================================================================================================== # 1. sample latent variables from their variational distributions. # ============================================================================================================== sample_dict = self . sample_coefficient_dictionary ( num_seeds ) # ============================================================================================================== # 2. compute log p(latent) prior. # (num_seeds,) --mean--> scalar. elbo = self . log_prior ( batch , sample_dict ) . mean ( dim = 0 ) # ============================================================================================================== # ============================================================================================================== # 3. compute the log likelihood log p(obs|latent). # sum over independent purchase decision for individual observations, mean over MC seeds. # the forward() function calls module.rsample(num_seeds) for module in self.additional_modules. # ============================================================================================================== if self . pred_item : # the prediction target is item_index. elbo += self . forward ( batch , return_type = 'log_prob' , return_scope = 'item_index' , deterministic = False , sample_dict = sample_dict ) . sum ( dim = 1 ) . mean ( dim = 0 ) # (num_seeds, len(batch)) --> scalar. else : # the prediction target is binary. # TODO: update the prediction function. utility = self . forward ( batch , return_type = 'utility' , return_scope = 'item_index' , deterministic = False , sample_dict = sample_dict ) # (num_seeds, len(batch)) # compute the log-likelihood for binary label. # (num_seeds, len(batch)) y_stacked = torch . stack ([ batch . label ] * num_seeds ) . float () assert y_stacked . shape == utility . shape bce = nn . BCELoss ( reduction = 'none' ) # scalar. ll = - bce ( torch . sigmoid ( utility ), y_stacked ) . sum ( dim = 1 ) . mean ( dim = 0 ) elbo += ll # ============================================================================================================== # 4. optionally add log likelihood under variational distributions q(latent). # ============================================================================================================== if self . trace_log_q : elbo -= self . log_variational ( sample_dict ) . mean ( dim = 0 ) return elbo","title":"elbo()"},{"location":"api_bemb/#bemb.model.bemb.BEMBFlex.forward","text":"A combined method for inference with the model. Parameters: Name Type Description Default batch ChoiceDataset batch data containing choice information. required return_type str either 'log_prob' or 'utility'. 'log_prob': return the log-probability (by within-category log-softmax) for items 'utility': return the utility value of items. required return_scope str either 'item_index' or 'all_items'. 'item_index': for each observation i, return log-prob/utility for the chosen item batch.item_index[i] only. 'all_items': for each observation i, return log-prob/utility for all items. required deterministic bool True: expectations of parameter variational distributions are used for inference. False: the user needs to supply a dictionary of sampled parameters for inference. Defaults to True. True sample_dict Optional[Dict[str, torch.Tensor]] sampled parameters for inference task. This is not needed when deterministic is True. When deterministic is False, the user can supply a sample_dict . If sample_dict is not provided, this method will create num_seeds samples. Defaults to None. None num_seeds Optional[int] the number of random samples of parameters to construct. This is only required if deterministic is False (i.e., stochastic mode) and sample_dict is not provided. Defaults to None. None Returns: Type Description torch.Tensor a tensor of log-probabilities or utilities, depending on return_type . The shape of the returned tensor depends on return_scope and deterministic . ------------------------------------------------------------------------- | return_scope | deterministic | Output shape | ------------------------------------------------------------------------- | 'item_index` | True | (len(batch),) | ------------------------------------------------------------------------- | 'all_items' | True | (len(batch), num_items) | ------------------------------------------------------------------------- | 'item_index' | False | (num_seeds, len(batch)) | ------------------------------------------------------------------------- | 'all_items' | False | (num_seeds, len(batch), num_items) | ------------------------------------------------------------------------- Source code in bemb/model/bemb.py def forward ( self , batch : ChoiceDataset , return_type : str , return_scope : str , deterministic : bool = True , sample_dict : Optional [ Dict [ str , torch . Tensor ]] = None , num_seeds : Optional [ int ] = None ) -> torch . Tensor : \"\"\"A combined method for inference with the model. Args: batch (ChoiceDataset): batch data containing choice information. return_type (str): either 'log_prob' or 'utility'. 'log_prob': return the log-probability (by within-category log-softmax) for items 'utility': return the utility value of items. return_scope (str): either 'item_index' or 'all_items'. 'item_index': for each observation i, return log-prob/utility for the chosen item batch.item_index[i] only. 'all_items': for each observation i, return log-prob/utility for all items. deterministic (bool, optional): True: expectations of parameter variational distributions are used for inference. False: the user needs to supply a dictionary of sampled parameters for inference. Defaults to True. sample_dict (Optional[Dict[str, torch.Tensor]], optional): sampled parameters for inference task. This is not needed when `deterministic` is True. When `deterministic` is False, the user can supply a `sample_dict`. If `sample_dict` is not provided, this method will create `num_seeds` samples. Defaults to None. num_seeds (Optional[int]): the number of random samples of parameters to construct. This is only required if `deterministic` is False (i.e., stochastic mode) and `sample_dict` is not provided. Defaults to None. Returns: torch.Tensor: a tensor of log-probabilities or utilities, depending on `return_type`. The shape of the returned tensor depends on `return_scope` and `deterministic`. ------------------------------------------------------------------------- | `return_scope` | `deterministic` | Output shape | ------------------------------------------------------------------------- | 'item_index` | True | (len(batch),) | ------------------------------------------------------------------------- | 'all_items' | True | (len(batch), num_items) | ------------------------------------------------------------------------- | 'item_index' | False | (num_seeds, len(batch)) | ------------------------------------------------------------------------- | 'all_items' | False | (num_seeds, len(batch), num_items) | ------------------------------------------------------------------------- \"\"\" # ============================================================================================================== # check arguments. # ============================================================================================================== assert return_type in [ 'log_prob' , 'utility' ], \"return_type must be either 'log_prob' or 'utility'.\" assert return_scope in [ 'item_index' , 'all_items' ], \"return_scope must be either 'item_index' or 'all_items'.\" assert deterministic in [ True , False ] if ( not deterministic ) and ( sample_dict is None ): assert num_seeds >= 1 , \"A positive interger `num_seeds` is required if `deterministic` is False and no `sample_dict` is provided.\" # when pred_item is true, the model is predicting which item is bought (specified by item_index). if self . pred_item : batch . label = batch . item_index # ============================================================================================================== # get sample_dict ready. # ============================================================================================================== if deterministic : num_seeds = 1 # Use the means of variational distributions as the sole deterministic MC sample. # NOTE: here we don't need to sample the obs2prior weight H since we only compute the log-likelihood. # TODO: is this correct? sample_dict = dict () for coef_name , coef in self . coef_dict . items (): sample_dict [ coef_name ] = coef . variational_distribution . mean . unsqueeze ( dim = 0 ) # (1, num_*, dim) else : if sample_dict is None : # sample stochastic parameters. sample_dict = self . sample_coefficient_dictionary ( num_seeds ) else : # use the provided sample_dict. num_seeds = list ( sample_dict . values ())[ 0 ] . shape [ 0 ] # ============================================================================================================== # call the sampling method of additional modules. # ============================================================================================================== for module in self . additional_modules : # deterministic sample. if deterministic : module . dsample () else : module . rsample ( num_seeds = num_seeds ) # if utility is requested, don't run log-softmax, simply return logit. return_logit = ( return_type == 'utility' ) if return_scope == 'all_items' : # (num_seeds, len(batch), num_items) out = self . log_likelihood_all_items ( batch = batch , sample_dict = sample_dict , return_logit = return_logit ) elif return_scope == 'item_index' : # (num_seeds, len(batch)) out = self . log_likelihood_item_index ( batch = batch , sample_dict = sample_dict , return_logit = return_logit ) if deterministic : # drop the first dimension, which has size of `num_seeds` (equals 1 in the deterministic case). # (len(batch), num_items) or (len(batch),) return out . squeeze ( dim = 0 ) return out","title":"forward()"},{"location":"api_bemb/#bemb.model.bemb.BEMBFlex.get_within_category_accuracy","text":"A helper function for computing prediction accuracy (i.e., all non-differential metrics) within category. In particular, this method calculates the accuracy, precision, recall and F1 score. This method has the same functionality as the following peusodcode: for C in categories: # get sessions in which item in category C was purchased. T <- (t for t in {0,1,..., len(label)-1} if label[t] is in C) Y <- label[T] predictions = list() for t in T: # get the prediction within category for this session. y_pred = argmax_{items in C} log prob computed before. predictions.append(y_pred) accuracy = mean(Y == predictions) Similarly, this function computes precision, recall and f1score as well. Parameters: Name Type Description Default log_p_all_items torch.Tensor shape (num_sessions, num_items) the log probability of choosing each item in each session. required label torch.LongTensor shape (num_sessions,), the IDs of items purchased in each session. required Returns: Type Description [Dict[str, float]] A dictionary containing performance metrics. Source code in bemb/model/bemb.py @torch . no_grad () def get_within_category_accuracy ( self , log_p_all_items : torch . Tensor , label : torch . LongTensor ) -> Dict [ str , float ]: \"\"\"A helper function for computing prediction accuracy (i.e., all non-differential metrics) within category. In particular, this method calculates the accuracy, precision, recall and F1 score. This method has the same functionality as the following peusodcode: for C in categories: # get sessions in which item in category C was purchased. T <- (t for t in {0,1,..., len(label)-1} if label[t] is in C) Y <- label[T] predictions = list() for t in T: # get the prediction within category for this session. y_pred = argmax_{items in C} log prob computed before. predictions.append(y_pred) accuracy = mean(Y == predictions) Similarly, this function computes precision, recall and f1score as well. Args: log_p_all_items (torch.Tensor): shape (num_sessions, num_items) the log probability of choosing each item in each session. label (torch.LongTensor): shape (num_sessions,), the IDs of items purchased in each session. Returns: [Dict[str, float]]: A dictionary containing performance metrics. \"\"\" # argmax: (num_sessions, num_categories), within category argmax. # item IDs are consecutive, thus argmax is the same as IDs of the item with highest P. _ , argmax_by_category = scatter_max ( log_p_all_items , self . item_to_category_tensor , dim =- 1 ) # category_purchased[t] = the category of item label[t]. # (num_sessions,) category_purchased = self . item_to_category_tensor [ label ] # pred[t] = the item with highest utility from the category item label[t] belongs to. # (num_sessions,) pred_from_category = argmax_by_category [ torch . arange ( len ( label )), category_purchased ] within_category_accuracy = ( pred_from_category == label ) . float () . mean () . item () # precision precision = list () recall = list () for i in range ( self . num_items ): correct_i = torch . sum ( ( torch . logical_and ( pred_from_category == i , label == i )) . float ()) precision_i = correct_i / \\ torch . sum (( pred_from_category == i ) . float ()) recall_i = correct_i / torch . sum (( label == i ) . float ()) # do not add if divided by zero. if torch . any ( pred_from_category == i ): precision . append ( precision_i . cpu () . item ()) if torch . any ( label == i ): recall . append ( recall_i . cpu () . item ()) precision = float ( np . mean ( precision )) recall = float ( np . mean ( recall )) if precision == recall == 0 : f1 = 0 else : f1 = 2 * precision * recall / ( precision + recall ) return { 'accuracy' : within_category_accuracy , 'precision' : precision , 'recall' : recall , 'f1score' : f1 }","title":"get_within_category_accuracy()"},{"location":"api_bemb/#bemb.model.bemb.BEMBFlex.ivs","text":"The combined method of computing utilities and log probability. Parameters: Name Type Description Default batch dict a batch of data. required Returns: Type Description torch.Tensor the combined utility and log probability. Source code in bemb/model/bemb.py def ivs ( self , batch ) -> torch . Tensor : \"\"\"The combined method of computing utilities and log probability. Args: batch (dict): a batch of data. Returns: torch.Tensor: the combined utility and log probability. \"\"\" # Use the means of variational distributions as the sole MC sample. sample_dict = dict () for coef_name , coef in self . coef_dict . items (): sample_dict [ coef_name ] = coef . variational_distribution . mean . unsqueeze ( dim = 0 ) # (1, num_*, dim) # there is 1 random seed in this case. # (num_seeds=1, len(batch), num_items) out = self . log_likelihood_all_items ( batch , return_logit = True , sample_dict = sample_dict ) out = out . squeeze ( 0 ) # import pdb; pdb.set_trace() ivs = scatter_logsumexp ( out , self . item_to_category_tensor , dim =- 1 ) return ivs # (len(batch), num_categories)","title":"ivs()"},{"location":"api_bemb/#bemb.model.bemb.BEMBFlex.log_likelihood_all_items","text":"NOTE to developers: NOTE (akanodia to tianyudu): Is this really slow; even with log_likelihood you need log_prob which depends on logits of all items? This method computes utilities for all items available, which is a relatively slow operation. For training the model, you only need the utility/log-prob for the chosen/relevant item (i.e., item_index[i] for each i-th observation). Use this method for inference only. Use self.log_likelihood_item_index() for training instead. Computes the log probability of choosing each item in each session based on current model parameters. NOTE (akanodiadu to tianyudu): What does the next line mean? I think it just says its allowing for samples instead of posterior mean. This method allows for specifying {user, item}_latent_value for Monte Carlo estimation in ELBO. For actual prediction tasks, use the forward() function, which will use means of variational distributions for user and item latents. Parameters: Name Type Description Default batch ChoiceDataset a ChoiceDataset object containing relevant information. required return_logit(bool) if set to True, return the log-probability, otherwise return the logit/utility. required sample_dict(Dict[str, torch.Tensor] Monte Carlo samples for model coefficients (i.e., those Greek letters). sample_dict.keys() should be the same as keys of self.obs2prior_dict, i.e., those greek letters actually enter the functional form of utility. The value of sample_dict should be tensors of shape (num_seeds, num_classes, dim) where num_classes in {num_users, num_items, 1} and dim in {latent_dim(K), num_item_obs, num_user_obs, 1}. required Returns: Type Description torch.Tensor a tensor of shape (num_seeds, len(batch), self.num_items), where out[x, y, z] is the probability of choosing item z in session y conditioned on latents to be the x-th Monte Carlo sample. Source code in bemb/model/bemb.py def log_likelihood_all_items ( self , batch : ChoiceDataset , return_logit : bool , sample_dict : Dict [ str , torch . Tensor ]) -> torch . Tensor : \"\"\" NOTE to developers: NOTE (akanodia to tianyudu): Is this really slow; even with log_likelihood you need log_prob which depends on logits of all items? This method computes utilities for all items available, which is a relatively slow operation. For training the model, you only need the utility/log-prob for the chosen/relevant item (i.e., item_index[i] for each i-th observation). Use this method for inference only. Use self.log_likelihood_item_index() for training instead. Computes the log probability of choosing `each` item in each session based on current model parameters. NOTE (akanodiadu to tianyudu): What does the next line mean? I think it just says its allowing for samples instead of posterior mean. This method allows for specifying {user, item}_latent_value for Monte Carlo estimation in ELBO. For actual prediction tasks, use the forward() function, which will use means of variational distributions for user and item latents. Args: batch (ChoiceDataset): a ChoiceDataset object containing relevant information. return_logit(bool): if set to True, return the log-probability, otherwise return the logit/utility. sample_dict(Dict[str, torch.Tensor]): Monte Carlo samples for model coefficients (i.e., those Greek letters). sample_dict.keys() should be the same as keys of self.obs2prior_dict, i.e., those greek letters actually enter the functional form of utility. The value of sample_dict should be tensors of shape (num_seeds, num_classes, dim) where num_classes in {num_users, num_items, 1} and dim in {latent_dim(K), num_item_obs, num_user_obs, 1}. Returns: torch.Tensor: a tensor of shape (num_seeds, len(batch), self.num_items), where out[x, y, z] is the probability of choosing item z in session y conditioned on latents to be the x-th Monte Carlo sample. \"\"\" num_seeds = next ( iter ( sample_dict . values ())) . shape [ 0 ] # avoid repeated work when user purchased several items in the same session. user_session_index = torch . stack ( [ batch . user_index , batch . session_index ]) assert user_session_index . shape == ( 2 , len ( batch )) unique_user_sess , inverse_indices = torch . unique ( user_session_index , dim = 1 , return_inverse = True ) user_index = unique_user_sess [ 0 , :] session_index = unique_user_sess [ 1 , :] assert len ( user_index ) == len ( session_index ) # short-hands for easier shape check. R = num_seeds # P = len(batch) # num_purchases. P = unique_user_sess . shape [ 1 ] S = self . num_sessions U = self . num_users I = self . num_items NC = self . num_categories # ============================================================================================================== # Helper Functions for Reshaping. # ============================================================================================================== def reshape_user_coef_sample ( C ): # input shape (R, U, *) C = C . view ( R , U , 1 , - 1 ) . expand ( - 1 , - 1 , I , - 1 ) # (R, U, I, *) C = C [:, user_index , :, :] assert C . shape == ( R , P , I , positive_integer ) return C def reshape_item_coef_sample ( C ): # input shape (R, I, *) C = C . view ( R , 1 , I , - 1 ) . expand ( - 1 , P , - 1 , - 1 ) assert C . shape == ( R , P , I , positive_integer ) return C def reshape_category_coef_sample ( C ): # input shape (R, NC, *) C = torch . repeat_interleave ( C , self . category_to_size_tensor , dim = 1 ) # input shape (R, I, *) C = C . view ( R , 1 , I , - 1 ) . expand ( - 1 , P , - 1 , - 1 ) assert C . shape == ( R , P , I , positive_integer ) return C def reshape_constant_coef_sample ( C ): # input shape (R, *) C = C . view ( R , 1 , 1 , - 1 ) . expand ( - 1 , P , I , - 1 ) assert C . shape == ( R , P , I , positive_integer ) return C def reshape_coef_sample ( sample , name ): # reshape the monte carlo sample of coefficients to (R, P, I, *). if name . endswith ( '_user' ): # (R, U, *) --> (R, P, I, *) return reshape_user_coef_sample ( sample ) elif name . endswith ( '_item' ): # (R, I, *) --> (R, P, I, *) return reshape_item_coef_sample ( sample ) elif name . endswith ( '_category' ): # (R, NC, *) --> (R, P, NC, *) return reshape_category_coef_sample ( sample ) elif name . endswith ( '_constant' ): # (R, *) --> (R, P, I, *) return reshape_constant_coef_sample ( sample ) else : raise ValueError def reshape_observable ( obs , name ): # reshape observable to (R, P, I, *) so that it can be multiplied with monte carlo # samples of coefficients. O = obs . shape [ - 1 ] # number of observables. assert O == positive_integer if name . startswith ( 'item_' ): assert obs . shape == ( I , O ) obs = obs . view ( 1 , 1 , I , O ) . expand ( R , P , - 1 , - 1 ) elif name . startswith ( 'user_' ): assert obs . shape == ( U , O ) obs = obs [ user_index , :] # (P, O) obs = obs . view ( 1 , P , 1 , O ) . expand ( R , - 1 , I , - 1 ) elif name . startswith ( 'session_' ): assert obs . shape == ( S , O ) obs = obs [ session_index , :] # (P, O) return obs . view ( 1 , P , 1 , O ) . expand ( R , - 1 , I , - 1 ) elif name . startswith ( 'price_' ): assert obs . shape == ( S , I , O ) obs = obs [ session_index , :, :] # (P, I, O) return obs . view ( 1 , P , I , O ) . expand ( R , - 1 , - 1 , - 1 ) elif name . startswith ( 'taste_' ): assert obs . shape == ( U , I , O ) obs = obs [ user_index , :, :] # (P, I, O) return obs . view ( 1 , P , I , O ) . expand ( R , - 1 , - 1 , - 1 ) else : raise ValueError assert obs . shape == ( R , P , I , O ) return obs # ============================================================================================================== # Copmute the Utility Term by Term. # ============================================================================================================== # P is the number of unique (user, session) pairs. # (random_seeds, P, num_items). utility = torch . zeros ( R , P , I , device = self . device ) # loop over additive term to utility for term in self . formula : # Type I: single coefficient, e.g., lambda_item or lambda_user. if len ( term [ 'coefficient' ]) == 1 and term [ 'observable' ] is None : # E.g., lambda_item or lambda_user coef_name = term [ 'coefficient' ][ 0 ] coef_sample = reshape_coef_sample ( sample_dict [ coef_name ], coef_name ) assert coef_sample . shape == ( R , P , I , 1 ) additive_term = coef_sample . view ( R , P , I ) # Type II: factorized coefficient, e.g., <theta_user, lambda_item>. elif len ( term [ 'coefficient' ]) == 2 and term [ 'observable' ] is None : coef_name_0 = term [ 'coefficient' ][ 0 ] coef_name_1 = term [ 'coefficient' ][ 1 ] coef_sample_0 = reshape_coef_sample ( sample_dict [ coef_name_0 ], coef_name_0 ) coef_sample_1 = reshape_coef_sample ( sample_dict [ coef_name_1 ], coef_name_1 ) assert coef_sample_0 . shape == coef_sample_1 . shape == ( R , P , I , positive_integer ) additive_term = ( coef_sample_0 * coef_sample_1 ) . sum ( dim =- 1 ) # Type III: single coefficient multiplied by observable, e.g., theta_user * x_obs_item. elif len ( term [ 'coefficient' ]) == 1 and term [ 'observable' ] is not None : coef_name = term [ 'coefficient' ][ 0 ] coef_sample = reshape_coef_sample ( sample_dict [ coef_name ], coef_name ) assert coef_sample . shape == ( R , P , I , positive_integer ) obs_name = term [ 'observable' ] obs = reshape_observable ( getattr ( batch , obs_name ), obs_name ) assert obs . shape == ( R , P , I , positive_integer ) additive_term = ( coef_sample * obs ) . sum ( dim =- 1 ) # Type IV: factorized coefficient multiplied by observable. # e.g., gamma_user * beta_item * price_obs. elif len ( term [ 'coefficient' ]) == 2 and term [ 'observable' ] is not None : coef_name_0 , coef_name_1 = term [ 'coefficient' ][ 0 ], term [ 'coefficient' ][ 1 ] coef_sample_0 = reshape_coef_sample ( sample_dict [ coef_name_0 ], coef_name_0 ) coef_sample_1 = reshape_coef_sample ( sample_dict [ coef_name_1 ], coef_name_1 ) assert coef_sample_0 . shape == coef_sample_1 . shape == ( R , P , I , positive_integer ) num_obs_times_latent_dim = coef_sample_0 . shape [ - 1 ] obs_name = term [ 'observable' ] obs = reshape_observable ( getattr ( batch , obs_name ), obs_name ) assert obs . shape == ( R , P , I , positive_integer ) num_obs = obs . shape [ - 1 ] # number of observables. assert ( num_obs_times_latent_dim % num_obs ) == 0 latent_dim = num_obs_times_latent_dim // num_obs coef_sample_0 = coef_sample_0 . view ( R , P , I , num_obs , latent_dim ) coef_sample_1 = coef_sample_1 . view ( R , P , I , num_obs , latent_dim ) # compute the factorized coefficient with shape (R, P, I, O). coef = ( coef_sample_0 * coef_sample_1 ) . sum ( dim =- 1 ) additive_term = ( coef * obs ) . sum ( dim =- 1 ) else : raise ValueError ( f 'Undefined term type: { term } ' ) assert additive_term . shape == ( R , P , I ) utility += additive_term # ============================================================================================================== # Mask Out Unavailable Items in Each Session. # ============================================================================================================== if batch . item_availability is not None : # expand to the Monte Carlo sample dimension. # (S, I) -> (P, I) -> (1, P, I) -> (R, P, I) A = batch . item_availability [ session_index , :] . unsqueeze ( dim = 0 ) . expand ( R , - 1 , - 1 ) utility [ ~ A ] = - ( torch . finfo ( utility . dtype ) . max / 2 ) utility = utility [:, inverse_indices , :] assert utility . shape == ( R , len ( batch ), I ) for module in self . additional_modules : additive_term = module ( batch ) assert additive_term . shape == ( R , len ( batch ), 1 ) utility += additive_term . expand ( - 1 , - 1 , I ) if return_logit : # output shape: (num_seeds, len(batch), num_items) return utility else : # compute log likelihood log p(choosing item i | user, item latents) # compute log softmax separately within each category. if self . pred_item : # output shape: (num_seeds, len(batch), num_items) log_p = scatter_log_softmax ( utility , self . item_to_category_tensor , dim =- 1 ) else : log_p = torch . nn . functional . logsigmoid ( utility ) return log_p","title":"log_likelihood_all_items()"},{"location":"api_bemb/#bemb.model.bemb.BEMBFlex.log_likelihood_item_index","text":"NOTE for developers: This method is more efficient and only computes log-likelihood/logit(utility) for item in item_index[i] for each i-th observation. Developers should use use log_likelihood_all_items for inference purpose and to computes log-likelihoods/utilities for ALL items for the i-th observation. Computes the log probability of choosing item_index[i] in each session based on current model parameters. This method allows for specifying {user, item}_latent_value for Monte Carlo estimation in ELBO. For actual prediction tasks, use the forward() function, which will use means of variational distributions for user and item latents. Parameters: Name Type Description Default batch ChoiceDataset a ChoiceDataset object containing relevant information. required return_logit(bool) if set to True, return the log-probability, otherwise return the logit/utility. required sample_dict(Dict[str, torch.Tensor] Monte Carlo samples for model coefficients (i.e., those Greek letters). sample_dict.keys() should be the same as keys of self.obs2prior_dict, i.e., those greek letters actually enter the functional form of utility. The value of sample_dict should be tensors of shape (num_seeds, num_classes, dim) where num_classes in {num_users, num_items, 1} and dim in {latent_dim(K), num_item_obs, num_user_obs, 1}. required Returns: Type Description torch.Tensor a tensor of shape (num_seeds, len(batch)), where out[x, y] is the probabilities of choosing item batch.item[y] in session y conditioned on latents to be the x-th Monte Carlo sample. Source code in bemb/model/bemb.py def log_likelihood_item_index ( self , batch : ChoiceDataset , return_logit : bool , sample_dict : Dict [ str , torch . Tensor ]) -> torch . Tensor : \"\"\" NOTE for developers: This method is more efficient and only computes log-likelihood/logit(utility) for item in item_index[i] for each i-th observation. Developers should use use `log_likelihood_all_items` for inference purpose and to computes log-likelihoods/utilities for ALL items for the i-th observation. Computes the log probability of choosing item_index[i] in each session based on current model parameters. This method allows for specifying {user, item}_latent_value for Monte Carlo estimation in ELBO. For actual prediction tasks, use the forward() function, which will use means of variational distributions for user and item latents. Args: batch (ChoiceDataset): a ChoiceDataset object containing relevant information. return_logit(bool): if set to True, return the log-probability, otherwise return the logit/utility. sample_dict(Dict[str, torch.Tensor]): Monte Carlo samples for model coefficients (i.e., those Greek letters). sample_dict.keys() should be the same as keys of self.obs2prior_dict, i.e., those greek letters actually enter the functional form of utility. The value of sample_dict should be tensors of shape (num_seeds, num_classes, dim) where num_classes in {num_users, num_items, 1} and dim in {latent_dim(K), num_item_obs, num_user_obs, 1}. Returns: torch.Tensor: a tensor of shape (num_seeds, len(batch)), where out[x, y] is the probabilities of choosing item batch.item[y] in session y conditioned on latents to be the x-th Monte Carlo sample. \"\"\" num_seeds = next ( iter ( sample_dict . values ())) . shape [ 0 ] # get category id of the item bought in each row of batch. cate_index = self . item_to_category_tensor [ batch . item_index ] # get item ids of all items from the same category of each item bought. relevant_item_index = self . category_to_item_tensor [ cate_index , :] relevant_item_index = relevant_item_index . view ( - 1 ,) # index were padded with -1's, drop those dummy entries. relevant_item_index = relevant_item_index [ relevant_item_index != - 1 ] # the first repeats[0] entries in relevant_item_index are for the category of item_index[0] repeats = self . category_to_size_tensor [ cate_index ] # argwhere(reverse_indices == k) are positions in relevant_item_index for the category of item_index[k]. reverse_indices = torch . repeat_interleave ( torch . arange ( len ( batch ), device = self . device ), repeats ) # expand the user_index and session_index. user_index = torch . repeat_interleave ( batch . user_index , repeats ) repeat_category_index = torch . repeat_interleave ( cate_index , repeats ) session_index = torch . repeat_interleave ( batch . session_index , repeats ) # duplicate the item focused to match. item_index_expanded = torch . repeat_interleave ( batch . item_index , repeats ) # short-hands for easier shape check. R = num_seeds # total number of relevant items. total_computation = len ( session_index ) S = self . num_sessions U = self . num_users I = self . num_items NC = self . num_categories # ========================================================================================== # Helper Functions for Reshaping. # ========================================================================================== def reshape_coef_sample ( sample , name ): # reshape the monte carlo sample of coefficients to (R, P, I, *). if name . endswith ( '_user' ): # (R, U, *) --> (R, total_computation, *) return sample [:, user_index , :] elif name . endswith ( '_item' ): # (R, I, *) --> (R, total_computation, *) return sample [:, relevant_item_index , :] elif name . endswith ( '_category' ): # (R, NC, *) --> (R, total_computation, *) return sample [:, repeat_category_index , :] elif name . endswith ( '_constant' ): # (R, *) --> (R, total_computation, *) return sample . view ( R , 1 , - 1 ) . expand ( - 1 , total_computation , - 1 ) else : raise ValueError def reshape_observable ( obs , name ): # reshape observable to (R, P, I, *) so that it can be multiplied with monte carlo # samples of coefficients. O = obs . shape [ - 1 ] # number of observables. assert O == positive_integer if name . startswith ( 'item_' ): assert obs . shape == ( I , O ) obs = obs [ relevant_item_index , :] elif name . startswith ( 'user_' ): assert obs . shape == ( U , O ) obs = obs [ user_index , :] elif name . startswith ( 'session_' ): assert obs . shape == ( S , O ) obs = obs [ session_index , :] elif name . startswith ( 'price_' ): assert obs . shape == ( S , I , O ) obs = obs [ session_index , relevant_item_index , :] elif name . startswith ( 'taste_' ): assert obs . shape == ( U , I , O ) obs = obs [ user_index , relevant_item_index , :] else : raise ValueError assert obs . shape == ( total_computation , O ) return obs . unsqueeze ( dim = 0 ) . expand ( R , - 1 , - 1 ) # ========================================================================================== # Compute Components related to users and items only. # ========================================================================================== utility = torch . zeros ( R , total_computation , device = self . device ) # loop over additive term to utility for term in self . formula : # Type I: single coefficient, e.g., lambda_item or lambda_user. if len ( term [ 'coefficient' ]) == 1 and term [ 'observable' ] is None : # E.g., lambda_item or lambda_user coef_name = term [ 'coefficient' ][ 0 ] coef_sample = reshape_coef_sample ( sample_dict [ coef_name ], coef_name ) assert coef_sample . shape == ( R , total_computation , 1 ) additive_term = coef_sample . view ( R , total_computation ) # Type II: factorized coefficient, e.g., <theta_user, lambda_item>. elif len ( term [ 'coefficient' ]) == 2 and term [ 'observable' ] is None : coef_name_0 = term [ 'coefficient' ][ 0 ] coef_name_1 = term [ 'coefficient' ][ 1 ] coef_sample_0 = reshape_coef_sample ( sample_dict [ coef_name_0 ], coef_name_0 ) coef_sample_1 = reshape_coef_sample ( sample_dict [ coef_name_1 ], coef_name_1 ) assert coef_sample_0 . shape == coef_sample_1 . shape == ( R , total_computation , positive_integer ) additive_term = ( coef_sample_0 * coef_sample_1 ) . sum ( dim =- 1 ) # Type III: single coefficient multiplied by observable, e.g., theta_user * x_obs_item. elif len ( term [ 'coefficient' ]) == 1 and term [ 'observable' ] is not None : coef_name = term [ 'coefficient' ][ 0 ] coef_sample = reshape_coef_sample ( sample_dict [ coef_name ], coef_name ) assert coef_sample . shape == ( R , total_computation , positive_integer ) obs_name = term [ 'observable' ] obs = reshape_observable ( getattr ( batch , obs_name ), obs_name ) assert obs . shape == ( R , total_computation , positive_integer ) additive_term = ( coef_sample * obs ) . sum ( dim =- 1 ) # Type IV: factorized coefficient multiplied by observable. # e.g., gamma_user * beta_item * price_obs. elif len ( term [ 'coefficient' ]) == 2 and term [ 'observable' ] is not None : coef_name_0 , coef_name_1 = term [ 'coefficient' ][ 0 ], term [ 'coefficient' ][ 1 ] coef_sample_0 = reshape_coef_sample ( sample_dict [ coef_name_0 ], coef_name_0 ) coef_sample_1 = reshape_coef_sample ( sample_dict [ coef_name_1 ], coef_name_1 ) assert coef_sample_0 . shape == coef_sample_1 . shape == ( R , total_computation , positive_integer ) num_obs_times_latent_dim = coef_sample_0 . shape [ - 1 ] obs_name = term [ 'observable' ] obs = reshape_observable ( getattr ( batch , obs_name ), obs_name ) assert obs . shape == ( R , total_computation , positive_integer ) num_obs = obs . shape [ - 1 ] # number of observables. assert ( num_obs_times_latent_dim % num_obs ) == 0 latent_dim = num_obs_times_latent_dim // num_obs coef_sample_0 = coef_sample_0 . view ( R , total_computation , num_obs , latent_dim ) coef_sample_1 = coef_sample_1 . view ( R , total_computation , num_obs , latent_dim ) # compute the factorized coefficient with shape (R, P, I, O). coef = ( coef_sample_0 * coef_sample_1 ) . sum ( dim =- 1 ) additive_term = ( coef * obs ) . sum ( dim =- 1 ) else : raise ValueError ( f 'Undefined term type: { term } ' ) assert additive_term . shape == ( R , total_computation ) utility += additive_term # ========================================================================================== # Mask Out Unavailable Items in Each Session. # ========================================================================================== if batch . item_availability is not None : # expand to the Monte Carlo sample dimension. A = batch . item_availability [ session_index , relevant_item_index ] . unsqueeze ( dim = 0 ) . expand ( R , - 1 ) utility [ ~ A ] = - ( torch . finfo ( utility . dtype ) . max / 2 ) for module in self . additional_modules : # current utility shape: (R, total_computation) additive_term = module ( batch ) assert additive_term . shape == ( R , len ( batch )) or additive_term . shape == ( R , len ( batch ), 1 ) if additive_term . shape == ( R , len ( batch ), 1 ): # TODO: need to make this consistent with log_likelihood_all. # be tolerant for some customized module with BayesianLinear that returns (R, len(batch), 1). additive_term = additive_term . view ( R , len ( batch )) # expand to total number of computation, query by reverse_indices. # reverse_indices has length total_computation, and reverse_indices[i] correspond to the row-id that this # computation is responsible for. additive_term = additive_term [:, reverse_indices ] assert additive_term . shape == ( R , total_computation ) # compute log likelihood log p(choosing item i | user, item latents) if return_logit : log_p = utility else : if self . pred_item : # compute the log probability from logits/utilities. # output shape: (num_seeds, len(batch), num_items) log_p = scatter_log_softmax ( utility , reverse_indices , dim =- 1 ) # select the log-P of the item actually bought. log_p = log_p [:, item_index_expanded == relevant_item_index ] else : # This is the binomial choice situation in which case we just report sigmoid log likelihood bce = nn . BCELoss ( reduction = 'none' ) log_p = - bce ( torch . sigmoid ( utility . view ( - 1 )), batch . label . to ( torch . float32 )) return log_p","title":"log_likelihood_item_index()"},{"location":"api_bemb/#bemb.model.bemb.BEMBFlex.log_prior","text":"Calculates the log-likelihood of Monte Carlo samples of Bayesian coefficients under their prior distribution. This method assume coefficients are statistically independent. Parameters: Name Type Description Default batch ChoiceDataset a dataset object contains observables for computing the prior distribution if obs2prior is True. required sample_dict Dict[str, torch.Tensor] a dictionary coefficient names to Monte Carlo samples. required Exceptions: Type Description ValueError [description] Returns: Type Description torch.scalar_tensor a tensor with shape (num_seeds,) of [ log P_{prior_distribution}(param[i]) ], where param[i] is the i-th Monte Carlo sample. Source code in bemb/model/bemb.py def log_prior ( self , batch : ChoiceDataset , sample_dict : Dict [ str , torch . Tensor ]) -> torch . Tensor : \"\"\"Calculates the log-likelihood of Monte Carlo samples of Bayesian coefficients under their prior distribution. This method assume coefficients are statistically independent. Args: batch (ChoiceDataset): a dataset object contains observables for computing the prior distribution if obs2prior is True. sample_dict (Dict[str, torch.Tensor]): a dictionary coefficient names to Monte Carlo samples. Raises: ValueError: [description] Returns: torch.scalar_tensor: a tensor with shape (num_seeds,) of [ log P_{prior_distribution}(param[i]) ], where param[i] is the i-th Monte Carlo sample. \"\"\" # assert sample_dict.keys() == self.coef_dict.keys() num_seeds = next ( iter ( sample_dict . values ())) . shape [ 0 ] total = torch . zeros ( num_seeds , device = self . device ) for coef_name , coef in self . coef_dict . items (): if self . obs2prior_dict [ coef_name ]: if coef_name . endswith ( '_item' ): x_obs = batch . item_obs elif coef_name . endswith ( '_user' ): x_obs = batch . user_obs else : raise ValueError ( f 'No observable found to support obs2prior for { coef_name } .' ) total += coef . log_prior ( sample = sample_dict [ coef_name ], H_sample = sample_dict [ coef_name + '.H' ], x_obs = x_obs ) . sum ( dim =- 1 ) else : # log_prob outputs (num_seeds, num_{items, users}), sum to (num_seeds). total += coef . log_prior ( sample = sample_dict [ coef_name ], H_sample = None , x_obs = None ) . sum ( dim =- 1 ) for module in self . additional_modules : raise NotImplementedError () total += module . log_prior () return total","title":"log_prior()"},{"location":"api_bemb/#bemb.model.bemb.BEMBFlex.log_variational","text":"Calculate the log-likelihood of samples in sample_dict under the current variational distribution. Parameters: Name Type Description Default sample_dict Dict[str, torch.Tensor] a dictionary coefficient names to Monte Carlo samples. required Returns: Type Description torch.Tensor a tensor of shape (num_seeds) of [ log P_{variational_distribution}(param[i]) ], where param[i] is the i-th Monte Carlo sample. Source code in bemb/model/bemb.py def log_variational ( self , sample_dict : Dict [ str , torch . Tensor ]) -> torch . Tensor : \"\"\"Calculate the log-likelihood of samples in sample_dict under the current variational distribution. Args: sample_dict (Dict[str, torch.Tensor]): a dictionary coefficient names to Monte Carlo samples. Returns: torch.Tensor: a tensor of shape (num_seeds) of [ log P_{variational_distribution}(param[i]) ], where param[i] is the i-th Monte Carlo sample. \"\"\" num_seeds = list ( sample_dict . values ())[ 0 ] . shape [ 0 ] total = torch . zeros ( num_seeds , device = self . device ) for coef_name , coef in self . coef_dict . items (): # log_prob outputs (num_seeds, num_{items, users}), sum to (num_seeds). total += coef . log_variational ( sample_dict [ coef_name ]) . sum ( dim =- 1 ) for module in self . additional_modules : raise NotImplementedError () # with shape (num_seeds,) total += module . log_variational () . sum () return total","title":"log_variational()"},{"location":"api_bemb/#bemb.model.bemb.BEMBFlex.posterior_mean","text":"Returns the mean of estimated posterior distribution of coefficient coef_name . Parameters: Name Type Description Default coef_name str name of the coefficient to query. required Returns: Type Description torch.Tensor mean of the estimated posterior distribution of coef_name . Source code in bemb/model/bemb.py def posterior_mean ( self , coef_name : str ) -> torch . Tensor : \"\"\"Returns the mean of estimated posterior distribution of coefficient `coef_name`. Args: coef_name (str): name of the coefficient to query. Returns: torch.Tensor: mean of the estimated posterior distribution of `coef_name`. \"\"\" if coef_name in self . coef_dict . keys (): return self . coef_dict [ coef_name ] . variational_mean else : raise KeyError ( f ' { coef_name } is not a valid coefficient name in { self . utility_formula } .' )","title":"posterior_mean()"},{"location":"api_bemb/#bemb.model.bemb.BEMBFlex.sample_choices","text":"Samples choices given model paramaters and trips batch(ChoiceDataset): batch data containing trip information; item choice information is discarded debug(bool): whether to print debug information Tuple[torch.Tensor]: sampled choices; shape: (batch_size, num_categories) Source code in bemb/model/bemb.py def sample_choices ( self , batch : ChoiceDataset , debug : bool = False , num_seeds : int = 1 , ** kwargs ) -> Tuple [ torch . Tensor ]: \"\"\"Samples choices given model paramaters and trips Args: batch(ChoiceDataset): batch data containing trip information; item choice information is discarded debug(bool): whether to print debug information Returns: Tuple[torch.Tensor]: sampled choices; shape: (batch_size, num_categories) \"\"\" # Use the means of variational distributions as the sole MC sample. sample_dict = dict () for coef_name , coef in self . coef_dict . items (): sample_dict [ coef_name ] = coef . variational_distribution . mean . unsqueeze ( dim = 0 ) # (1, num_*, dim) # sample_dict = self.sample_coefficient_dictionary(num_seeds) maxes , out = self . sample_log_likelihoods ( batch , sample_dict ) return maxes . squeeze (), out . squeeze ()","title":"sample_choices()"},{"location":"api_bemb/#bemb.model.bemb.BEMBFlex.sample_coefficient_dictionary","text":"A helper function to sample parameters from coefficients. Parameters: Name Type Description Default num_seeds int number of random samples. required Returns: Type Description Dict[str, torch.Tensor] a dictionary maps coefficient names to tensor of sampled coefficient parameters, where the first dimension of the sampled tensor has size num_seeds . Each sample tensor has shape (num_seeds, num_classes, dim). Source code in bemb/model/bemb.py def sample_coefficient_dictionary ( self , num_seeds : int ) -> Dict [ str , torch . Tensor ]: \"\"\"A helper function to sample parameters from coefficients. Args: num_seeds (int): number of random samples. Returns: Dict[str, torch.Tensor]: a dictionary maps coefficient names to tensor of sampled coefficient parameters, where the first dimension of the sampled tensor has size `num_seeds`. Each sample tensor has shape (num_seeds, num_classes, dim). \"\"\" sample_dict = dict () for coef_name , coef in self . coef_dict . items (): s = coef . rsample ( num_seeds ) if coef . obs2prior : # sample both obs2prior weight and realization of variable. assert isinstance ( s , tuple ) and len ( s ) == 2 sample_dict [ coef_name ] = s [ 0 ] sample_dict [ coef_name + '.H' ] = s [ 1 ] else : # only sample the realization of variable. assert torch . is_tensor ( s ) sample_dict [ coef_name ] = s return sample_dict","title":"sample_coefficient_dictionary()"},{"location":"api_bemb/#bemb.model.bemb.BEMBFlex.sample_log_likelihoods","text":"Samples log likelihoods given model paramaters and trips batch(ChoiceDataset): batch data containing trip information; item choice information is discarded sample_dict(Dict[str, torch.Tensor]): sampled coefficient values Tuple[torch.Tensor]: sampled log likelihoods; shape: (batch_size, num_categories) Source code in bemb/model/bemb.py def sample_log_likelihoods ( self , batch : ChoiceDataset , sample_dict : Dict [ str , torch . Tensor ]) -> Tuple [ torch . Tensor , torch . Tensor ]: \"\"\"Samples log likelihoods given model paramaters and trips Args: batch(ChoiceDataset): batch data containing trip information; item choice information is discarded sample_dict(Dict[str, torch.Tensor]): sampled coefficient values Returns: Tuple[torch.Tensor]: sampled log likelihoods; shape: (batch_size, num_categories) \"\"\" # get the log likelihoods for all items for all categories utility = self . log_likelihood_all_items ( batch , return_logit = True , sample_dict = sample_dict ) mu_gumbel = 0.0 beta_gumbel = 1.0 EUL_MAS_CONST = 0.5772156649 mean_gumbel = torch . tensor ([ mu_gumbel + beta_gumbel * EUL_MAS_CONST ], device = self . device ) m = torch . distributions . gumbel . Gumbel ( torch . tensor ([ 0.0 ], device = self . device ), torch . tensor ([ 1.0 ], device = self . device )) # m = torch.distributions.gumbel.Gumbel(0.0, 1.0) gumbel_samples = m . sample ( utility . shape ) . squeeze ( - 1 ) gumbel_samples -= mean_gumbel utility += gumbel_samples max_by_category , argmax_by_category = scatter_max ( utility , self . item_to_category_tensor , dim =- 1 ) return max_by_category , argmax_by_category log_likelihoods = self . sample_log_likelihoods_per_category ( batch , sample_dict ) # sum over all categories. log_likelihoods = log_likelihoods . sum ( dim = 1 ) return log_likelihoods , log_likelihoods","title":"sample_log_likelihoods()"},{"location":"api_bemb/#bemb.model.bemb.parse_utility","text":"A helper function parse utility string into a list of additive terms. Examples: utility_string = 'lambda_item + theta_user * alpha_item + gamma_user * beta_item * price_obs' output = [ { 'coefficient': ['lambda_item'], 'observable': None }, { 'coefficient': ['theta_user', 'alpha_item'], 'observable': None }, { 'coefficient': ['gamma_user', 'beta_item'], 'observable': 'price_obs' } ] Source code in bemb/model/bemb.py def parse_utility ( utility_string : str ) -> List [ Dict [ str , Union [ List [ str ], None ]]]: \"\"\" A helper function parse utility string into a list of additive terms. Example: utility_string = 'lambda_item + theta_user * alpha_item + gamma_user * beta_item * price_obs' output = [ { 'coefficient': ['lambda_item'], 'observable': None }, { 'coefficient': ['theta_user', 'alpha_item'], 'observable': None }, { 'coefficient': ['gamma_user', 'beta_item'], 'observable': 'price_obs' } ] \"\"\" # split additive terms coefficient_suffix = ( '_item' , '_user' , '_constant' , '_category' ) observable_prefix = ( 'item_' , 'user_' , 'session_' , 'price_' , 'taste_' ) def is_coefficient ( name : str ) -> bool : return any ( name . endswith ( suffix ) for suffix in coefficient_suffix ) def is_observable ( name : str ) -> bool : return any ( name . startswith ( prefix ) for prefix in observable_prefix ) additive_terms = utility_string . split ( ' + ' ) additive_decomposition = list () for term in additive_terms : atom = { 'coefficient' : [], 'observable' : None } # split multiplicative terms. for x in term . split ( ' * ' ): if is_coefficient ( x ): atom [ 'coefficient' ] . append ( x ) elif is_observable ( x ): atom [ 'observable' ] = x else : raise ValueError ( f ' { x } term cannot be classified.' ) additive_decomposition . append ( atom ) return additive_decomposition","title":"parse_utility()"},{"location":"api_bemb/#bemb.model.bemb_flex_lightning","text":"PyTorch lightning wrapper for the BEMB Flex model, allows for more smooth model training and inference. You can still use this package without using LitBEMBFlex. Author: Tianyu Du Update: Apr. 29, 2022","title":"bemb_flex_lightning"},{"location":"api_bemb/#bemb.model.bemb_flex_lightning.LitBEMBFlex","text":"Source code in bemb/model/bemb_flex_lightning.py class LitBEMBFlex ( pl . LightningModule ): def __init__ ( self , learning_rate : float = 0.3 , num_seeds : int = 1 , ** kwargs ): \"\"\"The initialization method of the wrapper model. Args: learning_rate (float, optional): the learning rate of optimization. Defaults to 0.3. num_seeds (int, optional): number of random seeds for the Monte Carlo estimation in the variational inference. Defaults to 1. **kwargs: all keyword arguments used for constructing the wrapped BEMB model. \"\"\" # use kwargs to pass parameter to BEMB Torch. super () . __init__ () self . model = BEMBFlex ( ** kwargs ) self . num_needs = num_seeds self . learning_rate = learning_rate def __str__ ( self ) -> str : return str ( self . model ) def forward ( self , args , kwargs ): \"\"\"Calls the forward method of the wrapped BEMB model, please refer to the documentaton of the BEMB class for detailed definitions of the arguments. Args: args (_type_): arguments passed to the forward method of the wrapped BEMB model. kwargs (_type_): keyword arguments passed to the forward method of the wrapped BEMB model. Returns: _type_: returns whatever the wrapped BEMB model returns. \"\"\" return self . model ( * args , ** kwargs ) def training_step ( self , batch , batch_idx ): elbo = self . model . elbo ( batch , num_seeds = self . num_needs ) self . log ( 'train_elbo' , elbo ) loss = - elbo return loss def _get_performance_dict ( self , batch ): if self . model . pred_item : log_p = self . model ( batch , return_type = 'log_prob' , return_scope = 'all_items' , deterministic = True ) . cpu () . numpy () num_classes = log_p . shape [ 1 ] y_pred = np . argmax ( log_p , axis = 1 ) y_true = batch . item_index . cpu () . numpy () performance = { 'acc' : metrics . accuracy_score ( y_true = y_true , y_pred = y_pred ), 'll' : - metrics . log_loss ( y_true = y_true , y_pred = np . exp ( log_p ), labels = np . arange ( num_classes ))} else : # making binary station. pred = self . model ( batch , return_type = 'utility' , return_scope = 'item_index' , deterministic = True ) y_pred = torch . sigmoid ( pred ) . cpu () . numpy () y_true = batch . label . cpu () . numpy () performance = { 'acc' : metrics . accuracy_score ( y_true = y_true , y_pred = ( y_pred >= 0.5 ) . astype ( int )), 'll' : - metrics . log_loss ( y_true = y_true , y_pred = y_pred , eps = 1E-5 , labels = [ 0 , 1 ]), # 'auc': metrics.roc_auc_score(y_true=y_true, y_score=y_pred), # 'f1': metrics.f1_score(y_true=y_true, y_pred=(y_pred >= 0.5).astype(int)) } return performance def validation_step ( self , batch , batch_idx ): # LL = self.model.forward(batch, return_type='log_prob', return_scope='item_index', deterministic=True).mean() # self.log('val_log_likelihood', LL, prog_bar=True) # pred = self.model(batch) # performance = self.model.get_within_category_accuracy(pred, batch.label) # utility. for key , val in self . _get_performance_dict ( batch ) . items (): self . log ( 'val_' + key , val , prog_bar = True , batch_size = len ( batch )) def test_step ( self , batch , batch_idx ): # LL = self.model.forward(batch, return_logit=False, all_items=False).mean() # self.log('test_log_likelihood', LL) # pred = self.model(batch, return_type='utility', return_scope='item_index', deterministic=True) # y_pred = torch.sigmoid(pred).cpu().numpy() # y_true = batch.label.cpu().numpy() # performance = {'acc': metrics.accuracy_score(y_true=y_true, y_pred=(y_pred >= 0.5).astype(int)), # 'll': - metrics.log_loss(y_true=y_true, y_pred=y_pred, eps=1E-5, labels=[0, 1]), # # 'auc': metrics.roc_auc_score(y_true=y_true, y_score=y_pred), # # 'f1': metrics.f1_score(y_true=y_true, y_pred=(y_pred >= 0.5).astype(int)) # } # pred = self.model(batch) # performance = self.model.get_within_category_accuracy(pred, batch.label) for key , val in self . _get_performance_dict ( batch ) . items (): self . log ( 'test_' + key , val , prog_bar = True , batch_size = len ( batch )) def configure_optimizers ( self ): optimizer = torch . optim . Adam ( self . parameters (), lr = self . learning_rate ) return optimizer def fit_model ( self , dataset_list : List [ ChoiceDataset ], batch_size : int =- 1 , num_epochs : int = 10 , num_workers : int = 8 , ** kwargs ) -> \"LitBEMBFlex\" : \"\"\"A standard pipeline of model training and evaluation. Args: dataset_list (List[ChoiceDataset]): train_dataset, validation_test, and test_dataset in a list of length 3. batch_size (int, optional): batch_size for training and evaluation. Defaults to -1, which indicates full-batch training. num_epochs (int, optional): number of epochs for training. Defaults to 10. **kwargs: additional keyword argument for the pytorch-lightning Trainer. Returns: LitBEMBFlex: the trained bemb model. \"\"\" def section_print ( input_text ): \"\"\"Helper function for printing\"\"\" print ( '=' * 20 , input_text , '=' * 20 ) # present a summary of the model received. section_print ( 'model received' ) print ( self ) # present a summary of datasets received. section_print ( 'data set received' ) print ( '[Training dataset]' , dataset_list [ 0 ]) print ( '[Validation dataset]' , dataset_list [ 1 ]) print ( '[Testing dataset]' , dataset_list [ 2 ]) # create pytorch dataloader objects. train = create_data_loader ( dataset_list [ 0 ], batch_size = batch_size , shuffle = True , num_workers = num_workers ) validation = create_data_loader ( dataset_list [ 1 ], batch_size = batch_size , shuffle = False , num_workers = num_workers ) # WARNING: the test step takes extensive memory cost since it computes likelihood for all items. # we run the test step with a much smaller batch_size. test = create_data_loader ( dataset_list [ 2 ], batch_size = batch_size // 10 , shuffle = False , num_workers = num_workers ) section_print ( 'train the model' ) trainer = pl . Trainer ( gpus = 1 if ( 'cuda' in str ( self )) else 0 , # use GPU if the model is currently on the GPU. max_epochs = num_epochs , check_val_every_n_epoch = 1 , log_every_n_steps = 1 , ** kwargs ) start_time = time . time () trainer . fit ( self , train_dataloaders = train , val_dataloaders = validation ) print ( f 'time taken: { time . time () - start_time } ' ) section_print ( 'test performance' ) trainer . test ( self , dataloaders = test ) return self","title":"LitBEMBFlex"},{"location":"api_bemb/#bemb.model.bemb_flex_lightning.LitBEMBFlex.__init__","text":"The initialization method of the wrapper model. Parameters: Name Type Description Default learning_rate float the learning rate of optimization. Defaults to 0.3. 0.3 num_seeds int number of random seeds for the Monte Carlo estimation in the variational inference. Defaults to 1. 1 **kwargs all keyword arguments used for constructing the wrapped BEMB model. {} Source code in bemb/model/bemb_flex_lightning.py def __init__ ( self , learning_rate : float = 0.3 , num_seeds : int = 1 , ** kwargs ): \"\"\"The initialization method of the wrapper model. Args: learning_rate (float, optional): the learning rate of optimization. Defaults to 0.3. num_seeds (int, optional): number of random seeds for the Monte Carlo estimation in the variational inference. Defaults to 1. **kwargs: all keyword arguments used for constructing the wrapped BEMB model. \"\"\" # use kwargs to pass parameter to BEMB Torch. super () . __init__ () self . model = BEMBFlex ( ** kwargs ) self . num_needs = num_seeds self . learning_rate = learning_rate","title":"__init__()"},{"location":"api_bemb/#bemb.model.bemb_flex_lightning.LitBEMBFlex.configure_optimizers","text":"Choose what optimizers and learning-rate schedulers to use in your optimization. Normally you'd need one. But in the case of GANs or similar you might have multiple. Returns: Type Description Any of these 6 options. Single optimizer . List or Tuple of optimizers. Two lists - The first list has multiple optimizers, and the second has multiple LR schedulers (or multiple lr_scheduler_config ). Dictionary , with an \"optimizer\" key, and (optionally) a \"lr_scheduler\" key whose value is a single LR scheduler or lr_scheduler_config . Tuple of dictionaries as described above, with an optional \"frequency\" key. None - Fit will run without any optimizer. The lr_scheduler_config is a dictionary which contains the scheduler and its associated configuration. The default configuration is shown below. .. code-block:: python lr_scheduler_config = { # REQUIRED: The scheduler instance \"scheduler\": lr_scheduler, # The unit of the scheduler's step size, could also be 'step'. # 'epoch' updates the scheduler on epoch end whereas 'step' # updates it after a optimizer update. \"interval\": \"epoch\", # How many epochs/steps should pass between calls to # `scheduler.step()`. 1 corresponds to updating the learning # rate after every epoch/step. \"frequency\": 1, # Metric to to monitor for schedulers like `ReduceLROnPlateau` \"monitor\": \"val_loss\", # If set to `True`, will enforce that the value specified 'monitor' # is available when the scheduler is updated, thus stopping # training if not found. If set to `False`, it will only produce a warning \"strict\": True, # If using the `LearningRateMonitor` callback to monitor the # learning rate progress, this keyword can be used to specify # a custom logged name \"name\": None, } When there are schedulers in which the .step() method is conditioned on a value, such as the :class: torch.optim.lr_scheduler.ReduceLROnPlateau scheduler, Lightning requires that the lr_scheduler_config contains the keyword \"monitor\" set to the metric name that the scheduler should be conditioned on. .. testcode:: # The ReduceLROnPlateau scheduler requires a monitor def configure_optimizers(self): optimizer = Adam(...) return { \"optimizer\": optimizer, \"lr_scheduler\": { \"scheduler\": ReduceLROnPlateau(optimizer, ...), \"monitor\": \"metric_to_track\", \"frequency\": \"indicates how often the metric is updated\" # If \"monitor\" references validation metrics, then \"frequency\" should be set to a # multiple of \"trainer.check_val_every_n_epoch\". }, } # In the case of two optimizers, only one using the ReduceLROnPlateau scheduler def configure_optimizers(self): optimizer1 = Adam(...) optimizer2 = SGD(...) scheduler1 = ReduceLROnPlateau(optimizer1, ...) scheduler2 = LambdaLR(optimizer2, ...) return ( { \"optimizer\": optimizer1, \"lr_scheduler\": { \"scheduler\": scheduler1, \"monitor\": \"metric_to_track\", }, }, {\"optimizer\": optimizer2, \"lr_scheduler\": scheduler2}, ) Metrics can be made available to monitor by simply logging it using self.log('metric_to_track', metric_val) in your :class: ~pytorch_lightning.core.lightning.LightningModule . !!! note The frequency value specified in a dict along with the optimizer key is an int corresponding to the number of sequential batches optimized with the specific optimizer. It should be given to none or to all of the optimizers. There is a difference between passing multiple optimizers in a list, and passing multiple optimizers in dictionaries with a frequency of 1: - In the former case, all optimizers will operate on the given batch in each optimization step. - In the latter, only one optimizer will operate on the given batch at every step. This is different from the ``frequency`` value specified in the ``lr_scheduler_config`` mentioned above. .. code-block:: python def configure_optimizers(self): optimizer_one = torch.optim.SGD(self.model.parameters(), lr=0.01) optimizer_two = torch.optim.SGD(self.model.parameters(), lr=0.01) return [ {\"optimizer\": optimizer_one, \"frequency\": 5}, {\"optimizer\": optimizer_two, \"frequency\": 10}, ] In this example, the first optimizer will be used for the first 5 steps, the second optimizer for the next 10 steps and that cycle will continue. If an LR scheduler is specified for an optimizer using the ``lr_scheduler`` key in the above dict, the scheduler will only be updated when its optimizer is being used. Examples:: # most cases. no learning rate scheduler def configure_optimizers(self): return Adam(self.parameters(), lr=1e-3) # multiple optimizer case (e.g.: GAN) def configure_optimizers(self): gen_opt = Adam(self.model_gen.parameters(), lr=0.01) dis_opt = Adam(self.model_dis.parameters(), lr=0.02) return gen_opt, dis_opt # example with learning rate schedulers def configure_optimizers(self): gen_opt = Adam(self.model_gen.parameters(), lr=0.01) dis_opt = Adam(self.model_dis.parameters(), lr=0.02) dis_sch = CosineAnnealing(dis_opt, T_max=10) return [gen_opt, dis_opt], [dis_sch] # example with step-based learning rate schedulers # each optimizer has its own scheduler def configure_optimizers(self): gen_opt = Adam(self.model_gen.parameters(), lr=0.01) dis_opt = Adam(self.model_dis.parameters(), lr=0.02) gen_sch = { 'scheduler': ExponentialLR(gen_opt, 0.99), 'interval': 'step' # called after each training step } dis_sch = CosineAnnealing(dis_opt, T_max=10) # called every epoch return [gen_opt, dis_opt], [gen_sch, dis_sch] # example with optimizer frequencies # see training procedure in `Improved Training of Wasserstein GANs`, Algorithm 1 # https://arxiv.org/abs/1704.00028 def configure_optimizers(self): gen_opt = Adam(self.model_gen.parameters(), lr=0.01) dis_opt = Adam(self.model_dis.parameters(), lr=0.02) n_critic = 5 return ( {'optimizer': dis_opt, 'frequency': n_critic}, {'optimizer': gen_opt, 'frequency': 1} ) !!! note Some things to know: - Lightning calls ``.backward()`` and ``.step()`` on each optimizer and learning rate scheduler as needed. - If you use 16-bit precision (``precision=16``), Lightning will automatically handle the optimizers. - If you use multiple optimizers, :meth:`training_step` will have an additional ``optimizer_idx`` parameter. - If you use :class:`torch.optim.LBFGS`, Lightning handles the closure function automatically for you. - If you use multiple optimizers, gradients will be calculated only for the parameters of current optimizer at each training step. - If you need to control how often those optimizers step or override the default ``.step()`` schedule, override the :meth:`optimizer_step` hook. Source code in bemb/model/bemb_flex_lightning.py def configure_optimizers ( self ): optimizer = torch . optim . Adam ( self . parameters (), lr = self . learning_rate ) return optimizer","title":"configure_optimizers()"},{"location":"api_bemb/#bemb.model.bemb_flex_lightning.LitBEMBFlex.fit_model","text":"A standard pipeline of model training and evaluation. Parameters: Name Type Description Default dataset_list List[ChoiceDataset] train_dataset, validation_test, and test_dataset in a list of length 3. required batch_size int batch_size for training and evaluation. Defaults to -1, which indicates full-batch training. -1 num_epochs int number of epochs for training. Defaults to 10. 10 **kwargs additional keyword argument for the pytorch-lightning Trainer. {} Returns: Type Description LitBEMBFlex the trained bemb model. Source code in bemb/model/bemb_flex_lightning.py def fit_model ( self , dataset_list : List [ ChoiceDataset ], batch_size : int =- 1 , num_epochs : int = 10 , num_workers : int = 8 , ** kwargs ) -> \"LitBEMBFlex\" : \"\"\"A standard pipeline of model training and evaluation. Args: dataset_list (List[ChoiceDataset]): train_dataset, validation_test, and test_dataset in a list of length 3. batch_size (int, optional): batch_size for training and evaluation. Defaults to -1, which indicates full-batch training. num_epochs (int, optional): number of epochs for training. Defaults to 10. **kwargs: additional keyword argument for the pytorch-lightning Trainer. Returns: LitBEMBFlex: the trained bemb model. \"\"\" def section_print ( input_text ): \"\"\"Helper function for printing\"\"\" print ( '=' * 20 , input_text , '=' * 20 ) # present a summary of the model received. section_print ( 'model received' ) print ( self ) # present a summary of datasets received. section_print ( 'data set received' ) print ( '[Training dataset]' , dataset_list [ 0 ]) print ( '[Validation dataset]' , dataset_list [ 1 ]) print ( '[Testing dataset]' , dataset_list [ 2 ]) # create pytorch dataloader objects. train = create_data_loader ( dataset_list [ 0 ], batch_size = batch_size , shuffle = True , num_workers = num_workers ) validation = create_data_loader ( dataset_list [ 1 ], batch_size = batch_size , shuffle = False , num_workers = num_workers ) # WARNING: the test step takes extensive memory cost since it computes likelihood for all items. # we run the test step with a much smaller batch_size. test = create_data_loader ( dataset_list [ 2 ], batch_size = batch_size // 10 , shuffle = False , num_workers = num_workers ) section_print ( 'train the model' ) trainer = pl . Trainer ( gpus = 1 if ( 'cuda' in str ( self )) else 0 , # use GPU if the model is currently on the GPU. max_epochs = num_epochs , check_val_every_n_epoch = 1 , log_every_n_steps = 1 , ** kwargs ) start_time = time . time () trainer . fit ( self , train_dataloaders = train , val_dataloaders = validation ) print ( f 'time taken: { time . time () - start_time } ' ) section_print ( 'test performance' ) trainer . test ( self , dataloaders = test ) return self","title":"fit_model()"},{"location":"api_bemb/#bemb.model.bemb_flex_lightning.LitBEMBFlex.forward","text":"Calls the forward method of the wrapped BEMB model, please refer to the documentaton of the BEMB class for detailed definitions of the arguments. Parameters: Name Type Description Default args _type_ arguments passed to the forward method of the wrapped BEMB model. required kwargs _type_ keyword arguments passed to the forward method of the wrapped BEMB model. required Returns: Type Description _type_ returns whatever the wrapped BEMB model returns. Source code in bemb/model/bemb_flex_lightning.py def forward ( self , args , kwargs ): \"\"\"Calls the forward method of the wrapped BEMB model, please refer to the documentaton of the BEMB class for detailed definitions of the arguments. Args: args (_type_): arguments passed to the forward method of the wrapped BEMB model. kwargs (_type_): keyword arguments passed to the forward method of the wrapped BEMB model. Returns: _type_: returns whatever the wrapped BEMB model returns. \"\"\" return self . model ( * args , ** kwargs )","title":"forward()"},{"location":"api_bemb/#bemb.model.bemb_flex_lightning.LitBEMBFlex.test_step","text":"Operates on a single batch of data from the test set. In this step you'd normally generate examples or calculate anything of interest such as accuracy. .. code-block:: python # the pseudocode for these calls test_outs = [] for test_batch in test_data: out = test_step(test_batch) test_outs.append(out) test_epoch_end(test_outs) Parameters: Name Type Description Default batch The output of your :class: ~torch.utils.data.DataLoader . required batch_idx The index of this batch. required dataloader_id The index of the dataloader that produced this batch. (only if multiple test dataloaders used). required Returns: Type Description Any of. Any object or value None - Testing will skip to the next batch .. code-block:: python # if you have one test dataloader: def test_step(self, batch, batch_idx): ... # if you have multiple test dataloaders: def test_step(self, batch, batch_idx, dataloader_idx=0): ... Examples:: # CASE 1: A single test dataset def test_step(self, batch, batch_idx): x, y = batch # implement your own out = self(x) loss = self.loss(out, y) # log 6 example images # or generated text... or whatever sample_imgs = x[:6] grid = torchvision.utils.make_grid(sample_imgs) self.logger.experiment.add_image('example_images', grid, 0) # calculate acc labels_hat = torch.argmax(out, dim=1) test_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0) # log the outputs! self.log_dict({'test_loss': loss, 'test_acc': test_acc}) If you pass in multiple test dataloaders, :meth: test_step will have an additional argument. We recommend setting the default value of 0 so that you can quickly switch between single and multiple dataloaders. .. code-block:: python # CASE 2: multiple test dataloaders def test_step(self, batch, batch_idx, dataloader_idx=0): # dataloader_idx tells you which dataset this is. ... !!! note If you don't need to test you don't need to implement this method. !!! note When the :meth: test_step is called, the model has been put in eval mode and PyTorch gradients have been disabled. At the end of the test epoch, the model goes back to training mode and gradients are enabled. Source code in bemb/model/bemb_flex_lightning.py def test_step ( self , batch , batch_idx ): # LL = self.model.forward(batch, return_logit=False, all_items=False).mean() # self.log('test_log_likelihood', LL) # pred = self.model(batch, return_type='utility', return_scope='item_index', deterministic=True) # y_pred = torch.sigmoid(pred).cpu().numpy() # y_true = batch.label.cpu().numpy() # performance = {'acc': metrics.accuracy_score(y_true=y_true, y_pred=(y_pred >= 0.5).astype(int)), # 'll': - metrics.log_loss(y_true=y_true, y_pred=y_pred, eps=1E-5, labels=[0, 1]), # # 'auc': metrics.roc_auc_score(y_true=y_true, y_score=y_pred), # # 'f1': metrics.f1_score(y_true=y_true, y_pred=(y_pred >= 0.5).astype(int)) # } # pred = self.model(batch) # performance = self.model.get_within_category_accuracy(pred, batch.label) for key , val in self . _get_performance_dict ( batch ) . items (): self . log ( 'test_' + key , val , prog_bar = True , batch_size = len ( batch ))","title":"test_step()"},{"location":"api_bemb/#bemb.model.bemb_flex_lightning.LitBEMBFlex.training_step","text":"Here you compute and return the training loss and some additional metrics for e.g. the progress bar or logger. Parameters: Name Type Description Default batch class: ~torch.Tensor | (:class: ~torch.Tensor , ...) | [:class: ~torch.Tensor , ...]): The output of your :class: ~torch.utils.data.DataLoader . A tensor, tuple or list. required batch_idx ``int`` Integer displaying index of this batch required optimizer_idx ``int`` When using multiple optimizers, this argument will also be present. required hiddens ``Any`` Passed in if :paramref: ~pytorch_lightning.core.lightning.LightningModule.truncated_bptt_steps > 0. required Returns: Type Description Any of. - class: ~torch.Tensor - The loss tensor - dict - A dictionary. Can include any keys, but must include the key 'loss' - None - Training will skip to the next batch. This is only for automatic optimization. This is not supported for multi-GPU, TPU, IPU, or DeepSpeed. In this step you'd normally do the forward pass and calculate the loss for a batch. You can also do fancier things like multiple forward passes or something model specific. Example:: def training_step(self, batch, batch_idx): x, y, z = batch out = self.encoder(x) loss = self.loss(out, x) return loss If you define multiple optimizers, this step will be called with an additional optimizer_idx parameter. .. code-block:: python # Multiple optimizers (e.g.: GANs) def training_step(self, batch, batch_idx, optimizer_idx): if optimizer_idx == 0: # do training_step with encoder ... if optimizer_idx == 1: # do training_step with decoder ... If you add truncated back propagation through time you will also get an additional argument with the hidden states of the previous step. .. code-block:: python # Truncated back-propagation through time def training_step(self, batch, batch_idx, hiddens): # hiddens are the hidden states from the previous truncated backprop step out, hiddens = self.lstm(data, hiddens) loss = ... return {\"loss\": loss, \"hiddens\": hiddens} !!! note The loss value shown in the progress bar is smoothed (averaged) over the last values, so it differs from the actual loss returned in train/validation step. Source code in bemb/model/bemb_flex_lightning.py def training_step ( self , batch , batch_idx ): elbo = self . model . elbo ( batch , num_seeds = self . num_needs ) self . log ( 'train_elbo' , elbo ) loss = - elbo return loss","title":"training_step()"},{"location":"api_bemb/#bemb.model.bemb_flex_lightning.LitBEMBFlex.validation_step","text":"Operates on a single batch of data from the validation set. In this step you'd might generate examples or calculate anything of interest like accuracy. .. code-block:: python # the pseudocode for these calls val_outs = [] for val_batch in val_data: out = validation_step(val_batch) val_outs.append(out) validation_epoch_end(val_outs) Parameters: Name Type Description Default batch The output of your :class: ~torch.utils.data.DataLoader . required batch_idx The index of this batch. required dataloader_idx The index of the dataloader that produced this batch. (only if multiple val dataloaders used) required Returns: Type Description Any object or value None - Validation will skip to the next batch .. code-block:: python # pseudocode of order val_outs = [] for val_batch in val_data: out = validation_step(val_batch) if defined(\"validation_step_end\"): out = validation_step_end(out) val_outs.append(out) val_outs = validation_epoch_end(val_outs) .. code-block:: python # if you have one val dataloader: def validation_step(self, batch, batch_idx): ... # if you have multiple val dataloaders: def validation_step(self, batch, batch_idx, dataloader_idx=0): ... Examples:: # CASE 1: A single validation dataset def validation_step(self, batch, batch_idx): x, y = batch # implement your own out = self(x) loss = self.loss(out, y) # log 6 example images # or generated text... or whatever sample_imgs = x[:6] grid = torchvision.utils.make_grid(sample_imgs) self.logger.experiment.add_image('example_images', grid, 0) # calculate acc labels_hat = torch.argmax(out, dim=1) val_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0) # log the outputs! self.log_dict({'val_loss': loss, 'val_acc': val_acc}) If you pass in multiple val dataloaders, :meth: validation_step will have an additional argument. We recommend setting the default value of 0 so that you can quickly switch between single and multiple dataloaders. .. code-block:: python # CASE 2: multiple validation dataloaders def validation_step(self, batch, batch_idx, dataloader_idx=0): # dataloader_idx tells you which dataset this is. ... !!! note If you don't need to validate you don't need to implement this method. !!! note When the :meth: validation_step is called, the model has been put in eval mode and PyTorch gradients have been disabled. At the end of validation, the model goes back to training mode and gradients are enabled. Source code in bemb/model/bemb_flex_lightning.py def validation_step ( self , batch , batch_idx ): # LL = self.model.forward(batch, return_type='log_prob', return_scope='item_index', deterministic=True).mean() # self.log('val_log_likelihood', LL, prog_bar=True) # pred = self.model(batch) # performance = self.model.get_within_category_accuracy(pred, batch.label) # utility. for key , val in self . _get_performance_dict ( batch ) . items (): self . log ( 'val_' + key , val , prog_bar = True , batch_size = len ( batch ))","title":"validation_step()"},{"location":"api_bemb/#bemb.utils","text":"","title":"utils"},{"location":"api_bemb/#bemb.utils.run_helper","text":"This script contains a helper function for training and testing the BEMB model. The helper function here serves as a template for the training procedure, we encourage users to make a copy of this function and modify it to fully leverage the potential of pytorch lightning (e.g., early stopping and checkpointing).","title":"run_helper"},{"location":"api_bemb/#bemb.utils.run_helper.run","text":"A standard pipeline of model training and evaluation. Parameters: Name Type Description Default model LitBEMBFlex the initialized pytorch-lightning wrapper of bemb. required dataset_list List[ChoiceDataset] train_dataset, validation_test, and test_dataset in a list of length 3. required batch_size int batch_size for training and evaluation. Defaults to -1, which indicates full-batch training. -1 num_epochs int number of epochs for training. Defaults to 10. 10 **kwargs additional keyword argument for the pytorch-lightning Trainer. {} Returns: Type Description LitBEMBFlex the trained bemb model. Source code in bemb/utils/run_helper.py def run ( model : LitBEMBFlex , dataset_list : List [ ChoiceDataset ], batch_size : int =- 1 , num_epochs : int = 10 , num_workers : int = 8 , ** kwargs ) -> LitBEMBFlex : \"\"\"A standard pipeline of model training and evaluation. Args: model (LitBEMBFlex): the initialized pytorch-lightning wrapper of bemb. dataset_list (List[ChoiceDataset]): train_dataset, validation_test, and test_dataset in a list of length 3. batch_size (int, optional): batch_size for training and evaluation. Defaults to -1, which indicates full-batch training. num_epochs (int, optional): number of epochs for training. Defaults to 10. **kwargs: additional keyword argument for the pytorch-lightning Trainer. Returns: LitBEMBFlex: the trained bemb model. \"\"\" # present a summary of the model received. section_print ( 'model received' ) print ( model ) # present a summary of datasets received. section_print ( 'data set received' ) print ( '[Training dataset]' , dataset_list [ 0 ]) print ( '[Validation dataset]' , dataset_list [ 1 ]) print ( '[Testing dataset]' , dataset_list [ 2 ]) # create pytorch dataloader objects. train = create_data_loader ( dataset_list [ 0 ], batch_size = batch_size , shuffle = True , num_workers = num_workers ) validation = create_data_loader ( dataset_list [ 1 ], batch_size = batch_size , shuffle = False , num_workers = num_workers ) # WARNING: the test step takes extensive memory cost since it computes likelihood for all items. # we run the test step with a much smaller batch_size. test = create_data_loader ( dataset_list [ 2 ], batch_size = batch_size // 10 , shuffle = False , num_workers = num_workers ) section_print ( 'train the model' ) trainer = pl . Trainer ( gpus = 1 if ( 'cuda' in str ( model . device )) else 0 , # use GPU if the model is currently on the GPU. max_epochs = num_epochs , check_val_every_n_epoch = 1 , log_every_n_steps = 1 , ** kwargs ) start_time = time . time () trainer . fit ( model , train_dataloaders = train , val_dataloaders = validation ) print ( f 'time taken: { time . time () - start_time } ' ) section_print ( 'test performance' ) trainer . test ( model , dataloaders = test ) return model","title":"run()"},{"location":"api_bemb/#bemb.utils.run_helper.section_print","text":"Helper function for printing Source code in bemb/utils/run_helper.py def section_print ( input_text ): \"\"\"Helper function for printing\"\"\" print ( '=' * 20 , input_text , '=' * 20 )","title":"section_print()"},{"location":"bemb/","text":"BEMB Tutorial This tutorial assumes the reader has ready gone through the Data Management tutorial. Through this tutorial, we use Greek letters (except for \\(\\varepsilon\\) as error term) to denote learnable coefficients of the model. However, researchers are not restricted to use Greek letters in practice. Bayesian EMBedding (BEMB) is a hierarchical Bayesian model for modelling consumer choices. The model can naturally extend to other use cases which can be formulated into the consumer choice framework. For example, in a job-transition modelling study, we formulated the starting job as the user and ending job as the item and applied the BEMB framework. Suppose we have a dataset of purchase records consisting of \\(U\\) users, \\(I\\) items, and \\(S\\) sessions, at it's core (assume no \\(s\\) -level effect for now), the BEMB model aims to build user embeddings \\(\\theta_u \\in \\mathbb{R}^{L}\\) and item embeddings \\(\\alpha_i \\in \\mathbb{R}^{L}\\) , then the model predicts the probability for user \\(u\\) to purchase item \\(i\\) as $$ P(i|u,s) = F(\\theta_u^\\top \\alpha_i), $$ where \\(F: \\mathbb{R} \\to [0, 1]\\) is an increasing function. Both of \\(\\theta_u\\) and \\(\\alpha_i\\) are Bayesian , which means there is a prior distribution and a variational distribution associated with each of them. By default, the prior distribution of all entries of \\(\\theta_u\\) and \\(\\alpha_i\\) are i.i.d. standard Gaussian distributions. The variational distributions are Gaussian with learnable mean and standard deviation, these parameters are trained by minimizing the ELBO so that the predicted purchasing probabilities best fit the observed dataset. TODO : add reference to the paper introducing BEMB for a complete description of the model. Running BEMB Running BEMB requires you to (1) build the ChoiceDataset object and (2) training the model. The ChoiceDataset Please refer to the Data Management tutorial for a detailed walk-through of how to constructing the dataset. For simplicity, we assume that item/user/session/price observables are named as {item, user, session, price}_obs in the ChoiceDataset , the researcher can use arbitrary variable names as long as they satisfy the naming convention (e.g., user-level observables should start with user_ and cannot be user_index ) and have the correct shape (e.g., user-level observables should have shape (num_users, num_obs) ). Setup the BEMB Model (PyTorch-Lightning Interface) You will be constructing the LitBEMBFlex class, which is a PyTorch-lightning wrapper of the BEMB model implemented in plain PyTorch. The lighting wrapper free researchers from complications such as setting up the training loop and optimizers. To initialize the LitBEMBFlex class, the researcher needs to provide it with the following arguments. We recommend the research to encompass all arguments in a separate yaml file. Most of these arguments should be self explanatory, Please refer to the doc string of BEMBFlex.__init__() for a detailed elaboration. Utility Formula: utility_formula Note : for the string parsing to work correctly, please do add spaces around + and * . This section covers how to convert the utility representation in a choice problem into the utility_formula argument of the BEMBFlex model and LitBEMBFlex wrapper. The core of specifying a BEMB model is to specify the utility function \\(\\mathcal{U}(u,i,s)\\) for user \\(u\\) to purchase item \\(i\\) in session \\(s\\) , the bemb package provides an easy-to-use string-parsing mechanism for researchers to provide their ideal utility representations. With the utility representation, the probability for consumer \\(u\\) to purchase item \\(i\\) in session \\(s\\) is the following \\[ P(i|u,s) = \\frac{e^{\\mathcal{U}(u, i, s)}}{\\sum_{i' \\in I_c} e^{\\mathcal{U}(u, i', s)}} \\] where \\(I_c\\) is the set of items in the same category of item \\(i\\) . If there is no category information, the model considers all items to be in the same category, i.e., \\(I_c = \\{1, 2, \\dots I\\}\\) . The BEMB admits a linear additive form of utility formula. For example, the model parses utility formula string lambda_item + theta_user * alpha_item + zeta_user * item_obs into the following representation: \\[ \\mathcal{U}(u, i, s)= \\lambda_i + \\theta_u^\\top \\alpha_i + \\zeta_u^\\top X^{item}_i + \\varepsilon \\in \\mathbb{R} \\] The utility_formula consists of two classes of objects: 1. learnable coefficients (i.e., Greek letters): the string-parser identifies learnable coefficients by looking at their suffix. These variables can be (1) constant across all items and users, (2) user-specific, or (3) item-specific. For example, the \\(\\lambda_i\\) term above is item-specific intercept and it is presented as item_item in the utility_formula . To ensure the string-parsing is working properly, learnable coefficients must ends with one of {_item, _user, _constant} . 2. Observable Tensors are identified by their prefix, which tells whether they are item-specific (with item_ prefix), user-specific (with user_ prefix), session-specific (with session_ prefix), or session-and-item-specific (with price_ prefix) observables. Each of these observables should present in the ChoiceDataset data structure constructed. Warning : the utility_formula parser identifies learnable coefficients as using suffix and observables using prefix, the researcher should never name things with both prefix in {user_, item_, session_, price_} and suffix {_constant, _user, _item} such as item_quality_user . Overall, there are four types of additive component, except the error term \\(\\epsilon\\) , in the utility representation: Standalone coefficients \\(\\lambda, \\lambda_i, \\lambda_u \\in \\mathbb{R}\\) representing intercepts and item/user level fixed effects. \u201cMatrix factorization\u201d coefficients \\(\\theta_u^\\top \\alpha_i\\) , where \\(\\theta_u,\\alpha_i \\in \\mathbb{R}^L\\) are embedding/latent of users and items, \\(L\\) is the latent dimension specified by the researcher. Observable terms \\(\\zeta_u^\\top X^{item}_i\\) , where each \\(\\zeta_u \\in \\mathbb{R}^{K_{item}}\\) is the user specific coefficients for item observables. This type of component is written as zeta_user * item_obs in the utility formula. For sure, one can use coefficients constant among users by simply putting zeta_constant in the utility formula. \u201cMatrix factorization\u201d coefficients of observables written as gamma_user * beta_item * price_obs . This type of component factorizes the coefficient of observables into user and item latents. For example, suppose there are \\(K_{price}\\) price observables (i.e., observables varying by both item and session, price is one of them!), for each of price observable \\(X^{price}_{is}[k] \\in \\mathbb{R}\\) , a pair of latent \\(\\gamma_u^k, \\beta_i^k \\in \\mathbb{R}^L\\) is trained to construct the coefficient of the \\(k^{th}\\) price observable, where \\(L\\) is the latent dimension specified by the researcher. In this case, the utility is \\(\\mathcal{U}(u, i, s) = \\sum_{k=1}^K (\\gamma_u^{k\\top} \\beta_i^k) X^{price}_{is}[k]\\) . One can for sure replace the price_obs with any of {user, item, session}_obs . If the researcher wish to treat different part of item observable differently, for example, \\[ \\mathcal{U}(u, i, s) = \\dots + \\zeta_u^\\top Y^{item}_i + \\omega^\\top Z^{item}_i + \\dots \\] where we partition item observables into two parts \\(X^{item}_i = [Y^{item}_i, Z^{item}_i]\\) , and the coefficient for \\(Y^{item}_i\\) is user-specific but the coefficient for the second part is constant across all users. In this case, the researcher should use separate tensors item_obs_part1 and item_obs_part2 while constructing the ChoiceDataset (both of them needs to start with item_ ), and use the utility formula with zeta_user * item_obs_part1 + omega_constant * item_obs_part2 . With the above four cases as building blocks, the researcher can specify all kinds of utility functions. Number of Users/Items/Sessions num_{users, items, sessions} The researcher is responsible for providing the size of the prediction problem. For every model, the num_items is required . However, num_users and num_sessions are required only if there is any user/session-specific observables or parameters involved in the utility_formula . Specifying the Dimensions of Coefficients with the coef_dim_dict dictionary To correctly initialize the model, the constructor needs to know the shape of each learnable coefficients (i.e., Greek letters above). For item/user-specific parameters, the value of coef_dim_dict is the number of parameters for each user/item, not the total number of parameters. 1. For standalone coefficients like lambda_item , coef_dim_dict['lambda_item'] = 1 always. 2. For matrix factorization coefficients like theta_user and alpha_item , coef_dim_dict['theta_user'] = coef_dim_dict[alpha_item] = L , where L is the desired latent dimension. For the inner product between \\(\\alpha_i\\) and \\(\\theta_u\\) to work properly, coef_dim_dict['theta_user'] == coef_dim_dict['alpha_item'] . 3. For terms like \\(\\zeta_u^\\top X^{item}_i\\) , coef_dim_dict['zeta_user'] needs to be the dimension of \\(X^{item}_i\\) . 4. For matrix factorization coefficients, the dimension needs to be the latent dimension multiplied by the number of observables. For example, if you have a 3-dimensional feature \\(X = (x_1, x_2, x_3)\\) , the utility is \\(\\mathcal{U}(u, i, s) = \\zeta_{u, i}^\\top X\\) , and \\(\\zeta_{u, i}\\) needs to be factorized into two an user-specific and item-specific part (both in \\(\\mathbb{R}^L\\) ) as below \\[ \\mathcal{U}(u, i, s) = \\sum_{k=1}^3 (\\gamma_u^{k\\top} \\beta_i^k) x_k \\] then coef_dim_dict[gamma_user] = coef_dim_dict[beta_item] = 3 * L . TODO : sounds like a lot of work? we are currently developing helper function to infer all these information from the ChoiceDataset , but we will still provide researchers with the full control over the configuration. Specifying Variance of Coefficient Prior Distributions with prior_variance The prior_variance term can be either a scalar or a dictionary with the same keys of coef_dim_dict , which provides the variance of prior distribution for each learnable coefficients. If a float is provided, all priors will be Gaussian distribution with diagonal covariance matrix with prior_variance along the diagonal. If a dictionary is provided, keys of prior_variance should be coefficient names, and the prior of each coef_name would be a Gaussian with diagonal covariance matrix with prior_variance[coef_name] along the diagonal. This value is default to be 1.0 , which means priors of all coefficients are standard Gaussian distributions. Incorporating Observables to the Bayesian Prior with obs2prior_dict BEMB is a Bayesian factorization model trained by optimizing the evidence lower bound (ELBO). Each parameter (i.e., these with _item, _user, _constant suffix.) in the BEMB model carries a prior distribution, which is set to \\(\\mathcal{N}(\\mathbf{0}, \\mathbf{I})\\) by default. With prior_variance argument described above, one can specify different scales/variances for different learnable coefficients. Beyond this baseline case, the hierarchical nature of BEMB allows the mean of the prior distribution to depend on observables as a (learnable) linear mapping. For example: \\[ \\theta_{i} \\overset{prior}{\\sim} \\mathcal{N}(HX^{item}_i, \\mathbf{I}) \\] where the prior mean is a linear transformation of the item observable and \\(H: \\mathbb{R}^{K_{item}} \\to \\mathbb{R}^L\\) . To enable the observable-to-prior feature, one needs to set obs2prior_dict['theta_item']=True . In order to leverage obs-to-prior for item-specific coefficients like theta_item , the researchers need to include item_obs tensor to the ChoiceDataset , the attribute name needs to be exactly item_obs , just with item_ prefix is not sufficient. Similarly, user_obs are required if obs-to-prior is turned on for any of user-specific coefficients. Grouping Items into Categories with category_to_item In some cases the researcher wishes to provide additional guidance to the model by providing the category of the bought item in teach purchasing record. In this case, the probability of purchasing each \\(i\\) will be normalized only across other items from the same category rather than all items. The category_to_item argument provides a dictionary with category id or name as keys, and category_to_item[C] contains the list of item ids belonging to category C . With category_to_item provided, for the probability of purchasing item \\(i\\) by user \\(u\\) in session, let \\(I_c\\) denote the set of items belonging to the same category \\(i\\) , the probability of purchasing is \\[ P(i|u,s) = \\frac{e^{\\mathcal{U}(u, i, s)}}{\\sum_{i' \\in I_c} e^{\\mathcal{U}(u, i', s)}} \\] If category_to_item is not provided (or None is provided), the probability of purchasing item \\(i\\) by user \\(u\\) in session \\(s\\) is (note the difference in summation scope, this is computed as if all items are from the same category): \\[ P(i|u,s) = \\frac{e^{\\mathcal{U}(u, i, s)}}{\\sum_{i'=1}^I e^{\\mathcal{U}(u, i', s)}} \\] Last Step: Create the LitBEMBFlex wrapper The last step is to create the LitBEMBFlex object which contains all information we gathered above. You will also need to provide a learning_rate for the the optimizer and a num_seeds for the Monte-Carlo estimator of gradient in ELBO. model = bemb . model . LitBEMBFlex ( learning_rate = 0.01 , num_seeds = 4 , utility_formula = utility_formula , num_users = num_users , num_items = num_items , num_sessions = num_sessions , obs2prior_dict = obs2prior_dict , coef_dim_dict = coef_dim_dict , category_to_item = category_to_item , num_user_obs = num_user_obs , num_item_obs = num_item_obs , ) Training the Model We provide a ready-to-use scrip to train the model, where dataset_list is a list consists of three ChoiceDataset objects (see the Data Management tutorial for splitting datasets), the training, validation, and testing dataset. model = model . to ( 'cuda' ) # only if GPU is installed model = bemb . utils . run_helper . run ( model , dataset_list , batch_size = 32 , num_epochs = 10 ) Inference Lastly, to get the utilities (i.e., the logit) of the item bought for each row of the test dataset, the model.model.forward() method does the trick. You can either compute the utility for the purchased item or for all items, we put significant effort on optimizing the pipeline for estimating utility of the bought item, so it's much faster than computing utilities of all items. with torch . no_grad (): # disable gradient tracking to save computational cost. utility_chosen = model . model . forward ( dataset_list [ 2 ], return_logit = True , all_items = False ) # uses much higher memory! utility_all = model . model . forward ( dataset_list [ 2 ], return_logit = True , all_items = True )","title":"Tutorial for Bayesian Embedding (BEMB)"},{"location":"bemb/#bemb-tutorial","text":"This tutorial assumes the reader has ready gone through the Data Management tutorial. Through this tutorial, we use Greek letters (except for \\(\\varepsilon\\) as error term) to denote learnable coefficients of the model. However, researchers are not restricted to use Greek letters in practice. Bayesian EMBedding (BEMB) is a hierarchical Bayesian model for modelling consumer choices. The model can naturally extend to other use cases which can be formulated into the consumer choice framework. For example, in a job-transition modelling study, we formulated the starting job as the user and ending job as the item and applied the BEMB framework. Suppose we have a dataset of purchase records consisting of \\(U\\) users, \\(I\\) items, and \\(S\\) sessions, at it's core (assume no \\(s\\) -level effect for now), the BEMB model aims to build user embeddings \\(\\theta_u \\in \\mathbb{R}^{L}\\) and item embeddings \\(\\alpha_i \\in \\mathbb{R}^{L}\\) , then the model predicts the probability for user \\(u\\) to purchase item \\(i\\) as $$ P(i|u,s) = F(\\theta_u^\\top \\alpha_i), $$ where \\(F: \\mathbb{R} \\to [0, 1]\\) is an increasing function. Both of \\(\\theta_u\\) and \\(\\alpha_i\\) are Bayesian , which means there is a prior distribution and a variational distribution associated with each of them. By default, the prior distribution of all entries of \\(\\theta_u\\) and \\(\\alpha_i\\) are i.i.d. standard Gaussian distributions. The variational distributions are Gaussian with learnable mean and standard deviation, these parameters are trained by minimizing the ELBO so that the predicted purchasing probabilities best fit the observed dataset. TODO : add reference to the paper introducing BEMB for a complete description of the model.","title":"BEMB Tutorial"},{"location":"bemb/#running-bemb","text":"Running BEMB requires you to (1) build the ChoiceDataset object and (2) training the model.","title":"Running BEMB"},{"location":"bemb/#the-choicedataset","text":"Please refer to the Data Management tutorial for a detailed walk-through of how to constructing the dataset. For simplicity, we assume that item/user/session/price observables are named as {item, user, session, price}_obs in the ChoiceDataset , the researcher can use arbitrary variable names as long as they satisfy the naming convention (e.g., user-level observables should start with user_ and cannot be user_index ) and have the correct shape (e.g., user-level observables should have shape (num_users, num_obs) ).","title":"The ChoiceDataset"},{"location":"bemb/#setup-the-bemb-model-pytorch-lightning-interface","text":"You will be constructing the LitBEMBFlex class, which is a PyTorch-lightning wrapper of the BEMB model implemented in plain PyTorch. The lighting wrapper free researchers from complications such as setting up the training loop and optimizers. To initialize the LitBEMBFlex class, the researcher needs to provide it with the following arguments. We recommend the research to encompass all arguments in a separate yaml file. Most of these arguments should be self explanatory, Please refer to the doc string of BEMBFlex.__init__() for a detailed elaboration.","title":"Setup the BEMB Model (PyTorch-Lightning Interface)"},{"location":"bemb/#utility-formula-utility_formula","text":"Note : for the string parsing to work correctly, please do add spaces around + and * . This section covers how to convert the utility representation in a choice problem into the utility_formula argument of the BEMBFlex model and LitBEMBFlex wrapper. The core of specifying a BEMB model is to specify the utility function \\(\\mathcal{U}(u,i,s)\\) for user \\(u\\) to purchase item \\(i\\) in session \\(s\\) , the bemb package provides an easy-to-use string-parsing mechanism for researchers to provide their ideal utility representations. With the utility representation, the probability for consumer \\(u\\) to purchase item \\(i\\) in session \\(s\\) is the following \\[ P(i|u,s) = \\frac{e^{\\mathcal{U}(u, i, s)}}{\\sum_{i' \\in I_c} e^{\\mathcal{U}(u, i', s)}} \\] where \\(I_c\\) is the set of items in the same category of item \\(i\\) . If there is no category information, the model considers all items to be in the same category, i.e., \\(I_c = \\{1, 2, \\dots I\\}\\) . The BEMB admits a linear additive form of utility formula. For example, the model parses utility formula string lambda_item + theta_user * alpha_item + zeta_user * item_obs into the following representation: \\[ \\mathcal{U}(u, i, s)= \\lambda_i + \\theta_u^\\top \\alpha_i + \\zeta_u^\\top X^{item}_i + \\varepsilon \\in \\mathbb{R} \\] The utility_formula consists of two classes of objects: 1. learnable coefficients (i.e., Greek letters): the string-parser identifies learnable coefficients by looking at their suffix. These variables can be (1) constant across all items and users, (2) user-specific, or (3) item-specific. For example, the \\(\\lambda_i\\) term above is item-specific intercept and it is presented as item_item in the utility_formula . To ensure the string-parsing is working properly, learnable coefficients must ends with one of {_item, _user, _constant} . 2. Observable Tensors are identified by their prefix, which tells whether they are item-specific (with item_ prefix), user-specific (with user_ prefix), session-specific (with session_ prefix), or session-and-item-specific (with price_ prefix) observables. Each of these observables should present in the ChoiceDataset data structure constructed. Warning : the utility_formula parser identifies learnable coefficients as using suffix and observables using prefix, the researcher should never name things with both prefix in {user_, item_, session_, price_} and suffix {_constant, _user, _item} such as item_quality_user . Overall, there are four types of additive component, except the error term \\(\\epsilon\\) , in the utility representation: Standalone coefficients \\(\\lambda, \\lambda_i, \\lambda_u \\in \\mathbb{R}\\) representing intercepts and item/user level fixed effects. \u201cMatrix factorization\u201d coefficients \\(\\theta_u^\\top \\alpha_i\\) , where \\(\\theta_u,\\alpha_i \\in \\mathbb{R}^L\\) are embedding/latent of users and items, \\(L\\) is the latent dimension specified by the researcher. Observable terms \\(\\zeta_u^\\top X^{item}_i\\) , where each \\(\\zeta_u \\in \\mathbb{R}^{K_{item}}\\) is the user specific coefficients for item observables. This type of component is written as zeta_user * item_obs in the utility formula. For sure, one can use coefficients constant among users by simply putting zeta_constant in the utility formula. \u201cMatrix factorization\u201d coefficients of observables written as gamma_user * beta_item * price_obs . This type of component factorizes the coefficient of observables into user and item latents. For example, suppose there are \\(K_{price}\\) price observables (i.e., observables varying by both item and session, price is one of them!), for each of price observable \\(X^{price}_{is}[k] \\in \\mathbb{R}\\) , a pair of latent \\(\\gamma_u^k, \\beta_i^k \\in \\mathbb{R}^L\\) is trained to construct the coefficient of the \\(k^{th}\\) price observable, where \\(L\\) is the latent dimension specified by the researcher. In this case, the utility is \\(\\mathcal{U}(u, i, s) = \\sum_{k=1}^K (\\gamma_u^{k\\top} \\beta_i^k) X^{price}_{is}[k]\\) . One can for sure replace the price_obs with any of {user, item, session}_obs . If the researcher wish to treat different part of item observable differently, for example, \\[ \\mathcal{U}(u, i, s) = \\dots + \\zeta_u^\\top Y^{item}_i + \\omega^\\top Z^{item}_i + \\dots \\] where we partition item observables into two parts \\(X^{item}_i = [Y^{item}_i, Z^{item}_i]\\) , and the coefficient for \\(Y^{item}_i\\) is user-specific but the coefficient for the second part is constant across all users. In this case, the researcher should use separate tensors item_obs_part1 and item_obs_part2 while constructing the ChoiceDataset (both of them needs to start with item_ ), and use the utility formula with zeta_user * item_obs_part1 + omega_constant * item_obs_part2 . With the above four cases as building blocks, the researcher can specify all kinds of utility functions.","title":"Utility Formula: utility_formula"},{"location":"bemb/#number-of-usersitemssessions-num_users-items-sessions","text":"The researcher is responsible for providing the size of the prediction problem. For every model, the num_items is required . However, num_users and num_sessions are required only if there is any user/session-specific observables or parameters involved in the utility_formula .","title":"Number of Users/Items/Sessions num_{users, items, sessions}"},{"location":"bemb/#specifying-the-dimensions-of-coefficients-with-the-coef_dim_dict-dictionary","text":"To correctly initialize the model, the constructor needs to know the shape of each learnable coefficients (i.e., Greek letters above). For item/user-specific parameters, the value of coef_dim_dict is the number of parameters for each user/item, not the total number of parameters. 1. For standalone coefficients like lambda_item , coef_dim_dict['lambda_item'] = 1 always. 2. For matrix factorization coefficients like theta_user and alpha_item , coef_dim_dict['theta_user'] = coef_dim_dict[alpha_item] = L , where L is the desired latent dimension. For the inner product between \\(\\alpha_i\\) and \\(\\theta_u\\) to work properly, coef_dim_dict['theta_user'] == coef_dim_dict['alpha_item'] . 3. For terms like \\(\\zeta_u^\\top X^{item}_i\\) , coef_dim_dict['zeta_user'] needs to be the dimension of \\(X^{item}_i\\) . 4. For matrix factorization coefficients, the dimension needs to be the latent dimension multiplied by the number of observables. For example, if you have a 3-dimensional feature \\(X = (x_1, x_2, x_3)\\) , the utility is \\(\\mathcal{U}(u, i, s) = \\zeta_{u, i}^\\top X\\) , and \\(\\zeta_{u, i}\\) needs to be factorized into two an user-specific and item-specific part (both in \\(\\mathbb{R}^L\\) ) as below \\[ \\mathcal{U}(u, i, s) = \\sum_{k=1}^3 (\\gamma_u^{k\\top} \\beta_i^k) x_k \\] then coef_dim_dict[gamma_user] = coef_dim_dict[beta_item] = 3 * L . TODO : sounds like a lot of work? we are currently developing helper function to infer all these information from the ChoiceDataset , but we will still provide researchers with the full control over the configuration.","title":"Specifying the Dimensions of Coefficients with the coef_dim_dict dictionary"},{"location":"bemb/#specifying-variance-of-coefficient-prior-distributions-with-prior_variance","text":"The prior_variance term can be either a scalar or a dictionary with the same keys of coef_dim_dict , which provides the variance of prior distribution for each learnable coefficients. If a float is provided, all priors will be Gaussian distribution with diagonal covariance matrix with prior_variance along the diagonal. If a dictionary is provided, keys of prior_variance should be coefficient names, and the prior of each coef_name would be a Gaussian with diagonal covariance matrix with prior_variance[coef_name] along the diagonal. This value is default to be 1.0 , which means priors of all coefficients are standard Gaussian distributions.","title":"Specifying Variance of Coefficient Prior Distributions with prior_variance"},{"location":"bemb/#incorporating-observables-to-the-bayesian-prior-with-obs2prior_dict","text":"BEMB is a Bayesian factorization model trained by optimizing the evidence lower bound (ELBO). Each parameter (i.e., these with _item, _user, _constant suffix.) in the BEMB model carries a prior distribution, which is set to \\(\\mathcal{N}(\\mathbf{0}, \\mathbf{I})\\) by default. With prior_variance argument described above, one can specify different scales/variances for different learnable coefficients. Beyond this baseline case, the hierarchical nature of BEMB allows the mean of the prior distribution to depend on observables as a (learnable) linear mapping. For example: \\[ \\theta_{i} \\overset{prior}{\\sim} \\mathcal{N}(HX^{item}_i, \\mathbf{I}) \\] where the prior mean is a linear transformation of the item observable and \\(H: \\mathbb{R}^{K_{item}} \\to \\mathbb{R}^L\\) . To enable the observable-to-prior feature, one needs to set obs2prior_dict['theta_item']=True . In order to leverage obs-to-prior for item-specific coefficients like theta_item , the researchers need to include item_obs tensor to the ChoiceDataset , the attribute name needs to be exactly item_obs , just with item_ prefix is not sufficient. Similarly, user_obs are required if obs-to-prior is turned on for any of user-specific coefficients.","title":"Incorporating Observables to the Bayesian Prior with obs2prior_dict"},{"location":"bemb/#grouping-items-into-categories-with-category_to_item","text":"In some cases the researcher wishes to provide additional guidance to the model by providing the category of the bought item in teach purchasing record. In this case, the probability of purchasing each \\(i\\) will be normalized only across other items from the same category rather than all items. The category_to_item argument provides a dictionary with category id or name as keys, and category_to_item[C] contains the list of item ids belonging to category C . With category_to_item provided, for the probability of purchasing item \\(i\\) by user \\(u\\) in session, let \\(I_c\\) denote the set of items belonging to the same category \\(i\\) , the probability of purchasing is \\[ P(i|u,s) = \\frac{e^{\\mathcal{U}(u, i, s)}}{\\sum_{i' \\in I_c} e^{\\mathcal{U}(u, i', s)}} \\] If category_to_item is not provided (or None is provided), the probability of purchasing item \\(i\\) by user \\(u\\) in session \\(s\\) is (note the difference in summation scope, this is computed as if all items are from the same category): \\[ P(i|u,s) = \\frac{e^{\\mathcal{U}(u, i, s)}}{\\sum_{i'=1}^I e^{\\mathcal{U}(u, i', s)}} \\]","title":"Grouping Items into Categories with category_to_item"},{"location":"bemb/#last-step-create-the-litbembflex-wrapper","text":"The last step is to create the LitBEMBFlex object which contains all information we gathered above. You will also need to provide a learning_rate for the the optimizer and a num_seeds for the Monte-Carlo estimator of gradient in ELBO. model = bemb . model . LitBEMBFlex ( learning_rate = 0.01 , num_seeds = 4 , utility_formula = utility_formula , num_users = num_users , num_items = num_items , num_sessions = num_sessions , obs2prior_dict = obs2prior_dict , coef_dim_dict = coef_dim_dict , category_to_item = category_to_item , num_user_obs = num_user_obs , num_item_obs = num_item_obs , )","title":"Last Step: Create the LitBEMBFlex wrapper"},{"location":"bemb/#training-the-model","text":"We provide a ready-to-use scrip to train the model, where dataset_list is a list consists of three ChoiceDataset objects (see the Data Management tutorial for splitting datasets), the training, validation, and testing dataset. model = model . to ( 'cuda' ) # only if GPU is installed model = bemb . utils . run_helper . run ( model , dataset_list , batch_size = 32 , num_epochs = 10 )","title":"Training the Model"},{"location":"bemb/#inference","text":"Lastly, to get the utilities (i.e., the logit) of the item bought for each row of the test dataset, the model.model.forward() method does the trick. You can either compute the utility for the purchased item or for all items, we put significant effort on optimizing the pipeline for estimating utility of the bought item, so it's much faster than computing utilities of all items. with torch . no_grad (): # disable gradient tracking to save computational cost. utility_chosen = model . model . forward ( dataset_list [ 2 ], return_logit = True , all_items = False ) # uses much higher memory! utility_all = model . model . forward ( dataset_list [ 2 ], return_logit = True , all_items = True )","title":"Inference"},{"location":"bemb_obs2prior_simulation/","text":"Tutorial for BEMB with Simulated Data and the obs2prior Option Author: Tianyu Du Update: May. 6, 2022 This tutorial offers a simple simulation exercise to demonstrate how to use BEMB model and the power of BEMB's obs2prior feature. We highly recommend you to read the BEMB tutorial first. The executable Jupyter notebook for this tutorial can be found here import numpy as np import pandas as pd import torch from torch_choice.data import ChoiceDataset from bemb.model import LitBEMBFlex from bemb.utils.run_helper import run import matplotlib.pyplot as plt import seaborn as sns Simulate Dataset We first specify the number of users and number of items in the dataset. The data_size denotes the number of user-item choice pairs to generate. Each user-item choice pair is called a purchasing record in our terminology, you can revise the data management tutorial. Please note that the data_size is much smaller than num_users \\(\\times\\) num_items and we are factorizing a spare matrix here. num_users = 1500 num_items = 50 data_size = 1000 For each of data_size purchasing records, we randomly select one user as the decision maker. This information is stored the user_index tensor, which has length data_size . user_index = torch . LongTensor ( np . random . choice ( num_users , size = data_size )) We further assign each individual some preferences so that our simulated is not totally random. In particular, for each user \\(u \\in \\{0, 1, \\dots, num\\_users - 1\\}\\) , we assume \\(u\\) particularly loves the item \\(i^*(u) \\in \\{0, 1, \\dots, num\\_item - 1\\}\\) : \\[ i^{love}(u) = \\left \\lfloor \\frac{\\sin \\left( \\frac{u}{num\\_users} \\times 4 \\times \\pi \\right) + 1}{2} \\times num\\_items \\right \\rfloor \\] The PREFERENCE dictionary maps each user \\(u\\) to the item she loves. Us = np . arange ( num_users ) Is = np . sin ( np . arange ( num_users ) / num_users * 4 * np . pi ) Is = ( Is + 1 ) / 2 * num_items Is = Is . astype ( int ) PREFERENCE = dict (( u , i ) for ( u , i ) in zip ( Us , Is )) Even though the the formula looks complicated, the who-love-what pattern is quite simple. The figure below draws which item (y-axis) each user (x-axis) likes. plt . close () plt . plot ( Us , Is ) plt . xlabel ( 'User ID' ) plt . ylabel ( 'Item ID the user loves: $i^ {love} (u)$' ) plt . title ( 'A visualization of $i^ {love} (u)$ pattern defined above.' ) plt . show () To add some randomness, for each purchasing records, with 50\\% chance, user \\(u\\) chooses the item \\(i^*(u)\\) she loves, and with 50\\% of chance she chooses an item randomly. # construct users. item_index = torch . LongTensor ( np . random . choice ( num_items , size = data_size )) for idx in range ( data_size ): if np . random . rand () <= 0.5 : item_index [ idx ] = PREFERENCE [ int ( user_index [ idx ])] To have a visual inspection on the preference we added, we can plot a heat map indexed by (user, item) and visualize the frequency of bought items by each user. In the heat map below, each row represents the empirical distribution of items (x-axis) bought. Warmer color (red) indicates high purchasing frequencies, which shows the synthetic sin-curve of preference we enforced above. df = pd . DataFrame ( data = { 'item' : item_index , 'user' : user_index }) . groupby ([ 'item' , 'user' ]) . size () . rename ( 'size' ) . reset_index () df = df . pivot ( 'item' , 'user' , 'size' ) . fillna ( 0.0 ) fig , ax = plt . subplots ( figsize = ( 18 , 3 )) sns . heatmap ( df . values , square = False , ax = ax , cmap = 'coolwarm' ) ax . set ( xlabel = 'item' , ylabel = 'user' ) fig . show () Build the ChoiceDataset Object We have created the user_index and item_index tensors, let's create a dataset object encompassing these tensors. Further, we split the dataset into train-validation-test subsets with ratio 80\\%-10\\%-10\\%. We wish to add some dummy user observables and item observables to that we can experiment the obs2prior feature of BEMB later. The default item observable is simply the one-hot vector of the item identity. The observable of a particular user is a one-hot vector with width num_items and one on the position of item this user loves (as mentioned previously). user_obs = torch . zeros ( num_users , num_items ) user_obs [ torch . arange ( num_users ), Is ] = 1 item_obs = torch . eye ( num_items ) dataset = ChoiceDataset ( user_index = user_index , item_index = item_index , user_obs = user_obs , item_obs = item_obs ) idx = np . random . permutation ( len ( dataset )) train_size = int ( 0.8 * len ( dataset )) val_size = int ( 0.1 * len ( dataset )) train_idx = idx [: train_size ] val_idx = idx [ train_size : train_size + val_size ] test_idx = idx [ train_size + val_size :] dataset_list = [ dataset [ train_idx ], dataset [ val_idx ], dataset [ test_idx ]] No `session_index` is provided, assume each choice instance is in its own session. dataset ChoiceDataset(label=[], item_index=[1000], user_index=[1000], session_index=[1000], item_availability=[], user_obs=[1500, 50], item_obs=[50, 50], device=cpu) Fitting the Model We will be fitting a Bayesian matrix factorization model with utility form $$ \\mathcal{U}_{u, i} = \\theta_u^\\top \\alpha_i $$ where \\(\\theta_u\\) and \\(\\alpha_i\\) are Bayesian variables. Please refer to the BEMB tutorial for a detailed description on how this kind of model works. There are two options on the prior distributions of these Bayesian variables \\(\\theta_u\\) and \\(\\alpha_i\\) . Firstly, we can simply use standard Gaussian as the prior distribution: \\[ \\theta_u \\overset{prior}{\\sim} \\mathcal{N}(\\mathbf{0}, I) \\quad \\alpha_i \\overset{prior}{\\sim} \\mathcal{N}(\\mathbf{0}, I) \\] Alternatively, the prior can be chosen using a data-driven method called obs2prior . In particular, the mean of prior distribution can be a learnable linear function of user/item observables. Let \\(X^{(user)}_u\\) and \\(X^{(item)}_i\\) denote the observables of user \\(u\\) and item \\(i\\) respectively. The obs2prior -augmented prior distribution is the following: \\[ \\theta_u \\overset{prior}{\\sim} \\mathcal{N}(H X^{(user)}_u, I) \\quad \\alpha_i \\overset{prior}{\\sim} \\mathcal{N}(W X^{(item)}_i, I) \\] where \\(H\\) and \\(W\\) are two learnable parameters. def fit_model ( obs2prior : bool ): LATENT_DIM = 10 # the dimension of alpha and theta. bemb = LitBEMBFlex ( learning_rate = 0.03 , # set the learning rate, feel free to play with different levels. pred_item = True , # let the model predict item_index, don't change this one. num_seeds = 32 , # number of Monte Carlo samples for estimating the ELBO. utility_formula = 'theta_user * alpha_item' , # the utility formula. num_users = num_users , num_items = num_items , num_user_obs = dataset . user_obs . shape [ 1 ], num_item_obs = dataset . item_obs . shape [ 1 ], # whether to turn on obs2prior for each parameter. obs2prior_dict = { 'theta_user' : obs2prior , 'alpha_item' : obs2prior }, # the dimension of latents, since the utility is an inner product of theta and alpha, they should have # the same dimension. coef_dim_dict = { 'theta_user' : LATENT_DIM , 'alpha_item' : LATENT_DIM } ) # use GPU if available. if torch . cuda . is_available (): bemb = bemb . to ( 'cuda' ) # use the provided run helper to train the model. # we set batch size to be 5% of the data size, and train the model for 10 epochs. # there would be 20*10=200 gradient update steps in total. bemb = run ( bemb , dataset_list , batch_size = len ( dataset ) // 20 , num_epochs = 50 ) # visualize the prediction. T = bemb . model . coef_dict [ 'theta_user' ] . variational_mean_flexible . data A = bemb . model . coef_dict [ 'alpha_item' ] . variational_mean_flexible . data fig , ax = plt . subplots ( figsize = ( 18 , 6 )) sns . heatmap (( A @ T . T ) . numpy (), square = False , ax = ax , cmap = 'coolwarm' ) ax . set_title ( f 'obs2prior = { obs2prior } ' ) fig . show () fit_model ( obs2prior = False ) BEMB: utility formula parsed: [{'coefficient': ['theta_user', 'alpha_item'], 'observable': None}] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params ----------------------------------- 0 | model | BEMBFlex | 31.0 K ----------------------------------- 31.0 K Trainable params 0 Non-trainable params 31.0 K Total params 0.124 Total estimated model params size (MB) ==================== model received ==================== Bayesian EMBedding Model with U[user, item, session] = theta_user * alpha_item Total number of parameters: 31000. With the following coefficients: ModuleDict( (theta_user): BayesianCoefficient(num_classes=1500, dimension=10, prior=N(0, I)) (alpha_item): BayesianCoefficient(num_classes=50, dimension=10, prior=N(0, I)) ) [] ==================== data set received ==================== [Training dataset] ChoiceDataset(label=[], item_index=[800], user_index=[800], session_index=[800], item_availability=[], user_obs=[1500, 50], item_obs=[50, 50], device=cpu) [Validation dataset] ChoiceDataset(label=[], item_index=[100], user_index=[100], session_index=[100], item_availability=[], user_obs=[1500, 50], item_obs=[50, 50], device=cpu) [Testing dataset] ChoiceDataset(label=[], item_index=[100], user_index=[100], session_index=[100], item_availability=[], user_obs=[1500, 50], item_obs=[50, 50], device=cpu) ==================== train the model ==================== time taken: 40.19812321662903 ==================== test performance ==================== Testing: 0it [00:00, ?it/s] \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Test metric DataLoader 0 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 test_acc 0.02 test_ll -3.912011494636536 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 fit_model ( obs2prior = True ) GPU available: True, used: True TPU available: False, using: 0 TPU cores IPU available: False, using: 0 IPUs HPU available: False, using: 0 HPUs LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params ----------------------------------- 0 | model | BEMBFlex | 33.0 K ----------------------------------- 33.0 K Trainable params 0 Non-trainable params 33.0 K Total params 0.132 Total estimated model params size (MB) BEMB: utility formula parsed: [{'coefficient': ['theta_user', 'alpha_item'], 'observable': None}] ==================== model received ==================== Bayesian EMBedding Model with U[user, item, session] = theta_user * alpha_item Total number of parameters: 33000. With the following coefficients: ModuleDict( (theta_user): BayesianCoefficient(num_classes=1500, dimension=10, prior=N(H*X_obs(H shape=torch.Size([10, 50]), X_obs shape=50), Ix1.0)) (alpha_item): BayesianCoefficient(num_classes=50, dimension=10, prior=N(H*X_obs(H shape=torch.Size([10, 50]), X_obs shape=50), Ix1.0)) ) [] ==================== data set received ==================== [Training dataset] ChoiceDataset(label=[], item_index=[800], user_index=[800], session_index=[800], item_availability=[], user_obs=[1500, 50], item_obs=[50, 50], device=cpu) [Validation dataset] ChoiceDataset(label=[], item_index=[100], user_index=[100], session_index=[100], item_availability=[], user_obs=[1500, 50], item_obs=[50, 50], device=cpu) [Testing dataset] ChoiceDataset(label=[], item_index=[100], user_index=[100], session_index=[100], item_availability=[], user_obs=[1500, 50], item_obs=[50, 50], device=cpu) ==================== train the model ==================== time taken: 40.98820662498474 ==================== test performance ==================== Testing: 0it [00:00, ?it/s] \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Test metric DataLoader 0 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 test_acc 0.47 test_ll -3.126977977901697 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Now we compare the difference between two options of prior distributions. We provide a fit_model helper function to train and visualize the model. You can go through fit_model method to have a preliminary understanding on how to train a BEMB model. Visualization : The method visualize the fitted model by plotting \\(\\theta_u^\\top \\alpha_i\\) for all pairs of user \\(u\\) and item \\(i\\) on a heat map. The sine-curve on the heat map indicates the model successfully recovered the preference pattern we added.","title":"Tutorial for BEMB obs2prior feature"},{"location":"bemb_obs2prior_simulation/#tutorial-for-bemb-with-simulated-data-and-the-obs2prior-option","text":"Author: Tianyu Du Update: May. 6, 2022 This tutorial offers a simple simulation exercise to demonstrate how to use BEMB model and the power of BEMB's obs2prior feature. We highly recommend you to read the BEMB tutorial first. The executable Jupyter notebook for this tutorial can be found here import numpy as np import pandas as pd import torch from torch_choice.data import ChoiceDataset from bemb.model import LitBEMBFlex from bemb.utils.run_helper import run import matplotlib.pyplot as plt import seaborn as sns","title":"Tutorial for BEMB with Simulated Data and the obs2prior Option"},{"location":"bemb_obs2prior_simulation/#simulate-dataset","text":"We first specify the number of users and number of items in the dataset. The data_size denotes the number of user-item choice pairs to generate. Each user-item choice pair is called a purchasing record in our terminology, you can revise the data management tutorial. Please note that the data_size is much smaller than num_users \\(\\times\\) num_items and we are factorizing a spare matrix here. num_users = 1500 num_items = 50 data_size = 1000 For each of data_size purchasing records, we randomly select one user as the decision maker. This information is stored the user_index tensor, which has length data_size . user_index = torch . LongTensor ( np . random . choice ( num_users , size = data_size )) We further assign each individual some preferences so that our simulated is not totally random. In particular, for each user \\(u \\in \\{0, 1, \\dots, num\\_users - 1\\}\\) , we assume \\(u\\) particularly loves the item \\(i^*(u) \\in \\{0, 1, \\dots, num\\_item - 1\\}\\) : \\[ i^{love}(u) = \\left \\lfloor \\frac{\\sin \\left( \\frac{u}{num\\_users} \\times 4 \\times \\pi \\right) + 1}{2} \\times num\\_items \\right \\rfloor \\] The PREFERENCE dictionary maps each user \\(u\\) to the item she loves. Us = np . arange ( num_users ) Is = np . sin ( np . arange ( num_users ) / num_users * 4 * np . pi ) Is = ( Is + 1 ) / 2 * num_items Is = Is . astype ( int ) PREFERENCE = dict (( u , i ) for ( u , i ) in zip ( Us , Is )) Even though the the formula looks complicated, the who-love-what pattern is quite simple. The figure below draws which item (y-axis) each user (x-axis) likes. plt . close () plt . plot ( Us , Is ) plt . xlabel ( 'User ID' ) plt . ylabel ( 'Item ID the user loves: $i^ {love} (u)$' ) plt . title ( 'A visualization of $i^ {love} (u)$ pattern defined above.' ) plt . show () To add some randomness, for each purchasing records, with 50\\% chance, user \\(u\\) chooses the item \\(i^*(u)\\) she loves, and with 50\\% of chance she chooses an item randomly. # construct users. item_index = torch . LongTensor ( np . random . choice ( num_items , size = data_size )) for idx in range ( data_size ): if np . random . rand () <= 0.5 : item_index [ idx ] = PREFERENCE [ int ( user_index [ idx ])] To have a visual inspection on the preference we added, we can plot a heat map indexed by (user, item) and visualize the frequency of bought items by each user. In the heat map below, each row represents the empirical distribution of items (x-axis) bought. Warmer color (red) indicates high purchasing frequencies, which shows the synthetic sin-curve of preference we enforced above. df = pd . DataFrame ( data = { 'item' : item_index , 'user' : user_index }) . groupby ([ 'item' , 'user' ]) . size () . rename ( 'size' ) . reset_index () df = df . pivot ( 'item' , 'user' , 'size' ) . fillna ( 0.0 ) fig , ax = plt . subplots ( figsize = ( 18 , 3 )) sns . heatmap ( df . values , square = False , ax = ax , cmap = 'coolwarm' ) ax . set ( xlabel = 'item' , ylabel = 'user' ) fig . show ()","title":"Simulate Dataset"},{"location":"bemb_obs2prior_simulation/#build-the-choicedataset-object","text":"We have created the user_index and item_index tensors, let's create a dataset object encompassing these tensors. Further, we split the dataset into train-validation-test subsets with ratio 80\\%-10\\%-10\\%. We wish to add some dummy user observables and item observables to that we can experiment the obs2prior feature of BEMB later. The default item observable is simply the one-hot vector of the item identity. The observable of a particular user is a one-hot vector with width num_items and one on the position of item this user loves (as mentioned previously). user_obs = torch . zeros ( num_users , num_items ) user_obs [ torch . arange ( num_users ), Is ] = 1 item_obs = torch . eye ( num_items ) dataset = ChoiceDataset ( user_index = user_index , item_index = item_index , user_obs = user_obs , item_obs = item_obs ) idx = np . random . permutation ( len ( dataset )) train_size = int ( 0.8 * len ( dataset )) val_size = int ( 0.1 * len ( dataset )) train_idx = idx [: train_size ] val_idx = idx [ train_size : train_size + val_size ] test_idx = idx [ train_size + val_size :] dataset_list = [ dataset [ train_idx ], dataset [ val_idx ], dataset [ test_idx ]] No `session_index` is provided, assume each choice instance is in its own session. dataset ChoiceDataset(label=[], item_index=[1000], user_index=[1000], session_index=[1000], item_availability=[], user_obs=[1500, 50], item_obs=[50, 50], device=cpu)","title":"Build the ChoiceDataset Object"},{"location":"bemb_obs2prior_simulation/#fitting-the-model","text":"We will be fitting a Bayesian matrix factorization model with utility form $$ \\mathcal{U}_{u, i} = \\theta_u^\\top \\alpha_i $$ where \\(\\theta_u\\) and \\(\\alpha_i\\) are Bayesian variables. Please refer to the BEMB tutorial for a detailed description on how this kind of model works. There are two options on the prior distributions of these Bayesian variables \\(\\theta_u\\) and \\(\\alpha_i\\) . Firstly, we can simply use standard Gaussian as the prior distribution: \\[ \\theta_u \\overset{prior}{\\sim} \\mathcal{N}(\\mathbf{0}, I) \\quad \\alpha_i \\overset{prior}{\\sim} \\mathcal{N}(\\mathbf{0}, I) \\] Alternatively, the prior can be chosen using a data-driven method called obs2prior . In particular, the mean of prior distribution can be a learnable linear function of user/item observables. Let \\(X^{(user)}_u\\) and \\(X^{(item)}_i\\) denote the observables of user \\(u\\) and item \\(i\\) respectively. The obs2prior -augmented prior distribution is the following: \\[ \\theta_u \\overset{prior}{\\sim} \\mathcal{N}(H X^{(user)}_u, I) \\quad \\alpha_i \\overset{prior}{\\sim} \\mathcal{N}(W X^{(item)}_i, I) \\] where \\(H\\) and \\(W\\) are two learnable parameters. def fit_model ( obs2prior : bool ): LATENT_DIM = 10 # the dimension of alpha and theta. bemb = LitBEMBFlex ( learning_rate = 0.03 , # set the learning rate, feel free to play with different levels. pred_item = True , # let the model predict item_index, don't change this one. num_seeds = 32 , # number of Monte Carlo samples for estimating the ELBO. utility_formula = 'theta_user * alpha_item' , # the utility formula. num_users = num_users , num_items = num_items , num_user_obs = dataset . user_obs . shape [ 1 ], num_item_obs = dataset . item_obs . shape [ 1 ], # whether to turn on obs2prior for each parameter. obs2prior_dict = { 'theta_user' : obs2prior , 'alpha_item' : obs2prior }, # the dimension of latents, since the utility is an inner product of theta and alpha, they should have # the same dimension. coef_dim_dict = { 'theta_user' : LATENT_DIM , 'alpha_item' : LATENT_DIM } ) # use GPU if available. if torch . cuda . is_available (): bemb = bemb . to ( 'cuda' ) # use the provided run helper to train the model. # we set batch size to be 5% of the data size, and train the model for 10 epochs. # there would be 20*10=200 gradient update steps in total. bemb = run ( bemb , dataset_list , batch_size = len ( dataset ) // 20 , num_epochs = 50 ) # visualize the prediction. T = bemb . model . coef_dict [ 'theta_user' ] . variational_mean_flexible . data A = bemb . model . coef_dict [ 'alpha_item' ] . variational_mean_flexible . data fig , ax = plt . subplots ( figsize = ( 18 , 6 )) sns . heatmap (( A @ T . T ) . numpy (), square = False , ax = ax , cmap = 'coolwarm' ) ax . set_title ( f 'obs2prior = { obs2prior } ' ) fig . show () fit_model ( obs2prior = False ) BEMB: utility formula parsed: [{'coefficient': ['theta_user', 'alpha_item'], 'observable': None}] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params ----------------------------------- 0 | model | BEMBFlex | 31.0 K ----------------------------------- 31.0 K Trainable params 0 Non-trainable params 31.0 K Total params 0.124 Total estimated model params size (MB) ==================== model received ==================== Bayesian EMBedding Model with U[user, item, session] = theta_user * alpha_item Total number of parameters: 31000. With the following coefficients: ModuleDict( (theta_user): BayesianCoefficient(num_classes=1500, dimension=10, prior=N(0, I)) (alpha_item): BayesianCoefficient(num_classes=50, dimension=10, prior=N(0, I)) ) [] ==================== data set received ==================== [Training dataset] ChoiceDataset(label=[], item_index=[800], user_index=[800], session_index=[800], item_availability=[], user_obs=[1500, 50], item_obs=[50, 50], device=cpu) [Validation dataset] ChoiceDataset(label=[], item_index=[100], user_index=[100], session_index=[100], item_availability=[], user_obs=[1500, 50], item_obs=[50, 50], device=cpu) [Testing dataset] ChoiceDataset(label=[], item_index=[100], user_index=[100], session_index=[100], item_availability=[], user_obs=[1500, 50], item_obs=[50, 50], device=cpu) ==================== train the model ==================== time taken: 40.19812321662903 ==================== test performance ==================== Testing: 0it [00:00, ?it/s] \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Test metric DataLoader 0 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 test_acc 0.02 test_ll -3.912011494636536 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 fit_model ( obs2prior = True ) GPU available: True, used: True TPU available: False, using: 0 TPU cores IPU available: False, using: 0 IPUs HPU available: False, using: 0 HPUs LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params ----------------------------------- 0 | model | BEMBFlex | 33.0 K ----------------------------------- 33.0 K Trainable params 0 Non-trainable params 33.0 K Total params 0.132 Total estimated model params size (MB) BEMB: utility formula parsed: [{'coefficient': ['theta_user', 'alpha_item'], 'observable': None}] ==================== model received ==================== Bayesian EMBedding Model with U[user, item, session] = theta_user * alpha_item Total number of parameters: 33000. With the following coefficients: ModuleDict( (theta_user): BayesianCoefficient(num_classes=1500, dimension=10, prior=N(H*X_obs(H shape=torch.Size([10, 50]), X_obs shape=50), Ix1.0)) (alpha_item): BayesianCoefficient(num_classes=50, dimension=10, prior=N(H*X_obs(H shape=torch.Size([10, 50]), X_obs shape=50), Ix1.0)) ) [] ==================== data set received ==================== [Training dataset] ChoiceDataset(label=[], item_index=[800], user_index=[800], session_index=[800], item_availability=[], user_obs=[1500, 50], item_obs=[50, 50], device=cpu) [Validation dataset] ChoiceDataset(label=[], item_index=[100], user_index=[100], session_index=[100], item_availability=[], user_obs=[1500, 50], item_obs=[50, 50], device=cpu) [Testing dataset] ChoiceDataset(label=[], item_index=[100], user_index=[100], session_index=[100], item_availability=[], user_obs=[1500, 50], item_obs=[50, 50], device=cpu) ==================== train the model ==================== time taken: 40.98820662498474 ==================== test performance ==================== Testing: 0it [00:00, ?it/s] \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Test metric DataLoader 0 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 test_acc 0.47 test_ll -3.126977977901697 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Now we compare the difference between two options of prior distributions. We provide a fit_model helper function to train and visualize the model. You can go through fit_model method to have a preliminary understanding on how to train a BEMB model. Visualization : The method visualize the fitted model by plotting \\(\\theta_u^\\top \\alpha_i\\) for all pairs of user \\(u\\) and item \\(i\\) on a heat map. The sine-curve on the heat map indicates the model successfully recovered the preference pattern we added.","title":"Fitting the Model"},{"location":"education_data/","text":"Tutorial for Bayesian Embedding (BEMB) with Educational Data Author: Tianyu Du Date: May. 7, 2022 This tutorial helps lab members to deploy the BEMB model on educational question-answering (QA) datasets. We will be using the 17Zuoye data, which is available on Sherlock, throughout this tutorial. However, this tutorial generalizes to any QA datasets in which each row of the dataset corresponds to a triple (student, question, label). Equivalently, each row of these QA datasets is about a student answering a question correctly/incorrectly. You can find the executable Jupyter notebook for this tutorial here import os import numpy as np import pandas as pd import torch from bemb.model import LitBEMBFlex from bemb.utils.run_helper import run from sklearn import preprocessing from torch_choice.data import ChoiceDataset Load Data We build some helper functions especially for the Zuoye data for demonstration, you can skip this part if you have your own data ready. Please see below for the formats data. def get_all_unique_fields ( column , field = 'id' ): unique_fields = set () for tag_list in column : for entry in tag_list : unique_fields . add ( entry [ field ]) return list ( unique_fields ) def convert_tag_list_into_binary_vector ( tag_list , encoder , vec_len ): index = encoder . transform ([ x [ 'id' ] for x in tag_list ]) out = torch . zeros ([ vec_len ], dtype = torch . float64 ) out [ index ] = 1 return out def convert_column_to_binary_vectors ( column ): all_elements = get_all_unique_fields ( column ) my_encoder = preprocessing . LabelEncoder () my_encoder . fit ( all_elements ) out = column . apply ( lambda x : convert_tag_list_into_binary_vector ( x , my_encoder , len ( all_elements ))) return out If you wish to try this tutorial on the 17Zuoye dataset, which is located at data_path on Sherlock. Please make sure the data_path is correct if you are running on your local machine. Henry prepared these datasets in the feather format. Feather is a portable file format for storing Arrow tables or data frames (from languages like Python or R) that utilizes the Arrow IPC format internally. Feather was created early in the Arrow project as a proof of concept for fast, language-agnostic data frame storage for Python (pandas) and R (see here for more information about Feather data format). You can easily load the data using pandas. data_path = '/oak/stanford/groups/athey/17Zuoye/bayesian_measurement_17zy/bayes' response_path = os . path . join ( data_path , 'exam_response_with_attrib.feather' ) attribute_path = os . path . join ( data_path , 'exam_response_ques_attrib.feather' ) The User-Item and Label Dataset (i.e., The Response Dataset) For the student response use case, the response dataset contains at least three columns: {user_id, item_id, label} . Where user_id is typically the student's ID, item_id is the question's ID, and label is the student's response to the question, which is a binary variable indicating whether the student answered the question correctly. In the df_resp dataset loaded below, the student_id column corresponds to the user_id , the question_id column corresponds to the item_id , and the correct column corresponds to the label . The length of the df_resp dataset is the total number of times students answer questions, this corresponds to the number of purchasing records following our terminology in the data management tutorial. df_resp = pd . read_feather ( response_path ) print ( 'Number of student-question response pairs:' , len ( df_resp )) df_resp Number of student-question response pairs: 8621720 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } student_id question_id correct subject grade 0 90368 409 0 CHINESE 2 1 90368 409 0 CHINESE 2 2 90368 409 0 CHINESE 2 3 93193 409 0 CHINESE 2 4 93193 409 0 CHINESE 2 ... ... ... ... ... ... 8621715 115131 2080 0 MATH 2 8621716 83680 2561 1 ENGLISH 3 8621717 83680 2564 1 ENGLISH 3 8621718 83680 2563 1 ENGLISH 3 8621719 83680 2562 1 ENGLISH 3 8621720 rows \u00d7 5 columns The dataset contains 261,756 students and 3,604 questions. Student IDs are already encoded as integers ranging from 0 to 261,755 , and question IDs are already encoded as integers ranging from 0 to 3,603 . print ( df_resp [ 'student_id' ] . nunique ()) print ( df_resp [ 'question_id' ] . nunique ()) 261756 3604 print ( df_resp [ 'student_id' ] . max ()) print ( df_resp [ 'question_id' ] . max ()) 261755 3603 The Attribute Dataset Researchers can optionally supply a separate attribute dataset including observables of users (i.e., students) and items (i.e., questions). Here we load the df_attr dataset, which has length equal to the number of questions. Each row of df_attr contains attributes/observables of each question. Specifically, df_attr contains a column called question_id and several other columns of attributes. For each question, we have two attribute as known as capability and knowledge . df_attr = pd . read_feather ( attribute_path ) . sort_values ( 'question_id' ) . reset_index ( drop = True ) df_attr .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } question_id capability knowledge kp 0 0 [{'id': 'TAG_10100001553832', 'type': 0}, {'id... [{'id': '0101001', 'type': 0.0}, {'id': '01020... [{'id': 'KP_10100071064944'}, {'id': 'KP_10100... 1 1 [{'id': 'TAG_10100001553832', 'type': 0}, {'id... [{'id': '0101001', 'type': 0.0}, {'id': '01020... [{'id': 'KP_10100050863402'}, {'id': 'KP_10100... 2 2 [{'id': 'TAG_10100001553832', 'type': 0}, {'id... [{'id': '0101001', 'type': 0.0}, {'id': '01020... [{'id': 'KP_10100050866393'}] 3 3 [{'id': 'TAG_10100001553832', 'type': 0}, {'id... [{'id': '0101001', 'type': 0.0}, {'id': '01020... [{'id': 'KP_10100125674593'}, {'id': 'KP_10100... 4 4 [{'id': 'TAG_10100001553832', 'type': 0}, {'id... [{'id': '0101001', 'type': 0.0}, {'id': '01020... [{'id': 'KP_10100077305590'}, {'id': 'KP_10100... ... ... ... ... ... 3599 3599 [{'id': 'TAG_10300000827653', 'type': 0}, {'id... [{'id': '0301001', 'type': 0.0}, {'id': '03020... [{'id': 'KP_10300117105040'}] 3600 3600 [{'id': 'TAG_10300000827653', 'type': 0}, {'id... [{'id': '0301001', 'type': 0.0}, {'id': '03020... [{'id': 'KP_10300212870515'}] 3601 3601 [{'id': 'TAG_10300000827653', 'type': 0}, {'id... [{'id': '0301001', 'type': 0.0}, {'id': '03020... [{'id': 'KP_10300111435423'}] 3602 3602 [{'id': 'TAG_10300000827653', 'type': 0}, {'id... [{'id': '0301001', 'type': 0.0}, {'id': '03020... [{'id': 'KP_10300213265389'}] 3603 3603 [{'id': 'TAG_10300000827653', 'type': 0}, {'id... [{'id': '0301001', 'type': 0.0}, {'id': '03020... [{'id': 'KP_10300111316448'}] 3604 rows \u00d7 4 columns There are 90 types of capabilities and 34 types of knowledge required by different questions in ths dataset. We convert these attributes into two binary vectors named capability_vec and knowledge_vec . The capability_vec vector has shape (number_of_questions, 90) and the knowledge_vec vector has shape (number_of_questions, 34) . For example, knowledge_vec[i, j] = 1 indicates answering question i correctly requires type j of knowledge. def f ( z ): # extract knowledge domain. return z [ - 1 ][ 'id' ] knowledge_domain = [ f ( x ) for x in df_attr [ 'knowledge' ] . values ] df_attr [ 'capability_vec' ] = convert_column_to_binary_vectors ( df_attr [ 'capability' ]) df_attr [ 'knowledge_vec' ] = convert_column_to_binary_vectors ( df_attr [ 'knowledge' ]) capability_vec = torch . stack ( df_attr [ 'capability_vec' ] . to_list (), dim = 0 ) . float () knowledge_vec = torch . stack ( df_attr [ 'knowledge_vec' ] . to_list (), dim = 0 ) . float () print ( f \" { knowledge_vec . shape =:} \" ) print ( f \" { capability_vec . shape =:} \" ) knowledge_vec.shape=torch.Size([3604, 34]) capability_vec.shape=torch.Size([3604, 90]) Lastly, we concatenate the capability_vec and knowledge_vec vectors into a single vector called item_obs with shape (number_of_questions, 124) . This vector encompasses all attributes/observables of items (i.e., questions in this context). item_obs = torch . cat ([ capability_vec , knowledge_vec ], dim = 1 ) print ( f \" { item_obs . shape =:} \" ) item_obs.shape=torch.Size([3604, 124]) Construct the ChoiceDataset Object The last step is to construct the ChoiceDataset object. The item_index ( user_index ) keyword argument holds the identify of question answered (student answering the question) in each student-question response pair respectively. The label argument is a binary tensor indicating whether the student answered the question correctly. Lastly, we put the item_obs to capture observables of questions to the dataset. In this tutorial, we don't have any user observables (i.e., observables of students). choice_dataset = ChoiceDataset ( item_index = torch . LongTensor ( df_resp [ 'question_id' ] . values ), user_index = torch . LongTensor ( df_resp [ 'student_id' ] . values ), label = torch . LongTensor ( df_resp [ 'correct' ] . values ), item_obs = item_obs ) No `session_index` is provided, assume each choice instance is in its own session. You can print the choice_dataset to see information about tensors encompassed. print ( choice_dataset ) ChoiceDataset(label=[8621720], item_index=[8621720], user_index=[8621720], session_index=[8621720], item_availability=[], item_obs=[3604, 124], device=cpu) num_users = len ( torch . unique ( choice_dataset . user_index )) num_items = len ( torch . unique ( choice_dataset . item_index )) num_item_obs = choice_dataset . item_obs . shape [ - 1 ] Splitting Data into Training, Validation, and Testing Sets To test the generalizability of the model, we split the data into training, validation, and testing sets. Specifically, we randomly take 80% of student-question pairs as the training set, 10% as the validation set, and the rest 10% as the testing set. # randomly permutate the index ranging from (0, 1, ..., len(choice_Dataset) - 1). idx = np . random . permutation ( len ( choice_dataset )) # take the first 80% from the random permutation as indices for the training set. train_size = int ( 0.8 * len ( choice_dataset )) val_size = int ( 0.1 * len ( choice_dataset )) train_idx = idx [: train_size ] val_idx = idx [ train_size : train_size + val_size ] test_idx = idx [ train_size + val_size :] # we put train/validation/test datasets into a list. dataset_list = [ choice_dataset [ train_idx ], choice_dataset [ val_idx ], choice_dataset [ test_idx ]] print ( '[Training dataset]' , dataset_list [ 0 ]) print ( '[Validation dataset]' , dataset_list [ 1 ]) print ( '[Testing dataset]' , dataset_list [ 2 ]) [Training dataset] ChoiceDataset(label=[6897376], item_index=[6897376], user_index=[6897376], session_index=[6897376], item_availability=[], item_obs=[3604, 124], device=cpu) [Validation dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu) [Testing dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu) Fitting the Model One Basic Model Now let's fit a basic BEMB model to the data. Recall that an user \\(u\\) corresponds to a student and an item \\(i\\) corresponds to question in this tutorial. The basic model we will be fitting has utility representation \\[ U_{ui} = \\lambda_i + \\theta_u^\\top \\alpha_i \\] where \\[ \\theta_u, \\alpha_i \\in \\mathbb{R}^{10} \\] The predicted probability for student \\(u\\) to correctly answer question \\(i\\) is \\[ \\frac{1}{1 + e^{-U_{ui}}} \\] Important : be sure to set pred_item=False below since the model is predicting choice_dataset.label instead of choice_dataset.item as in traditional consumer choice modeling. obs2prior_dict = { 'lambda_item' : False , 'theta_user' : False , 'alpha_item' : False } LATENT_DIM = 10 coef_dim_dict = { 'lambda_item' : 1 , 'theta_user' : LATENT_DIM , 'alpha_item' : LATENT_DIM } bemb = LitBEMBFlex ( learning_rate = 0.1 , pred_item = False , num_seeds = 4 , utility_formula = 'lambda_item + theta_user * alpha_item' , num_users = num_users , num_items = num_items , obs2prior_dict = obs2prior_dict , coef_dim_dict = coef_dim_dict , trace_log_q = True , num_item_obs = num_item_obs , prior_variance = 1 ) if torch . cuda . is_available (): bemb = bemb . to ( 'cuda' ) bemb = run ( bemb , dataset_list , batch_size = len ( choice_dataset ) // 20 , num_epochs = 10 ) BEMB: utility formula parsed: [{'coefficient': ['lambda_item'], 'observable': None}, {'coefficient': ['theta_user', 'alpha_item'], 'observable': None}] GPU available: True, used: True TPU available: False, using: 0 TPU cores IPU available: False, using: 0 IPUs HPU available: False, using: 0 HPUs LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params ----------------------------------- 0 | model | BEMBFlex | 5.3 M ----------------------------------- 5.3 M Trainable params 0 Non-trainable params 5.3 M Total params 21.258 Total estimated model params size (MB) ==================== model received ==================== Bayesian EMBedding Model with U[user, item, session] = lambda_item + theta_user * alpha_item Total number of parameters: 5314408. With the following coefficients: ModuleDict( (lambda_item): BayesianCoefficient(num_classes=3604, dimension=1, prior=N(0, I)) (theta_user): BayesianCoefficient(num_classes=261756, dimension=10, prior=N(0, I)) (alpha_item): BayesianCoefficient(num_classes=3604, dimension=10, prior=N(0, I)) ) [] ==================== data set received ==================== [Training dataset] ChoiceDataset(label=[6897376], item_index=[6897376], user_index=[6897376], session_index=[6897376], item_availability=[], item_obs=[3604, 124], device=cpu) [Validation dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu) [Testing dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu) ==================== train the model ==================== Sanity Checking: 0it [00:00, ?it/s] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] time taken: 89.43709015846252 ==================== test performance ==================== Testing: 0it [00:00, ?it/s] \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Test metric DataLoader 0 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 test_acc 0.8308121813280877 test_ll -0.3618064307005444 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Leveraging More Complex Utility Representations Let's add the item-observable measuring capacities and knowledge required by answering each question to the utility representation. \\[ U_{ui} = \\lambda_i + \\theta_u^\\top \\alpha_i + \\eta_u^\\top X^{(item\\_obs)}_i \\] where \\[ \\theta_u, \\alpha_i \\in \\mathbb{R}^{10} \\] and \\[ \\eta_u, X^{(item\\_obs)}_i \\in \\mathbb{R}^{124} \\] obs2prior_dict = { 'lambda_item' : False , 'theta_user' : False , 'alpha_item' : False , 'eta_user' : False } LATENT_DIM = 10 coef_dim_dict = { 'lambda_item' : 1 , 'theta_user' : LATENT_DIM , 'alpha_item' : LATENT_DIM , 'eta_user' : num_item_obs } bemb = LitBEMBFlex ( # trainings args. learning_rate = 0.1 , pred_item = False , num_seeds = 4 , # model args, will be passed to BEMB constructor. utility_formula = 'lambda_item + theta_user * alpha_item + eta_user * item_obs' , num_users = num_users , num_items = num_items , obs2prior_dict = obs2prior_dict , coef_dim_dict = coef_dim_dict , trace_log_q = True , num_item_obs = num_item_obs , prior_variance = 1 ) if torch . cuda . is_available (): bemb = bemb . to ( 'cuda' ) bemb = run ( bemb , dataset_list , batch_size = len ( choice_dataset ) // 20 , num_epochs = 10 ) BEMB: utility formula parsed: [{'coefficient': ['lambda_item'], 'observable': None}, {'coefficient': ['theta_user', 'alpha_item'], 'observable': None}, {'coefficient': ['eta_user'], 'observable': 'item_obs'}] GPU available: True, used: True TPU available: False, using: 0 TPU cores IPU available: False, using: 0 IPUs HPU available: False, using: 0 HPUs LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params ----------------------------------- 0 | model | BEMBFlex | 70.2 M ----------------------------------- 70.2 M Trainable params 0 Non-trainable params 70.2 M Total params 280.920 Total estimated model params size (MB) ==================== model received ==================== Bayesian EMBedding Model with U[user, item, session] = lambda_item + theta_user * alpha_item + eta_user * item_obs Total number of parameters: 70229896. With the following coefficients: ModuleDict( (lambda_item): BayesianCoefficient(num_classes=3604, dimension=1, prior=N(0, I)) (theta_user): BayesianCoefficient(num_classes=261756, dimension=10, prior=N(0, I)) (alpha_item): BayesianCoefficient(num_classes=3604, dimension=10, prior=N(0, I)) (eta_user): BayesianCoefficient(num_classes=261756, dimension=124, prior=N(0, I)) ) [] ==================== data set received ==================== [Training dataset] ChoiceDataset(label=[6897376], item_index=[6897376], user_index=[6897376], session_index=[6897376], item_availability=[], item_obs=[3604, 124], device=cpu) [Validation dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu) [Testing dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu) ==================== train the model ==================== LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] time taken: 185.29189801216125 ==================== test performance ==================== Testing: 0it [00:00, ?it/s] \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Test metric DataLoader 0 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 test_acc 0.852068960717815 test_ll -0.3408827750695644 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Leveraging obs2prior In both examples above, the prior of all coefficients were standard Gaussian distributions. We can improve the model by incorporating the obs2prior option and let the mean of prior distribution of item-specific coefficients (i.e., \\(\\lambda_i\\) and \\(\\alpha_i\\) ) depend on item observables. One can turn on the obs2prior option easily by setting obs2prior_dict['lambda_item'] = True and obs2prior_dict['alpha_item'] = True . Important : we recommend to set a small prior_variance to make obs2prior more effective. For example, if one set prior_variance= \\(\\infty\\) , prior distributions do not matter at all to the optimization, and the obs2prior will be ineffectively as a result. \\[ U_{ui} = \\lambda_i + \\theta_u^\\top \\alpha_i \\] where \\[ \\theta_u, \\alpha_i \\in \\mathbb{R}^{10} \\] obs2prior_dict = { 'lambda_item' : True , 'theta_user' : False , 'alpha_item' : True , 'eta_user' : False } LATENT_DIM = 10 coef_dim_dict = { 'lambda_user' : 1 , 'lambda_item' : 1 , 'theta_user' : LATENT_DIM , 'alpha_item' : LATENT_DIM , 'eta_user' : num_item_obs } bemb = LitBEMBFlex ( # trainings args. learning_rate = 0.1 , pred_item = False , num_seeds = 4 , # model args, will be passed to BEMB constructor. utility_formula = 'lambda_item + theta_user * alpha_item + eta_user * item_obs' , num_users = num_users , num_items = num_items , obs2prior_dict = obs2prior_dict , coef_dim_dict = coef_dim_dict , trace_log_q = True , num_item_obs = num_item_obs , prior_variance = 0.01 ) if torch . cuda . is_available (): bemb = bemb . to ( 'cuda' ) bemb = run ( bemb , dataset_list , batch_size = len ( choice_dataset ) // 20 , num_epochs = 50 ) BEMB: utility formula parsed: [{'coefficient': ['lambda_item'], 'observable': None}, {'coefficient': ['theta_user', 'alpha_item'], 'observable': None}, {'coefficient': ['eta_user'], 'observable': 'item_obs'}] GPU available: True, used: True TPU available: False, using: 0 TPU cores IPU available: False, using: 0 IPUs HPU available: False, using: 0 HPUs LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params ----------------------------------- 0 | model | BEMBFlex | 70.2 M ----------------------------------- 70.2 M Trainable params 0 Non-trainable params 70.2 M Total params 280.930 Total estimated model params size (MB) ==================== model received ==================== Bayesian EMBedding Model with U[user, item, session] = lambda_item + theta_user * alpha_item + eta_user * item_obs Total number of parameters: 70232624. With the following coefficients: ModuleDict( (lambda_item): BayesianCoefficient(num_classes=3604, dimension=1, prior=N(H*X_obs(H shape=torch.Size([1, 124]), X_obs shape=124), Ix0.01)) (theta_user): BayesianCoefficient(num_classes=261756, dimension=10, prior=N(0, I)) (alpha_item): BayesianCoefficient(num_classes=3604, dimension=10, prior=N(H*X_obs(H shape=torch.Size([10, 124]), X_obs shape=124), Ix0.01)) (eta_user): BayesianCoefficient(num_classes=261756, dimension=124, prior=N(0, I)) ) [] ==================== data set received ==================== [Training dataset] ChoiceDataset(label=[6897376], item_index=[6897376], user_index=[6897376], session_index=[6897376], item_availability=[], item_obs=[3604, 124], device=cpu) [Validation dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu) [Testing dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu) ==================== train the model ==================== Sanity Checking: 0it [00:00, ?it/s] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] time taken: 941.1486117839813 ==================== test performance ==================== Testing: 0it [00:00, ?it/s] \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Test metric DataLoader 0 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 test_acc 0.8209313222883601 test_ll -0.3934649652798017 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Tuning the Model There are tons of parameters in models above, for example, we choose LATENT_DIM = 10 based on our own experience. However, these choices of hyper-parameters can be sub-optimal. We recommend researchers to try out different combinations of hyper-parameters before sticking with a particular hyper-parameter configuration. We will be providing a script for effectively parameter tuning though the learning-tool-competition project.","title":"Tutorial for Bayesian Embedding (BEMB) with Educational Data"},{"location":"education_data/#tutorial-for-bayesian-embedding-bemb-with-educational-data","text":"Author: Tianyu Du Date: May. 7, 2022 This tutorial helps lab members to deploy the BEMB model on educational question-answering (QA) datasets. We will be using the 17Zuoye data, which is available on Sherlock, throughout this tutorial. However, this tutorial generalizes to any QA datasets in which each row of the dataset corresponds to a triple (student, question, label). Equivalently, each row of these QA datasets is about a student answering a question correctly/incorrectly. You can find the executable Jupyter notebook for this tutorial here import os import numpy as np import pandas as pd import torch from bemb.model import LitBEMBFlex from bemb.utils.run_helper import run from sklearn import preprocessing from torch_choice.data import ChoiceDataset","title":"Tutorial for Bayesian Embedding (BEMB) with Educational Data"},{"location":"education_data/#load-data","text":"We build some helper functions especially for the Zuoye data for demonstration, you can skip this part if you have your own data ready. Please see below for the formats data. def get_all_unique_fields ( column , field = 'id' ): unique_fields = set () for tag_list in column : for entry in tag_list : unique_fields . add ( entry [ field ]) return list ( unique_fields ) def convert_tag_list_into_binary_vector ( tag_list , encoder , vec_len ): index = encoder . transform ([ x [ 'id' ] for x in tag_list ]) out = torch . zeros ([ vec_len ], dtype = torch . float64 ) out [ index ] = 1 return out def convert_column_to_binary_vectors ( column ): all_elements = get_all_unique_fields ( column ) my_encoder = preprocessing . LabelEncoder () my_encoder . fit ( all_elements ) out = column . apply ( lambda x : convert_tag_list_into_binary_vector ( x , my_encoder , len ( all_elements ))) return out If you wish to try this tutorial on the 17Zuoye dataset, which is located at data_path on Sherlock. Please make sure the data_path is correct if you are running on your local machine. Henry prepared these datasets in the feather format. Feather is a portable file format for storing Arrow tables or data frames (from languages like Python or R) that utilizes the Arrow IPC format internally. Feather was created early in the Arrow project as a proof of concept for fast, language-agnostic data frame storage for Python (pandas) and R (see here for more information about Feather data format). You can easily load the data using pandas. data_path = '/oak/stanford/groups/athey/17Zuoye/bayesian_measurement_17zy/bayes' response_path = os . path . join ( data_path , 'exam_response_with_attrib.feather' ) attribute_path = os . path . join ( data_path , 'exam_response_ques_attrib.feather' )","title":"Load Data"},{"location":"education_data/#the-user-item-and-label-dataset-ie-the-response-dataset","text":"For the student response use case, the response dataset contains at least three columns: {user_id, item_id, label} . Where user_id is typically the student's ID, item_id is the question's ID, and label is the student's response to the question, which is a binary variable indicating whether the student answered the question correctly. In the df_resp dataset loaded below, the student_id column corresponds to the user_id , the question_id column corresponds to the item_id , and the correct column corresponds to the label . The length of the df_resp dataset is the total number of times students answer questions, this corresponds to the number of purchasing records following our terminology in the data management tutorial. df_resp = pd . read_feather ( response_path ) print ( 'Number of student-question response pairs:' , len ( df_resp )) df_resp Number of student-question response pairs: 8621720 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } student_id question_id correct subject grade 0 90368 409 0 CHINESE 2 1 90368 409 0 CHINESE 2 2 90368 409 0 CHINESE 2 3 93193 409 0 CHINESE 2 4 93193 409 0 CHINESE 2 ... ... ... ... ... ... 8621715 115131 2080 0 MATH 2 8621716 83680 2561 1 ENGLISH 3 8621717 83680 2564 1 ENGLISH 3 8621718 83680 2563 1 ENGLISH 3 8621719 83680 2562 1 ENGLISH 3 8621720 rows \u00d7 5 columns The dataset contains 261,756 students and 3,604 questions. Student IDs are already encoded as integers ranging from 0 to 261,755 , and question IDs are already encoded as integers ranging from 0 to 3,603 . print ( df_resp [ 'student_id' ] . nunique ()) print ( df_resp [ 'question_id' ] . nunique ()) 261756 3604 print ( df_resp [ 'student_id' ] . max ()) print ( df_resp [ 'question_id' ] . max ()) 261755 3603","title":"The User-Item and Label Dataset (i.e., The Response Dataset)"},{"location":"education_data/#the-attribute-dataset","text":"Researchers can optionally supply a separate attribute dataset including observables of users (i.e., students) and items (i.e., questions). Here we load the df_attr dataset, which has length equal to the number of questions. Each row of df_attr contains attributes/observables of each question. Specifically, df_attr contains a column called question_id and several other columns of attributes. For each question, we have two attribute as known as capability and knowledge . df_attr = pd . read_feather ( attribute_path ) . sort_values ( 'question_id' ) . reset_index ( drop = True ) df_attr .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } question_id capability knowledge kp 0 0 [{'id': 'TAG_10100001553832', 'type': 0}, {'id... [{'id': '0101001', 'type': 0.0}, {'id': '01020... [{'id': 'KP_10100071064944'}, {'id': 'KP_10100... 1 1 [{'id': 'TAG_10100001553832', 'type': 0}, {'id... [{'id': '0101001', 'type': 0.0}, {'id': '01020... [{'id': 'KP_10100050863402'}, {'id': 'KP_10100... 2 2 [{'id': 'TAG_10100001553832', 'type': 0}, {'id... [{'id': '0101001', 'type': 0.0}, {'id': '01020... [{'id': 'KP_10100050866393'}] 3 3 [{'id': 'TAG_10100001553832', 'type': 0}, {'id... [{'id': '0101001', 'type': 0.0}, {'id': '01020... [{'id': 'KP_10100125674593'}, {'id': 'KP_10100... 4 4 [{'id': 'TAG_10100001553832', 'type': 0}, {'id... [{'id': '0101001', 'type': 0.0}, {'id': '01020... [{'id': 'KP_10100077305590'}, {'id': 'KP_10100... ... ... ... ... ... 3599 3599 [{'id': 'TAG_10300000827653', 'type': 0}, {'id... [{'id': '0301001', 'type': 0.0}, {'id': '03020... [{'id': 'KP_10300117105040'}] 3600 3600 [{'id': 'TAG_10300000827653', 'type': 0}, {'id... [{'id': '0301001', 'type': 0.0}, {'id': '03020... [{'id': 'KP_10300212870515'}] 3601 3601 [{'id': 'TAG_10300000827653', 'type': 0}, {'id... [{'id': '0301001', 'type': 0.0}, {'id': '03020... [{'id': 'KP_10300111435423'}] 3602 3602 [{'id': 'TAG_10300000827653', 'type': 0}, {'id... [{'id': '0301001', 'type': 0.0}, {'id': '03020... [{'id': 'KP_10300213265389'}] 3603 3603 [{'id': 'TAG_10300000827653', 'type': 0}, {'id... [{'id': '0301001', 'type': 0.0}, {'id': '03020... [{'id': 'KP_10300111316448'}] 3604 rows \u00d7 4 columns There are 90 types of capabilities and 34 types of knowledge required by different questions in ths dataset. We convert these attributes into two binary vectors named capability_vec and knowledge_vec . The capability_vec vector has shape (number_of_questions, 90) and the knowledge_vec vector has shape (number_of_questions, 34) . For example, knowledge_vec[i, j] = 1 indicates answering question i correctly requires type j of knowledge. def f ( z ): # extract knowledge domain. return z [ - 1 ][ 'id' ] knowledge_domain = [ f ( x ) for x in df_attr [ 'knowledge' ] . values ] df_attr [ 'capability_vec' ] = convert_column_to_binary_vectors ( df_attr [ 'capability' ]) df_attr [ 'knowledge_vec' ] = convert_column_to_binary_vectors ( df_attr [ 'knowledge' ]) capability_vec = torch . stack ( df_attr [ 'capability_vec' ] . to_list (), dim = 0 ) . float () knowledge_vec = torch . stack ( df_attr [ 'knowledge_vec' ] . to_list (), dim = 0 ) . float () print ( f \" { knowledge_vec . shape =:} \" ) print ( f \" { capability_vec . shape =:} \" ) knowledge_vec.shape=torch.Size([3604, 34]) capability_vec.shape=torch.Size([3604, 90]) Lastly, we concatenate the capability_vec and knowledge_vec vectors into a single vector called item_obs with shape (number_of_questions, 124) . This vector encompasses all attributes/observables of items (i.e., questions in this context). item_obs = torch . cat ([ capability_vec , knowledge_vec ], dim = 1 ) print ( f \" { item_obs . shape =:} \" ) item_obs.shape=torch.Size([3604, 124])","title":"The Attribute Dataset"},{"location":"education_data/#construct-the-choicedataset-object","text":"The last step is to construct the ChoiceDataset object. The item_index ( user_index ) keyword argument holds the identify of question answered (student answering the question) in each student-question response pair respectively. The label argument is a binary tensor indicating whether the student answered the question correctly. Lastly, we put the item_obs to capture observables of questions to the dataset. In this tutorial, we don't have any user observables (i.e., observables of students). choice_dataset = ChoiceDataset ( item_index = torch . LongTensor ( df_resp [ 'question_id' ] . values ), user_index = torch . LongTensor ( df_resp [ 'student_id' ] . values ), label = torch . LongTensor ( df_resp [ 'correct' ] . values ), item_obs = item_obs ) No `session_index` is provided, assume each choice instance is in its own session. You can print the choice_dataset to see information about tensors encompassed. print ( choice_dataset ) ChoiceDataset(label=[8621720], item_index=[8621720], user_index=[8621720], session_index=[8621720], item_availability=[], item_obs=[3604, 124], device=cpu) num_users = len ( torch . unique ( choice_dataset . user_index )) num_items = len ( torch . unique ( choice_dataset . item_index )) num_item_obs = choice_dataset . item_obs . shape [ - 1 ]","title":"Construct the ChoiceDataset Object"},{"location":"education_data/#splitting-data-into-training-validation-and-testing-sets","text":"To test the generalizability of the model, we split the data into training, validation, and testing sets. Specifically, we randomly take 80% of student-question pairs as the training set, 10% as the validation set, and the rest 10% as the testing set. # randomly permutate the index ranging from (0, 1, ..., len(choice_Dataset) - 1). idx = np . random . permutation ( len ( choice_dataset )) # take the first 80% from the random permutation as indices for the training set. train_size = int ( 0.8 * len ( choice_dataset )) val_size = int ( 0.1 * len ( choice_dataset )) train_idx = idx [: train_size ] val_idx = idx [ train_size : train_size + val_size ] test_idx = idx [ train_size + val_size :] # we put train/validation/test datasets into a list. dataset_list = [ choice_dataset [ train_idx ], choice_dataset [ val_idx ], choice_dataset [ test_idx ]] print ( '[Training dataset]' , dataset_list [ 0 ]) print ( '[Validation dataset]' , dataset_list [ 1 ]) print ( '[Testing dataset]' , dataset_list [ 2 ]) [Training dataset] ChoiceDataset(label=[6897376], item_index=[6897376], user_index=[6897376], session_index=[6897376], item_availability=[], item_obs=[3604, 124], device=cpu) [Validation dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu) [Testing dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu)","title":"Splitting Data into Training, Validation, and Testing Sets"},{"location":"education_data/#fitting-the-model","text":"","title":"Fitting the Model"},{"location":"education_data/#one-basic-model","text":"Now let's fit a basic BEMB model to the data. Recall that an user \\(u\\) corresponds to a student and an item \\(i\\) corresponds to question in this tutorial. The basic model we will be fitting has utility representation \\[ U_{ui} = \\lambda_i + \\theta_u^\\top \\alpha_i \\] where \\[ \\theta_u, \\alpha_i \\in \\mathbb{R}^{10} \\] The predicted probability for student \\(u\\) to correctly answer question \\(i\\) is \\[ \\frac{1}{1 + e^{-U_{ui}}} \\] Important : be sure to set pred_item=False below since the model is predicting choice_dataset.label instead of choice_dataset.item as in traditional consumer choice modeling. obs2prior_dict = { 'lambda_item' : False , 'theta_user' : False , 'alpha_item' : False } LATENT_DIM = 10 coef_dim_dict = { 'lambda_item' : 1 , 'theta_user' : LATENT_DIM , 'alpha_item' : LATENT_DIM } bemb = LitBEMBFlex ( learning_rate = 0.1 , pred_item = False , num_seeds = 4 , utility_formula = 'lambda_item + theta_user * alpha_item' , num_users = num_users , num_items = num_items , obs2prior_dict = obs2prior_dict , coef_dim_dict = coef_dim_dict , trace_log_q = True , num_item_obs = num_item_obs , prior_variance = 1 ) if torch . cuda . is_available (): bemb = bemb . to ( 'cuda' ) bemb = run ( bemb , dataset_list , batch_size = len ( choice_dataset ) // 20 , num_epochs = 10 ) BEMB: utility formula parsed: [{'coefficient': ['lambda_item'], 'observable': None}, {'coefficient': ['theta_user', 'alpha_item'], 'observable': None}] GPU available: True, used: True TPU available: False, using: 0 TPU cores IPU available: False, using: 0 IPUs HPU available: False, using: 0 HPUs LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params ----------------------------------- 0 | model | BEMBFlex | 5.3 M ----------------------------------- 5.3 M Trainable params 0 Non-trainable params 5.3 M Total params 21.258 Total estimated model params size (MB) ==================== model received ==================== Bayesian EMBedding Model with U[user, item, session] = lambda_item + theta_user * alpha_item Total number of parameters: 5314408. With the following coefficients: ModuleDict( (lambda_item): BayesianCoefficient(num_classes=3604, dimension=1, prior=N(0, I)) (theta_user): BayesianCoefficient(num_classes=261756, dimension=10, prior=N(0, I)) (alpha_item): BayesianCoefficient(num_classes=3604, dimension=10, prior=N(0, I)) ) [] ==================== data set received ==================== [Training dataset] ChoiceDataset(label=[6897376], item_index=[6897376], user_index=[6897376], session_index=[6897376], item_availability=[], item_obs=[3604, 124], device=cpu) [Validation dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu) [Testing dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu) ==================== train the model ==================== Sanity Checking: 0it [00:00, ?it/s] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] time taken: 89.43709015846252 ==================== test performance ==================== Testing: 0it [00:00, ?it/s] \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Test metric DataLoader 0 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 test_acc 0.8308121813280877 test_ll -0.3618064307005444 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500","title":"One Basic Model"},{"location":"education_data/#leveraging-more-complex-utility-representations","text":"Let's add the item-observable measuring capacities and knowledge required by answering each question to the utility representation. \\[ U_{ui} = \\lambda_i + \\theta_u^\\top \\alpha_i + \\eta_u^\\top X^{(item\\_obs)}_i \\] where \\[ \\theta_u, \\alpha_i \\in \\mathbb{R}^{10} \\] and \\[ \\eta_u, X^{(item\\_obs)}_i \\in \\mathbb{R}^{124} \\] obs2prior_dict = { 'lambda_item' : False , 'theta_user' : False , 'alpha_item' : False , 'eta_user' : False } LATENT_DIM = 10 coef_dim_dict = { 'lambda_item' : 1 , 'theta_user' : LATENT_DIM , 'alpha_item' : LATENT_DIM , 'eta_user' : num_item_obs } bemb = LitBEMBFlex ( # trainings args. learning_rate = 0.1 , pred_item = False , num_seeds = 4 , # model args, will be passed to BEMB constructor. utility_formula = 'lambda_item + theta_user * alpha_item + eta_user * item_obs' , num_users = num_users , num_items = num_items , obs2prior_dict = obs2prior_dict , coef_dim_dict = coef_dim_dict , trace_log_q = True , num_item_obs = num_item_obs , prior_variance = 1 ) if torch . cuda . is_available (): bemb = bemb . to ( 'cuda' ) bemb = run ( bemb , dataset_list , batch_size = len ( choice_dataset ) // 20 , num_epochs = 10 ) BEMB: utility formula parsed: [{'coefficient': ['lambda_item'], 'observable': None}, {'coefficient': ['theta_user', 'alpha_item'], 'observable': None}, {'coefficient': ['eta_user'], 'observable': 'item_obs'}] GPU available: True, used: True TPU available: False, using: 0 TPU cores IPU available: False, using: 0 IPUs HPU available: False, using: 0 HPUs LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params ----------------------------------- 0 | model | BEMBFlex | 70.2 M ----------------------------------- 70.2 M Trainable params 0 Non-trainable params 70.2 M Total params 280.920 Total estimated model params size (MB) ==================== model received ==================== Bayesian EMBedding Model with U[user, item, session] = lambda_item + theta_user * alpha_item + eta_user * item_obs Total number of parameters: 70229896. With the following coefficients: ModuleDict( (lambda_item): BayesianCoefficient(num_classes=3604, dimension=1, prior=N(0, I)) (theta_user): BayesianCoefficient(num_classes=261756, dimension=10, prior=N(0, I)) (alpha_item): BayesianCoefficient(num_classes=3604, dimension=10, prior=N(0, I)) (eta_user): BayesianCoefficient(num_classes=261756, dimension=124, prior=N(0, I)) ) [] ==================== data set received ==================== [Training dataset] ChoiceDataset(label=[6897376], item_index=[6897376], user_index=[6897376], session_index=[6897376], item_availability=[], item_obs=[3604, 124], device=cpu) [Validation dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu) [Testing dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu) ==================== train the model ==================== LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] time taken: 185.29189801216125 ==================== test performance ==================== Testing: 0it [00:00, ?it/s] \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Test metric DataLoader 0 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 test_acc 0.852068960717815 test_ll -0.3408827750695644 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500","title":"Leveraging More Complex Utility Representations"},{"location":"education_data/#leveraging-obs2prior","text":"In both examples above, the prior of all coefficients were standard Gaussian distributions. We can improve the model by incorporating the obs2prior option and let the mean of prior distribution of item-specific coefficients (i.e., \\(\\lambda_i\\) and \\(\\alpha_i\\) ) depend on item observables. One can turn on the obs2prior option easily by setting obs2prior_dict['lambda_item'] = True and obs2prior_dict['alpha_item'] = True . Important : we recommend to set a small prior_variance to make obs2prior more effective. For example, if one set prior_variance= \\(\\infty\\) , prior distributions do not matter at all to the optimization, and the obs2prior will be ineffectively as a result. \\[ U_{ui} = \\lambda_i + \\theta_u^\\top \\alpha_i \\] where \\[ \\theta_u, \\alpha_i \\in \\mathbb{R}^{10} \\] obs2prior_dict = { 'lambda_item' : True , 'theta_user' : False , 'alpha_item' : True , 'eta_user' : False } LATENT_DIM = 10 coef_dim_dict = { 'lambda_user' : 1 , 'lambda_item' : 1 , 'theta_user' : LATENT_DIM , 'alpha_item' : LATENT_DIM , 'eta_user' : num_item_obs } bemb = LitBEMBFlex ( # trainings args. learning_rate = 0.1 , pred_item = False , num_seeds = 4 , # model args, will be passed to BEMB constructor. utility_formula = 'lambda_item + theta_user * alpha_item + eta_user * item_obs' , num_users = num_users , num_items = num_items , obs2prior_dict = obs2prior_dict , coef_dim_dict = coef_dim_dict , trace_log_q = True , num_item_obs = num_item_obs , prior_variance = 0.01 ) if torch . cuda . is_available (): bemb = bemb . to ( 'cuda' ) bemb = run ( bemb , dataset_list , batch_size = len ( choice_dataset ) // 20 , num_epochs = 50 ) BEMB: utility formula parsed: [{'coefficient': ['lambda_item'], 'observable': None}, {'coefficient': ['theta_user', 'alpha_item'], 'observable': None}, {'coefficient': ['eta_user'], 'observable': 'item_obs'}] GPU available: True, used: True TPU available: False, using: 0 TPU cores IPU available: False, using: 0 IPUs HPU available: False, using: 0 HPUs LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params ----------------------------------- 0 | model | BEMBFlex | 70.2 M ----------------------------------- 70.2 M Trainable params 0 Non-trainable params 70.2 M Total params 280.930 Total estimated model params size (MB) ==================== model received ==================== Bayesian EMBedding Model with U[user, item, session] = lambda_item + theta_user * alpha_item + eta_user * item_obs Total number of parameters: 70232624. With the following coefficients: ModuleDict( (lambda_item): BayesianCoefficient(num_classes=3604, dimension=1, prior=N(H*X_obs(H shape=torch.Size([1, 124]), X_obs shape=124), Ix0.01)) (theta_user): BayesianCoefficient(num_classes=261756, dimension=10, prior=N(0, I)) (alpha_item): BayesianCoefficient(num_classes=3604, dimension=10, prior=N(H*X_obs(H shape=torch.Size([10, 124]), X_obs shape=124), Ix0.01)) (eta_user): BayesianCoefficient(num_classes=261756, dimension=124, prior=N(0, I)) ) [] ==================== data set received ==================== [Training dataset] ChoiceDataset(label=[6897376], item_index=[6897376], user_index=[6897376], session_index=[6897376], item_availability=[], item_obs=[3604, 124], device=cpu) [Validation dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu) [Testing dataset] ChoiceDataset(label=[862172], item_index=[862172], user_index=[862172], session_index=[862172], item_availability=[], item_obs=[3604, 124], device=cpu) ==================== train the model ==================== Sanity Checking: 0it [00:00, ?it/s] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] time taken: 941.1486117839813 ==================== test performance ==================== Testing: 0it [00:00, ?it/s] \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Test metric DataLoader 0 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 test_acc 0.8209313222883601 test_ll -0.3934649652798017 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500","title":"Leveraging obs2prior"},{"location":"education_data/#tuning-the-model","text":"There are tons of parameters in models above, for example, we choose LATENT_DIM = 10 based on our own experience. However, these choices of hyper-parameters can be sub-optimal. We recommend researchers to try out different combinations of hyper-parameters before sticking with a particular hyper-parameter configuration. We will be providing a script for effectively parameter tuning though the learning-tool-competition project.","title":"Tuning the Model"},{"location":"intro/","text":"Introduction This document provides a short introduction to the consumer choice model we aim to solve. In short, all models in the package aim to predict which item an user will purchase while facing the shelves in a supermarket. More specifically, for each user \\(u\\) and item \\(i\\) , models compute a value \\(U_{ui}\\) predicting the utility user \\(u\\) will get from purchasing item \\(i\\) , then user \\(u\\) is predicted to purchase the item \\(i\\) generating the maximum utility. However, the usage of our models is not limited to this supermarket context, researchers can adjust the definition of user and item to fit any choice modelling context. The related project page overviews some extensions of our models to other context. Components of the Consumer Choice Modelling Problem We begin with essential component of the consumer choice modelling problem. Walking through these components should help you understand what kind of data our models are working on. Purchasing Record Each row (record) of the dataset is called a purchasing record , which includes who bought what at when and where . Let \\(B\\) denote the number of purchasing records in the dataset (i.e., number of rows of the dataset). Each row \\(b \\in \\{1,2,\\dots, B\\}\\) corresponds to a purchase record (i.e., who bought what at where and when ). Items and Categories To begin with, there are \\(I\\) items indexed by \\(i \\in \\{1,2,\\dots,I\\}\\) under our consideration. Further, the researcher can optionally partition the set items into \\(C\\) categories indexed by \\(c \\in \\{1,2,\\dots,C\\}\\) . Let \\(I_c\\) denote the collection of items in category \\(c\\) , it is easy to verify that $ \\bigcup_{c \\in {1, 2, \\dots, C}} I_c = {1, 2, \\dots I} $ If the researcher does not wish to model different categories differently, the researcher can simply put all items in one single category: \\(I_1 = \\{1, 2, \\dots I\\}\\) , so that all items belong to the same category. Note : since we will be using PyTorch to train our model, we represent their identities with integer values instead of the raw human-readable names of items (e.g., Dell 24 inch LCD monitor). Raw item names can be encoded easily with sklearn.preprocessing.OrdinalEncoder Users Each purchaing reocrd is naturally associated with an user indexed by \\(u \\in \\{1,2,\\dots,U\\}\\) ( who ) as well. Sessions Our data structure encompasses where and when using a notion called session indexed by \\(s \\in \\{1,2,\\dots, S\\}\\) . For example, when the data came from a single store over the period of a year. In this case, the notion of where does not matter that much, and session \\(s\\) is simply the date of purchase. Another example is that we have the purchase record from different stores, the session \\(s\\) can be defined as a pair of (date, store) instead. If the researcher does not wish to handle records from different sessions differently, the researcher can assign the same session ID to all rows of the dataset. To summarize, each purchasing record \\(b\\) in the dataset is characterized by a user-session-item tuple \\((u, s, i)\\) . When there are multiple items bought by the same user in the same session, there will be multiple rows in the dataset with the same \\((u, s)\\) corresponding to the same receipt. Item Availability It is not necessarily that all items are available in every session, items can get out-of-stock in particular sessions. To handle these cases, the researcher can optionally provide a boolean tensor \\(\\in \\{\\texttt{True}, \\texttt{False}\\}^{S\\times I}\\) to indicate which items are available for purchasing in each session. While predicting the purchase probabilities, the model sets the probability for these unavailable items to zero and normalizes probabilities among available items. If the item availability is not provided, the model assumes all items are available in all sessions. Available Models","title":"About"},{"location":"intro/#introduction","text":"This document provides a short introduction to the consumer choice model we aim to solve. In short, all models in the package aim to predict which item an user will purchase while facing the shelves in a supermarket. More specifically, for each user \\(u\\) and item \\(i\\) , models compute a value \\(U_{ui}\\) predicting the utility user \\(u\\) will get from purchasing item \\(i\\) , then user \\(u\\) is predicted to purchase the item \\(i\\) generating the maximum utility. However, the usage of our models is not limited to this supermarket context, researchers can adjust the definition of user and item to fit any choice modelling context. The related project page overviews some extensions of our models to other context.","title":"Introduction"},{"location":"intro/#components-of-the-consumer-choice-modelling-problem","text":"We begin with essential component of the consumer choice modelling problem. Walking through these components should help you understand what kind of data our models are working on.","title":"Components of the Consumer Choice Modelling Problem"},{"location":"intro/#purchasing-record","text":"Each row (record) of the dataset is called a purchasing record , which includes who bought what at when and where . Let \\(B\\) denote the number of purchasing records in the dataset (i.e., number of rows of the dataset). Each row \\(b \\in \\{1,2,\\dots, B\\}\\) corresponds to a purchase record (i.e., who bought what at where and when ).","title":"Purchasing Record"},{"location":"intro/#items-and-categories","text":"To begin with, there are \\(I\\) items indexed by \\(i \\in \\{1,2,\\dots,I\\}\\) under our consideration. Further, the researcher can optionally partition the set items into \\(C\\) categories indexed by \\(c \\in \\{1,2,\\dots,C\\}\\) . Let \\(I_c\\) denote the collection of items in category \\(c\\) , it is easy to verify that $ \\bigcup_{c \\in {1, 2, \\dots, C}} I_c = {1, 2, \\dots I} $ If the researcher does not wish to model different categories differently, the researcher can simply put all items in one single category: \\(I_1 = \\{1, 2, \\dots I\\}\\) , so that all items belong to the same category. Note : since we will be using PyTorch to train our model, we represent their identities with integer values instead of the raw human-readable names of items (e.g., Dell 24 inch LCD monitor). Raw item names can be encoded easily with sklearn.preprocessing.OrdinalEncoder","title":"Items and Categories"},{"location":"intro/#users","text":"Each purchaing reocrd is naturally associated with an user indexed by \\(u \\in \\{1,2,\\dots,U\\}\\) ( who ) as well.","title":"Users"},{"location":"intro/#sessions","text":"Our data structure encompasses where and when using a notion called session indexed by \\(s \\in \\{1,2,\\dots, S\\}\\) . For example, when the data came from a single store over the period of a year. In this case, the notion of where does not matter that much, and session \\(s\\) is simply the date of purchase. Another example is that we have the purchase record from different stores, the session \\(s\\) can be defined as a pair of (date, store) instead. If the researcher does not wish to handle records from different sessions differently, the researcher can assign the same session ID to all rows of the dataset. To summarize, each purchasing record \\(b\\) in the dataset is characterized by a user-session-item tuple \\((u, s, i)\\) . When there are multiple items bought by the same user in the same session, there will be multiple rows in the dataset with the same \\((u, s)\\) corresponding to the same receipt.","title":"Sessions"},{"location":"intro/#item-availability","text":"It is not necessarily that all items are available in every session, items can get out-of-stock in particular sessions. To handle these cases, the researcher can optionally provide a boolean tensor \\(\\in \\{\\texttt{True}, \\texttt{False}\\}^{S\\times I}\\) to indicate which items are available for purchasing in each session. While predicting the purchase probabilities, the model sets the probability for these unavailable items to zero and normalizes probabilities among available items. If the item availability is not provided, the model assumes all items are available in all sessions.","title":"Item Availability"},{"location":"intro/#available-models","text":"","title":"Available Models"},{"location":"projects/","text":"Research Projects using this Package Question-Answering Data for Educational Applications Tutorial on Educational Question-Answering","title":"Related Projects"},{"location":"projects/#research-projects-using-this-package","text":"","title":"Research Projects using this Package"},{"location":"projects/#question-answering-data-for-educational-applications","text":"Tutorial on Educational Question-Answering","title":"Question-Answering Data for Educational Applications"},{"location":"test/","text":"Compatibility Check List We have tested the tutorials using the following environments, please let us know if there is any issue with our packages on other systems. Tutorial Platform Versions CPU GPU Device Tested Data Management MacOS 12.2 Python 3.9.7 PyTorch 1.10.0 M1 Max N/A cpu Data Management Ubuntu 20.04 Python 3.8.10 PyTorch 1.10.1 CUDA 11.3 11700F RTX3090 cpu and cuda Conditional Logit Model MacOS 12.2 Python 3.9 PyTorch 1.10.0 M1 Max N/A cpu Conditional Logit Model Ubuntu 20.04 Python 3.8.10 PyTorch 1.10.1 CUDA 11.3 11700F RTX3090 cpu and cuda Nested Logit Model MacOS 12.2 Python 3.9.7 PyTorch 1.10.0 M1 Max N/A cpu Nested Logit Model Ubuntu 20.04 Python 3.8.10 PyTorch 1.10.1 CUDA 11.3 11700F RTX3090 cpu and cuda","title":"Compatibility Tests"},{"location":"test/#compatibility-check-list","text":"We have tested the tutorials using the following environments, please let us know if there is any issue with our packages on other systems. Tutorial Platform Versions CPU GPU Device Tested Data Management MacOS 12.2 Python 3.9.7 PyTorch 1.10.0 M1 Max N/A cpu Data Management Ubuntu 20.04 Python 3.8.10 PyTorch 1.10.1 CUDA 11.3 11700F RTX3090 cpu and cuda Conditional Logit Model MacOS 12.2 Python 3.9 PyTorch 1.10.0 M1 Max N/A cpu Conditional Logit Model Ubuntu 20.04 Python 3.8.10 PyTorch 1.10.1 CUDA 11.3 11700F RTX3090 cpu and cuda Nested Logit Model MacOS 12.2 Python 3.9.7 PyTorch 1.10.0 M1 Max N/A cpu Nested Logit Model Ubuntu 20.04 Python 3.8.10 PyTorch 1.10.1 CUDA 11.3 11700F RTX3090 cpu and cuda","title":"Compatibility Check List"},{"location":"tutorials/","text":"Tutorials The following tutorials demonstrates how to use our packages for modelling consumer choices. Data Management We begin with creating the ChoiceDataset data strcuture holding all purchasing records. Please navigate to data data managment tutorial . The executable Jupyter notebook for this tutorial is located at data management tutorial . Random Utility Model (RUM) 1: Conditional Logit Model The executable Jupyter notebook for this tutorial is located at Random Utility Model (RUM) 1: Conditional Logit Model Random Utility Model (RUM) 2: Nested Logit Model The executable Jupyter notebook for this tutorial is located at Random Utility Model (RUM) 2: Nested Logit Model Bayesian Embedding Model (BEMB) Bayesian Embedding Model (BEMB)","title":"Tutorials"},{"location":"tutorials/#tutorials","text":"The following tutorials demonstrates how to use our packages for modelling consumer choices.","title":"Tutorials"},{"location":"tutorials/#data-management","text":"We begin with creating the ChoiceDataset data strcuture holding all purchasing records. Please navigate to data data managment tutorial . The executable Jupyter notebook for this tutorial is located at data management tutorial .","title":"Data Management"},{"location":"tutorials/#random-utility-model-rum-1-conditional-logit-model","text":"The executable Jupyter notebook for this tutorial is located at Random Utility Model (RUM) 1: Conditional Logit Model","title":"Random Utility Model (RUM) 1: Conditional Logit Model"},{"location":"tutorials/#random-utility-model-rum-2-nested-logit-model","text":"The executable Jupyter notebook for this tutorial is located at Random Utility Model (RUM) 2: Nested Logit Model","title":"Random Utility Model (RUM) 2: Nested Logit Model"},{"location":"tutorials/#bayesian-embedding-model-bemb","text":"Bayesian Embedding Model (BEMB)","title":"Bayesian Embedding Model (BEMB)"}]}