
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://example.com/api_bemb/">
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.3.1, mkdocs-material-8.4.2">
    
    
      
        <title>API Reference BEMB - Bayesian Embedding (BEMB)</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.69437709.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.cbb835fc.min.css">
        
          
          
          <meta name="theme-color" content="#02a6f2">
        
      
      
    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="light-blue" data-md-color-accent="">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#api-reference-bemb" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Bayesian Embedding (BEMB)" class="md-header__button md-logo" aria-label="Bayesian Embedding (BEMB)" data-md-component="logo">
      
  
  <?xml version="1.0" encoding="UTF-8"?>
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="241.9pt" height="365pt" viewBox="0 0 241.9 365" version="1.1">
<defs>
<clipPath id="clip1">
  <path d="M 0 0 L 241.898438 0 L 241.898438 365 L 0 365 Z M 0 0 "/>
</clipPath>
</defs>
<g id="surface1">
<g clip-path="url(#clip1)" clip-rule="nonzero">
<path style=" stroke:none;fill-rule:nonzero;fill:rgb(60.398865%,10.598755%,11.799622%);fill-opacity:1;" d="M 235.886719 119.484375 C 235.886719 118.5625 235.886719 117.898438 235.886719 117.230469 C 235.886719 96.425781 235.875 75.621094 235.917969 54.820313 C 235.921875 53.394531 235.460938 52.414063 234.449219 51.449219 C 219.242188 36.867188 204.058594 22.257813 188.898438 7.625 C 187.800781 6.566406 186.710938 6.074219 185.140625 6.078125 C 142.371094 6.121094 99.605469 6.117188 56.835938 6.078125 C 55.355469 6.078125 54.261719 6.46875 53.21875 7.492188 C 49.527344 11.125 45.773438 14.699219 42.039063 18.289063 C 33.683594 26.320313 25.324219 34.347656 16.96875 42.382813 C 13.335938 45.871094 9.71875 49.378906 6.113281 52.855469 C 6.113281 53.300781 6.113281 53.640625 6.113281 53.980469 C 6.113281 96.339844 6.117188 138.695313 6.085938 181.054688 C 6.085938 182.261719 6.496094 183.066406 7.324219 183.894531 C 20.417969 196.941406 33.492188 210.011719 46.535156 223.109375 C 47.472656 224.050781 48.410156 224.464844 49.75 224.457031 C 57.320313 224.398438 64.890625 224.425781 72.464844 224.433594 C 73.042969 224.433594 73.621094 224.488281 74.644531 224.539063 C 71.742188 227.257813 70.460938 230.371094 69.59375 234.179688 C 71.082031 234.234375 72.199219 234.359375 73.308594 234.300781 C 78.976563 233.992188 84.304688 232.523438 89.242188 229.652344 C 90.832031 228.726563 92.546875 228.898438 94.125 229.796875 C 95.808594 230.753906 96.222656 232.242188 95.316406 233.96875 C 94.910156 234.746094 94.429688 235.511719 93.875 236.195313 C 90.800781 239.984375 86.703125 241.890625 81.96875 242.726563 C 79.636719 243.136719 77.316406 243.722656 75.074219 244.484375 C 73.582031 244.992188 72.875 246.195313 73.230469 247.292969 C 73.503906 248.140625 74.152344 248.90625 74.765625 249.589844 C 75.394531 250.289063 76.183594 250.84375 76.902344 251.460938 C 76.828125 251.609375 76.753906 251.761719 76.679688 251.910156 C 53.242188 251.910156 29.804688 251.910156 6.164063 251.910156 C 6.164063 252.78125 6.164063 253.449219 6.164063 254.117188 C 6.144531 272.804688 6.144531 291.496094 6.082031 310.183594 C 6.074219 311.609375 6.515625 312.585938 7.527344 313.554688 C 16.839844 322.457031 26.117188 331.402344 35.398438 340.34375 C 41.289063 346.019531 47.175781 351.699219 53.039063 357.40625 C 54.113281 358.449219 55.214844 358.96875 56.800781 358.96875 C 99.640625 358.917969 142.476563 358.921875 185.3125 358.960938 C 186.71875 358.960938 187.746094 358.570313 188.742188 357.605469 C 195.199219 351.339844 201.703125 345.117188 208.1875 338.878906 C 216.886719 330.511719 225.566406 322.132813 234.292969 313.792969 C 235.394531 312.738281 235.929688 311.679688 235.925781 310.082031 C 235.878906 270.109375 235.878906 230.140625 235.917969 190.167969 C 235.921875 188.683594 235.5 187.640625 234.445313 186.59375 C 221.4375 173.652344 208.464844 160.679688 195.523438 147.671875 C 194.46875 146.609375 193.417969 146.195313 191.9375 146.203125 C 181.980469 146.261719 172.019531 146.242188 162.0625 146.21875 C 161.265625 146.214844 160.328125 146.230469 159.699219 145.84375 C 155.351563 143.167969 150.949219 140.546875 146.800781 137.585938 C 143.5625 135.273438 141.082031 132.121094 139.085938 128.667969 C 138.125 127.007813 137.503906 125.199219 138.632813 123.179688 C 139.15625 123.265625 139.660156 123.234375 140.050781 123.429688 C 146.277344 126.621094 153.035156 127.347656 159.871094 127.726563 C 162.050781 127.847656 164.191406 128.058594 166.242188 128.980469 C 168.035156 129.785156 169.601563 128.535156 169.25 126.59375 C 169.085938 125.695313 168.609375 124.796875 168.085938 124.027344 C 167.070313 122.539063 165.925781 121.144531 164.660156 119.484375 C 188.476563 119.484375 211.996094 119.484375 235.886719 119.484375 Z M 0 315.160156 C 0 291.964844 0 268.773438 0 245.578125 C 0.609375 245.621094 1.21875 245.703125 1.828125 245.707031 C 23.648438 245.710938 45.472656 245.710938 67.296875 245.707031 C 67.894531 245.707031 68.496094 245.648438 69.097656 245.617188 C 69.898438 243.046875 71.621094 241.488281 73.90625 240.480469 C 74.777344 240.097656 75.699219 239.824219 76.550781 239.402344 C 76.941406 239.207031 77.21875 238.773438 77.542969 238.449219 C 77.46875 238.320313 77.394531 238.191406 77.320313 238.058594 C 76.046875 238.160156 74.773438 238.320313 73.5 238.347656 C 72.214844 238.371094 70.894531 238.429688 69.648438 238.179688 C 66.917969 237.628906 65.417969 235.339844 65.773438 232.585938 C 65.847656 231.992188 65.910156 231.398438 66.003906 230.550781 C 65.113281 230.550781 64.382813 230.550781 63.648438 230.550781 C 58.261719 230.550781 52.875 230.503906 47.488281 230.578125 C 46.007813 230.601563 44.960938 230.179688 43.90625 229.117188 C 29.859375 215.003906 15.769531 200.929688 1.679688 186.855469 C 1.160156 186.335938 0.5625 185.890625 0 185.410156 C 0 140.253906 0 95.09375 0 49.933594 C 0.332031 49.714844 0.710938 49.539063 0.992188 49.265625 C 4.589844 45.828125 8.171875 42.375 11.757813 38.929688 C 22.8125 28.300781 33.875 17.683594 44.917969 7.042969 C 47.3125 4.738281 49.628906 2.351563 51.980469 0 C 97.957031 0 143.9375 0 189.914063 0 C 190.371094 0.496094 190.804688 1.023438 191.292969 1.492188 C 195.417969 5.460938 199.558594 9.414063 203.6875 13.382813 C 211.546875 20.941406 219.402344 28.507813 227.257813 36.074219 C 232.113281 40.753906 236.964844 45.441406 241.703125 50.015625 C 241.703125 75.300781 241.703125 100.425781 241.703125 125.695313 C 218.851563 125.695313 196.160156 125.695313 173.40625 125.695313 C 173.40625 126.246094 173.421875 126.648438 173.402344 127.050781 C 173.167969 131.855469 169.175781 134.410156 164.660156 132.78125 C 163.15625 132.238281 161.507813 132.0625 159.910156 131.832031 C 158.632813 131.648438 157.320313 131.703125 156.039063 131.535156 C 152.410156 131.058594 148.785156 130.523438 145.085938 130.003906 C 145.410156 130.421875 145.71875 130.84375 146.050781 131.246094 C 148.84375 134.617188 152.519531 136.839844 156.195313 139.074219 C 157.402344 139.808594 158.613281 140.144531 160.042969 140.136719 C 171.5 140.09375 182.957031 140.140625 194.414063 140.078125 C 195.976563 140.070313 197.0625 140.550781 198.15625 141.648438 C 212.15625 155.714844 226.191406 169.75 240.261719 183.746094 C 241.410156 184.890625 241.902344 186.011719 241.902344 187.652344 C 241.855469 229.324219 241.867188 270.992188 241.867188 312.664063 C 241.867188 313.410156 241.867188 314.15625 241.867188 314.941406 C 224.503906 331.652344 207.171875 348.335938 189.855469 365 C 143.90625 365 98.019531 365 52.15625 365 C 49.609375 362.539063 47.113281 360.121094 44.609375 357.707031 C 30.621094 344.226563 16.636719 330.742188 2.636719 317.273438 C 1.828125 316.496094 0.882813 315.859375 0 315.160156 "/>
</g>
<path style=" stroke:none;fill-rule:nonzero;fill:rgb(100%,100%,100%);fill-opacity:1;" d="M 12.75 258.398438 C 12.71875 259.09375 12.667969 259.6875 12.667969 260.285156 C 12.632813 275.835938 12.636719 291.386719 12.527344 306.933594 C 12.515625 308.765625 13.140625 309.972656 14.410156 311.164063 C 19.472656 315.925781 24.476563 320.757813 29.488281 325.574219 C 38.429688 334.175781 47.375 342.777344 56.285156 351.40625 C 57.03125 352.128906 57.757813 352.464844 58.796875 352.449219 C 62.960938 352.398438 67.121094 352.472656 71.28125 352.417969 C 76.671875 352.347656 81.402344 350.507813 85.453125 346.933594 C 88.347656 344.371094 90.582031 341.277344 92.527344 337.984375 C 94.738281 334.253906 97.441406 330.957031 100.652344 328.054688 C 102.167969 326.683594 103.621094 325.238281 105.199219 323.9375 C 107.410156 322.117188 108.589844 319.746094 109.335938 317.054688 C 110.398438 313.207031 110.707031 309.253906 110.75 305.3125 C 110.882813 292.765625 110.859375 280.21875 110.878906 267.667969 C 110.882813 267.03125 110.722656 266.390625 110.640625 265.789063 C 109.265625 265.410156 108.386719 266.027344 107.609375 266.632813 C 106.375 267.59375 105.183594 268.632813 104.097656 269.753906 C 102.339844 271.5625 100.289063 272.878906 97.871094 273.5 C 95.902344 274.007813 93.882813 274.367188 91.863281 274.640625 C 89.441406 274.96875 86.878906 274.75 84.578125 275.441406 C 76.71875 277.800781 69.570313 281.523438 63.78125 287.511719 C 62.996094 288.320313 62.191406 289.050781 60.941406 288.664063 C 59.738281 288.289063 59.351563 287.253906 59.046875 286.1875 C 58.933594 285.800781 58.933594 285.378906 58.914063 284.972656 C 58.757813 281.015625 62.476563 270.03125 65.003906 266.992188 C 67.679688 263.773438 71.144531 261.648438 74.863281 259.871094 C 75.628906 259.503906 76.363281 259.082031 77.109375 258.6875 C 77.0625 258.589844 77.019531 258.496094 76.972656 258.398438 C 55.605469 258.398438 34.238281 258.398438 12.75 258.398438 Z M 172.03125 241.433594 C 170.605469 241.496094 169.546875 241.628906 168.496094 241.574219 C 162.835938 241.273438 157.476563 239.898438 152.546875 236.996094 C 150.722656 235.925781 148.867188 236.140625 147.15625 237.328125 C 145.804688 238.265625 145.417969 239.660156 146.234375 241.046875 C 146.992188 242.324219 147.835938 243.601563 148.859375 244.667969 C 151.964844 247.890625 155.894531 249.433594 160.273438 250.089844 C 162.277344 250.390625 164.3125 250.828125 166.1875 251.574219 C 168.828125 252.628906 169.503906 254.75 168.191406 257.242188 C 167.660156 258.253906 166.914063 259.175781 166.152344 260.03125 C 164.253906 262.160156 164.160156 264.085938 166.082031 266.179688 C 166.710938 266.863281 167.550781 267.375 168.34375 267.894531 C 169.882813 268.898438 171.503906 269.78125 172.996094 270.851563 C 175.296875 272.492188 177.421875 274.425781 178.417969 277.109375 C 180.027344 281.445313 181.433594 285.863281 182.75 290.296875 C 183.144531 291.628906 183.097656 293.140625 183.003906 294.554688 C 182.902344 296.148438 181.867188 296.878906 180.316406 296.464844 C 179.082031 296.132813 177.855469 295.625 176.761719 294.96875 C 174.191406 293.425781 171.757813 291.652344 169.171875 290.144531 C 165.941406 288.257813 162.6875 286.386719 159.304688 284.800781 C 156.441406 283.457031 153.332031 283.042969 150.121094 283.484375 C 148.371094 283.726563 146.585938 283.675781 144.816406 283.777344 C 141.253906 283.980469 138.101563 282.945313 135.308594 280.730469 C 134.363281 279.984375 133.34375 278.957031 132.054688 279.496094 C 130.582031 280.113281 130.871094 281.648438 130.867188 282.914063 C 130.851563 291.234375 130.847656 299.554688 130.867188 307.878906 C 130.871094 310.875 130.78125 313.886719 131.015625 316.871094 C 131.722656 325.789063 135.359375 332.960938 143.585938 337.296875 C 147.066406 339.128906 149.996094 341.652344 152.550781 344.640625 C 153.296875 345.511719 154.160156 346.339844 155.121094 346.949219 C 160.089844 350.117188 165.496094 352.117188 171.414063 352.402344 C 175.359375 352.589844 179.320313 352.457031 183.273438 352.539063 C 184.339844 352.5625 185.039063 352.128906 185.765625 351.425781 C 190.457031 346.863281 195.179688 342.335938 199.898438 337.800781 C 209.332031 328.726563 218.761719 319.648438 228.222656 310.605469 C 229.132813 309.738281 229.511719 308.851563 229.507813 307.574219 C 229.476563 269.246094 229.476563 230.914063 229.507813 192.582031 C 229.511719 191.308594 229.113281 190.433594 228.222656 189.554688 C 216.273438 177.679688 204.347656 165.78125 192.449219 153.859375 C 191.609375 153.015625 190.777344 152.664063 189.59375 152.671875 C 182.636719 152.722656 175.679688 152.695313 168.722656 152.699219 C 168.191406 152.699219 167.660156 152.746094 166.984375 152.78125 C 167.207031 153.324219 167.355469 153.765625 167.554688 154.179688 C 169.433594 158.035156 170.238281 162.179688 170.753906 166.382813 C 171.03125 168.664063 169.851563 169.792969 167.597656 169.328125 C 166.15625 169.03125 164.785156 168.363281 163.40625 167.800781 C 162.335938 167.367188 161.332031 166.765625 160.25 166.371094 C 155.332031 164.566406 150.398438 162.808594 145.46875 161.035156 C 144.636719 160.734375 143.820313 160.363281 142.964844 160.15625 C 141.582031 159.824219 140.425781 160.347656 139.445313 161.320313 C 138.472656 162.28125 138.863281 163.34375 139.273438 164.359375 C 140.578125 167.625 142.609375 170.296875 145.757813 171.988281 C 147.253906 172.789063 148.78125 173.550781 150.335938 174.242188 C 154.101563 175.910156 157.644531 177.925781 160.648438 180.769531 C 161.382813 181.464844 162.089844 182.25 162.578125 183.125 C 163.484375 184.753906 162.628906 185.945313 160.753906 185.828125 C 160.484375 185.8125 160.191406 185.789063 159.953125 185.679688 C 157.648438 184.601563 155.296875 184.886719 152.945313 185.445313 C 149.5625 186.253906 146.328125 185.863281 143.175781 184.421875 C 141.878906 183.828125 140.53125 183.328125 139.175781 182.890625 C 138.585938 182.699219 137.910156 182.761719 137.308594 182.714844 C 136.777344 183.953125 137.230469 184.816406 137.675781 185.652344 C 138.851563 187.851563 140.457031 189.664063 142.5 191.121094 C 147.054688 194.367188 151.722656 197.421875 156.734375 199.941406 C 164.527344 203.855469 168.496094 210.597656 170.34375 218.820313 C 170.503906 219.53125 170.3125 220.320313 170.265625 221.527344 C 168.789063 220.925781 167.566406 220.71875 166.746094 220.035156 C 164.597656 218.246094 162.183594 217.707031 159.503906 217.875 C 155.089844 218.152344 151.332031 216.757813 148.269531 213.511719 C 147.871094 213.089844 147.207031 212.910156 146.679688 212.625 C 144.632813 216.027344 145.734375 220.753906 148.84375 222.5625 C 149.777344 223.105469 150.824219 223.457031 151.816406 223.90625 C 155.414063 225.53125 159.050781 227.085938 162.59375 228.832031 C 164.160156 229.609375 165.648438 230.652344 166.972656 231.804688 C 169.734375 234.207031 171.183594 237.375 172.03125 241.433594 Z M 95.757813 205.304688 C 93.78125 205.304688 92.03125 205.417969 90.300781 205.269531 C 88.816406 205.140625 87.359375 204.703125 85.886719 204.417969 C 82.757813 203.808594 79.675781 203.613281 76.707031 205.183594 C 76.097656 205.503906 75.308594 205.476563 74.683594 205.59375 C 73.894531 204.425781 74.425781 203.554688 74.8125 202.707031 C 77.011719 197.871094 80.933594 194.742188 85.480469 192.378906 C 90.523438 189.761719 95.242188 186.667969 99.816406 183.328125 C 101.625 182.007813 103.039063 180.332031 103.933594 178.332031 C 104.5 177.070313 104.796875 175.597656 104.839844 174.207031 C 104.902344 172.167969 103.5 171.414063 101.707031 172.335938 C 101.40625 172.488281 101.109375 172.667969 100.835938 172.867188 C 94.964844 177.140625 88.488281 177.3125 81.738281 175.683594 C 81.507813 174.40625 81.484375 174.195313 82.246094 173.335938 C 83.832031 171.546875 85.433594 169.769531 87.660156 168.730469 C 89.453125 167.894531 91.273438 167.113281 93.011719 166.183594 C 94.804688 165.222656 96.640625 164.261719 98.238281 163.023438 C 100.507813 161.269531 101.964844 158.886719 102.511719 156.019531 C 102.679688 155.144531 102.847656 154.238281 101.539063 153.535156 C 100.746094 153.921875 99.679688 154.242188 98.863281 154.878906 C 95.441406 157.53125 91.484375 158.292969 87.316406 158.269531 C 82.019531 158.234375 77.566406 159.871094 74.308594 164.265625 C 73.644531 165.164063 72.835938 166.082031 71.472656 166.101563 C 70.191406 165.113281 70.3125 163.683594 70.476563 162.367188 C 70.835938 159.460938 71.285156 156.5625 71.820313 153.683594 C 73.140625 146.550781 76.871094 141.175781 83.363281 137.710938 C 86.488281 136.046875 89.445313 134.066406 92.433594 132.164063 C 95.582031 130.164063 98.128906 127.492188 100.335938 124.53125 C 101.257813 123.292969 102.03125 121.863281 102.511719 120.402344 C 103.140625 118.5 103.152344 116.527344 101.441406 114.648438 C 100.640625 115.214844 99.890625 115.742188 99.148438 116.277344 C 97.996094 117.117188 96.964844 118.3125 95.679688 118.738281 C 91.734375 120.050781 87.699219 121.105469 83.449219 120.410156 C 80.894531 119.996094 78.421875 120.257813 76.085938 121.441406 C 75.839844 121.566406 75.589844 121.679688 75.335938 121.769531 C 73.550781 122.382813 72.113281 121.296875 72.382813 119.410156 C 72.503906 118.570313 72.875 117.683594 73.378906 117 C 74.140625 115.964844 75.050781 115.019531 76.007813 114.15625 C 80.847656 109.800781 86.300781 106.296875 91.925781 103.078125 C 96.242188 100.609375 100.738281 98.464844 105.046875 95.988281 C 106.480469 95.164063 107.773438 93.914063 108.796875 92.601563 C 110.34375 90.613281 109.386719 88.445313 106.878906 88.140625 C 105.78125 88.007813 104.605469 88.339844 103.492188 88.585938 C 102.171875 88.878906 100.894531 89.53125 99.570313 89.621094 C 97.261719 89.777344 94.933594 89.671875 92.621094 89.570313 C 91.863281 89.535156 91.121094 89.167969 89.996094 88.84375 C 90.585938 87.824219 90.898438 87.003906 91.445313 86.394531 C 93 84.644531 94.863281 83.277344 97.023438 82.328125 C 99.207031 81.371094 101.394531 80.421875 103.554688 79.417969 C 105.476563 78.53125 106.699219 77.035156 107.039063 74.925781 C 107.40625 72.660156 106.378906 71.558594 104.121094 71.730469 C 103.105469 71.808594 102.085938 71.996094 101.070313 71.984375 C 100.15625 71.972656 99.25 71.757813 98.054688 71.589844 C 98.320313 70.585938 98.359375 69.8125 98.71875 69.238281 C 99.292969 68.324219 100.011719 67.476563 100.789063 66.722656 C 103.664063 63.929688 106.925781 61.761719 110.84375 60.671875 C 112.089844 60.324219 113.316406 59.867188 113.65625 58.261719 C 112.875 57.246094 111.746094 57.019531 110.59375 56.898438 C 109.171875 56.746094 107.726563 56.738281 106.328125 56.472656 C 105.667969 56.347656 104.746094 55.882813 104.582031 55.367188 C 104.425781 54.878906 104.945313 53.9375 105.441406 53.519531 C 106.839844 52.335938 108.417969 51.363281 109.855469 50.21875 C 111.71875 48.738281 113.601563 47.265625 115.308594 45.617188 C 116.519531 44.445313 116.363281 43.636719 115.085938 42.519531 C 114.160156 41.714844 113.144531 41.011719 112.222656 40.203125 C 111.570313 39.636719 110.820313 39.0625 111.085938 37.746094 C 111.613281 37.605469 112.230469 37.300781 112.855469 37.296875 C 114.582031 37.285156 115.714844 36.394531 116.371094 34.933594 C 116.980469 33.574219 117.488281 32.152344 117.882813 30.714844 C 118.5 28.480469 118.964844 26.210938 119.535156 23.964844 C 119.722656 23.21875 119.757813 22.285156 121.035156 22.195313 C 121.210938 22.925781 121.382813 23.644531 121.550781 24.363281 C 122.089844 26.6875 122.535156 29.03125 123.183594 31.324219 C 123.8125 33.53125 124.90625 35.339844 127.660156 35.3125 C 128.226563 35.308594 128.804688 35.777344 129.363281 36.023438 C 128.964844 37.851563 127.558594 38.503906 126.589844 39.507813 C 124.914063 41.25 125.261719 43.148438 127.515625 43.992188 C 128.460938 44.34375 129.503906 44.433594 130.507813 44.597656 C 132.433594 44.914063 132.867188 45.851563 131.613281 47.363281 C 130.839844 48.296875 129.851563 49.058594 128.910156 49.839844 C 127.152344 51.296875 126.9375 52.183594 128.390625 53.9375 C 129.425781 55.1875 130.6875 56.257813 131.933594 57.304688 C 133.132813 58.3125 134.511719 59.101563 135.683594 60.136719 C 138.261719 62.417969 138.078125 63.71875 135.089844 65.28125 C 134.789063 65.441406 134.488281 65.605469 134.210938 65.800781 C 133.445313 66.339844 132.515625 66.753906 132.546875 68.1875 C 133.074219 68.484375 133.699219 68.84375 134.324219 69.195313 C 137.695313 71.070313 140.769531 73.320313 142.949219 76.5625 C 144.042969 78.183594 143.53125 79.15625 141.574219 79.246094 C 140.222656 79.304688 138.847656 79.179688 137.5 78.996094 C 135.007813 78.660156 134.472656 80.128906 134.652344 81.835938 C 134.742188 82.6875 135.035156 83.558594 135.425781 84.328125 C 136.105469 85.660156 137.335938 86.410156 138.675781 87.003906 C 141.601563 88.300781 144.597656 89.472656 147.410156 90.988281 C 149.234375 91.96875 150.976563 93.277344 152.414063 94.769531 C 153.910156 96.328125 153.269531 98.144531 151.160156 98.628906 C 149.800781 98.9375 148.332031 98.890625 146.921875 98.816406 C 144.820313 98.703125 142.730469 98.265625 140.632813 98.261719 C 138.828125 98.257813 137.011719 98.625 135.554688 99.796875 C 135.585938 101.222656 136.3125 102.042969 137.285156 102.570313 C 138.714844 103.347656 140.167969 104.175781 141.714844 104.636719 C 146.890625 106.179688 151.464844 108.835938 155.75 112.027344 C 156.804688 112.8125 157.855469 113.105469 159.140625 113.097656 C 166.027344 113.058594 172.917969 113.089844 179.808594 113.078125 C 195.632813 113.054688 211.457031 113.019531 227.28125 112.988281 C 227.945313 112.984375 228.605469 112.929688 229.480469 112.890625 C 229.480469 111.953125 229.480469 111.152344 229.480469 110.351563 C 229.480469 92.960938 229.453125 75.5625 229.527344 58.171875 C 229.535156 56.347656 228.933594 55.144531 227.667969 53.9375 C 220.550781 47.175781 213.5 40.34375 206.421875 33.539063 C 199.640625 27.019531 192.820313 20.535156 186.09375 13.960938 C 185.007813 12.898438 183.9375 12.550781 182.484375 12.550781 C 141.488281 12.578125 100.492188 12.574219 59.496094 12.574219 C 59.222656 12.574219 58.949219 12.597656 58.675781 12.570313 C 57.714844 12.464844 57.035156 12.875 56.34375 13.539063 C 42.207031 27.167969 28.054688 40.78125 13.867188 54.355469 C 12.949219 55.238281 12.546875 56.085938 12.550781 57.355469 C 12.578125 97.605469 12.578125 137.851563 12.546875 178.097656 C 12.546875 179.367188 12.941406 180.246094 13.828125 181.132813 C 25.699219 192.992188 37.550781 204.871094 49.359375 216.792969 C 50.367188 217.804688 51.371094 218.164063 52.769531 218.15625 C 62.25 218.101563 71.734375 218.015625 81.210938 218.183594 C 84.789063 218.246094 88 217.4375 91.269531 216.117188 C 96 214.210938 96.300781 210.089844 95.9375 205.519531 C 95.925781 205.363281 95.683594 205.222656 95.757813 205.304688 Z M 235.886719 119.484375 C 211.996094 119.484375 188.476563 119.484375 164.660156 119.484375 C 165.925781 121.144531 167.070313 122.539063 168.085938 124.027344 C 168.609375 124.796875 169.085938 125.695313 169.25 126.59375 C 169.601563 128.535156 168.035156 129.785156 166.242188 128.980469 C 164.191406 128.058594 162.050781 127.847656 159.871094 127.726563 C 153.035156 127.347656 146.277344 126.621094 140.050781 123.429688 C 139.660156 123.234375 139.15625 123.265625 138.632813 123.179688 C 137.503906 125.199219 138.125 127.007813 139.085938 128.667969 C 141.082031 132.121094 143.5625 135.273438 146.800781 137.585938 C 150.949219 140.546875 155.351563 143.167969 159.699219 145.84375 C 160.328125 146.230469 161.265625 146.214844 162.0625 146.21875 C 172.019531 146.242188 181.980469 146.261719 191.9375 146.203125 C 193.417969 146.195313 194.46875 146.609375 195.523438 147.671875 C 208.464844 160.679688 221.4375 173.652344 234.445313 186.59375 C 235.5 187.640625 235.921875 188.683594 235.917969 190.167969 C 235.878906 230.140625 235.878906 270.109375 235.925781 310.082031 C 235.929688 311.679688 235.394531 312.738281 234.292969 313.792969 C 225.566406 322.132813 216.886719 330.511719 208.1875 338.878906 C 201.703125 345.117188 195.199219 351.339844 188.742188 357.605469 C 187.746094 358.570313 186.71875 358.960938 185.3125 358.960938 C 142.476563 358.921875 99.640625 358.917969 56.800781 358.96875 C 55.214844 358.96875 54.113281 358.449219 53.039063 357.40625 C 47.175781 351.699219 41.289063 346.019531 35.398438 340.34375 C 26.117188 331.402344 16.839844 322.457031 7.527344 313.554688 C 6.515625 312.585938 6.074219 311.609375 6.082031 310.183594 C 6.144531 291.496094 6.144531 272.804688 6.164063 254.117188 C 6.164063 253.449219 6.164063 252.78125 6.164063 251.910156 C 29.804688 251.910156 53.242188 251.910156 76.679688 251.910156 C 76.753906 251.761719 76.828125 251.609375 76.902344 251.460938 C 76.183594 250.84375 75.394531 250.289063 74.765625 249.589844 C 74.152344 248.90625 73.503906 248.140625 73.230469 247.292969 C 72.875 246.195313 73.582031 244.992188 75.074219 244.484375 C 77.316406 243.722656 79.636719 243.136719 81.96875 242.726563 C 86.703125 241.890625 90.800781 239.984375 93.875 236.195313 C 94.429688 235.511719 94.910156 234.746094 95.316406 233.96875 C 96.222656 232.242188 95.808594 230.753906 94.125 229.796875 C 92.546875 228.898438 90.832031 228.726563 89.242188 229.652344 C 84.304688 232.523438 78.976563 233.992188 73.308594 234.300781 C 72.199219 234.359375 71.082031 234.234375 69.59375 234.179688 C 70.460938 230.371094 71.742188 227.257813 74.644531 224.539063 C 73.621094 224.488281 73.042969 224.433594 72.464844 224.433594 C 64.890625 224.425781 57.320313 224.398438 49.75 224.457031 C 48.410156 224.464844 47.472656 224.050781 46.535156 223.109375 C 33.492188 210.011719 20.417969 196.941406 7.324219 183.894531 C 6.496094 183.066406 6.085938 182.261719 6.085938 181.054688 C 6.117188 138.695313 6.113281 96.339844 6.113281 53.980469 C 6.113281 53.640625 6.113281 53.300781 6.113281 52.855469 C 9.71875 49.378906 13.335938 45.871094 16.96875 42.382813 C 25.324219 34.347656 33.683594 26.320313 42.039063 18.289063 C 45.773438 14.699219 49.527344 11.125 53.21875 7.492188 C 54.261719 6.46875 55.355469 6.078125 56.835938 6.078125 C 99.605469 6.117188 142.371094 6.121094 185.140625 6.078125 C 186.710938 6.074219 187.800781 6.566406 188.898438 7.625 C 204.058594 22.257813 219.242188 36.867188 234.449219 51.449219 C 235.460938 52.414063 235.921875 53.394531 235.917969 54.820313 C 235.875 75.621094 235.886719 96.425781 235.886719 117.230469 C 235.886719 117.898438 235.886719 118.5625 235.886719 119.484375 "/>
<path style=" stroke:none;fill-rule:nonzero;fill:rgb(60.398865%,10.598755%,11.799622%);fill-opacity:1;" d="M 95.757813 205.304688 C 95.683594 205.222656 95.925781 205.363281 95.9375 205.519531 C 96.300781 210.089844 96 214.210938 91.269531 216.117188 C 88 217.4375 84.789063 218.246094 81.210938 218.183594 C 71.734375 218.015625 62.25 218.101563 52.769531 218.15625 C 51.371094 218.164063 50.367188 217.804688 49.359375 216.792969 C 37.550781 204.871094 25.699219 192.992188 13.828125 181.132813 C 12.941406 180.246094 12.546875 179.367188 12.546875 178.097656 C 12.578125 137.851563 12.578125 97.605469 12.550781 57.355469 C 12.546875 56.085938 12.949219 55.238281 13.867188 54.355469 C 28.054688 40.78125 42.207031 27.167969 56.34375 13.539063 C 57.035156 12.875 57.714844 12.464844 58.675781 12.570313 C 58.949219 12.597656 59.222656 12.574219 59.496094 12.574219 C 100.492188 12.574219 141.488281 12.578125 182.484375 12.550781 C 183.9375 12.550781 185.007813 12.898438 186.09375 13.960938 C 192.820313 20.535156 199.640625 27.019531 206.421875 33.539063 C 213.5 40.34375 220.550781 47.175781 227.667969 53.9375 C 228.933594 55.144531 229.535156 56.347656 229.527344 58.171875 C 229.453125 75.5625 229.480469 92.960938 229.480469 110.351563 C 229.480469 111.152344 229.480469 111.953125 229.480469 112.890625 C 228.605469 112.929688 227.945313 112.984375 227.28125 112.988281 C 211.457031 113.019531 195.632813 113.054688 179.808594 113.078125 C 172.917969 113.089844 166.027344 113.058594 159.140625 113.097656 C 157.855469 113.105469 156.804688 112.8125 155.75 112.027344 C 151.464844 108.835938 146.890625 106.179688 141.714844 104.636719 C 140.167969 104.175781 138.714844 103.347656 137.285156 102.570313 C 136.3125 102.042969 135.585938 101.222656 135.554688 99.796875 C 137.011719 98.625 138.828125 98.257813 140.632813 98.261719 C 142.730469 98.265625 144.820313 98.703125 146.921875 98.816406 C 148.332031 98.890625 149.800781 98.9375 151.160156 98.628906 C 153.269531 98.144531 153.910156 96.328125 152.414063 94.769531 C 150.976563 93.277344 149.234375 91.96875 147.410156 90.988281 C 144.597656 89.472656 141.601563 88.300781 138.675781 87.003906 C 137.335938 86.410156 136.105469 85.660156 135.425781 84.328125 C 135.035156 83.558594 134.742188 82.6875 134.652344 81.835938 C 134.472656 80.128906 135.007813 78.660156 137.5 78.996094 C 138.847656 79.179688 140.222656 79.304688 141.574219 79.246094 C 143.53125 79.15625 144.042969 78.183594 142.949219 76.5625 C 140.769531 73.320313 137.695313 71.070313 134.324219 69.195313 C 133.699219 68.84375 133.074219 68.484375 132.546875 68.1875 C 132.515625 66.753906 133.445313 66.339844 134.210938 65.800781 C 134.488281 65.605469 134.789063 65.441406 135.089844 65.28125 C 138.078125 63.71875 138.261719 62.417969 135.683594 60.136719 C 134.511719 59.101563 133.132813 58.3125 131.933594 57.304688 C 130.6875 56.257813 129.425781 55.1875 128.390625 53.9375 C 126.9375 52.183594 127.152344 51.296875 128.910156 49.839844 C 129.851563 49.058594 130.839844 48.296875 131.613281 47.363281 C 132.867188 45.851563 132.433594 44.914063 130.507813 44.597656 C 129.503906 44.433594 128.460938 44.34375 127.515625 43.992188 C 125.261719 43.148438 124.914063 41.25 126.589844 39.507813 C 127.558594 38.503906 128.964844 37.851563 129.363281 36.023438 C 128.804688 35.777344 128.226563 35.308594 127.660156 35.3125 C 124.90625 35.339844 123.8125 33.53125 123.183594 31.324219 C 122.535156 29.03125 122.089844 26.6875 121.550781 24.363281 C 121.382813 23.644531 121.210938 22.925781 121.035156 22.195313 C 119.757813 22.285156 119.722656 23.21875 119.535156 23.964844 C 118.964844 26.210938 118.5 28.480469 117.882813 30.714844 C 117.488281 32.152344 116.980469 33.574219 116.371094 34.933594 C 115.714844 36.394531 114.582031 37.285156 112.855469 37.296875 C 112.230469 37.300781 111.613281 37.605469 111.085938 37.746094 C 110.820313 39.0625 111.570313 39.636719 112.222656 40.203125 C 113.144531 41.011719 114.160156 41.714844 115.085938 42.519531 C 116.363281 43.636719 116.519531 44.445313 115.308594 45.617188 C 113.601563 47.265625 111.71875 48.738281 109.855469 50.21875 C 108.417969 51.363281 106.839844 52.335938 105.441406 53.519531 C 104.945313 53.9375 104.425781 54.878906 104.582031 55.367188 C 104.746094 55.882813 105.667969 56.347656 106.328125 56.472656 C 107.726563 56.738281 109.171875 56.746094 110.59375 56.898438 C 111.746094 57.019531 112.875 57.246094 113.65625 58.261719 C 113.316406 59.867188 112.089844 60.324219 110.84375 60.671875 C 106.925781 61.761719 103.664063 63.929688 100.789063 66.722656 C 100.011719 67.476563 99.292969 68.324219 98.71875 69.238281 C 98.359375 69.8125 98.320313 70.585938 98.054688 71.589844 C 99.25 71.757813 100.15625 71.972656 101.070313 71.984375 C 102.085938 71.996094 103.105469 71.808594 104.121094 71.730469 C 106.378906 71.558594 107.40625 72.660156 107.039063 74.925781 C 106.699219 77.035156 105.476563 78.53125 103.554688 79.417969 C 101.394531 80.421875 99.207031 81.371094 97.023438 82.328125 C 94.863281 83.277344 93 84.644531 91.445313 86.394531 C 90.898438 87.003906 90.585938 87.824219 89.996094 88.84375 C 91.121094 89.167969 91.863281 89.535156 92.621094 89.570313 C 94.933594 89.671875 97.261719 89.777344 99.570313 89.621094 C 100.894531 89.53125 102.171875 88.878906 103.492188 88.585938 C 104.605469 88.339844 105.78125 88.007813 106.878906 88.140625 C 109.386719 88.445313 110.34375 90.613281 108.796875 92.601563 C 107.773438 93.914063 106.480469 95.164063 105.046875 95.988281 C 100.738281 98.464844 96.242188 100.609375 91.925781 103.078125 C 86.300781 106.296875 80.847656 109.800781 76.007813 114.15625 C 75.050781 115.019531 74.140625 115.964844 73.378906 117 C 72.875 117.683594 72.503906 118.570313 72.382813 119.410156 C 72.113281 121.296875 73.550781 122.382813 75.335938 121.769531 C 75.589844 121.679688 75.839844 121.566406 76.085938 121.441406 C 78.421875 120.257813 80.894531 119.996094 83.449219 120.410156 C 87.699219 121.105469 91.734375 120.050781 95.679688 118.738281 C 96.964844 118.3125 97.996094 117.117188 99.148438 116.277344 C 99.890625 115.742188 100.640625 115.214844 101.441406 114.648438 C 103.152344 116.527344 103.140625 118.5 102.511719 120.402344 C 102.03125 121.863281 101.257813 123.292969 100.335938 124.53125 C 98.128906 127.492188 95.582031 130.164063 92.433594 132.164063 C 89.445313 134.066406 86.488281 136.046875 83.363281 137.710938 C 76.871094 141.175781 73.140625 146.550781 71.820313 153.683594 C 71.285156 156.5625 70.835938 159.460938 70.476563 162.367188 C 70.3125 163.683594 70.191406 165.113281 71.472656 166.101563 C 72.835938 166.082031 73.644531 165.164063 74.308594 164.265625 C 77.566406 159.871094 82.019531 158.234375 87.316406 158.269531 C 91.484375 158.292969 95.441406 157.53125 98.863281 154.878906 C 99.679688 154.242188 100.746094 153.921875 101.539063 153.535156 C 102.847656 154.238281 102.679688 155.144531 102.511719 156.019531 C 101.964844 158.886719 100.507813 161.269531 98.238281 163.023438 C 96.640625 164.261719 94.804688 165.222656 93.011719 166.183594 C 91.273438 167.113281 89.453125 167.894531 87.660156 168.730469 C 85.433594 169.769531 83.832031 171.546875 82.246094 173.335938 C 81.484375 174.195313 81.507813 174.40625 81.738281 175.683594 C 88.488281 177.3125 94.964844 177.140625 100.835938 172.867188 C 101.109375 172.667969 101.40625 172.488281 101.707031 172.335938 C 103.5 171.414063 104.902344 172.167969 104.839844 174.207031 C 104.796875 175.597656 104.5 177.070313 103.933594 178.332031 C 103.039063 180.332031 101.625 182.007813 99.816406 183.328125 C 95.242188 186.667969 90.523438 189.761719 85.480469 192.378906 C 80.933594 194.742188 77.011719 197.871094 74.8125 202.707031 C 74.425781 203.554688 73.894531 204.425781 74.683594 205.59375 C 75.308594 205.476563 76.097656 205.503906 76.707031 205.183594 C 79.675781 203.613281 82.757813 203.808594 85.886719 204.417969 C 87.359375 204.703125 88.816406 205.140625 90.300781 205.269531 C 92.03125 205.417969 93.78125 205.304688 95.757813 205.304688 "/>
<path style=" stroke:none;fill-rule:nonzero;fill:rgb(60.398865%,10.598755%,11.799622%);fill-opacity:1;" d="M 172.03125 241.433594 C 171.183594 237.375 169.734375 234.207031 166.972656 231.804688 C 165.648438 230.652344 164.160156 229.609375 162.59375 228.832031 C 159.050781 227.085938 155.414063 225.53125 151.816406 223.90625 C 150.824219 223.457031 149.777344 223.105469 148.84375 222.5625 C 145.734375 220.753906 144.632813 216.027344 146.679688 212.625 C 147.207031 212.910156 147.871094 213.089844 148.269531 213.511719 C 151.332031 216.757813 155.089844 218.152344 159.503906 217.875 C 162.183594 217.707031 164.597656 218.246094 166.746094 220.035156 C 167.566406 220.71875 168.789063 220.925781 170.265625 221.527344 C 170.3125 220.320313 170.503906 219.53125 170.34375 218.820313 C 168.496094 210.597656 164.527344 203.855469 156.734375 199.941406 C 151.722656 197.421875 147.054688 194.367188 142.5 191.121094 C 140.457031 189.664063 138.851563 187.851563 137.675781 185.652344 C 137.230469 184.816406 136.777344 183.953125 137.308594 182.714844 C 137.910156 182.761719 138.585938 182.699219 139.175781 182.890625 C 140.53125 183.328125 141.878906 183.828125 143.175781 184.421875 C 146.328125 185.863281 149.5625 186.253906 152.945313 185.445313 C 155.296875 184.886719 157.648438 184.601563 159.953125 185.679688 C 160.191406 185.789063 160.484375 185.8125 160.753906 185.828125 C 162.628906 185.945313 163.484375 184.753906 162.578125 183.125 C 162.089844 182.25 161.382813 181.464844 160.648438 180.769531 C 157.644531 177.925781 154.101563 175.910156 150.335938 174.242188 C 148.78125 173.550781 147.253906 172.789063 145.757813 171.988281 C 142.609375 170.296875 140.578125 167.625 139.273438 164.359375 C 138.863281 163.34375 138.472656 162.28125 139.445313 161.320313 C 140.425781 160.347656 141.582031 159.824219 142.964844 160.15625 C 143.820313 160.363281 144.636719 160.734375 145.46875 161.035156 C 150.398438 162.808594 155.332031 164.566406 160.25 166.371094 C 161.332031 166.765625 162.335938 167.367188 163.40625 167.800781 C 164.785156 168.363281 166.15625 169.03125 167.597656 169.328125 C 169.851563 169.792969 171.03125 168.664063 170.753906 166.382813 C 170.238281 162.179688 169.433594 158.035156 167.554688 154.179688 C 167.355469 153.765625 167.207031 153.324219 166.984375 152.78125 C 167.660156 152.746094 168.191406 152.699219 168.722656 152.699219 C 175.679688 152.695313 182.636719 152.722656 189.59375 152.671875 C 190.777344 152.664063 191.609375 153.015625 192.449219 153.859375 C 204.347656 165.78125 216.273438 177.679688 228.222656 189.554688 C 229.113281 190.433594 229.511719 191.308594 229.507813 192.582031 C 229.476563 230.914063 229.476563 269.246094 229.507813 307.574219 C 229.511719 308.851563 229.132813 309.738281 228.222656 310.605469 C 218.761719 319.648438 209.332031 328.726563 199.898438 337.800781 C 195.179688 342.335938 190.457031 346.863281 185.765625 351.425781 C 185.039063 352.128906 184.339844 352.5625 183.273438 352.539063 C 179.320313 352.457031 175.359375 352.589844 171.414063 352.402344 C 165.496094 352.117188 160.089844 350.117188 155.121094 346.949219 C 154.160156 346.339844 153.296875 345.511719 152.550781 344.640625 C 149.996094 341.652344 147.066406 339.128906 143.585938 337.296875 C 135.359375 332.960938 131.722656 325.789063 131.015625 316.871094 C 130.78125 313.886719 130.871094 310.875 130.867188 307.878906 C 130.847656 299.554688 130.851563 291.234375 130.867188 282.914063 C 130.871094 281.648438 130.582031 280.113281 132.054688 279.496094 C 133.34375 278.957031 134.363281 279.984375 135.308594 280.730469 C 138.101563 282.945313 141.253906 283.980469 144.816406 283.777344 C 146.585938 283.675781 148.371094 283.726563 150.121094 283.484375 C 153.332031 283.042969 156.441406 283.457031 159.304688 284.800781 C 162.6875 286.386719 165.941406 288.257813 169.171875 290.144531 C 171.757813 291.652344 174.191406 293.425781 176.761719 294.96875 C 177.855469 295.625 179.082031 296.132813 180.316406 296.464844 C 181.867188 296.878906 182.902344 296.148438 183.003906 294.554688 C 183.097656 293.140625 183.144531 291.628906 182.75 290.296875 C 181.433594 285.863281 180.027344 281.445313 178.417969 277.109375 C 177.421875 274.425781 175.296875 272.492188 172.996094 270.851563 C 171.503906 269.78125 169.882813 268.898438 168.34375 267.894531 C 167.550781 267.375 166.710938 266.863281 166.082031 266.179688 C 164.160156 264.085938 164.253906 262.160156 166.152344 260.03125 C 166.914063 259.175781 167.660156 258.253906 168.191406 257.242188 C 169.503906 254.75 168.828125 252.628906 166.1875 251.574219 C 164.3125 250.828125 162.277344 250.390625 160.273438 250.089844 C 155.894531 249.433594 151.964844 247.890625 148.859375 244.667969 C 147.835938 243.601563 146.992188 242.324219 146.234375 241.046875 C 145.417969 239.660156 145.804688 238.265625 147.15625 237.328125 C 148.867188 236.140625 150.722656 235.925781 152.546875 236.996094 C 157.476563 239.898438 162.835938 241.273438 168.496094 241.574219 C 169.546875 241.628906 170.605469 241.496094 172.03125 241.433594 "/>
<path style=" stroke:none;fill-rule:nonzero;fill:rgb(60.398865%,10.598755%,11.799622%);fill-opacity:1;" d="M 12.75 258.398438 C 34.238281 258.398438 55.605469 258.398438 76.972656 258.398438 C 77.019531 258.496094 77.0625 258.589844 77.109375 258.6875 C 76.363281 259.082031 75.628906 259.503906 74.863281 259.871094 C 71.144531 261.648438 67.679688 263.773438 65.003906 266.992188 C 62.476563 270.03125 58.757813 281.015625 58.914063 284.972656 C 58.933594 285.378906 58.933594 285.800781 59.046875 286.1875 C 59.351563 287.253906 59.738281 288.289063 60.941406 288.664063 C 62.191406 289.050781 62.996094 288.320313 63.78125 287.511719 C 69.570313 281.523438 76.71875 277.800781 84.578125 275.441406 C 86.878906 274.75 89.441406 274.96875 91.863281 274.640625 C 93.882813 274.367188 95.902344 274.007813 97.871094 273.5 C 100.289063 272.878906 102.339844 271.5625 104.097656 269.753906 C 105.183594 268.632813 106.375 267.59375 107.609375 266.632813 C 108.386719 266.027344 109.265625 265.410156 110.640625 265.789063 C 110.722656 266.390625 110.882813 267.03125 110.878906 267.667969 C 110.859375 280.21875 110.882813 292.765625 110.75 305.3125 C 110.707031 309.253906 110.398438 313.207031 109.335938 317.054688 C 108.589844 319.746094 107.410156 322.117188 105.199219 323.9375 C 103.621094 325.238281 102.167969 326.683594 100.652344 328.054688 C 97.441406 330.957031 94.738281 334.253906 92.527344 337.984375 C 90.582031 341.277344 88.347656 344.371094 85.453125 346.933594 C 81.402344 350.507813 76.671875 352.347656 71.28125 352.417969 C 67.121094 352.472656 62.960938 352.398438 58.796875 352.449219 C 57.757813 352.464844 57.03125 352.128906 56.285156 351.40625 C 47.375 342.777344 38.429688 334.175781 29.488281 325.574219 C 24.476563 320.757813 19.472656 315.925781 14.410156 311.164063 C 13.140625 309.972656 12.515625 308.765625 12.527344 306.933594 C 12.636719 291.386719 12.632813 275.835938 12.667969 260.285156 C 12.667969 259.6875 12.71875 259.09375 12.75 258.398438 "/>
</g>
</svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Bayesian Embedding (BEMB)
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              API Reference BEMB
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Bayesian Embedding (BEMB)" class="md-nav__button md-logo" aria-label="Bayesian Embedding (BEMB)" data-md-component="logo">
      
  
  <?xml version="1.0" encoding="UTF-8"?>
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="241.9pt" height="365pt" viewBox="0 0 241.9 365" version="1.1">
<defs>
<clipPath id="clip1">
  <path d="M 0 0 L 241.898438 0 L 241.898438 365 L 0 365 Z M 0 0 "/>
</clipPath>
</defs>
<g id="surface1">
<g clip-path="url(#clip1)" clip-rule="nonzero">
<path style=" stroke:none;fill-rule:nonzero;fill:rgb(60.398865%,10.598755%,11.799622%);fill-opacity:1;" d="M 235.886719 119.484375 C 235.886719 118.5625 235.886719 117.898438 235.886719 117.230469 C 235.886719 96.425781 235.875 75.621094 235.917969 54.820313 C 235.921875 53.394531 235.460938 52.414063 234.449219 51.449219 C 219.242188 36.867188 204.058594 22.257813 188.898438 7.625 C 187.800781 6.566406 186.710938 6.074219 185.140625 6.078125 C 142.371094 6.121094 99.605469 6.117188 56.835938 6.078125 C 55.355469 6.078125 54.261719 6.46875 53.21875 7.492188 C 49.527344 11.125 45.773438 14.699219 42.039063 18.289063 C 33.683594 26.320313 25.324219 34.347656 16.96875 42.382813 C 13.335938 45.871094 9.71875 49.378906 6.113281 52.855469 C 6.113281 53.300781 6.113281 53.640625 6.113281 53.980469 C 6.113281 96.339844 6.117188 138.695313 6.085938 181.054688 C 6.085938 182.261719 6.496094 183.066406 7.324219 183.894531 C 20.417969 196.941406 33.492188 210.011719 46.535156 223.109375 C 47.472656 224.050781 48.410156 224.464844 49.75 224.457031 C 57.320313 224.398438 64.890625 224.425781 72.464844 224.433594 C 73.042969 224.433594 73.621094 224.488281 74.644531 224.539063 C 71.742188 227.257813 70.460938 230.371094 69.59375 234.179688 C 71.082031 234.234375 72.199219 234.359375 73.308594 234.300781 C 78.976563 233.992188 84.304688 232.523438 89.242188 229.652344 C 90.832031 228.726563 92.546875 228.898438 94.125 229.796875 C 95.808594 230.753906 96.222656 232.242188 95.316406 233.96875 C 94.910156 234.746094 94.429688 235.511719 93.875 236.195313 C 90.800781 239.984375 86.703125 241.890625 81.96875 242.726563 C 79.636719 243.136719 77.316406 243.722656 75.074219 244.484375 C 73.582031 244.992188 72.875 246.195313 73.230469 247.292969 C 73.503906 248.140625 74.152344 248.90625 74.765625 249.589844 C 75.394531 250.289063 76.183594 250.84375 76.902344 251.460938 C 76.828125 251.609375 76.753906 251.761719 76.679688 251.910156 C 53.242188 251.910156 29.804688 251.910156 6.164063 251.910156 C 6.164063 252.78125 6.164063 253.449219 6.164063 254.117188 C 6.144531 272.804688 6.144531 291.496094 6.082031 310.183594 C 6.074219 311.609375 6.515625 312.585938 7.527344 313.554688 C 16.839844 322.457031 26.117188 331.402344 35.398438 340.34375 C 41.289063 346.019531 47.175781 351.699219 53.039063 357.40625 C 54.113281 358.449219 55.214844 358.96875 56.800781 358.96875 C 99.640625 358.917969 142.476563 358.921875 185.3125 358.960938 C 186.71875 358.960938 187.746094 358.570313 188.742188 357.605469 C 195.199219 351.339844 201.703125 345.117188 208.1875 338.878906 C 216.886719 330.511719 225.566406 322.132813 234.292969 313.792969 C 235.394531 312.738281 235.929688 311.679688 235.925781 310.082031 C 235.878906 270.109375 235.878906 230.140625 235.917969 190.167969 C 235.921875 188.683594 235.5 187.640625 234.445313 186.59375 C 221.4375 173.652344 208.464844 160.679688 195.523438 147.671875 C 194.46875 146.609375 193.417969 146.195313 191.9375 146.203125 C 181.980469 146.261719 172.019531 146.242188 162.0625 146.21875 C 161.265625 146.214844 160.328125 146.230469 159.699219 145.84375 C 155.351563 143.167969 150.949219 140.546875 146.800781 137.585938 C 143.5625 135.273438 141.082031 132.121094 139.085938 128.667969 C 138.125 127.007813 137.503906 125.199219 138.632813 123.179688 C 139.15625 123.265625 139.660156 123.234375 140.050781 123.429688 C 146.277344 126.621094 153.035156 127.347656 159.871094 127.726563 C 162.050781 127.847656 164.191406 128.058594 166.242188 128.980469 C 168.035156 129.785156 169.601563 128.535156 169.25 126.59375 C 169.085938 125.695313 168.609375 124.796875 168.085938 124.027344 C 167.070313 122.539063 165.925781 121.144531 164.660156 119.484375 C 188.476563 119.484375 211.996094 119.484375 235.886719 119.484375 Z M 0 315.160156 C 0 291.964844 0 268.773438 0 245.578125 C 0.609375 245.621094 1.21875 245.703125 1.828125 245.707031 C 23.648438 245.710938 45.472656 245.710938 67.296875 245.707031 C 67.894531 245.707031 68.496094 245.648438 69.097656 245.617188 C 69.898438 243.046875 71.621094 241.488281 73.90625 240.480469 C 74.777344 240.097656 75.699219 239.824219 76.550781 239.402344 C 76.941406 239.207031 77.21875 238.773438 77.542969 238.449219 C 77.46875 238.320313 77.394531 238.191406 77.320313 238.058594 C 76.046875 238.160156 74.773438 238.320313 73.5 238.347656 C 72.214844 238.371094 70.894531 238.429688 69.648438 238.179688 C 66.917969 237.628906 65.417969 235.339844 65.773438 232.585938 C 65.847656 231.992188 65.910156 231.398438 66.003906 230.550781 C 65.113281 230.550781 64.382813 230.550781 63.648438 230.550781 C 58.261719 230.550781 52.875 230.503906 47.488281 230.578125 C 46.007813 230.601563 44.960938 230.179688 43.90625 229.117188 C 29.859375 215.003906 15.769531 200.929688 1.679688 186.855469 C 1.160156 186.335938 0.5625 185.890625 0 185.410156 C 0 140.253906 0 95.09375 0 49.933594 C 0.332031 49.714844 0.710938 49.539063 0.992188 49.265625 C 4.589844 45.828125 8.171875 42.375 11.757813 38.929688 C 22.8125 28.300781 33.875 17.683594 44.917969 7.042969 C 47.3125 4.738281 49.628906 2.351563 51.980469 0 C 97.957031 0 143.9375 0 189.914063 0 C 190.371094 0.496094 190.804688 1.023438 191.292969 1.492188 C 195.417969 5.460938 199.558594 9.414063 203.6875 13.382813 C 211.546875 20.941406 219.402344 28.507813 227.257813 36.074219 C 232.113281 40.753906 236.964844 45.441406 241.703125 50.015625 C 241.703125 75.300781 241.703125 100.425781 241.703125 125.695313 C 218.851563 125.695313 196.160156 125.695313 173.40625 125.695313 C 173.40625 126.246094 173.421875 126.648438 173.402344 127.050781 C 173.167969 131.855469 169.175781 134.410156 164.660156 132.78125 C 163.15625 132.238281 161.507813 132.0625 159.910156 131.832031 C 158.632813 131.648438 157.320313 131.703125 156.039063 131.535156 C 152.410156 131.058594 148.785156 130.523438 145.085938 130.003906 C 145.410156 130.421875 145.71875 130.84375 146.050781 131.246094 C 148.84375 134.617188 152.519531 136.839844 156.195313 139.074219 C 157.402344 139.808594 158.613281 140.144531 160.042969 140.136719 C 171.5 140.09375 182.957031 140.140625 194.414063 140.078125 C 195.976563 140.070313 197.0625 140.550781 198.15625 141.648438 C 212.15625 155.714844 226.191406 169.75 240.261719 183.746094 C 241.410156 184.890625 241.902344 186.011719 241.902344 187.652344 C 241.855469 229.324219 241.867188 270.992188 241.867188 312.664063 C 241.867188 313.410156 241.867188 314.15625 241.867188 314.941406 C 224.503906 331.652344 207.171875 348.335938 189.855469 365 C 143.90625 365 98.019531 365 52.15625 365 C 49.609375 362.539063 47.113281 360.121094 44.609375 357.707031 C 30.621094 344.226563 16.636719 330.742188 2.636719 317.273438 C 1.828125 316.496094 0.882813 315.859375 0 315.160156 "/>
</g>
<path style=" stroke:none;fill-rule:nonzero;fill:rgb(100%,100%,100%);fill-opacity:1;" d="M 12.75 258.398438 C 12.71875 259.09375 12.667969 259.6875 12.667969 260.285156 C 12.632813 275.835938 12.636719 291.386719 12.527344 306.933594 C 12.515625 308.765625 13.140625 309.972656 14.410156 311.164063 C 19.472656 315.925781 24.476563 320.757813 29.488281 325.574219 C 38.429688 334.175781 47.375 342.777344 56.285156 351.40625 C 57.03125 352.128906 57.757813 352.464844 58.796875 352.449219 C 62.960938 352.398438 67.121094 352.472656 71.28125 352.417969 C 76.671875 352.347656 81.402344 350.507813 85.453125 346.933594 C 88.347656 344.371094 90.582031 341.277344 92.527344 337.984375 C 94.738281 334.253906 97.441406 330.957031 100.652344 328.054688 C 102.167969 326.683594 103.621094 325.238281 105.199219 323.9375 C 107.410156 322.117188 108.589844 319.746094 109.335938 317.054688 C 110.398438 313.207031 110.707031 309.253906 110.75 305.3125 C 110.882813 292.765625 110.859375 280.21875 110.878906 267.667969 C 110.882813 267.03125 110.722656 266.390625 110.640625 265.789063 C 109.265625 265.410156 108.386719 266.027344 107.609375 266.632813 C 106.375 267.59375 105.183594 268.632813 104.097656 269.753906 C 102.339844 271.5625 100.289063 272.878906 97.871094 273.5 C 95.902344 274.007813 93.882813 274.367188 91.863281 274.640625 C 89.441406 274.96875 86.878906 274.75 84.578125 275.441406 C 76.71875 277.800781 69.570313 281.523438 63.78125 287.511719 C 62.996094 288.320313 62.191406 289.050781 60.941406 288.664063 C 59.738281 288.289063 59.351563 287.253906 59.046875 286.1875 C 58.933594 285.800781 58.933594 285.378906 58.914063 284.972656 C 58.757813 281.015625 62.476563 270.03125 65.003906 266.992188 C 67.679688 263.773438 71.144531 261.648438 74.863281 259.871094 C 75.628906 259.503906 76.363281 259.082031 77.109375 258.6875 C 77.0625 258.589844 77.019531 258.496094 76.972656 258.398438 C 55.605469 258.398438 34.238281 258.398438 12.75 258.398438 Z M 172.03125 241.433594 C 170.605469 241.496094 169.546875 241.628906 168.496094 241.574219 C 162.835938 241.273438 157.476563 239.898438 152.546875 236.996094 C 150.722656 235.925781 148.867188 236.140625 147.15625 237.328125 C 145.804688 238.265625 145.417969 239.660156 146.234375 241.046875 C 146.992188 242.324219 147.835938 243.601563 148.859375 244.667969 C 151.964844 247.890625 155.894531 249.433594 160.273438 250.089844 C 162.277344 250.390625 164.3125 250.828125 166.1875 251.574219 C 168.828125 252.628906 169.503906 254.75 168.191406 257.242188 C 167.660156 258.253906 166.914063 259.175781 166.152344 260.03125 C 164.253906 262.160156 164.160156 264.085938 166.082031 266.179688 C 166.710938 266.863281 167.550781 267.375 168.34375 267.894531 C 169.882813 268.898438 171.503906 269.78125 172.996094 270.851563 C 175.296875 272.492188 177.421875 274.425781 178.417969 277.109375 C 180.027344 281.445313 181.433594 285.863281 182.75 290.296875 C 183.144531 291.628906 183.097656 293.140625 183.003906 294.554688 C 182.902344 296.148438 181.867188 296.878906 180.316406 296.464844 C 179.082031 296.132813 177.855469 295.625 176.761719 294.96875 C 174.191406 293.425781 171.757813 291.652344 169.171875 290.144531 C 165.941406 288.257813 162.6875 286.386719 159.304688 284.800781 C 156.441406 283.457031 153.332031 283.042969 150.121094 283.484375 C 148.371094 283.726563 146.585938 283.675781 144.816406 283.777344 C 141.253906 283.980469 138.101563 282.945313 135.308594 280.730469 C 134.363281 279.984375 133.34375 278.957031 132.054688 279.496094 C 130.582031 280.113281 130.871094 281.648438 130.867188 282.914063 C 130.851563 291.234375 130.847656 299.554688 130.867188 307.878906 C 130.871094 310.875 130.78125 313.886719 131.015625 316.871094 C 131.722656 325.789063 135.359375 332.960938 143.585938 337.296875 C 147.066406 339.128906 149.996094 341.652344 152.550781 344.640625 C 153.296875 345.511719 154.160156 346.339844 155.121094 346.949219 C 160.089844 350.117188 165.496094 352.117188 171.414063 352.402344 C 175.359375 352.589844 179.320313 352.457031 183.273438 352.539063 C 184.339844 352.5625 185.039063 352.128906 185.765625 351.425781 C 190.457031 346.863281 195.179688 342.335938 199.898438 337.800781 C 209.332031 328.726563 218.761719 319.648438 228.222656 310.605469 C 229.132813 309.738281 229.511719 308.851563 229.507813 307.574219 C 229.476563 269.246094 229.476563 230.914063 229.507813 192.582031 C 229.511719 191.308594 229.113281 190.433594 228.222656 189.554688 C 216.273438 177.679688 204.347656 165.78125 192.449219 153.859375 C 191.609375 153.015625 190.777344 152.664063 189.59375 152.671875 C 182.636719 152.722656 175.679688 152.695313 168.722656 152.699219 C 168.191406 152.699219 167.660156 152.746094 166.984375 152.78125 C 167.207031 153.324219 167.355469 153.765625 167.554688 154.179688 C 169.433594 158.035156 170.238281 162.179688 170.753906 166.382813 C 171.03125 168.664063 169.851563 169.792969 167.597656 169.328125 C 166.15625 169.03125 164.785156 168.363281 163.40625 167.800781 C 162.335938 167.367188 161.332031 166.765625 160.25 166.371094 C 155.332031 164.566406 150.398438 162.808594 145.46875 161.035156 C 144.636719 160.734375 143.820313 160.363281 142.964844 160.15625 C 141.582031 159.824219 140.425781 160.347656 139.445313 161.320313 C 138.472656 162.28125 138.863281 163.34375 139.273438 164.359375 C 140.578125 167.625 142.609375 170.296875 145.757813 171.988281 C 147.253906 172.789063 148.78125 173.550781 150.335938 174.242188 C 154.101563 175.910156 157.644531 177.925781 160.648438 180.769531 C 161.382813 181.464844 162.089844 182.25 162.578125 183.125 C 163.484375 184.753906 162.628906 185.945313 160.753906 185.828125 C 160.484375 185.8125 160.191406 185.789063 159.953125 185.679688 C 157.648438 184.601563 155.296875 184.886719 152.945313 185.445313 C 149.5625 186.253906 146.328125 185.863281 143.175781 184.421875 C 141.878906 183.828125 140.53125 183.328125 139.175781 182.890625 C 138.585938 182.699219 137.910156 182.761719 137.308594 182.714844 C 136.777344 183.953125 137.230469 184.816406 137.675781 185.652344 C 138.851563 187.851563 140.457031 189.664063 142.5 191.121094 C 147.054688 194.367188 151.722656 197.421875 156.734375 199.941406 C 164.527344 203.855469 168.496094 210.597656 170.34375 218.820313 C 170.503906 219.53125 170.3125 220.320313 170.265625 221.527344 C 168.789063 220.925781 167.566406 220.71875 166.746094 220.035156 C 164.597656 218.246094 162.183594 217.707031 159.503906 217.875 C 155.089844 218.152344 151.332031 216.757813 148.269531 213.511719 C 147.871094 213.089844 147.207031 212.910156 146.679688 212.625 C 144.632813 216.027344 145.734375 220.753906 148.84375 222.5625 C 149.777344 223.105469 150.824219 223.457031 151.816406 223.90625 C 155.414063 225.53125 159.050781 227.085938 162.59375 228.832031 C 164.160156 229.609375 165.648438 230.652344 166.972656 231.804688 C 169.734375 234.207031 171.183594 237.375 172.03125 241.433594 Z M 95.757813 205.304688 C 93.78125 205.304688 92.03125 205.417969 90.300781 205.269531 C 88.816406 205.140625 87.359375 204.703125 85.886719 204.417969 C 82.757813 203.808594 79.675781 203.613281 76.707031 205.183594 C 76.097656 205.503906 75.308594 205.476563 74.683594 205.59375 C 73.894531 204.425781 74.425781 203.554688 74.8125 202.707031 C 77.011719 197.871094 80.933594 194.742188 85.480469 192.378906 C 90.523438 189.761719 95.242188 186.667969 99.816406 183.328125 C 101.625 182.007813 103.039063 180.332031 103.933594 178.332031 C 104.5 177.070313 104.796875 175.597656 104.839844 174.207031 C 104.902344 172.167969 103.5 171.414063 101.707031 172.335938 C 101.40625 172.488281 101.109375 172.667969 100.835938 172.867188 C 94.964844 177.140625 88.488281 177.3125 81.738281 175.683594 C 81.507813 174.40625 81.484375 174.195313 82.246094 173.335938 C 83.832031 171.546875 85.433594 169.769531 87.660156 168.730469 C 89.453125 167.894531 91.273438 167.113281 93.011719 166.183594 C 94.804688 165.222656 96.640625 164.261719 98.238281 163.023438 C 100.507813 161.269531 101.964844 158.886719 102.511719 156.019531 C 102.679688 155.144531 102.847656 154.238281 101.539063 153.535156 C 100.746094 153.921875 99.679688 154.242188 98.863281 154.878906 C 95.441406 157.53125 91.484375 158.292969 87.316406 158.269531 C 82.019531 158.234375 77.566406 159.871094 74.308594 164.265625 C 73.644531 165.164063 72.835938 166.082031 71.472656 166.101563 C 70.191406 165.113281 70.3125 163.683594 70.476563 162.367188 C 70.835938 159.460938 71.285156 156.5625 71.820313 153.683594 C 73.140625 146.550781 76.871094 141.175781 83.363281 137.710938 C 86.488281 136.046875 89.445313 134.066406 92.433594 132.164063 C 95.582031 130.164063 98.128906 127.492188 100.335938 124.53125 C 101.257813 123.292969 102.03125 121.863281 102.511719 120.402344 C 103.140625 118.5 103.152344 116.527344 101.441406 114.648438 C 100.640625 115.214844 99.890625 115.742188 99.148438 116.277344 C 97.996094 117.117188 96.964844 118.3125 95.679688 118.738281 C 91.734375 120.050781 87.699219 121.105469 83.449219 120.410156 C 80.894531 119.996094 78.421875 120.257813 76.085938 121.441406 C 75.839844 121.566406 75.589844 121.679688 75.335938 121.769531 C 73.550781 122.382813 72.113281 121.296875 72.382813 119.410156 C 72.503906 118.570313 72.875 117.683594 73.378906 117 C 74.140625 115.964844 75.050781 115.019531 76.007813 114.15625 C 80.847656 109.800781 86.300781 106.296875 91.925781 103.078125 C 96.242188 100.609375 100.738281 98.464844 105.046875 95.988281 C 106.480469 95.164063 107.773438 93.914063 108.796875 92.601563 C 110.34375 90.613281 109.386719 88.445313 106.878906 88.140625 C 105.78125 88.007813 104.605469 88.339844 103.492188 88.585938 C 102.171875 88.878906 100.894531 89.53125 99.570313 89.621094 C 97.261719 89.777344 94.933594 89.671875 92.621094 89.570313 C 91.863281 89.535156 91.121094 89.167969 89.996094 88.84375 C 90.585938 87.824219 90.898438 87.003906 91.445313 86.394531 C 93 84.644531 94.863281 83.277344 97.023438 82.328125 C 99.207031 81.371094 101.394531 80.421875 103.554688 79.417969 C 105.476563 78.53125 106.699219 77.035156 107.039063 74.925781 C 107.40625 72.660156 106.378906 71.558594 104.121094 71.730469 C 103.105469 71.808594 102.085938 71.996094 101.070313 71.984375 C 100.15625 71.972656 99.25 71.757813 98.054688 71.589844 C 98.320313 70.585938 98.359375 69.8125 98.71875 69.238281 C 99.292969 68.324219 100.011719 67.476563 100.789063 66.722656 C 103.664063 63.929688 106.925781 61.761719 110.84375 60.671875 C 112.089844 60.324219 113.316406 59.867188 113.65625 58.261719 C 112.875 57.246094 111.746094 57.019531 110.59375 56.898438 C 109.171875 56.746094 107.726563 56.738281 106.328125 56.472656 C 105.667969 56.347656 104.746094 55.882813 104.582031 55.367188 C 104.425781 54.878906 104.945313 53.9375 105.441406 53.519531 C 106.839844 52.335938 108.417969 51.363281 109.855469 50.21875 C 111.71875 48.738281 113.601563 47.265625 115.308594 45.617188 C 116.519531 44.445313 116.363281 43.636719 115.085938 42.519531 C 114.160156 41.714844 113.144531 41.011719 112.222656 40.203125 C 111.570313 39.636719 110.820313 39.0625 111.085938 37.746094 C 111.613281 37.605469 112.230469 37.300781 112.855469 37.296875 C 114.582031 37.285156 115.714844 36.394531 116.371094 34.933594 C 116.980469 33.574219 117.488281 32.152344 117.882813 30.714844 C 118.5 28.480469 118.964844 26.210938 119.535156 23.964844 C 119.722656 23.21875 119.757813 22.285156 121.035156 22.195313 C 121.210938 22.925781 121.382813 23.644531 121.550781 24.363281 C 122.089844 26.6875 122.535156 29.03125 123.183594 31.324219 C 123.8125 33.53125 124.90625 35.339844 127.660156 35.3125 C 128.226563 35.308594 128.804688 35.777344 129.363281 36.023438 C 128.964844 37.851563 127.558594 38.503906 126.589844 39.507813 C 124.914063 41.25 125.261719 43.148438 127.515625 43.992188 C 128.460938 44.34375 129.503906 44.433594 130.507813 44.597656 C 132.433594 44.914063 132.867188 45.851563 131.613281 47.363281 C 130.839844 48.296875 129.851563 49.058594 128.910156 49.839844 C 127.152344 51.296875 126.9375 52.183594 128.390625 53.9375 C 129.425781 55.1875 130.6875 56.257813 131.933594 57.304688 C 133.132813 58.3125 134.511719 59.101563 135.683594 60.136719 C 138.261719 62.417969 138.078125 63.71875 135.089844 65.28125 C 134.789063 65.441406 134.488281 65.605469 134.210938 65.800781 C 133.445313 66.339844 132.515625 66.753906 132.546875 68.1875 C 133.074219 68.484375 133.699219 68.84375 134.324219 69.195313 C 137.695313 71.070313 140.769531 73.320313 142.949219 76.5625 C 144.042969 78.183594 143.53125 79.15625 141.574219 79.246094 C 140.222656 79.304688 138.847656 79.179688 137.5 78.996094 C 135.007813 78.660156 134.472656 80.128906 134.652344 81.835938 C 134.742188 82.6875 135.035156 83.558594 135.425781 84.328125 C 136.105469 85.660156 137.335938 86.410156 138.675781 87.003906 C 141.601563 88.300781 144.597656 89.472656 147.410156 90.988281 C 149.234375 91.96875 150.976563 93.277344 152.414063 94.769531 C 153.910156 96.328125 153.269531 98.144531 151.160156 98.628906 C 149.800781 98.9375 148.332031 98.890625 146.921875 98.816406 C 144.820313 98.703125 142.730469 98.265625 140.632813 98.261719 C 138.828125 98.257813 137.011719 98.625 135.554688 99.796875 C 135.585938 101.222656 136.3125 102.042969 137.285156 102.570313 C 138.714844 103.347656 140.167969 104.175781 141.714844 104.636719 C 146.890625 106.179688 151.464844 108.835938 155.75 112.027344 C 156.804688 112.8125 157.855469 113.105469 159.140625 113.097656 C 166.027344 113.058594 172.917969 113.089844 179.808594 113.078125 C 195.632813 113.054688 211.457031 113.019531 227.28125 112.988281 C 227.945313 112.984375 228.605469 112.929688 229.480469 112.890625 C 229.480469 111.953125 229.480469 111.152344 229.480469 110.351563 C 229.480469 92.960938 229.453125 75.5625 229.527344 58.171875 C 229.535156 56.347656 228.933594 55.144531 227.667969 53.9375 C 220.550781 47.175781 213.5 40.34375 206.421875 33.539063 C 199.640625 27.019531 192.820313 20.535156 186.09375 13.960938 C 185.007813 12.898438 183.9375 12.550781 182.484375 12.550781 C 141.488281 12.578125 100.492188 12.574219 59.496094 12.574219 C 59.222656 12.574219 58.949219 12.597656 58.675781 12.570313 C 57.714844 12.464844 57.035156 12.875 56.34375 13.539063 C 42.207031 27.167969 28.054688 40.78125 13.867188 54.355469 C 12.949219 55.238281 12.546875 56.085938 12.550781 57.355469 C 12.578125 97.605469 12.578125 137.851563 12.546875 178.097656 C 12.546875 179.367188 12.941406 180.246094 13.828125 181.132813 C 25.699219 192.992188 37.550781 204.871094 49.359375 216.792969 C 50.367188 217.804688 51.371094 218.164063 52.769531 218.15625 C 62.25 218.101563 71.734375 218.015625 81.210938 218.183594 C 84.789063 218.246094 88 217.4375 91.269531 216.117188 C 96 214.210938 96.300781 210.089844 95.9375 205.519531 C 95.925781 205.363281 95.683594 205.222656 95.757813 205.304688 Z M 235.886719 119.484375 C 211.996094 119.484375 188.476563 119.484375 164.660156 119.484375 C 165.925781 121.144531 167.070313 122.539063 168.085938 124.027344 C 168.609375 124.796875 169.085938 125.695313 169.25 126.59375 C 169.601563 128.535156 168.035156 129.785156 166.242188 128.980469 C 164.191406 128.058594 162.050781 127.847656 159.871094 127.726563 C 153.035156 127.347656 146.277344 126.621094 140.050781 123.429688 C 139.660156 123.234375 139.15625 123.265625 138.632813 123.179688 C 137.503906 125.199219 138.125 127.007813 139.085938 128.667969 C 141.082031 132.121094 143.5625 135.273438 146.800781 137.585938 C 150.949219 140.546875 155.351563 143.167969 159.699219 145.84375 C 160.328125 146.230469 161.265625 146.214844 162.0625 146.21875 C 172.019531 146.242188 181.980469 146.261719 191.9375 146.203125 C 193.417969 146.195313 194.46875 146.609375 195.523438 147.671875 C 208.464844 160.679688 221.4375 173.652344 234.445313 186.59375 C 235.5 187.640625 235.921875 188.683594 235.917969 190.167969 C 235.878906 230.140625 235.878906 270.109375 235.925781 310.082031 C 235.929688 311.679688 235.394531 312.738281 234.292969 313.792969 C 225.566406 322.132813 216.886719 330.511719 208.1875 338.878906 C 201.703125 345.117188 195.199219 351.339844 188.742188 357.605469 C 187.746094 358.570313 186.71875 358.960938 185.3125 358.960938 C 142.476563 358.921875 99.640625 358.917969 56.800781 358.96875 C 55.214844 358.96875 54.113281 358.449219 53.039063 357.40625 C 47.175781 351.699219 41.289063 346.019531 35.398438 340.34375 C 26.117188 331.402344 16.839844 322.457031 7.527344 313.554688 C 6.515625 312.585938 6.074219 311.609375 6.082031 310.183594 C 6.144531 291.496094 6.144531 272.804688 6.164063 254.117188 C 6.164063 253.449219 6.164063 252.78125 6.164063 251.910156 C 29.804688 251.910156 53.242188 251.910156 76.679688 251.910156 C 76.753906 251.761719 76.828125 251.609375 76.902344 251.460938 C 76.183594 250.84375 75.394531 250.289063 74.765625 249.589844 C 74.152344 248.90625 73.503906 248.140625 73.230469 247.292969 C 72.875 246.195313 73.582031 244.992188 75.074219 244.484375 C 77.316406 243.722656 79.636719 243.136719 81.96875 242.726563 C 86.703125 241.890625 90.800781 239.984375 93.875 236.195313 C 94.429688 235.511719 94.910156 234.746094 95.316406 233.96875 C 96.222656 232.242188 95.808594 230.753906 94.125 229.796875 C 92.546875 228.898438 90.832031 228.726563 89.242188 229.652344 C 84.304688 232.523438 78.976563 233.992188 73.308594 234.300781 C 72.199219 234.359375 71.082031 234.234375 69.59375 234.179688 C 70.460938 230.371094 71.742188 227.257813 74.644531 224.539063 C 73.621094 224.488281 73.042969 224.433594 72.464844 224.433594 C 64.890625 224.425781 57.320313 224.398438 49.75 224.457031 C 48.410156 224.464844 47.472656 224.050781 46.535156 223.109375 C 33.492188 210.011719 20.417969 196.941406 7.324219 183.894531 C 6.496094 183.066406 6.085938 182.261719 6.085938 181.054688 C 6.117188 138.695313 6.113281 96.339844 6.113281 53.980469 C 6.113281 53.640625 6.113281 53.300781 6.113281 52.855469 C 9.71875 49.378906 13.335938 45.871094 16.96875 42.382813 C 25.324219 34.347656 33.683594 26.320313 42.039063 18.289063 C 45.773438 14.699219 49.527344 11.125 53.21875 7.492188 C 54.261719 6.46875 55.355469 6.078125 56.835938 6.078125 C 99.605469 6.117188 142.371094 6.121094 185.140625 6.078125 C 186.710938 6.074219 187.800781 6.566406 188.898438 7.625 C 204.058594 22.257813 219.242188 36.867188 234.449219 51.449219 C 235.460938 52.414063 235.921875 53.394531 235.917969 54.820313 C 235.875 75.621094 235.886719 96.425781 235.886719 117.230469 C 235.886719 117.898438 235.886719 118.5625 235.886719 119.484375 "/>
<path style=" stroke:none;fill-rule:nonzero;fill:rgb(60.398865%,10.598755%,11.799622%);fill-opacity:1;" d="M 95.757813 205.304688 C 95.683594 205.222656 95.925781 205.363281 95.9375 205.519531 C 96.300781 210.089844 96 214.210938 91.269531 216.117188 C 88 217.4375 84.789063 218.246094 81.210938 218.183594 C 71.734375 218.015625 62.25 218.101563 52.769531 218.15625 C 51.371094 218.164063 50.367188 217.804688 49.359375 216.792969 C 37.550781 204.871094 25.699219 192.992188 13.828125 181.132813 C 12.941406 180.246094 12.546875 179.367188 12.546875 178.097656 C 12.578125 137.851563 12.578125 97.605469 12.550781 57.355469 C 12.546875 56.085938 12.949219 55.238281 13.867188 54.355469 C 28.054688 40.78125 42.207031 27.167969 56.34375 13.539063 C 57.035156 12.875 57.714844 12.464844 58.675781 12.570313 C 58.949219 12.597656 59.222656 12.574219 59.496094 12.574219 C 100.492188 12.574219 141.488281 12.578125 182.484375 12.550781 C 183.9375 12.550781 185.007813 12.898438 186.09375 13.960938 C 192.820313 20.535156 199.640625 27.019531 206.421875 33.539063 C 213.5 40.34375 220.550781 47.175781 227.667969 53.9375 C 228.933594 55.144531 229.535156 56.347656 229.527344 58.171875 C 229.453125 75.5625 229.480469 92.960938 229.480469 110.351563 C 229.480469 111.152344 229.480469 111.953125 229.480469 112.890625 C 228.605469 112.929688 227.945313 112.984375 227.28125 112.988281 C 211.457031 113.019531 195.632813 113.054688 179.808594 113.078125 C 172.917969 113.089844 166.027344 113.058594 159.140625 113.097656 C 157.855469 113.105469 156.804688 112.8125 155.75 112.027344 C 151.464844 108.835938 146.890625 106.179688 141.714844 104.636719 C 140.167969 104.175781 138.714844 103.347656 137.285156 102.570313 C 136.3125 102.042969 135.585938 101.222656 135.554688 99.796875 C 137.011719 98.625 138.828125 98.257813 140.632813 98.261719 C 142.730469 98.265625 144.820313 98.703125 146.921875 98.816406 C 148.332031 98.890625 149.800781 98.9375 151.160156 98.628906 C 153.269531 98.144531 153.910156 96.328125 152.414063 94.769531 C 150.976563 93.277344 149.234375 91.96875 147.410156 90.988281 C 144.597656 89.472656 141.601563 88.300781 138.675781 87.003906 C 137.335938 86.410156 136.105469 85.660156 135.425781 84.328125 C 135.035156 83.558594 134.742188 82.6875 134.652344 81.835938 C 134.472656 80.128906 135.007813 78.660156 137.5 78.996094 C 138.847656 79.179688 140.222656 79.304688 141.574219 79.246094 C 143.53125 79.15625 144.042969 78.183594 142.949219 76.5625 C 140.769531 73.320313 137.695313 71.070313 134.324219 69.195313 C 133.699219 68.84375 133.074219 68.484375 132.546875 68.1875 C 132.515625 66.753906 133.445313 66.339844 134.210938 65.800781 C 134.488281 65.605469 134.789063 65.441406 135.089844 65.28125 C 138.078125 63.71875 138.261719 62.417969 135.683594 60.136719 C 134.511719 59.101563 133.132813 58.3125 131.933594 57.304688 C 130.6875 56.257813 129.425781 55.1875 128.390625 53.9375 C 126.9375 52.183594 127.152344 51.296875 128.910156 49.839844 C 129.851563 49.058594 130.839844 48.296875 131.613281 47.363281 C 132.867188 45.851563 132.433594 44.914063 130.507813 44.597656 C 129.503906 44.433594 128.460938 44.34375 127.515625 43.992188 C 125.261719 43.148438 124.914063 41.25 126.589844 39.507813 C 127.558594 38.503906 128.964844 37.851563 129.363281 36.023438 C 128.804688 35.777344 128.226563 35.308594 127.660156 35.3125 C 124.90625 35.339844 123.8125 33.53125 123.183594 31.324219 C 122.535156 29.03125 122.089844 26.6875 121.550781 24.363281 C 121.382813 23.644531 121.210938 22.925781 121.035156 22.195313 C 119.757813 22.285156 119.722656 23.21875 119.535156 23.964844 C 118.964844 26.210938 118.5 28.480469 117.882813 30.714844 C 117.488281 32.152344 116.980469 33.574219 116.371094 34.933594 C 115.714844 36.394531 114.582031 37.285156 112.855469 37.296875 C 112.230469 37.300781 111.613281 37.605469 111.085938 37.746094 C 110.820313 39.0625 111.570313 39.636719 112.222656 40.203125 C 113.144531 41.011719 114.160156 41.714844 115.085938 42.519531 C 116.363281 43.636719 116.519531 44.445313 115.308594 45.617188 C 113.601563 47.265625 111.71875 48.738281 109.855469 50.21875 C 108.417969 51.363281 106.839844 52.335938 105.441406 53.519531 C 104.945313 53.9375 104.425781 54.878906 104.582031 55.367188 C 104.746094 55.882813 105.667969 56.347656 106.328125 56.472656 C 107.726563 56.738281 109.171875 56.746094 110.59375 56.898438 C 111.746094 57.019531 112.875 57.246094 113.65625 58.261719 C 113.316406 59.867188 112.089844 60.324219 110.84375 60.671875 C 106.925781 61.761719 103.664063 63.929688 100.789063 66.722656 C 100.011719 67.476563 99.292969 68.324219 98.71875 69.238281 C 98.359375 69.8125 98.320313 70.585938 98.054688 71.589844 C 99.25 71.757813 100.15625 71.972656 101.070313 71.984375 C 102.085938 71.996094 103.105469 71.808594 104.121094 71.730469 C 106.378906 71.558594 107.40625 72.660156 107.039063 74.925781 C 106.699219 77.035156 105.476563 78.53125 103.554688 79.417969 C 101.394531 80.421875 99.207031 81.371094 97.023438 82.328125 C 94.863281 83.277344 93 84.644531 91.445313 86.394531 C 90.898438 87.003906 90.585938 87.824219 89.996094 88.84375 C 91.121094 89.167969 91.863281 89.535156 92.621094 89.570313 C 94.933594 89.671875 97.261719 89.777344 99.570313 89.621094 C 100.894531 89.53125 102.171875 88.878906 103.492188 88.585938 C 104.605469 88.339844 105.78125 88.007813 106.878906 88.140625 C 109.386719 88.445313 110.34375 90.613281 108.796875 92.601563 C 107.773438 93.914063 106.480469 95.164063 105.046875 95.988281 C 100.738281 98.464844 96.242188 100.609375 91.925781 103.078125 C 86.300781 106.296875 80.847656 109.800781 76.007813 114.15625 C 75.050781 115.019531 74.140625 115.964844 73.378906 117 C 72.875 117.683594 72.503906 118.570313 72.382813 119.410156 C 72.113281 121.296875 73.550781 122.382813 75.335938 121.769531 C 75.589844 121.679688 75.839844 121.566406 76.085938 121.441406 C 78.421875 120.257813 80.894531 119.996094 83.449219 120.410156 C 87.699219 121.105469 91.734375 120.050781 95.679688 118.738281 C 96.964844 118.3125 97.996094 117.117188 99.148438 116.277344 C 99.890625 115.742188 100.640625 115.214844 101.441406 114.648438 C 103.152344 116.527344 103.140625 118.5 102.511719 120.402344 C 102.03125 121.863281 101.257813 123.292969 100.335938 124.53125 C 98.128906 127.492188 95.582031 130.164063 92.433594 132.164063 C 89.445313 134.066406 86.488281 136.046875 83.363281 137.710938 C 76.871094 141.175781 73.140625 146.550781 71.820313 153.683594 C 71.285156 156.5625 70.835938 159.460938 70.476563 162.367188 C 70.3125 163.683594 70.191406 165.113281 71.472656 166.101563 C 72.835938 166.082031 73.644531 165.164063 74.308594 164.265625 C 77.566406 159.871094 82.019531 158.234375 87.316406 158.269531 C 91.484375 158.292969 95.441406 157.53125 98.863281 154.878906 C 99.679688 154.242188 100.746094 153.921875 101.539063 153.535156 C 102.847656 154.238281 102.679688 155.144531 102.511719 156.019531 C 101.964844 158.886719 100.507813 161.269531 98.238281 163.023438 C 96.640625 164.261719 94.804688 165.222656 93.011719 166.183594 C 91.273438 167.113281 89.453125 167.894531 87.660156 168.730469 C 85.433594 169.769531 83.832031 171.546875 82.246094 173.335938 C 81.484375 174.195313 81.507813 174.40625 81.738281 175.683594 C 88.488281 177.3125 94.964844 177.140625 100.835938 172.867188 C 101.109375 172.667969 101.40625 172.488281 101.707031 172.335938 C 103.5 171.414063 104.902344 172.167969 104.839844 174.207031 C 104.796875 175.597656 104.5 177.070313 103.933594 178.332031 C 103.039063 180.332031 101.625 182.007813 99.816406 183.328125 C 95.242188 186.667969 90.523438 189.761719 85.480469 192.378906 C 80.933594 194.742188 77.011719 197.871094 74.8125 202.707031 C 74.425781 203.554688 73.894531 204.425781 74.683594 205.59375 C 75.308594 205.476563 76.097656 205.503906 76.707031 205.183594 C 79.675781 203.613281 82.757813 203.808594 85.886719 204.417969 C 87.359375 204.703125 88.816406 205.140625 90.300781 205.269531 C 92.03125 205.417969 93.78125 205.304688 95.757813 205.304688 "/>
<path style=" stroke:none;fill-rule:nonzero;fill:rgb(60.398865%,10.598755%,11.799622%);fill-opacity:1;" d="M 172.03125 241.433594 C 171.183594 237.375 169.734375 234.207031 166.972656 231.804688 C 165.648438 230.652344 164.160156 229.609375 162.59375 228.832031 C 159.050781 227.085938 155.414063 225.53125 151.816406 223.90625 C 150.824219 223.457031 149.777344 223.105469 148.84375 222.5625 C 145.734375 220.753906 144.632813 216.027344 146.679688 212.625 C 147.207031 212.910156 147.871094 213.089844 148.269531 213.511719 C 151.332031 216.757813 155.089844 218.152344 159.503906 217.875 C 162.183594 217.707031 164.597656 218.246094 166.746094 220.035156 C 167.566406 220.71875 168.789063 220.925781 170.265625 221.527344 C 170.3125 220.320313 170.503906 219.53125 170.34375 218.820313 C 168.496094 210.597656 164.527344 203.855469 156.734375 199.941406 C 151.722656 197.421875 147.054688 194.367188 142.5 191.121094 C 140.457031 189.664063 138.851563 187.851563 137.675781 185.652344 C 137.230469 184.816406 136.777344 183.953125 137.308594 182.714844 C 137.910156 182.761719 138.585938 182.699219 139.175781 182.890625 C 140.53125 183.328125 141.878906 183.828125 143.175781 184.421875 C 146.328125 185.863281 149.5625 186.253906 152.945313 185.445313 C 155.296875 184.886719 157.648438 184.601563 159.953125 185.679688 C 160.191406 185.789063 160.484375 185.8125 160.753906 185.828125 C 162.628906 185.945313 163.484375 184.753906 162.578125 183.125 C 162.089844 182.25 161.382813 181.464844 160.648438 180.769531 C 157.644531 177.925781 154.101563 175.910156 150.335938 174.242188 C 148.78125 173.550781 147.253906 172.789063 145.757813 171.988281 C 142.609375 170.296875 140.578125 167.625 139.273438 164.359375 C 138.863281 163.34375 138.472656 162.28125 139.445313 161.320313 C 140.425781 160.347656 141.582031 159.824219 142.964844 160.15625 C 143.820313 160.363281 144.636719 160.734375 145.46875 161.035156 C 150.398438 162.808594 155.332031 164.566406 160.25 166.371094 C 161.332031 166.765625 162.335938 167.367188 163.40625 167.800781 C 164.785156 168.363281 166.15625 169.03125 167.597656 169.328125 C 169.851563 169.792969 171.03125 168.664063 170.753906 166.382813 C 170.238281 162.179688 169.433594 158.035156 167.554688 154.179688 C 167.355469 153.765625 167.207031 153.324219 166.984375 152.78125 C 167.660156 152.746094 168.191406 152.699219 168.722656 152.699219 C 175.679688 152.695313 182.636719 152.722656 189.59375 152.671875 C 190.777344 152.664063 191.609375 153.015625 192.449219 153.859375 C 204.347656 165.78125 216.273438 177.679688 228.222656 189.554688 C 229.113281 190.433594 229.511719 191.308594 229.507813 192.582031 C 229.476563 230.914063 229.476563 269.246094 229.507813 307.574219 C 229.511719 308.851563 229.132813 309.738281 228.222656 310.605469 C 218.761719 319.648438 209.332031 328.726563 199.898438 337.800781 C 195.179688 342.335938 190.457031 346.863281 185.765625 351.425781 C 185.039063 352.128906 184.339844 352.5625 183.273438 352.539063 C 179.320313 352.457031 175.359375 352.589844 171.414063 352.402344 C 165.496094 352.117188 160.089844 350.117188 155.121094 346.949219 C 154.160156 346.339844 153.296875 345.511719 152.550781 344.640625 C 149.996094 341.652344 147.066406 339.128906 143.585938 337.296875 C 135.359375 332.960938 131.722656 325.789063 131.015625 316.871094 C 130.78125 313.886719 130.871094 310.875 130.867188 307.878906 C 130.847656 299.554688 130.851563 291.234375 130.867188 282.914063 C 130.871094 281.648438 130.582031 280.113281 132.054688 279.496094 C 133.34375 278.957031 134.363281 279.984375 135.308594 280.730469 C 138.101563 282.945313 141.253906 283.980469 144.816406 283.777344 C 146.585938 283.675781 148.371094 283.726563 150.121094 283.484375 C 153.332031 283.042969 156.441406 283.457031 159.304688 284.800781 C 162.6875 286.386719 165.941406 288.257813 169.171875 290.144531 C 171.757813 291.652344 174.191406 293.425781 176.761719 294.96875 C 177.855469 295.625 179.082031 296.132813 180.316406 296.464844 C 181.867188 296.878906 182.902344 296.148438 183.003906 294.554688 C 183.097656 293.140625 183.144531 291.628906 182.75 290.296875 C 181.433594 285.863281 180.027344 281.445313 178.417969 277.109375 C 177.421875 274.425781 175.296875 272.492188 172.996094 270.851563 C 171.503906 269.78125 169.882813 268.898438 168.34375 267.894531 C 167.550781 267.375 166.710938 266.863281 166.082031 266.179688 C 164.160156 264.085938 164.253906 262.160156 166.152344 260.03125 C 166.914063 259.175781 167.660156 258.253906 168.191406 257.242188 C 169.503906 254.75 168.828125 252.628906 166.1875 251.574219 C 164.3125 250.828125 162.277344 250.390625 160.273438 250.089844 C 155.894531 249.433594 151.964844 247.890625 148.859375 244.667969 C 147.835938 243.601563 146.992188 242.324219 146.234375 241.046875 C 145.417969 239.660156 145.804688 238.265625 147.15625 237.328125 C 148.867188 236.140625 150.722656 235.925781 152.546875 236.996094 C 157.476563 239.898438 162.835938 241.273438 168.496094 241.574219 C 169.546875 241.628906 170.605469 241.496094 172.03125 241.433594 "/>
<path style=" stroke:none;fill-rule:nonzero;fill:rgb(60.398865%,10.598755%,11.799622%);fill-opacity:1;" d="M 12.75 258.398438 C 34.238281 258.398438 55.605469 258.398438 76.972656 258.398438 C 77.019531 258.496094 77.0625 258.589844 77.109375 258.6875 C 76.363281 259.082031 75.628906 259.503906 74.863281 259.871094 C 71.144531 261.648438 67.679688 263.773438 65.003906 266.992188 C 62.476563 270.03125 58.757813 281.015625 58.914063 284.972656 C 58.933594 285.378906 58.933594 285.800781 59.046875 286.1875 C 59.351563 287.253906 59.738281 288.289063 60.941406 288.664063 C 62.191406 289.050781 62.996094 288.320313 63.78125 287.511719 C 69.570313 281.523438 76.71875 277.800781 84.578125 275.441406 C 86.878906 274.75 89.441406 274.96875 91.863281 274.640625 C 93.882813 274.367188 95.902344 274.007813 97.871094 273.5 C 100.289063 272.878906 102.339844 271.5625 104.097656 269.753906 C 105.183594 268.632813 106.375 267.59375 107.609375 266.632813 C 108.386719 266.027344 109.265625 265.410156 110.640625 265.789063 C 110.722656 266.390625 110.882813 267.03125 110.878906 267.667969 C 110.859375 280.21875 110.882813 292.765625 110.75 305.3125 C 110.707031 309.253906 110.398438 313.207031 109.335938 317.054688 C 108.589844 319.746094 107.410156 322.117188 105.199219 323.9375 C 103.621094 325.238281 102.167969 326.683594 100.652344 328.054688 C 97.441406 330.957031 94.738281 334.253906 92.527344 337.984375 C 90.582031 341.277344 88.347656 344.371094 85.453125 346.933594 C 81.402344 350.507813 76.671875 352.347656 71.28125 352.417969 C 67.121094 352.472656 62.960938 352.398438 58.796875 352.449219 C 57.757813 352.464844 57.03125 352.128906 56.285156 351.40625 C 47.375 342.777344 38.429688 334.175781 29.488281 325.574219 C 24.476563 320.757813 19.472656 315.925781 14.410156 311.164063 C 13.140625 309.972656 12.515625 308.765625 12.527344 306.933594 C 12.636719 291.386719 12.632813 275.835938 12.667969 260.285156 C 12.667969 259.6875 12.71875 259.09375 12.75 258.398438 "/>
</g>
</svg>

    </a>
    Bayesian Embedding (BEMB)
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../intro/" class="md-nav__link">
        About
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="https://gsbdbi.github.io/torch-choice/" class="md-nav__link">
        Torch Choice Documentation
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="https://gsbdbi.github.io/torch-choice/intro/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="https://gsbdbi.github.io/torch-choice/" class="md-nav__link">
        Documentation for Torch-Choice
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="https://gsbdbi.github.io/torch-choice/data_management/" class="md-nav__link">
        Tutorial for Data Management
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="https://gsbdbi.github.io/torch-choice/easy_data_management/" class="md-nav__link">
        Tutorial for Easy Data Management and Stata Users
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../bemb/" class="md-nav__link">
        Tutorial for Bayesian Embedding (BEMB)
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../bemb_obs2prior_simulation/" class="md-nav__link">
        Tutorial for BEMB obs2prior feature
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../bemb_inference/" class="md-nav__link">
        Tutorial for Inference with BEMB
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../projects/" class="md-nav__link">
        Related Projects
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../test/" class="md-nav__link">
        Compatibility Tests
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          API Reference BEMB
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        API Reference BEMB
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#bemb" class="md-nav__link">
    bemb
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bemb.model" class="md-nav__link">
    model
  </a>
  
    <nav class="md-nav" aria-label="model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_coefficient" class="md-nav__link">
    bayesian_coefficient
  </a>
  
    <nav class="md-nav" aria-label="bayesian_coefficient">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_coefficient.BayesianCoefficient" class="md-nav__link">
    BayesianCoefficient
  </a>
  
    <nav class="md-nav" aria-label="BayesianCoefficient">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_coefficient.BayesianCoefficient.device" class="md-nav__link">
    device
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_coefficient.BayesianCoefficient.variational_distribution" class="md-nav__link">
    variational_distribution
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_coefficient.BayesianCoefficient.variational_mean" class="md-nav__link">
    variational_mean
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_coefficient.BayesianCoefficient.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_coefficient.BayesianCoefficient.__repr__" class="md-nav__link">
    __repr__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_coefficient.BayesianCoefficient.log_prior" class="md-nav__link">
    log_prior()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_coefficient.BayesianCoefficient.log_variational" class="md-nav__link">
    log_variational()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_coefficient.BayesianCoefficient.rsample" class="md-nav__link">
    rsample()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_coefficient.BayesianCoefficient.update_variational_mean_fixed" class="md-nav__link">
    update_variational_mean_fixed()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_linear" class="md-nav__link">
    bayesian_linear
  </a>
  
    <nav class="md-nav" aria-label="bayesian_linear">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_linear.BayesianLinear" class="md-nav__link">
    BayesianLinear
  </a>
  
    <nav class="md-nav" aria-label="BayesianLinear">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_linear.BayesianLinear.W_variational_distribution" class="md-nav__link">
    W_variational_distribution
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_linear.BayesianLinear.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_linear.BayesianLinear.dsample" class="md-nav__link">
    dsample()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_linear.BayesianLinear.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_linear.BayesianLinear.log_prior" class="md-nav__link">
    log_prior()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_linear.BayesianLinear.log_variational" class="md-nav__link">
    log_variational()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_linear.BayesianLinear.rsample" class="md-nav__link">
    rsample()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb" class="md-nav__link">
    bemb
  </a>
  
    <nav class="md-nav" aria-label="bemb">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb.BEMBFlex" class="md-nav__link">
    BEMBFlex
  </a>
  
    <nav class="md-nav" aria-label="BEMBFlex">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb.BEMBFlex.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb.BEMBFlex.elbo" class="md-nav__link">
    elbo()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb.BEMBFlex.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb.BEMBFlex.get_within_category_accuracy" class="md-nav__link">
    get_within_category_accuracy()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb.BEMBFlex.ivs" class="md-nav__link">
    ivs()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb.BEMBFlex.log_likelihood_all_items" class="md-nav__link">
    log_likelihood_all_items()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb.BEMBFlex.log_likelihood_item_index" class="md-nav__link">
    log_likelihood_item_index()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb.BEMBFlex.log_prior" class="md-nav__link">
    log_prior()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb.BEMBFlex.log_variational" class="md-nav__link">
    log_variational()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb.BEMBFlex.posterior_distribution" class="md-nav__link">
    posterior_distribution()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb.BEMBFlex.posterior_mean" class="md-nav__link">
    posterior_mean()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb.BEMBFlex.predict_proba" class="md-nav__link">
    predict_proba()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb.BEMBFlex.sample_choices" class="md-nav__link">
    sample_choices()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb.BEMBFlex.sample_coefficient_dictionary" class="md-nav__link">
    sample_coefficient_dictionary()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb.BEMBFlex.sample_log_likelihoods" class="md-nav__link">
    sample_log_likelihoods()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb.parse_utility" class="md-nav__link">
    parse_utility()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb_flex_lightning" class="md-nav__link">
    bemb_flex_lightning
  </a>
  
    <nav class="md-nav" aria-label="bemb_flex_lightning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb_flex_lightning.LitBEMBFlex" class="md-nav__link">
    LitBEMBFlex
  </a>
  
    <nav class="md-nav" aria-label="LitBEMBFlex">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb_flex_lightning.LitBEMBFlex.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb_flex_lightning.LitBEMBFlex.configure_optimizers" class="md-nav__link">
    configure_optimizers()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb_flex_lightning.LitBEMBFlex.fit_model" class="md-nav__link">
    fit_model()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb_flex_lightning.LitBEMBFlex.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb_flex_lightning.LitBEMBFlex.test_step" class="md-nav__link">
    test_step()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb_flex_lightning.LitBEMBFlex.training_step" class="md-nav__link">
    training_step()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb_flex_lightning.LitBEMBFlex.validation_step" class="md-nav__link">
    validation_step()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bemb.utils" class="md-nav__link">
    utils
  </a>
  
    <nav class="md-nav" aria-label="utils">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bemb.utils.run_helper" class="md-nav__link">
    run_helper
  </a>
  
    <nav class="md-nav" aria-label="run_helper">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bemb.utils.run_helper.run" class="md-nav__link">
    run()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.utils.run_helper.section_print" class="md-nav__link">
    section_print()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#bemb" class="md-nav__link">
    bemb
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bemb.model" class="md-nav__link">
    model
  </a>
  
    <nav class="md-nav" aria-label="model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_coefficient" class="md-nav__link">
    bayesian_coefficient
  </a>
  
    <nav class="md-nav" aria-label="bayesian_coefficient">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_coefficient.BayesianCoefficient" class="md-nav__link">
    BayesianCoefficient
  </a>
  
    <nav class="md-nav" aria-label="BayesianCoefficient">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_coefficient.BayesianCoefficient.device" class="md-nav__link">
    device
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_coefficient.BayesianCoefficient.variational_distribution" class="md-nav__link">
    variational_distribution
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_coefficient.BayesianCoefficient.variational_mean" class="md-nav__link">
    variational_mean
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_coefficient.BayesianCoefficient.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_coefficient.BayesianCoefficient.__repr__" class="md-nav__link">
    __repr__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_coefficient.BayesianCoefficient.log_prior" class="md-nav__link">
    log_prior()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_coefficient.BayesianCoefficient.log_variational" class="md-nav__link">
    log_variational()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_coefficient.BayesianCoefficient.rsample" class="md-nav__link">
    rsample()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_coefficient.BayesianCoefficient.update_variational_mean_fixed" class="md-nav__link">
    update_variational_mean_fixed()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_linear" class="md-nav__link">
    bayesian_linear
  </a>
  
    <nav class="md-nav" aria-label="bayesian_linear">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_linear.BayesianLinear" class="md-nav__link">
    BayesianLinear
  </a>
  
    <nav class="md-nav" aria-label="BayesianLinear">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_linear.BayesianLinear.W_variational_distribution" class="md-nav__link">
    W_variational_distribution
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_linear.BayesianLinear.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_linear.BayesianLinear.dsample" class="md-nav__link">
    dsample()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_linear.BayesianLinear.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_linear.BayesianLinear.log_prior" class="md-nav__link">
    log_prior()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_linear.BayesianLinear.log_variational" class="md-nav__link">
    log_variational()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bayesian_linear.BayesianLinear.rsample" class="md-nav__link">
    rsample()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb" class="md-nav__link">
    bemb
  </a>
  
    <nav class="md-nav" aria-label="bemb">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb.BEMBFlex" class="md-nav__link">
    BEMBFlex
  </a>
  
    <nav class="md-nav" aria-label="BEMBFlex">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb.BEMBFlex.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb.BEMBFlex.elbo" class="md-nav__link">
    elbo()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb.BEMBFlex.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb.BEMBFlex.get_within_category_accuracy" class="md-nav__link">
    get_within_category_accuracy()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb.BEMBFlex.ivs" class="md-nav__link">
    ivs()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb.BEMBFlex.log_likelihood_all_items" class="md-nav__link">
    log_likelihood_all_items()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb.BEMBFlex.log_likelihood_item_index" class="md-nav__link">
    log_likelihood_item_index()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb.BEMBFlex.log_prior" class="md-nav__link">
    log_prior()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb.BEMBFlex.log_variational" class="md-nav__link">
    log_variational()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb.BEMBFlex.posterior_distribution" class="md-nav__link">
    posterior_distribution()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb.BEMBFlex.posterior_mean" class="md-nav__link">
    posterior_mean()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb.BEMBFlex.predict_proba" class="md-nav__link">
    predict_proba()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb.BEMBFlex.sample_choices" class="md-nav__link">
    sample_choices()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb.BEMBFlex.sample_coefficient_dictionary" class="md-nav__link">
    sample_coefficient_dictionary()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb.BEMBFlex.sample_log_likelihoods" class="md-nav__link">
    sample_log_likelihoods()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb.parse_utility" class="md-nav__link">
    parse_utility()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb_flex_lightning" class="md-nav__link">
    bemb_flex_lightning
  </a>
  
    <nav class="md-nav" aria-label="bemb_flex_lightning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb_flex_lightning.LitBEMBFlex" class="md-nav__link">
    LitBEMBFlex
  </a>
  
    <nav class="md-nav" aria-label="LitBEMBFlex">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb_flex_lightning.LitBEMBFlex.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb_flex_lightning.LitBEMBFlex.configure_optimizers" class="md-nav__link">
    configure_optimizers()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb_flex_lightning.LitBEMBFlex.fit_model" class="md-nav__link">
    fit_model()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb_flex_lightning.LitBEMBFlex.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb_flex_lightning.LitBEMBFlex.test_step" class="md-nav__link">
    test_step()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb_flex_lightning.LitBEMBFlex.training_step" class="md-nav__link">
    training_step()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.model.bemb_flex_lightning.LitBEMBFlex.validation_step" class="md-nav__link">
    validation_step()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bemb.utils" class="md-nav__link">
    utils
  </a>
  
    <nav class="md-nav" aria-label="utils">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bemb.utils.run_helper" class="md-nav__link">
    run_helper
  </a>
  
    <nav class="md-nav" aria-label="run_helper">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bemb.utils.run_helper.run" class="md-nav__link">
    run()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bemb.utils.run_helper.section_print" class="md-nav__link">
    section_print()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                


<h1 id="api-reference-bemb">API Reference: BEMB</h1>


  <div class="doc doc-object doc-module">

<a id="bemb"></a>
    <div class="doc doc-contents first">




  <div class="doc doc-children">











  <div class="doc doc-object doc-module">



<h2 id="bemb.model" class="doc doc-heading">
        <code>model</code>


  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h2>

    <div class="doc doc-contents ">




  <div class="doc doc-children">










  <div class="doc doc-object doc-module">



<h3 id="bemb.model.bayesian_coefficient" class="doc doc-heading">
        <code>bayesian_coefficient</code>



</h3>

    <div class="doc doc-contents ">

      <p>Bayesian Coefficient is the building block for the BEMB model.</p>
<p>Author: Tianyu Du
Update: Apr. 28, 2022</p>



  <div class="doc doc-children">







  <div class="doc doc-object doc-class">



<h4 id="bemb.model.bayesian_coefficient.BayesianCoefficient" class="doc doc-heading">
        <code>
BayesianCoefficient            (<span title="torch.nn.modules.module.Module">Module</span>)
        </code>



</h4>

    <div class="doc doc-contents ">


        <details class="quote">
          <summary>Source code in <code>bemb/model/bayesian_coefficient.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">class</span> <span class="nc">BayesianCoefficient</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>                 <span class="n">variation</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>                 <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>                 <span class="n">obs2prior</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>                 <span class="n">H_zero_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">BoolTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>                 <span class="n">is_H</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>                 <span class="n">num_obs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>                 <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>                 <span class="n">prior_mean</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>                 <span class="n">prior_variance</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>                 <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>        <span class="sd">&quot;&quot;&quot;The Bayesian coefficient object represents a learnable tensor mu_i in R^k, where i is from a family (e.g., user, item)</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a><span class="sd">            so there are num_classes * num_obs learnable weights in total.</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a><span class="sd">            The prior distribution of mu_i is N(0, I) or N(H*X_obs(H shape=num_obs, X_obs shape=dim), Ix1).</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a><span class="sd">            The posterior(i.e., variational) distribution of mu_i is a Gaussian distribution with learnable mean mu_i and unit covariance.</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a><span class="sd">            The mean of the variational distribution consists of two parts:</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a><span class="sd">                1. The fixed part, which is not learnable. This part is particularly useful when the researcher want to impose</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a><span class="sd">                    some structure on the variational distribution. For example, the research might have some variational mean</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a><span class="sd">                    learned from another model and wish to use BEMB to polish the learned mean.</span>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a><span class="sd">                2. The flexible part, which is the main learnable part of the variational mean.</span>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a><span class="sd">            variation (str): the variation # TODO: this will be removed in the next version, after we have a complete</span>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a><span class="sd">                test pipeline.</span>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a><span class="sd">            num_classes (int): number of classes in the coefficient. For example, if we have user-specific coefficients,</span>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a><span class="sd">                `theta_user`, the `num_classes` should be the number of users. If we have item-specific coefficients,</span>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a><span class="sd">                the the `num_classes` should be the number of items.</span>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a><span class="sd">            obs2prior (bool): whether the mean of coefficient prior depends on the observable or not.</span>
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a><span class="sd">            H_zero_mask (Optional[torch.BoolTensor]): to disable some of the learnable weights in the obs2prior term.</span>
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a><span class="sd">                Recall that the prior is defined to be Normal(H*X_obs, sigma*I) when `obs2prior` is True.</span>
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a><span class="sd">                The mask variable `H_zero_mask` will set `H[H_zero_mask]` to zeros and make them un-learnable.</span>
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a><span class="sd">                This method restricts interactions between the observables and prior mean.</span>
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a><span class="sd">                This is used only if `obs2prior` is True.</span>
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a><span class="sd">                Defaults to None.</span>
<a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a><span class="sd">            is_H (bool): whether this coefficient is the H variable in the obs2prior, do you set this argument yourself!</span>
<a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a><span class="sd">                Defaults to False.</span>
<a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a><span class="sd">            num_obs (int, optional): the number of observables associated with each class. For example, if the coefficient</span>
<a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a><span class="sd">                if item-specific, and we have `obs2prior` set to True, the `num_obs` should be the number of observables</span>
<a id="__codelineno-0-40" name="__codelineno-0-40" href="#__codelineno-0-40"></a><span class="sd">                for each item.</span>
<a id="__codelineno-0-41" name="__codelineno-0-41" href="#__codelineno-0-41"></a><span class="sd">                Defaults to None.</span>
<a id="__codelineno-0-42" name="__codelineno-0-42" href="#__codelineno-0-42"></a><span class="sd">            dim (int, optional): the dimension of the coefficient.</span>
<a id="__codelineno-0-43" name="__codelineno-0-43" href="#__codelineno-0-43"></a><span class="sd">                Defaults to 1.</span>
<a id="__codelineno-0-44" name="__codelineno-0-44" href="#__codelineno-0-44"></a><span class="sd">            prior_mean (float): the mean of the prior distribution of coefficient.</span>
<a id="__codelineno-0-45" name="__codelineno-0-45" href="#__codelineno-0-45"></a><span class="sd">                Defaults to 0.0.</span>
<a id="__codelineno-0-46" name="__codelineno-0-46" href="#__codelineno-0-46"></a><span class="sd">            prior_variance (float): the variance of the prior distribution of coefficient.</span>
<a id="__codelineno-0-47" name="__codelineno-0-47" href="#__codelineno-0-47"></a><span class="sd">                Defaults to 1.0.</span>
<a id="__codelineno-0-48" name="__codelineno-0-48" href="#__codelineno-0-48"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-49" name="__codelineno-0-49" href="#__codelineno-0-49"></a>        <span class="nb">super</span><span class="p">(</span><span class="n">BayesianCoefficient</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-50" name="__codelineno-0-50" href="#__codelineno-0-50"></a>        <span class="c1"># do we use this at all? TODO: drop self.variation.</span>
<a id="__codelineno-0-51" name="__codelineno-0-51" href="#__codelineno-0-51"></a>        <span class="k">assert</span> <span class="n">variation</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;item&#39;</span><span class="p">,</span> <span class="s1">&#39;user&#39;</span><span class="p">,</span> <span class="s1">&#39;constant&#39;</span><span class="p">,</span> <span class="s1">&#39;category&#39;</span><span class="p">]</span>
<a id="__codelineno-0-52" name="__codelineno-0-52" href="#__codelineno-0-52"></a>
<a id="__codelineno-0-53" name="__codelineno-0-53" href="#__codelineno-0-53"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">variation</span> <span class="o">=</span> <span class="n">variation</span>
<a id="__codelineno-0-54" name="__codelineno-0-54" href="#__codelineno-0-54"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">obs2prior</span> <span class="o">=</span> <span class="n">obs2prior</span>
<a id="__codelineno-0-55" name="__codelineno-0-55" href="#__codelineno-0-55"></a>        <span class="k">if</span> <span class="n">variation</span> <span class="o">==</span> <span class="s1">&#39;constant&#39;</span> <span class="ow">or</span> <span class="n">variation</span> <span class="o">==</span> <span class="s1">&#39;category&#39;</span><span class="p">:</span>
<a id="__codelineno-0-56" name="__codelineno-0-56" href="#__codelineno-0-56"></a>            <span class="k">if</span> <span class="n">obs2prior</span><span class="p">:</span>
<a id="__codelineno-0-57" name="__codelineno-0-57" href="#__codelineno-0-57"></a>                <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;obs2prior is not supported for constant and category variation at present.&#39;</span><span class="p">)</span>
<a id="__codelineno-0-58" name="__codelineno-0-58" href="#__codelineno-0-58"></a>
<a id="__codelineno-0-59" name="__codelineno-0-59" href="#__codelineno-0-59"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">num_classes</span>
<a id="__codelineno-0-60" name="__codelineno-0-60" href="#__codelineno-0-60"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_obs</span> <span class="o">=</span> <span class="n">num_obs</span>
<a id="__codelineno-0-61" name="__codelineno-0-61" href="#__codelineno-0-61"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>  <span class="c1"># the dimension of greek letter parameter.</span>
<a id="__codelineno-0-62" name="__codelineno-0-62" href="#__codelineno-0-62"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">prior_mean</span> <span class="o">=</span> <span class="n">prior_mean</span>
<a id="__codelineno-0-63" name="__codelineno-0-63" href="#__codelineno-0-63"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">prior_variance</span> <span class="o">=</span> <span class="n">prior_variance</span>
<a id="__codelineno-0-64" name="__codelineno-0-64" href="#__codelineno-0-64"></a>
<a id="__codelineno-0-65" name="__codelineno-0-65" href="#__codelineno-0-65"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">is_H</span> <span class="o">=</span> <span class="n">is_H</span>
<a id="__codelineno-0-66" name="__codelineno-0-66" href="#__codelineno-0-66"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">H_zero_mask</span> <span class="o">=</span> <span class="n">H_zero_mask</span>
<a id="__codelineno-0-67" name="__codelineno-0-67" href="#__codelineno-0-67"></a>
<a id="__codelineno-0-68" name="__codelineno-0-68" href="#__codelineno-0-68"></a>        <span class="c1"># assert self.prior_variance &gt; 0</span>
<a id="__codelineno-0-69" name="__codelineno-0-69" href="#__codelineno-0-69"></a>
<a id="__codelineno-0-70" name="__codelineno-0-70" href="#__codelineno-0-70"></a>        <span class="c1"># create prior distribution.</span>
<a id="__codelineno-0-71" name="__codelineno-0-71" href="#__codelineno-0-71"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">obs2prior</span><span class="p">:</span>
<a id="__codelineno-0-72" name="__codelineno-0-72" href="#__codelineno-0-72"></a>            <span class="c1"># the mean of prior distribution depends on observables.</span>
<a id="__codelineno-0-73" name="__codelineno-0-73" href="#__codelineno-0-73"></a>            <span class="c1"># initiate a Bayesian Coefficient with shape (dim, num_obs) standard Gaussian.</span>
<a id="__codelineno-0-74" name="__codelineno-0-74" href="#__codelineno-0-74"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">prior_H</span> <span class="o">=</span> <span class="n">BayesianCoefficient</span><span class="p">(</span><span class="n">variation</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">,</span>
<a id="__codelineno-0-75" name="__codelineno-0-75" href="#__codelineno-0-75"></a>                                               <span class="n">num_classes</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span>
<a id="__codelineno-0-76" name="__codelineno-0-76" href="#__codelineno-0-76"></a>                                               <span class="n">obs2prior</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-77" name="__codelineno-0-77" href="#__codelineno-0-77"></a>                                               <span class="n">dim</span><span class="o">=</span><span class="n">num_obs</span><span class="p">,</span>
<a id="__codelineno-0-78" name="__codelineno-0-78" href="#__codelineno-0-78"></a>                                               <span class="n">prior_variance</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-79" name="__codelineno-0-79" href="#__codelineno-0-79"></a>                                               <span class="n">H_zero_mask</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">H_zero_mask</span><span class="p">,</span>
<a id="__codelineno-0-80" name="__codelineno-0-80" href="#__codelineno-0-80"></a>                                               <span class="n">is_H</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># this is a distribution responsible for the obs2prior H term.</span>
<a id="__codelineno-0-81" name="__codelineno-0-81" href="#__codelineno-0-81"></a>
<a id="__codelineno-0-82" name="__codelineno-0-82" href="#__codelineno-0-82"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-83" name="__codelineno-0-83" href="#__codelineno-0-83"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
<a id="__codelineno-0-84" name="__codelineno-0-84" href="#__codelineno-0-84"></a>                <span class="s1">&#39;prior_zero_mean&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_mean</span><span class="p">))</span>
<a id="__codelineno-0-85" name="__codelineno-0-85" href="#__codelineno-0-85"></a>
<a id="__codelineno-0-86" name="__codelineno-0-86" href="#__codelineno-0-86"></a>        <span class="c1"># self.prior_cov_factor = nn.Parameter(torch.zeros(num_classes, dim, 1), requires_grad=False)</span>
<a id="__codelineno-0-87" name="__codelineno-0-87" href="#__codelineno-0-87"></a>        <span class="c1"># self.prior_cov_diag = nn.Parameter(torch.ones(num_classes, dim), requires_grad=False)</span>
<a id="__codelineno-0-88" name="__codelineno-0-88" href="#__codelineno-0-88"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;prior_cov_factor&#39;</span><span class="p">,</span>
<a id="__codelineno-0-89" name="__codelineno-0-89" href="#__codelineno-0-89"></a>                             <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<a id="__codelineno-0-90" name="__codelineno-0-90" href="#__codelineno-0-90"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;prior_cov_diag&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
<a id="__codelineno-0-91" name="__codelineno-0-91" href="#__codelineno-0-91"></a>            <span class="n">num_classes</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_variance</span><span class="p">)</span>
<a id="__codelineno-0-92" name="__codelineno-0-92" href="#__codelineno-0-92"></a>
<a id="__codelineno-0-93" name="__codelineno-0-93" href="#__codelineno-0-93"></a>        <span class="c1"># create variational distribution.</span>
<a id="__codelineno-0-94" name="__codelineno-0-94" href="#__codelineno-0-94"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">variational_mean_flexible</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
<a id="__codelineno-0-95" name="__codelineno-0-95" href="#__codelineno-0-95"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">dim</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-96" name="__codelineno-0-96" href="#__codelineno-0-96"></a>
<a id="__codelineno-0-97" name="__codelineno-0-97" href="#__codelineno-0-97"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_H</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">H_zero_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-98" name="__codelineno-0-98" href="#__codelineno-0-98"></a>            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">H_zero_mask</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">variational_mean_flexible</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> \
<a id="__codelineno-0-99" name="__codelineno-0-99" href="#__codelineno-0-99"></a>                <span class="sa">f</span><span class="s2">&quot;The H_zero_mask should have exactly the shape as the H variable, `H_zero_mask`.shape is </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">H_zero_mask</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, `H`.shape is </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">variational_mean_flexible</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> &quot;</span>
<a id="__codelineno-0-100" name="__codelineno-0-100" href="#__codelineno-0-100"></a>
<a id="__codelineno-0-101" name="__codelineno-0-101" href="#__codelineno-0-101"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">variational_logstd</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
<a id="__codelineno-0-102" name="__codelineno-0-102" href="#__codelineno-0-102"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">dim</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-103" name="__codelineno-0-103" href="#__codelineno-0-103"></a>
<a id="__codelineno-0-104" name="__codelineno-0-104" href="#__codelineno-0-104"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;variational_cov_factor&#39;</span><span class="p">,</span>
<a id="__codelineno-0-105" name="__codelineno-0-105" href="#__codelineno-0-105"></a>                             <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<a id="__codelineno-0-106" name="__codelineno-0-106" href="#__codelineno-0-106"></a>
<a id="__codelineno-0-107" name="__codelineno-0-107" href="#__codelineno-0-107"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">variational_mean_fixed</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-108" name="__codelineno-0-108" href="#__codelineno-0-108"></a>
<a id="__codelineno-0-109" name="__codelineno-0-109" href="#__codelineno-0-109"></a>    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<a id="__codelineno-0-110" name="__codelineno-0-110" href="#__codelineno-0-110"></a>        <span class="sd">&quot;&quot;&quot;Constructs a string representation of the Bayesian coefficient object.</span>
<a id="__codelineno-0-111" name="__codelineno-0-111" href="#__codelineno-0-111"></a>
<a id="__codelineno-0-112" name="__codelineno-0-112" href="#__codelineno-0-112"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-113" name="__codelineno-0-113" href="#__codelineno-0-113"></a><span class="sd">            str: the string representation of the Bayesian coefficient object.</span>
<a id="__codelineno-0-114" name="__codelineno-0-114" href="#__codelineno-0-114"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-115" name="__codelineno-0-115" href="#__codelineno-0-115"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">obs2prior</span><span class="p">:</span>
<a id="__codelineno-0-116" name="__codelineno-0-116" href="#__codelineno-0-116"></a>            <span class="n">prior_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;prior=N(H*X_obs(H shape=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_H</span><span class="o">.</span><span class="n">prior_zero_mean</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">, X_obs shape=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_H</span><span class="o">.</span><span class="n">dim</span><span class="si">}</span><span class="s1">), Ix</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_variance</span><span class="si">}</span><span class="s1">)&#39;</span>
<a id="__codelineno-0-117" name="__codelineno-0-117" href="#__codelineno-0-117"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-118" name="__codelineno-0-118" href="#__codelineno-0-118"></a>            <span class="n">prior_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;prior=N(0, I)&#39;</span>
<a id="__codelineno-0-119" name="__codelineno-0-119" href="#__codelineno-0-119"></a>        <span class="k">return</span> <span class="sa">f</span><span class="s1">&#39;BayesianCoefficient(num_classes=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="si">}</span><span class="s1">, dimension=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">prior_str</span><span class="si">}</span><span class="s1">)&#39;</span>
<a id="__codelineno-0-120" name="__codelineno-0-120" href="#__codelineno-0-120"></a>
<a id="__codelineno-0-121" name="__codelineno-0-121" href="#__codelineno-0-121"></a>    <span class="k">def</span> <span class="nf">update_variational_mean_fixed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-122" name="__codelineno-0-122" href="#__codelineno-0-122"></a>        <span class="sd">&quot;&quot;&quot;Updates the fixed part of the mean of the variational distribution.</span>
<a id="__codelineno-0-123" name="__codelineno-0-123" href="#__codelineno-0-123"></a>
<a id="__codelineno-0-124" name="__codelineno-0-124" href="#__codelineno-0-124"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-125" name="__codelineno-0-125" href="#__codelineno-0-125"></a><span class="sd">            new_value (torch.Tensor): the new value of the fixed part of the mean of the variational distribution.</span>
<a id="__codelineno-0-126" name="__codelineno-0-126" href="#__codelineno-0-126"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-127" name="__codelineno-0-127" href="#__codelineno-0-127"></a>        <span class="k">assert</span> <span class="n">new_value</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">variational_mean_flexible</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-128" name="__codelineno-0-128" href="#__codelineno-0-128"></a>        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">variational_mean_fixed</span>
<a id="__codelineno-0-129" name="__codelineno-0-129" href="#__codelineno-0-129"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;variational_mean_fixed&#39;</span><span class="p">,</span> <span class="n">new_value</span><span class="p">)</span>
<a id="__codelineno-0-130" name="__codelineno-0-130" href="#__codelineno-0-130"></a>
<a id="__codelineno-0-131" name="__codelineno-0-131" href="#__codelineno-0-131"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-132" name="__codelineno-0-132" href="#__codelineno-0-132"></a>    <span class="k">def</span> <span class="nf">variational_mean</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-133" name="__codelineno-0-133" href="#__codelineno-0-133"></a>        <span class="sd">&quot;&quot;&quot;Returns the mean of the variational distribution.</span>
<a id="__codelineno-0-134" name="__codelineno-0-134" href="#__codelineno-0-134"></a>
<a id="__codelineno-0-135" name="__codelineno-0-135" href="#__codelineno-0-135"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-136" name="__codelineno-0-136" href="#__codelineno-0-136"></a><span class="sd">            torch.Tensor: the current mean of the variational distribution with shape (num_classes, dim).</span>
<a id="__codelineno-0-137" name="__codelineno-0-137" href="#__codelineno-0-137"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-138" name="__codelineno-0-138" href="#__codelineno-0-138"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">variational_mean_fixed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-139" name="__codelineno-0-139" href="#__codelineno-0-139"></a>            <span class="n">M</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">variational_mean_flexible</span>
<a id="__codelineno-0-140" name="__codelineno-0-140" href="#__codelineno-0-140"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-141" name="__codelineno-0-141" href="#__codelineno-0-141"></a>            <span class="n">M</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">variational_mean_fixed</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">variational_mean_flexible</span>
<a id="__codelineno-0-142" name="__codelineno-0-142" href="#__codelineno-0-142"></a>
<a id="__codelineno-0-143" name="__codelineno-0-143" href="#__codelineno-0-143"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_H</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">H_zero_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>
<a id="__codelineno-0-144" name="__codelineno-0-144" href="#__codelineno-0-144"></a>            <span class="c1"># a H-variable with zero-entry restriction.</span>
<a id="__codelineno-0-145" name="__codelineno-0-145" href="#__codelineno-0-145"></a>            <span class="c1"># multiply zeros to entries with H_zero_mask[i, j] = 1.</span>
<a id="__codelineno-0-146" name="__codelineno-0-146" href="#__codelineno-0-146"></a>            <span class="k">assert</span> <span class="n">M</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">H_zero_mask</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-147" name="__codelineno-0-147" href="#__codelineno-0-147"></a>            <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">logical_not</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">H_zero_mask</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<a id="__codelineno-0-148" name="__codelineno-0-148" href="#__codelineno-0-148"></a>            <span class="k">return</span> <span class="n">M</span> <span class="o">*</span> <span class="n">mask</span>
<a id="__codelineno-0-149" name="__codelineno-0-149" href="#__codelineno-0-149"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-150" name="__codelineno-0-150" href="#__codelineno-0-150"></a>            <span class="c1"># a H-variable without zero-entry restriction or just a coefficient.</span>
<a id="__codelineno-0-151" name="__codelineno-0-151" href="#__codelineno-0-151"></a>            <span class="k">return</span> <span class="n">M</span>
<a id="__codelineno-0-152" name="__codelineno-0-152" href="#__codelineno-0-152"></a>
<a id="__codelineno-0-153" name="__codelineno-0-153" href="#__codelineno-0-153"></a>    <span class="k">def</span> <span class="nf">log_prior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-154" name="__codelineno-0-154" href="#__codelineno-0-154"></a>                  <span class="n">sample</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-155" name="__codelineno-0-155" href="#__codelineno-0-155"></a>                  <span class="n">H_sample</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-156" name="__codelineno-0-156" href="#__codelineno-0-156"></a>                  <span class="n">x_obs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-157" name="__codelineno-0-157" href="#__codelineno-0-157"></a>        <span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-158" name="__codelineno-0-158" href="#__codelineno-0-158"></a><span class="sd">        Computes the logP_{Prior}(Coefficient Sample) for provided samples of the coefficient. The prior will either be a</span>
<a id="__codelineno-0-159" name="__codelineno-0-159" href="#__codelineno-0-159"></a><span class="sd">        zero-mean Gaussian (if `obs2prior` is False) or a Gaussian with a learnable mean (if `obs2prior` is True).</span>
<a id="__codelineno-0-160" name="__codelineno-0-160" href="#__codelineno-0-160"></a>
<a id="__codelineno-0-161" name="__codelineno-0-161" href="#__codelineno-0-161"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-162" name="__codelineno-0-162" href="#__codelineno-0-162"></a><span class="sd">            sample (torch.Tensor): Monte Carlo samples of the variable with shape (num_seeds, num_classes, dim), where</span>
<a id="__codelineno-0-163" name="__codelineno-0-163" href="#__codelineno-0-163"></a><span class="sd">                sample[i, :, :] corresponds to one sample of the coefficient.</span>
<a id="__codelineno-0-164" name="__codelineno-0-164" href="#__codelineno-0-164"></a>
<a id="__codelineno-0-165" name="__codelineno-0-165" href="#__codelineno-0-165"></a><span class="sd">            # arguments required only if `obs2prior == True`:</span>
<a id="__codelineno-0-166" name="__codelineno-0-166" href="#__codelineno-0-166"></a><span class="sd">            H_sample (Optional[torch.Tensor], optional): Monte Carlo samples of the weight in obs2prior term, with shape</span>
<a id="__codelineno-0-167" name="__codelineno-0-167" href="#__codelineno-0-167"></a><span class="sd">                (num_seeds, dim, self.num_obs), this is required if and only if obs2prior == True.</span>
<a id="__codelineno-0-168" name="__codelineno-0-168" href="#__codelineno-0-168"></a><span class="sd">                Defaults to None.</span>
<a id="__codelineno-0-169" name="__codelineno-0-169" href="#__codelineno-0-169"></a><span class="sd">            x_obs (Optional[torch.Tensor], optional): observables for obs2prior with shape (num_classes, num_obs),</span>
<a id="__codelineno-0-170" name="__codelineno-0-170" href="#__codelineno-0-170"></a><span class="sd">                only required if and only if obs2prior == True.</span>
<a id="__codelineno-0-171" name="__codelineno-0-171" href="#__codelineno-0-171"></a><span class="sd">                Defaults to None.</span>
<a id="__codelineno-0-172" name="__codelineno-0-172" href="#__codelineno-0-172"></a>
<a id="__codelineno-0-173" name="__codelineno-0-173" href="#__codelineno-0-173"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-174" name="__codelineno-0-174" href="#__codelineno-0-174"></a><span class="sd">            torch.Tensor: the log prior of the variable with shape (num_seeds, num_classes).</span>
<a id="__codelineno-0-175" name="__codelineno-0-175" href="#__codelineno-0-175"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-176" name="__codelineno-0-176" href="#__codelineno-0-176"></a>        <span class="c1"># p(sample)</span>
<a id="__codelineno-0-177" name="__codelineno-0-177" href="#__codelineno-0-177"></a>        <span class="n">num_seeds</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-178" name="__codelineno-0-178" href="#__codelineno-0-178"></a>        <span class="c1"># shape (num_seeds, num_classes)</span>
<a id="__codelineno-0-179" name="__codelineno-0-179" href="#__codelineno-0-179"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">obs2prior</span><span class="p">:</span>
<a id="__codelineno-0-180" name="__codelineno-0-180" href="#__codelineno-0-180"></a>            <span class="k">assert</span> <span class="n">H_sample</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_seeds</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_obs</span><span class="p">)</span>
<a id="__codelineno-0-181" name="__codelineno-0-181" href="#__codelineno-0-181"></a>            <span class="k">assert</span> <span class="n">x_obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_obs</span><span class="p">)</span>
<a id="__codelineno-0-182" name="__codelineno-0-182" href="#__codelineno-0-182"></a>            <span class="n">x_obs</span> <span class="o">=</span> <span class="n">x_obs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_obs</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span>
<a id="__codelineno-0-183" name="__codelineno-0-183" href="#__codelineno-0-183"></a>                <span class="n">num_seeds</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-184" name="__codelineno-0-184" href="#__codelineno-0-184"></a>            <span class="n">H_sample</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">H_sample</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-0-185" name="__codelineno-0-185" href="#__codelineno-0-185"></a>            <span class="k">assert</span> <span class="n">H_sample</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_seeds</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_obs</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
<a id="__codelineno-0-186" name="__codelineno-0-186" href="#__codelineno-0-186"></a>            <span class="n">mu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">x_obs</span><span class="p">,</span> <span class="n">H_sample</span><span class="p">)</span>
<a id="__codelineno-0-187" name="__codelineno-0-187" href="#__codelineno-0-187"></a>            <span class="k">assert</span> <span class="n">mu</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_seeds</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
<a id="__codelineno-0-188" name="__codelineno-0-188" href="#__codelineno-0-188"></a>
<a id="__codelineno-0-189" name="__codelineno-0-189" href="#__codelineno-0-189"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-190" name="__codelineno-0-190" href="#__codelineno-0-190"></a>            <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_zero_mean</span>
<a id="__codelineno-0-191" name="__codelineno-0-191" href="#__codelineno-0-191"></a>        <span class="n">out</span> <span class="o">=</span> <span class="n">LowRankMultivariateNormal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span>
<a id="__codelineno-0-192" name="__codelineno-0-192" href="#__codelineno-0-192"></a>                                        <span class="n">cov_factor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_cov_factor</span><span class="p">,</span>
<a id="__codelineno-0-193" name="__codelineno-0-193" href="#__codelineno-0-193"></a>                                        <span class="n">cov_diag</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_cov_diag</span><span class="p">)</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
<a id="__codelineno-0-194" name="__codelineno-0-194" href="#__codelineno-0-194"></a>        <span class="k">assert</span> <span class="n">out</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_seeds</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
<a id="__codelineno-0-195" name="__codelineno-0-195" href="#__codelineno-0-195"></a>        <span class="k">return</span> <span class="n">out</span>
<a id="__codelineno-0-196" name="__codelineno-0-196" href="#__codelineno-0-196"></a>
<a id="__codelineno-0-197" name="__codelineno-0-197" href="#__codelineno-0-197"></a>    <span class="k">def</span> <span class="nf">log_variational</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-198" name="__codelineno-0-198" href="#__codelineno-0-198"></a>        <span class="sd">&quot;&quot;&quot;Given a set of sampled values of coefficients, with shape (num_seeds, num_classes, dim), computes the</span>
<a id="__codelineno-0-199" name="__codelineno-0-199" href="#__codelineno-0-199"></a><span class="sd">            the log probability of these sampled values of coefficients under the current variational distribution.</span>
<a id="__codelineno-0-200" name="__codelineno-0-200" href="#__codelineno-0-200"></a>
<a id="__codelineno-0-201" name="__codelineno-0-201" href="#__codelineno-0-201"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-202" name="__codelineno-0-202" href="#__codelineno-0-202"></a><span class="sd">            sample (torch.Tensor): a tensor of shape (num_seeds, num_classes, dim) containing sampled values of coefficients,</span>
<a id="__codelineno-0-203" name="__codelineno-0-203" href="#__codelineno-0-203"></a><span class="sd">                where sample[i, :, :] corresponds to one sample of the coefficient.</span>
<a id="__codelineno-0-204" name="__codelineno-0-204" href="#__codelineno-0-204"></a>
<a id="__codelineno-0-205" name="__codelineno-0-205" href="#__codelineno-0-205"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-206" name="__codelineno-0-206" href="#__codelineno-0-206"></a><span class="sd">            torch.Tensor: a tensor of shape (num_seeds, num_classes) containing the log probability of provided samples</span>
<a id="__codelineno-0-207" name="__codelineno-0-207" href="#__codelineno-0-207"></a><span class="sd">                under the variational distribution. The output is splitted by random seeds and classes, you can sum</span>
<a id="__codelineno-0-208" name="__codelineno-0-208" href="#__codelineno-0-208"></a><span class="sd">                along the second axis (i.e., the num_classes axis) to get the total log probability.</span>
<a id="__codelineno-0-209" name="__codelineno-0-209" href="#__codelineno-0-209"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-210" name="__codelineno-0-210" href="#__codelineno-0-210"></a>        <span class="n">num_seeds</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-211" name="__codelineno-0-211" href="#__codelineno-0-211"></a>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">variational_distribution</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
<a id="__codelineno-0-212" name="__codelineno-0-212" href="#__codelineno-0-212"></a>        <span class="k">assert</span> <span class="n">out</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_seeds</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
<a id="__codelineno-0-213" name="__codelineno-0-213" href="#__codelineno-0-213"></a>        <span class="k">return</span> <span class="n">out</span>
<a id="__codelineno-0-214" name="__codelineno-0-214" href="#__codelineno-0-214"></a>
<a id="__codelineno-0-215" name="__codelineno-0-215" href="#__codelineno-0-215"></a>    <span class="k">def</span> <span class="nf">rsample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_seeds</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
<a id="__codelineno-0-216" name="__codelineno-0-216" href="#__codelineno-0-216"></a>        <span class="sd">&quot;&quot;&quot;Samples values of the coefficient from the variational distribution using re-parameterization trick.</span>
<a id="__codelineno-0-217" name="__codelineno-0-217" href="#__codelineno-0-217"></a>
<a id="__codelineno-0-218" name="__codelineno-0-218" href="#__codelineno-0-218"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-219" name="__codelineno-0-219" href="#__codelineno-0-219"></a><span class="sd">            num_seeds (int, optional): number of values to be sampled. Defaults to 1.</span>
<a id="__codelineno-0-220" name="__codelineno-0-220" href="#__codelineno-0-220"></a>
<a id="__codelineno-0-221" name="__codelineno-0-221" href="#__codelineno-0-221"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-222" name="__codelineno-0-222" href="#__codelineno-0-222"></a><span class="sd">            Union[torch.Tensor, Tuple[torch.Tensor]]: if `obs2prior` is disabled, returns a tensor of shape (num_seeds, num_classes, dim)</span>
<a id="__codelineno-0-223" name="__codelineno-0-223" href="#__codelineno-0-223"></a><span class="sd">                where each output[i, :, :] corresponds to one sample of the coefficient.</span>
<a id="__codelineno-0-224" name="__codelineno-0-224" href="#__codelineno-0-224"></a><span class="sd">                If `obs2prior` is enabled, returns a tuple of samples: (1) a tensor of shape (num_seeds, num_classes, dim) containing</span>
<a id="__codelineno-0-225" name="__codelineno-0-225" href="#__codelineno-0-225"></a><span class="sd">                sampled values of coefficient, and (2) a tensor o shape (num_seeds, dim, num_obs) containing samples of the H weight</span>
<a id="__codelineno-0-226" name="__codelineno-0-226" href="#__codelineno-0-226"></a><span class="sd">                in the prior distribution.</span>
<a id="__codelineno-0-227" name="__codelineno-0-227" href="#__codelineno-0-227"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-228" name="__codelineno-0-228" href="#__codelineno-0-228"></a>        <span class="n">value_sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">variational_distribution</span><span class="o">.</span><span class="n">rsample</span><span class="p">(</span>
<a id="__codelineno-0-229" name="__codelineno-0-229" href="#__codelineno-0-229"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">num_seeds</span><span class="p">]))</span>
<a id="__codelineno-0-230" name="__codelineno-0-230" href="#__codelineno-0-230"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">obs2prior</span><span class="p">:</span>
<a id="__codelineno-0-231" name="__codelineno-0-231" href="#__codelineno-0-231"></a>            <span class="c1"># sample obs2prior H as well.</span>
<a id="__codelineno-0-232" name="__codelineno-0-232" href="#__codelineno-0-232"></a>            <span class="n">H_sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_H</span><span class="o">.</span><span class="n">rsample</span><span class="p">(</span><span class="n">num_seeds</span><span class="o">=</span><span class="n">num_seeds</span><span class="p">)</span>
<a id="__codelineno-0-233" name="__codelineno-0-233" href="#__codelineno-0-233"></a>            <span class="k">return</span> <span class="p">(</span><span class="n">value_sample</span><span class="p">,</span> <span class="n">H_sample</span><span class="p">)</span>
<a id="__codelineno-0-234" name="__codelineno-0-234" href="#__codelineno-0-234"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-235" name="__codelineno-0-235" href="#__codelineno-0-235"></a>            <span class="k">return</span> <span class="n">value_sample</span>
<a id="__codelineno-0-236" name="__codelineno-0-236" href="#__codelineno-0-236"></a>
<a id="__codelineno-0-237" name="__codelineno-0-237" href="#__codelineno-0-237"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-238" name="__codelineno-0-238" href="#__codelineno-0-238"></a>    <span class="k">def</span> <span class="nf">variational_distribution</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">LowRankMultivariateNormal</span><span class="p">:</span>
<a id="__codelineno-0-239" name="__codelineno-0-239" href="#__codelineno-0-239"></a>        <span class="sd">&quot;&quot;&quot;Constructs the current variational distribution of the coefficient from current variational mean and covariance.</span>
<a id="__codelineno-0-240" name="__codelineno-0-240" href="#__codelineno-0-240"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-241" name="__codelineno-0-241" href="#__codelineno-0-241"></a>        <span class="k">return</span> <span class="n">LowRankMultivariateNormal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">variational_mean</span><span class="p">,</span>
<a id="__codelineno-0-242" name="__codelineno-0-242" href="#__codelineno-0-242"></a>                                         <span class="n">cov_factor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">variational_cov_factor</span><span class="p">,</span>
<a id="__codelineno-0-243" name="__codelineno-0-243" href="#__codelineno-0-243"></a>                                         <span class="n">cov_diag</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">variational_logstd</span><span class="p">))</span>
<a id="__codelineno-0-244" name="__codelineno-0-244" href="#__codelineno-0-244"></a>
<a id="__codelineno-0-245" name="__codelineno-0-245" href="#__codelineno-0-245"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-246" name="__codelineno-0-246" href="#__codelineno-0-246"></a>    <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
<a id="__codelineno-0-247" name="__codelineno-0-247" href="#__codelineno-0-247"></a>        <span class="sd">&quot;&quot;&quot;Returns the device of tensors contained in this module.&quot;&quot;&quot;</span>
<a id="__codelineno-0-248" name="__codelineno-0-248" href="#__codelineno-0-248"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">variational_mean</span><span class="o">.</span><span class="n">device</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">






  <div class="doc doc-object doc-attribute">



<h5 id="bemb.model.bayesian_coefficient.BayesianCoefficient.device" class="doc doc-heading">
<code class="highlight language-python"><span class="n">device</span><span class="p">:</span> <span class="n">device</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

</h5>

    <div class="doc doc-contents ">

      <p>Returns the device of tensors contained in this module.</p>
    </div>

  </div>



  <div class="doc doc-object doc-attribute">



<h5 id="bemb.model.bayesian_coefficient.BayesianCoefficient.variational_distribution" class="doc doc-heading">
<code class="highlight language-python"><span class="n">variational_distribution</span><span class="p">:</span> <span class="n">LowRankMultivariateNormal</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

</h5>

    <div class="doc doc-contents ">

      <p>Constructs the current variational distribution of the coefficient from current variational mean and covariance.</p>
    </div>

  </div>



  <div class="doc doc-object doc-attribute">



<h5 id="bemb.model.bayesian_coefficient.BayesianCoefficient.variational_mean" class="doc doc-heading">
<code class="highlight language-python"><span class="n">variational_mean</span><span class="p">:</span> <span class="n">Tensor</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

</h5>

    <div class="doc doc-contents ">

      <p>Returns the mean of the variational distribution.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>torch.Tensor</code></td>
      <td><p>the current mean of the variational distribution with shape (num_classes, dim).</p></td>
    </tr>
  </tbody>
</table>    </div>

  </div>






  <div class="doc doc-object doc-method">



<h5 id="bemb.model.bayesian_coefficient.BayesianCoefficient.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variation</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">obs2prior</span><span class="p">,</span> <span class="n">H_zero_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">is_H</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_obs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">prior_mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">prior_variance</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h5>

    <div class="doc doc-contents ">

      <p>The Bayesian coefficient object represents a learnable tensor mu_i in R^k, where i is from a family (e.g., user, item)
    so there are num_classes * num_obs learnable weights in total.
    The prior distribution of mu_i is N(0, I) or N(H*X_obs(H shape=num_obs, X_obs shape=dim), Ix1).
    The posterior(i.e., variational) distribution of mu_i is a Gaussian distribution with learnable mean mu_i and unit covariance.
    The mean of the variational distribution consists of two parts:
        1. The fixed part, which is not learnable. This part is particularly useful when the researcher want to impose
            some structure on the variational distribution. For example, the research might have some variational mean
            learned from another model and wish to use BEMB to polish the learned mean.
        2. The flexible part, which is the main learnable part of the variational mean.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>variation</code></td>
        <td><code>str</code></td>
        <td><p>the variation # TODO: this will be removed in the next version, after we have a complete
test pipeline.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>num_classes</code></td>
        <td><code>int</code></td>
        <td><p>number of classes in the coefficient. For example, if we have user-specific coefficients,
<code>theta_user</code>, the <code>num_classes</code> should be the number of users. If we have item-specific coefficients,
the the <code>num_classes</code> should be the number of items.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>obs2prior</code></td>
        <td><code>bool</code></td>
        <td><p>whether the mean of coefficient prior depends on the observable or not.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>H_zero_mask</code></td>
        <td><code>Optional[torch.BoolTensor]</code></td>
        <td><p>to disable some of the learnable weights in the obs2prior term.
Recall that the prior is defined to be Normal(H<em>X_obs, sigma</em>I) when <code>obs2prior</code> is True.
The mask variable <code>H_zero_mask</code> will set <code>H[H_zero_mask]</code> to zeros and make them un-learnable.
This method restricts interactions between the observables and prior mean.
This is used only if <code>obs2prior</code> is True.
Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>is_H</code></td>
        <td><code>bool</code></td>
        <td><p>whether this coefficient is the H variable in the obs2prior, do you set this argument yourself!
Defaults to False.</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>num_obs</code></td>
        <td><code>int</code></td>
        <td><p>the number of observables associated with each class. For example, if the coefficient
if item-specific, and we have <code>obs2prior</code> set to True, the <code>num_obs</code> should be the number of observables
for each item.
Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>dim</code></td>
        <td><code>int</code></td>
        <td><p>the dimension of the coefficient.
Defaults to 1.</p></td>
        <td><code>1</code></td>
      </tr>
      <tr>
        <td><code>prior_mean</code></td>
        <td><code>float</code></td>
        <td><p>the mean of the prior distribution of coefficient.
Defaults to 0.0.</p></td>
        <td><code>0.0</code></td>
      </tr>
      <tr>
        <td><code>prior_variance</code></td>
        <td><code>float</code></td>
        <td><p>the variance of the prior distribution of coefficient.
Defaults to 1.0.</p></td>
        <td><code>1.0</code></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>bemb/model/bayesian_coefficient.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>             <span class="n">variation</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>             <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>             <span class="n">obs2prior</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>             <span class="n">H_zero_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">BoolTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>             <span class="n">is_H</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>             <span class="n">num_obs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>             <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>             <span class="n">prior_mean</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>             <span class="n">prior_variance</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>             <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>    <span class="sd">&quot;&quot;&quot;The Bayesian coefficient object represents a learnable tensor mu_i in R^k, where i is from a family (e.g., user, item)</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a><span class="sd">        so there are num_classes * num_obs learnable weights in total.</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a><span class="sd">        The prior distribution of mu_i is N(0, I) or N(H*X_obs(H shape=num_obs, X_obs shape=dim), Ix1).</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a><span class="sd">        The posterior(i.e., variational) distribution of mu_i is a Gaussian distribution with learnable mean mu_i and unit covariance.</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a><span class="sd">        The mean of the variational distribution consists of two parts:</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a><span class="sd">            1. The fixed part, which is not learnable. This part is particularly useful when the researcher want to impose</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a><span class="sd">                some structure on the variational distribution. For example, the research might have some variational mean</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a><span class="sd">                learned from another model and wish to use BEMB to polish the learned mean.</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a><span class="sd">            2. The flexible part, which is the main learnable part of the variational mean.</span>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a><span class="sd">        variation (str): the variation # TODO: this will be removed in the next version, after we have a complete</span>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a><span class="sd">            test pipeline.</span>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a><span class="sd">        num_classes (int): number of classes in the coefficient. For example, if we have user-specific coefficients,</span>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a><span class="sd">            `theta_user`, the `num_classes` should be the number of users. If we have item-specific coefficients,</span>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a><span class="sd">            the the `num_classes` should be the number of items.</span>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a><span class="sd">        obs2prior (bool): whether the mean of coefficient prior depends on the observable or not.</span>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a><span class="sd">        H_zero_mask (Optional[torch.BoolTensor]): to disable some of the learnable weights in the obs2prior term.</span>
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a><span class="sd">            Recall that the prior is defined to be Normal(H*X_obs, sigma*I) when `obs2prior` is True.</span>
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a><span class="sd">            The mask variable `H_zero_mask` will set `H[H_zero_mask]` to zeros and make them un-learnable.</span>
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a><span class="sd">            This method restricts interactions between the observables and prior mean.</span>
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a><span class="sd">            This is used only if `obs2prior` is True.</span>
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a><span class="sd">            Defaults to None.</span>
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a><span class="sd">        is_H (bool): whether this coefficient is the H variable in the obs2prior, do you set this argument yourself!</span>
<a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a><span class="sd">            Defaults to False.</span>
<a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a><span class="sd">        num_obs (int, optional): the number of observables associated with each class. For example, if the coefficient</span>
<a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a><span class="sd">            if item-specific, and we have `obs2prior` set to True, the `num_obs` should be the number of observables</span>
<a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a><span class="sd">            for each item.</span>
<a id="__codelineno-0-40" name="__codelineno-0-40" href="#__codelineno-0-40"></a><span class="sd">            Defaults to None.</span>
<a id="__codelineno-0-41" name="__codelineno-0-41" href="#__codelineno-0-41"></a><span class="sd">        dim (int, optional): the dimension of the coefficient.</span>
<a id="__codelineno-0-42" name="__codelineno-0-42" href="#__codelineno-0-42"></a><span class="sd">            Defaults to 1.</span>
<a id="__codelineno-0-43" name="__codelineno-0-43" href="#__codelineno-0-43"></a><span class="sd">        prior_mean (float): the mean of the prior distribution of coefficient.</span>
<a id="__codelineno-0-44" name="__codelineno-0-44" href="#__codelineno-0-44"></a><span class="sd">            Defaults to 0.0.</span>
<a id="__codelineno-0-45" name="__codelineno-0-45" href="#__codelineno-0-45"></a><span class="sd">        prior_variance (float): the variance of the prior distribution of coefficient.</span>
<a id="__codelineno-0-46" name="__codelineno-0-46" href="#__codelineno-0-46"></a><span class="sd">            Defaults to 1.0.</span>
<a id="__codelineno-0-47" name="__codelineno-0-47" href="#__codelineno-0-47"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-48" name="__codelineno-0-48" href="#__codelineno-0-48"></a>    <span class="nb">super</span><span class="p">(</span><span class="n">BayesianCoefficient</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-49" name="__codelineno-0-49" href="#__codelineno-0-49"></a>    <span class="c1"># do we use this at all? TODO: drop self.variation.</span>
<a id="__codelineno-0-50" name="__codelineno-0-50" href="#__codelineno-0-50"></a>    <span class="k">assert</span> <span class="n">variation</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;item&#39;</span><span class="p">,</span> <span class="s1">&#39;user&#39;</span><span class="p">,</span> <span class="s1">&#39;constant&#39;</span><span class="p">,</span> <span class="s1">&#39;category&#39;</span><span class="p">]</span>
<a id="__codelineno-0-51" name="__codelineno-0-51" href="#__codelineno-0-51"></a>
<a id="__codelineno-0-52" name="__codelineno-0-52" href="#__codelineno-0-52"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">variation</span> <span class="o">=</span> <span class="n">variation</span>
<a id="__codelineno-0-53" name="__codelineno-0-53" href="#__codelineno-0-53"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">obs2prior</span> <span class="o">=</span> <span class="n">obs2prior</span>
<a id="__codelineno-0-54" name="__codelineno-0-54" href="#__codelineno-0-54"></a>    <span class="k">if</span> <span class="n">variation</span> <span class="o">==</span> <span class="s1">&#39;constant&#39;</span> <span class="ow">or</span> <span class="n">variation</span> <span class="o">==</span> <span class="s1">&#39;category&#39;</span><span class="p">:</span>
<a id="__codelineno-0-55" name="__codelineno-0-55" href="#__codelineno-0-55"></a>        <span class="k">if</span> <span class="n">obs2prior</span><span class="p">:</span>
<a id="__codelineno-0-56" name="__codelineno-0-56" href="#__codelineno-0-56"></a>            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;obs2prior is not supported for constant and category variation at present.&#39;</span><span class="p">)</span>
<a id="__codelineno-0-57" name="__codelineno-0-57" href="#__codelineno-0-57"></a>
<a id="__codelineno-0-58" name="__codelineno-0-58" href="#__codelineno-0-58"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">num_classes</span>
<a id="__codelineno-0-59" name="__codelineno-0-59" href="#__codelineno-0-59"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">num_obs</span> <span class="o">=</span> <span class="n">num_obs</span>
<a id="__codelineno-0-60" name="__codelineno-0-60" href="#__codelineno-0-60"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>  <span class="c1"># the dimension of greek letter parameter.</span>
<a id="__codelineno-0-61" name="__codelineno-0-61" href="#__codelineno-0-61"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">prior_mean</span> <span class="o">=</span> <span class="n">prior_mean</span>
<a id="__codelineno-0-62" name="__codelineno-0-62" href="#__codelineno-0-62"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">prior_variance</span> <span class="o">=</span> <span class="n">prior_variance</span>
<a id="__codelineno-0-63" name="__codelineno-0-63" href="#__codelineno-0-63"></a>
<a id="__codelineno-0-64" name="__codelineno-0-64" href="#__codelineno-0-64"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">is_H</span> <span class="o">=</span> <span class="n">is_H</span>
<a id="__codelineno-0-65" name="__codelineno-0-65" href="#__codelineno-0-65"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">H_zero_mask</span> <span class="o">=</span> <span class="n">H_zero_mask</span>
<a id="__codelineno-0-66" name="__codelineno-0-66" href="#__codelineno-0-66"></a>
<a id="__codelineno-0-67" name="__codelineno-0-67" href="#__codelineno-0-67"></a>    <span class="c1"># assert self.prior_variance &gt; 0</span>
<a id="__codelineno-0-68" name="__codelineno-0-68" href="#__codelineno-0-68"></a>
<a id="__codelineno-0-69" name="__codelineno-0-69" href="#__codelineno-0-69"></a>    <span class="c1"># create prior distribution.</span>
<a id="__codelineno-0-70" name="__codelineno-0-70" href="#__codelineno-0-70"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">obs2prior</span><span class="p">:</span>
<a id="__codelineno-0-71" name="__codelineno-0-71" href="#__codelineno-0-71"></a>        <span class="c1"># the mean of prior distribution depends on observables.</span>
<a id="__codelineno-0-72" name="__codelineno-0-72" href="#__codelineno-0-72"></a>        <span class="c1"># initiate a Bayesian Coefficient with shape (dim, num_obs) standard Gaussian.</span>
<a id="__codelineno-0-73" name="__codelineno-0-73" href="#__codelineno-0-73"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">prior_H</span> <span class="o">=</span> <span class="n">BayesianCoefficient</span><span class="p">(</span><span class="n">variation</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">,</span>
<a id="__codelineno-0-74" name="__codelineno-0-74" href="#__codelineno-0-74"></a>                                           <span class="n">num_classes</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span>
<a id="__codelineno-0-75" name="__codelineno-0-75" href="#__codelineno-0-75"></a>                                           <span class="n">obs2prior</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-76" name="__codelineno-0-76" href="#__codelineno-0-76"></a>                                           <span class="n">dim</span><span class="o">=</span><span class="n">num_obs</span><span class="p">,</span>
<a id="__codelineno-0-77" name="__codelineno-0-77" href="#__codelineno-0-77"></a>                                           <span class="n">prior_variance</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-78" name="__codelineno-0-78" href="#__codelineno-0-78"></a>                                           <span class="n">H_zero_mask</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">H_zero_mask</span><span class="p">,</span>
<a id="__codelineno-0-79" name="__codelineno-0-79" href="#__codelineno-0-79"></a>                                           <span class="n">is_H</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># this is a distribution responsible for the obs2prior H term.</span>
<a id="__codelineno-0-80" name="__codelineno-0-80" href="#__codelineno-0-80"></a>
<a id="__codelineno-0-81" name="__codelineno-0-81" href="#__codelineno-0-81"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-82" name="__codelineno-0-82" href="#__codelineno-0-82"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
<a id="__codelineno-0-83" name="__codelineno-0-83" href="#__codelineno-0-83"></a>            <span class="s1">&#39;prior_zero_mean&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_mean</span><span class="p">))</span>
<a id="__codelineno-0-84" name="__codelineno-0-84" href="#__codelineno-0-84"></a>
<a id="__codelineno-0-85" name="__codelineno-0-85" href="#__codelineno-0-85"></a>    <span class="c1"># self.prior_cov_factor = nn.Parameter(torch.zeros(num_classes, dim, 1), requires_grad=False)</span>
<a id="__codelineno-0-86" name="__codelineno-0-86" href="#__codelineno-0-86"></a>    <span class="c1"># self.prior_cov_diag = nn.Parameter(torch.ones(num_classes, dim), requires_grad=False)</span>
<a id="__codelineno-0-87" name="__codelineno-0-87" href="#__codelineno-0-87"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;prior_cov_factor&#39;</span><span class="p">,</span>
<a id="__codelineno-0-88" name="__codelineno-0-88" href="#__codelineno-0-88"></a>                         <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<a id="__codelineno-0-89" name="__codelineno-0-89" href="#__codelineno-0-89"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;prior_cov_diag&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
<a id="__codelineno-0-90" name="__codelineno-0-90" href="#__codelineno-0-90"></a>        <span class="n">num_classes</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_variance</span><span class="p">)</span>
<a id="__codelineno-0-91" name="__codelineno-0-91" href="#__codelineno-0-91"></a>
<a id="__codelineno-0-92" name="__codelineno-0-92" href="#__codelineno-0-92"></a>    <span class="c1"># create variational distribution.</span>
<a id="__codelineno-0-93" name="__codelineno-0-93" href="#__codelineno-0-93"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">variational_mean_flexible</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
<a id="__codelineno-0-94" name="__codelineno-0-94" href="#__codelineno-0-94"></a>        <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">dim</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-95" name="__codelineno-0-95" href="#__codelineno-0-95"></a>
<a id="__codelineno-0-96" name="__codelineno-0-96" href="#__codelineno-0-96"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_H</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">H_zero_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-97" name="__codelineno-0-97" href="#__codelineno-0-97"></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">H_zero_mask</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">variational_mean_flexible</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> \
<a id="__codelineno-0-98" name="__codelineno-0-98" href="#__codelineno-0-98"></a>            <span class="sa">f</span><span class="s2">&quot;The H_zero_mask should have exactly the shape as the H variable, `H_zero_mask`.shape is </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">H_zero_mask</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, `H`.shape is </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">variational_mean_flexible</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> &quot;</span>
<a id="__codelineno-0-99" name="__codelineno-0-99" href="#__codelineno-0-99"></a>
<a id="__codelineno-0-100" name="__codelineno-0-100" href="#__codelineno-0-100"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">variational_logstd</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
<a id="__codelineno-0-101" name="__codelineno-0-101" href="#__codelineno-0-101"></a>        <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">dim</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-102" name="__codelineno-0-102" href="#__codelineno-0-102"></a>
<a id="__codelineno-0-103" name="__codelineno-0-103" href="#__codelineno-0-103"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;variational_cov_factor&#39;</span><span class="p">,</span>
<a id="__codelineno-0-104" name="__codelineno-0-104" href="#__codelineno-0-104"></a>                         <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<a id="__codelineno-0-105" name="__codelineno-0-105" href="#__codelineno-0-105"></a>
<a id="__codelineno-0-106" name="__codelineno-0-106" href="#__codelineno-0-106"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">variational_mean_fixed</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="bemb.model.bayesian_coefficient.BayesianCoefficient.__repr__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h5>

    <div class="doc doc-contents ">

      <p>Constructs a string representation of the Bayesian coefficient object.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>str</code></td>
      <td><p>the string representation of the Bayesian coefficient object.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>bemb/model/bayesian_coefficient.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="sd">&quot;&quot;&quot;Constructs a string representation of the Bayesian coefficient object.</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="sd">        str: the string representation of the Bayesian coefficient object.</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">obs2prior</span><span class="p">:</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>        <span class="n">prior_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;prior=N(H*X_obs(H shape=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_H</span><span class="o">.</span><span class="n">prior_zero_mean</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">, X_obs shape=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_H</span><span class="o">.</span><span class="n">dim</span><span class="si">}</span><span class="s1">), Ix</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_variance</span><span class="si">}</span><span class="s1">)&#39;</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>        <span class="n">prior_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;prior=N(0, I)&#39;</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    <span class="k">return</span> <span class="sa">f</span><span class="s1">&#39;BayesianCoefficient(num_classes=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="si">}</span><span class="s1">, dimension=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">prior_str</span><span class="si">}</span><span class="s1">)&#39;</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="bemb.model.bayesian_coefficient.BayesianCoefficient.log_prior" class="doc doc-heading">
<code class="highlight language-python"><span class="n">log_prior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample</span><span class="p">,</span> <span class="n">H_sample</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">x_obs</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>Computes the logP_{Prior}(Coefficient Sample) for provided samples of the coefficient. The prior will either be a
zero-mean Gaussian (if <code>obs2prior</code> is False) or a Gaussian with a learnable mean (if <code>obs2prior</code> is True).</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>sample</code></td>
        <td><code>torch.Tensor</code></td>
        <td><p>Monte Carlo samples of the variable with shape (num_seeds, num_classes, dim), where
sample[i, :, :] corresponds to one sample of the coefficient.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>#</code></td>
        <td><code>arguments required only if `obs2prior == True`</code></td>
        <td></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>H_sample</code></td>
        <td><code>Optional[torch.Tensor]</code></td>
        <td><p>Monte Carlo samples of the weight in obs2prior term, with shape
(num_seeds, dim, self.num_obs), this is required if and only if obs2prior == True.
Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>x_obs</code></td>
        <td><code>Optional[torch.Tensor]</code></td>
        <td><p>observables for obs2prior with shape (num_classes, num_obs),
only required if and only if obs2prior == True.
Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>torch.Tensor</code></td>
      <td><p>the log prior of the variable with shape (num_seeds, num_classes).</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>bemb/model/bayesian_coefficient.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="nf">log_prior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>              <span class="n">sample</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>              <span class="n">H_sample</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>              <span class="n">x_obs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="sd">    Computes the logP_{Prior}(Coefficient Sample) for provided samples of the coefficient. The prior will either be a</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="sd">    zero-mean Gaussian (if `obs2prior` is False) or a Gaussian with a learnable mean (if `obs2prior` is True).</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a><span class="sd">        sample (torch.Tensor): Monte Carlo samples of the variable with shape (num_seeds, num_classes, dim), where</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a><span class="sd">            sample[i, :, :] corresponds to one sample of the coefficient.</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a><span class="sd">        # arguments required only if `obs2prior == True`:</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a><span class="sd">        H_sample (Optional[torch.Tensor], optional): Monte Carlo samples of the weight in obs2prior term, with shape</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a><span class="sd">            (num_seeds, dim, self.num_obs), this is required if and only if obs2prior == True.</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a><span class="sd">            Defaults to None.</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a><span class="sd">        x_obs (Optional[torch.Tensor], optional): observables for obs2prior with shape (num_classes, num_obs),</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a><span class="sd">            only required if and only if obs2prior == True.</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a><span class="sd">            Defaults to None.</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a><span class="sd">        torch.Tensor: the log prior of the variable with shape (num_seeds, num_classes).</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>    <span class="c1"># p(sample)</span>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a>    <span class="n">num_seeds</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a>    <span class="c1"># shape (num_seeds, num_classes)</span>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">obs2prior</span><span class="p">:</span>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a>        <span class="k">assert</span> <span class="n">H_sample</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_seeds</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_obs</span><span class="p">)</span>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a>        <span class="k">assert</span> <span class="n">x_obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_obs</span><span class="p">)</span>
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a>        <span class="n">x_obs</span> <span class="o">=</span> <span class="n">x_obs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_obs</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span>
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a>            <span class="n">num_seeds</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a>        <span class="n">H_sample</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">H_sample</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a>        <span class="k">assert</span> <span class="n">H_sample</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_seeds</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_obs</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a>        <span class="n">mu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">x_obs</span><span class="p">,</span> <span class="n">H_sample</span><span class="p">)</span>
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a>        <span class="k">assert</span> <span class="n">mu</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_seeds</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
<a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a>
<a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a>        <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_zero_mean</span>
<a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a>    <span class="n">out</span> <span class="o">=</span> <span class="n">LowRankMultivariateNormal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span>
<a id="__codelineno-0-40" name="__codelineno-0-40" href="#__codelineno-0-40"></a>                                    <span class="n">cov_factor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_cov_factor</span><span class="p">,</span>
<a id="__codelineno-0-41" name="__codelineno-0-41" href="#__codelineno-0-41"></a>                                    <span class="n">cov_diag</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_cov_diag</span><span class="p">)</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
<a id="__codelineno-0-42" name="__codelineno-0-42" href="#__codelineno-0-42"></a>    <span class="k">assert</span> <span class="n">out</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_seeds</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
<a id="__codelineno-0-43" name="__codelineno-0-43" href="#__codelineno-0-43"></a>    <span class="k">return</span> <span class="n">out</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="bemb.model.bayesian_coefficient.BayesianCoefficient.log_variational" class="doc doc-heading">
<code class="highlight language-python"><span class="n">log_variational</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>Given a set of sampled values of coefficients, with shape (num_seeds, num_classes, dim), computes the
    the log probability of these sampled values of coefficients under the current variational distribution.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>sample</code></td>
        <td><code>torch.Tensor</code></td>
        <td><p>a tensor of shape (num_seeds, num_classes, dim) containing sampled values of coefficients,
where sample[i, :, :] corresponds to one sample of the coefficient.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>torch.Tensor</code></td>
      <td><p>a tensor of shape (num_seeds, num_classes) containing the log probability of provided samples
    under the variational distribution. The output is splitted by random seeds and classes, you can sum
    along the second axis (i.e., the num_classes axis) to get the total log probability.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>bemb/model/bayesian_coefficient.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="nf">log_variational</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="sd">&quot;&quot;&quot;Given a set of sampled values of coefficients, with shape (num_seeds, num_classes, dim), computes the</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="sd">        the log probability of these sampled values of coefficients under the current variational distribution.</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="sd">        sample (torch.Tensor): a tensor of shape (num_seeds, num_classes, dim) containing sampled values of coefficients,</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="sd">            where sample[i, :, :] corresponds to one sample of the coefficient.</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a><span class="sd">        torch.Tensor: a tensor of shape (num_seeds, num_classes) containing the log probability of provided samples</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a><span class="sd">            under the variational distribution. The output is splitted by random seeds and classes, you can sum</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a><span class="sd">            along the second axis (i.e., the num_classes axis) to get the total log probability.</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>    <span class="n">num_seeds</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">variational_distribution</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>    <span class="k">assert</span> <span class="n">out</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_seeds</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>    <span class="k">return</span> <span class="n">out</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="bemb.model.bayesian_coefficient.BayesianCoefficient.rsample" class="doc doc-heading">
<code class="highlight language-python"><span class="n">rsample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_seeds</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>Samples values of the coefficient from the variational distribution using re-parameterization trick.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>num_seeds</code></td>
        <td><code>int</code></td>
        <td><p>number of values to be sampled. Defaults to 1.</p></td>
        <td><code>1</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Union[torch.Tensor, Tuple[torch.Tensor]]</code></td>
      <td><p>if <code>obs2prior</code> is disabled, returns a tensor of shape (num_seeds, num_classes, dim)
    where each output[i, :, :] corresponds to one sample of the coefficient.
    If <code>obs2prior</code> is enabled, returns a tuple of samples: (1) a tensor of shape (num_seeds, num_classes, dim) containing
    sampled values of coefficient, and (2) a tensor o shape (num_seeds, dim, num_obs) containing samples of the H weight
    in the prior distribution.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>bemb/model/bayesian_coefficient.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="nf">rsample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_seeds</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="sd">&quot;&quot;&quot;Samples values of the coefficient from the variational distribution using re-parameterization trick.</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="sd">        num_seeds (int, optional): number of values to be sampled. Defaults to 1.</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="sd">        Union[torch.Tensor, Tuple[torch.Tensor]]: if `obs2prior` is disabled, returns a tensor of shape (num_seeds, num_classes, dim)</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="sd">            where each output[i, :, :] corresponds to one sample of the coefficient.</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a><span class="sd">            If `obs2prior` is enabled, returns a tuple of samples: (1) a tensor of shape (num_seeds, num_classes, dim) containing</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a><span class="sd">            sampled values of coefficient, and (2) a tensor o shape (num_seeds, dim, num_obs) containing samples of the H weight</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a><span class="sd">            in the prior distribution.</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>    <span class="n">value_sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">variational_distribution</span><span class="o">.</span><span class="n">rsample</span><span class="p">(</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>        <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">num_seeds</span><span class="p">]))</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">obs2prior</span><span class="p">:</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>        <span class="c1"># sample obs2prior H as well.</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>        <span class="n">H_sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_H</span><span class="o">.</span><span class="n">rsample</span><span class="p">(</span><span class="n">num_seeds</span><span class="o">=</span><span class="n">num_seeds</span><span class="p">)</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>        <span class="k">return</span> <span class="p">(</span><span class="n">value_sample</span><span class="p">,</span> <span class="n">H_sample</span><span class="p">)</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>        <span class="k">return</span> <span class="n">value_sample</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="bemb.model.bayesian_coefficient.BayesianCoefficient.update_variational_mean_fixed" class="doc doc-heading">
<code class="highlight language-python"><span class="n">update_variational_mean_fixed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_value</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>Updates the fixed part of the mean of the variational distribution.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>new_value</code></td>
        <td><code>torch.Tensor</code></td>
        <td><p>the new value of the fixed part of the mean of the variational distribution.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>bemb/model/bayesian_coefficient.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="nf">update_variational_mean_fixed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="sd">&quot;&quot;&quot;Updates the fixed part of the mean of the variational distribution.</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="sd">        new_value (torch.Tensor): the new value of the fixed part of the mean of the variational distribution.</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="k">assert</span> <span class="n">new_value</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">variational_mean_flexible</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">variational_mean_fixed</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;variational_mean_fixed&#39;</span><span class="p">,</span> <span class="n">new_value</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>







  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h3 id="bemb.model.bayesian_linear" class="doc doc-heading">
        <code>bayesian_linear</code>



</h3>

    <div class="doc doc-contents ">

      <p>Bayesian tensor object.</p>



  <div class="doc doc-children">







  <div class="doc doc-object doc-class">



<h4 id="bemb.model.bayesian_linear.BayesianLinear" class="doc doc-heading">
        <code>
BayesianLinear            (<span title="torch.nn.modules.module.Module">Module</span>)
        </code>



</h4>

    <div class="doc doc-contents ">


        <details class="quote">
          <summary>Source code in <code>bemb/model/bayesian_linear.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">class</span> <span class="nc">BayesianLinear</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>                 <span class="n">in_features</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>                 <span class="n">out_features</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>                 <span class="n">bias</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>                 <span class="n">W_variational_mean_fixed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>                 <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>                 <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>                 <span class="n">W_prior_variance</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>                 <span class="n">b_prior_variance</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="mf">1.0</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>                 <span class="p">):</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>        <span class="sd">&quot;&quot;&quot;Linear layer where weight and bias are modelled as distributions.</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>        <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;dtype is not Supported yet.&#39;</span><span class="p">)</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">in_features</span> <span class="o">=</span> <span class="n">in_features</span>  <span class="c1"># the same as number of classes before.</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">out_features</span> <span class="o">=</span> <span class="n">out_features</span>  <span class="c1"># the same as latent dimension before.</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">bias</span>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>        <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>        <span class="c1"># prior distributions for mean and bias.</span>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>        <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a>        <span class="c1"># the prior of weights are gausssian distributions independent across in_feature dimensions.</span>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;W_prior_mean&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">))</span>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;W_prior_logstd&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">W_prior_variance</span><span class="p">))</span>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">:</span>
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;b_prior_mean&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">))</span>
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;b_prior_logstd&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">b_prior_variance</span><span class="p">))</span>
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a>
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a>        <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a>        <span class="c1"># variational distributions for weight and bias.</span>
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a>        <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a>        <span class="k">if</span> <span class="n">W_variational_mean_fixed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">W_variational_mean_fixed</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a>            <span class="k">assert</span> <span class="n">W_variational_mean_fixed</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">),</span> \
<a id="__codelineno-0-40" name="__codelineno-0-40" href="#__codelineno-0-40"></a>                <span class="sa">f</span><span class="s1">&#39;W_variational_mean_fixed tensor should have shape (in_features, out_features), got </span><span class="si">{</span><span class="n">W_variational_mean_fixed</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span>
<a id="__codelineno-0-41" name="__codelineno-0-41" href="#__codelineno-0-41"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;W_variational_mean_fixed&#39;</span><span class="p">,</span> <span class="n">W_variational_mean_fixed</span><span class="p">)</span>
<a id="__codelineno-0-42" name="__codelineno-0-42" href="#__codelineno-0-42"></a>
<a id="__codelineno-0-43" name="__codelineno-0-43" href="#__codelineno-0-43"></a>        <span class="c1"># TODO: optionally add customizable initialization here.</span>
<a id="__codelineno-0-44" name="__codelineno-0-44" href="#__codelineno-0-44"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_variational_mean_flexible</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-45" name="__codelineno-0-45" href="#__codelineno-0-45"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_variational_logstd</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-46" name="__codelineno-0-46" href="#__codelineno-0-46"></a>
<a id="__codelineno-0-47" name="__codelineno-0-47" href="#__codelineno-0-47"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">:</span>
<a id="__codelineno-0-48" name="__codelineno-0-48" href="#__codelineno-0-48"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">b_variational_mean</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">out_features</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-49" name="__codelineno-0-49" href="#__codelineno-0-49"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">b_variational_logstd</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">out_features</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-50" name="__codelineno-0-50" href="#__codelineno-0-50"></a>
<a id="__codelineno-0-51" name="__codelineno-0-51" href="#__codelineno-0-51"></a>        <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-52" name="__codelineno-0-52" href="#__codelineno-0-52"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-53" name="__codelineno-0-53" href="#__codelineno-0-53"></a>
<a id="__codelineno-0-54" name="__codelineno-0-54" href="#__codelineno-0-54"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_sample</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-55" name="__codelineno-0-55" href="#__codelineno-0-55"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">b_sample</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-56" name="__codelineno-0-56" href="#__codelineno-0-56"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_seeds</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-57" name="__codelineno-0-57" href="#__codelineno-0-57"></a>
<a id="__codelineno-0-58" name="__codelineno-0-58" href="#__codelineno-0-58"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-59" name="__codelineno-0-59" href="#__codelineno-0-59"></a>    <span class="k">def</span> <span class="nf">W_variational_mean</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-60" name="__codelineno-0-60" href="#__codelineno-0-60"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_variational_mean_fixed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-61" name="__codelineno-0-61" href="#__codelineno-0-61"></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_variational_mean_flexible</span>
<a id="__codelineno-0-62" name="__codelineno-0-62" href="#__codelineno-0-62"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-63" name="__codelineno-0-63" href="#__codelineno-0-63"></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_variational_mean_fixed</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_variational_mean_flexible</span>
<a id="__codelineno-0-64" name="__codelineno-0-64" href="#__codelineno-0-64"></a>
<a id="__codelineno-0-65" name="__codelineno-0-65" href="#__codelineno-0-65"></a>    <span class="k">def</span> <span class="nf">rsample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_seeds</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]]:</span>
<a id="__codelineno-0-66" name="__codelineno-0-66" href="#__codelineno-0-66"></a>        <span class="sd">&quot;&quot;&quot;sample all parameters using re-parameterization trick.</span>
<a id="__codelineno-0-67" name="__codelineno-0-67" href="#__codelineno-0-67"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-68" name="__codelineno-0-68" href="#__codelineno-0-68"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_seeds</span> <span class="o">=</span> <span class="n">num_seeds</span>
<a id="__codelineno-0-69" name="__codelineno-0-69" href="#__codelineno-0-69"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_variational_distribution</span><span class="o">.</span><span class="n">rsample</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">num_seeds</span><span class="p">]))</span>
<a id="__codelineno-0-70" name="__codelineno-0-70" href="#__codelineno-0-70"></a>
<a id="__codelineno-0-71" name="__codelineno-0-71" href="#__codelineno-0-71"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">:</span>
<a id="__codelineno-0-72" name="__codelineno-0-72" href="#__codelineno-0-72"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">b_sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_variational_distribution</span><span class="o">.</span><span class="n">rsample</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">num_seeds</span><span class="p">]))</span>
<a id="__codelineno-0-73" name="__codelineno-0-73" href="#__codelineno-0-73"></a>
<a id="__codelineno-0-74" name="__codelineno-0-74" href="#__codelineno-0-74"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_sample</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_sample</span>
<a id="__codelineno-0-75" name="__codelineno-0-75" href="#__codelineno-0-75"></a>
<a id="__codelineno-0-76" name="__codelineno-0-76" href="#__codelineno-0-76"></a>    <span class="k">def</span> <span class="nf">dsample</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-77" name="__codelineno-0-77" href="#__codelineno-0-77"></a>        <span class="sd">&quot;&quot;&quot;Deterministic sample method, set (W, b) sample to the mean of variational distribution.&quot;&quot;&quot;</span>
<a id="__codelineno-0-78" name="__codelineno-0-78" href="#__codelineno-0-78"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_seeds</span> <span class="o">=</span> <span class="mi">1</span>
<a id="__codelineno-0-79" name="__codelineno-0-79" href="#__codelineno-0-79"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_variational_mean</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-80" name="__codelineno-0-80" href="#__codelineno-0-80"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">:</span>
<a id="__codelineno-0-81" name="__codelineno-0-81" href="#__codelineno-0-81"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">b_sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_variational_mean</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-82" name="__codelineno-0-82" href="#__codelineno-0-82"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_sample</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_sample</span>
<a id="__codelineno-0-83" name="__codelineno-0-83" href="#__codelineno-0-83"></a>
<a id="__codelineno-0-84" name="__codelineno-0-84" href="#__codelineno-0-84"></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mode</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="s1">&#39;multiply&#39;</span><span class="p">):</span>
<a id="__codelineno-0-85" name="__codelineno-0-85" href="#__codelineno-0-85"></a>        <span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-86" name="__codelineno-0-86" href="#__codelineno-0-86"></a><span class="sd">        Forward with weight sampling. Forward does out = XW + b, for forward() method behaves like the embedding layer</span>
<a id="__codelineno-0-87" name="__codelineno-0-87" href="#__codelineno-0-87"></a><span class="sd">        in PyTorch, use the lookup() method.</span>
<a id="__codelineno-0-88" name="__codelineno-0-88" href="#__codelineno-0-88"></a><span class="sd">        To have determinstic results, call self.dsample() before executing.</span>
<a id="__codelineno-0-89" name="__codelineno-0-89" href="#__codelineno-0-89"></a><span class="sd">        To have stochastic results, call self.rsample() before executing.</span>
<a id="__codelineno-0-90" name="__codelineno-0-90" href="#__codelineno-0-90"></a><span class="sd">        mode in [&#39;multiply&#39;, &#39;lookup&#39;]</span>
<a id="__codelineno-0-91" name="__codelineno-0-91" href="#__codelineno-0-91"></a>
<a id="__codelineno-0-92" name="__codelineno-0-92" href="#__codelineno-0-92"></a><span class="sd">        output shape: (num_seeds, batch_size, out_features).</span>
<a id="__codelineno-0-93" name="__codelineno-0-93" href="#__codelineno-0-93"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-94" name="__codelineno-0-94" href="#__codelineno-0-94"></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_seeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;run BayesianLinear.rsample() or dsample() first to sample weight and bias.&#39;</span>
<a id="__codelineno-0-95" name="__codelineno-0-95" href="#__codelineno-0-95"></a>
<a id="__codelineno-0-96" name="__codelineno-0-96" href="#__codelineno-0-96"></a>        <span class="c1"># if determinstic, num_seeds is set to 1.</span>
<a id="__codelineno-0-97" name="__codelineno-0-97" href="#__codelineno-0-97"></a>        <span class="c1"># w: (num_seeds, in_features=num_classes, out_features)</span>
<a id="__codelineno-0-98" name="__codelineno-0-98" href="#__codelineno-0-98"></a>        <span class="c1"># b: (num_seeds, out_features)</span>
<a id="__codelineno-0-99" name="__codelineno-0-99" href="#__codelineno-0-99"></a>        <span class="c1"># x: (N, in_features) if multiply and (N,) if lookup.</span>
<a id="__codelineno-0-100" name="__codelineno-0-100" href="#__codelineno-0-100"></a>        <span class="c1"># output: (num_seeds, N, out_features)</span>
<a id="__codelineno-0-101" name="__codelineno-0-101" href="#__codelineno-0-101"></a>
<a id="__codelineno-0-102" name="__codelineno-0-102" href="#__codelineno-0-102"></a>        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;multiply&#39;</span><span class="p">:</span>
<a id="__codelineno-0-103" name="__codelineno-0-103" href="#__codelineno-0-103"></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_features</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_seeds</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (num_seeds, N, in_features)</span>
<a id="__codelineno-0-104" name="__codelineno-0-104" href="#__codelineno-0-104"></a>            <span class="n">out</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_sample</span><span class="p">)</span>  <span class="c1"># (num_seeds, N, out_features)</span>
<a id="__codelineno-0-105" name="__codelineno-0-105" href="#__codelineno-0-105"></a>        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;lookup&#39;</span><span class="p">:</span>
<a id="__codelineno-0-106" name="__codelineno-0-106" href="#__codelineno-0-106"></a>            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_sample</span><span class="p">[:,</span> <span class="n">x</span><span class="p">,</span> <span class="p">:]</span>  <span class="c1"># (num_seeds, N, out_features)</span>
<a id="__codelineno-0-107" name="__codelineno-0-107" href="#__codelineno-0-107"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-108" name="__codelineno-0-108" href="#__codelineno-0-108"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;mode=</span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s1"> is not allowed.&#39;</span><span class="p">)</span>
<a id="__codelineno-0-109" name="__codelineno-0-109" href="#__codelineno-0-109"></a>
<a id="__codelineno-0-110" name="__codelineno-0-110" href="#__codelineno-0-110"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">:</span>
<a id="__codelineno-0-111" name="__codelineno-0-111" href="#__codelineno-0-111"></a>            <span class="n">out</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_sample</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_seeds</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_features</span><span class="p">)</span>
<a id="__codelineno-0-112" name="__codelineno-0-112" href="#__codelineno-0-112"></a>
<a id="__codelineno-0-113" name="__codelineno-0-113" href="#__codelineno-0-113"></a>        <span class="c1"># (num_seeds, N, out_features)</span>
<a id="__codelineno-0-114" name="__codelineno-0-114" href="#__codelineno-0-114"></a>        <span class="k">return</span> <span class="n">out</span>
<a id="__codelineno-0-115" name="__codelineno-0-115" href="#__codelineno-0-115"></a>
<a id="__codelineno-0-116" name="__codelineno-0-116" href="#__codelineno-0-116"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-117" name="__codelineno-0-117" href="#__codelineno-0-117"></a>    <span class="k">def</span> <span class="nf">W_variational_distribution</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-118" name="__codelineno-0-118" href="#__codelineno-0-118"></a>        <span class="sd">&quot;&quot;&quot;the weight variational distribution.&quot;&quot;&quot;</span>
<a id="__codelineno-0-119" name="__codelineno-0-119" href="#__codelineno-0-119"></a>        <span class="k">return</span> <span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">W_variational_mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_variational_logstd</span><span class="p">))</span>
<a id="__codelineno-0-120" name="__codelineno-0-120" href="#__codelineno-0-120"></a>
<a id="__codelineno-0-121" name="__codelineno-0-121" href="#__codelineno-0-121"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-122" name="__codelineno-0-122" href="#__codelineno-0-122"></a>    <span class="k">def</span> <span class="nf">b_variational_distribution</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-123" name="__codelineno-0-123" href="#__codelineno-0-123"></a>        <span class="k">return</span> <span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">b_variational_mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_variational_logstd</span><span class="p">))</span>
<a id="__codelineno-0-124" name="__codelineno-0-124" href="#__codelineno-0-124"></a>
<a id="__codelineno-0-125" name="__codelineno-0-125" href="#__codelineno-0-125"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-126" name="__codelineno-0-126" href="#__codelineno-0-126"></a>    <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
<a id="__codelineno-0-127" name="__codelineno-0-127" href="#__codelineno-0-127"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_variational_mean</span><span class="o">.</span><span class="n">device</span>
<a id="__codelineno-0-128" name="__codelineno-0-128" href="#__codelineno-0-128"></a>
<a id="__codelineno-0-129" name="__codelineno-0-129" href="#__codelineno-0-129"></a>    <span class="k">def</span> <span class="nf">log_prior</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-130" name="__codelineno-0-130" href="#__codelineno-0-130"></a>        <span class="sd">&quot;&quot;&quot;Evaluate the likelihood of the provided samples of parameter under the current prior distribution.&quot;&quot;&quot;</span>
<a id="__codelineno-0-131" name="__codelineno-0-131" href="#__codelineno-0-131"></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_seeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;run BayesianLinear.rsample() or dsample() first to sample weight and bias.&#39;</span>
<a id="__codelineno-0-132" name="__codelineno-0-132" href="#__codelineno-0-132"></a>        <span class="n">num_seeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_sample</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-133" name="__codelineno-0-133" href="#__codelineno-0-133"></a>        <span class="n">total_log_prob</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_seeds</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-134" name="__codelineno-0-134" href="#__codelineno-0-134"></a>        <span class="c1"># log P(W_sample). shape = (num_seeds,)</span>
<a id="__codelineno-0-135" name="__codelineno-0-135" href="#__codelineno-0-135"></a>        <span class="n">W_prior</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">W_prior_mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_prior_logstd</span><span class="p">))</span>
<a id="__codelineno-0-136" name="__codelineno-0-136" href="#__codelineno-0-136"></a>        <span class="n">total_log_prob</span> <span class="o">+=</span> <span class="n">W_prior</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_sample</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<a id="__codelineno-0-137" name="__codelineno-0-137" href="#__codelineno-0-137"></a>
<a id="__codelineno-0-138" name="__codelineno-0-138" href="#__codelineno-0-138"></a>        <span class="c1"># log P(b_sample) if applicable.</span>
<a id="__codelineno-0-139" name="__codelineno-0-139" href="#__codelineno-0-139"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">:</span>
<a id="__codelineno-0-140" name="__codelineno-0-140" href="#__codelineno-0-140"></a>            <span class="n">b_prior</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">b_prior_mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_prior_logstd</span><span class="p">))</span>
<a id="__codelineno-0-141" name="__codelineno-0-141" href="#__codelineno-0-141"></a>            <span class="n">total_log_prob</span> <span class="o">+=</span> <span class="n">b_prior</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_sample</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-142" name="__codelineno-0-142" href="#__codelineno-0-142"></a>
<a id="__codelineno-0-143" name="__codelineno-0-143" href="#__codelineno-0-143"></a>        <span class="k">assert</span> <span class="n">total_log_prob</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_seeds</span><span class="p">,)</span>
<a id="__codelineno-0-144" name="__codelineno-0-144" href="#__codelineno-0-144"></a>        <span class="k">return</span> <span class="n">total_log_prob</span>
<a id="__codelineno-0-145" name="__codelineno-0-145" href="#__codelineno-0-145"></a>
<a id="__codelineno-0-146" name="__codelineno-0-146" href="#__codelineno-0-146"></a>    <span class="k">def</span> <span class="nf">log_variational</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-147" name="__codelineno-0-147" href="#__codelineno-0-147"></a>        <span class="sd">&quot;&quot;&quot;Evaluate the likelihood of the provided samples of parameter under the current variational distribution.&quot;&quot;&quot;</span>
<a id="__codelineno-0-148" name="__codelineno-0-148" href="#__codelineno-0-148"></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_seeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;run BayesianLinear.rsample() or dsample() first to sample weight and bias.&#39;</span>
<a id="__codelineno-0-149" name="__codelineno-0-149" href="#__codelineno-0-149"></a>        <span class="n">num_seeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_sample</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-150" name="__codelineno-0-150" href="#__codelineno-0-150"></a>
<a id="__codelineno-0-151" name="__codelineno-0-151" href="#__codelineno-0-151"></a>        <span class="n">total_log_prob</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_seeds</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-152" name="__codelineno-0-152" href="#__codelineno-0-152"></a>        <span class="n">total_log_prob</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_variational_distribution</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_sample</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<a id="__codelineno-0-153" name="__codelineno-0-153" href="#__codelineno-0-153"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">:</span>
<a id="__codelineno-0-154" name="__codelineno-0-154" href="#__codelineno-0-154"></a>            <span class="n">total_log_prob</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_variational_distribution</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_sample</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-155" name="__codelineno-0-155" href="#__codelineno-0-155"></a>        <span class="k">assert</span> <span class="n">total_log_prob</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_seeds</span><span class="p">,)</span>
<a id="__codelineno-0-156" name="__codelineno-0-156" href="#__codelineno-0-156"></a>        <span class="k">return</span> <span class="n">total_log_prob</span>
<a id="__codelineno-0-157" name="__codelineno-0-157" href="#__codelineno-0-157"></a>
<a id="__codelineno-0-158" name="__codelineno-0-158" href="#__codelineno-0-158"></a>    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-159" name="__codelineno-0-159" href="#__codelineno-0-159"></a>        <span class="n">prior_info</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;W_prior ~ N(mu=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">W_prior_mean</span><span class="si">}</span><span class="s1">, logstd=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">W_prior_logstd</span><span class="si">}</span><span class="s1">)&#39;</span>
<a id="__codelineno-0-160" name="__codelineno-0-160" href="#__codelineno-0-160"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">:</span>
<a id="__codelineno-0-161" name="__codelineno-0-161" href="#__codelineno-0-161"></a>            <span class="n">prior_info</span> <span class="o">+=</span> <span class="sa">f</span><span class="s1">&#39;b_prior ~ N(mu=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">b_prior_mean</span><span class="si">}</span><span class="s1">, logstd=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">b_prior_logstd</span><span class="si">}</span><span class="s1">)&#39;</span>
<a id="__codelineno-0-162" name="__codelineno-0-162" href="#__codelineno-0-162"></a>        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;BayesianLinear(in_features=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">in_features</span><span class="si">}</span><span class="s2">, out_features=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">out_features</span><span class="si">}</span><span class="s2">, bias=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">prior_info</span><span class="si">}</span><span class="s2">)&quot;</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">






  <div class="doc doc-object doc-attribute">



<h5 id="bemb.model.bayesian_linear.BayesianLinear.W_variational_distribution" class="doc doc-heading">
<code class="highlight language-python"><span class="n">W_variational_distribution</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

</h5>

    <div class="doc doc-contents ">

      <p>the weight variational distribution.</p>
    </div>

  </div>









  <div class="doc doc-object doc-method">



<h5 id="bemb.model.bayesian_linear.BayesianLinear.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">W_variational_mean_fixed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">W_prior_variance</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">b_prior_variance</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h5>

    <div class="doc doc-contents ">

      <p>Linear layer where weight and bias are modelled as distributions.</p>

        <details class="quote">
          <summary>Source code in <code>bemb/model/bayesian_linear.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>             <span class="n">in_features</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>             <span class="n">out_features</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>             <span class="n">bias</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>             <span class="n">W_variational_mean_fixed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>             <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>             <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>             <span class="n">W_prior_variance</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>             <span class="n">b_prior_variance</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="mf">1.0</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>             <span class="p">):</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    <span class="sd">&quot;&quot;&quot;Linear layer where weight and bias are modelled as distributions.</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;dtype is not Supported yet.&#39;</span><span class="p">)</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">in_features</span> <span class="o">=</span> <span class="n">in_features</span>  <span class="c1"># the same as number of classes before.</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">out_features</span> <span class="o">=</span> <span class="n">out_features</span>  <span class="c1"># the same as latent dimension before.</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">bias</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>    <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>    <span class="c1"># prior distributions for mean and bias.</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>    <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>    <span class="c1"># the prior of weights are gausssian distributions independent across in_feature dimensions.</span>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;W_prior_mean&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">))</span>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;W_prior_logstd&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">W_prior_variance</span><span class="p">))</span>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">:</span>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;b_prior_mean&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">))</span>
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;b_prior_logstd&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">b_prior_variance</span><span class="p">))</span>
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a>
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a>    <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a>    <span class="c1"># variational distributions for weight and bias.</span>
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a>    <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a>    <span class="k">if</span> <span class="n">W_variational_mean_fixed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_variational_mean_fixed</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a>        <span class="k">assert</span> <span class="n">W_variational_mean_fixed</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">),</span> \
<a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a>            <span class="sa">f</span><span class="s1">&#39;W_variational_mean_fixed tensor should have shape (in_features, out_features), got </span><span class="si">{</span><span class="n">W_variational_mean_fixed</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span>
<a id="__codelineno-0-40" name="__codelineno-0-40" href="#__codelineno-0-40"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;W_variational_mean_fixed&#39;</span><span class="p">,</span> <span class="n">W_variational_mean_fixed</span><span class="p">)</span>
<a id="__codelineno-0-41" name="__codelineno-0-41" href="#__codelineno-0-41"></a>
<a id="__codelineno-0-42" name="__codelineno-0-42" href="#__codelineno-0-42"></a>    <span class="c1"># TODO: optionally add customizable initialization here.</span>
<a id="__codelineno-0-43" name="__codelineno-0-43" href="#__codelineno-0-43"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">W_variational_mean_flexible</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-44" name="__codelineno-0-44" href="#__codelineno-0-44"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">W_variational_logstd</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-45" name="__codelineno-0-45" href="#__codelineno-0-45"></a>
<a id="__codelineno-0-46" name="__codelineno-0-46" href="#__codelineno-0-46"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">:</span>
<a id="__codelineno-0-47" name="__codelineno-0-47" href="#__codelineno-0-47"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">b_variational_mean</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">out_features</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-48" name="__codelineno-0-48" href="#__codelineno-0-48"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">b_variational_logstd</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">out_features</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-49" name="__codelineno-0-49" href="#__codelineno-0-49"></a>
<a id="__codelineno-0-50" name="__codelineno-0-50" href="#__codelineno-0-50"></a>    <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-51" name="__codelineno-0-51" href="#__codelineno-0-51"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-52" name="__codelineno-0-52" href="#__codelineno-0-52"></a>
<a id="__codelineno-0-53" name="__codelineno-0-53" href="#__codelineno-0-53"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">W_sample</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-54" name="__codelineno-0-54" href="#__codelineno-0-54"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">b_sample</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-55" name="__codelineno-0-55" href="#__codelineno-0-55"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">num_seeds</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div>
        </details>
    </div>

  </div>




  <div class="doc doc-object doc-method">



<h5 id="bemb.model.bayesian_linear.BayesianLinear.dsample" class="doc doc-heading">
<code class="highlight language-python"><span class="n">dsample</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>Deterministic sample method, set (W, b) sample to the mean of variational distribution.</p>

        <details class="quote">
          <summary>Source code in <code>bemb/model/bayesian_linear.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="nf">dsample</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="sd">&quot;&quot;&quot;Deterministic sample method, set (W, b) sample to the mean of variational distribution.&quot;&quot;&quot;</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">num_seeds</span> <span class="o">=</span> <span class="mi">1</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">W_sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_variational_mean</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">:</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">b_sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_variational_mean</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_sample</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_sample</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="bemb.model.bayesian_linear.BayesianLinear.forward" class="doc doc-heading">
<code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;multiply&#39;</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>Forward with weight sampling. Forward does out = XW + b, for forward() method behaves like the embedding layer
in PyTorch, use the lookup() method.
To have determinstic results, call self.dsample() before executing.
To have stochastic results, call self.rsample() before executing.
mode in ['multiply', 'lookup']</p>
<p>output shape: (num_seeds, batch_size, out_features).</p>

        <details class="quote">
          <summary>Source code in <code>bemb/model/bayesian_linear.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mode</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="s1">&#39;multiply&#39;</span><span class="p">):</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="sd">    Forward with weight sampling. Forward does out = XW + b, for forward() method behaves like the embedding layer</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="sd">    in PyTorch, use the lookup() method.</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="sd">    To have determinstic results, call self.dsample() before executing.</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="sd">    To have stochastic results, call self.rsample() before executing.</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="sd">    mode in [&#39;multiply&#39;, &#39;lookup&#39;]</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="sd">    output shape: (num_seeds, batch_size, out_features).</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_seeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;run BayesianLinear.rsample() or dsample() first to sample weight and bias.&#39;</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>    <span class="c1"># if determinstic, num_seeds is set to 1.</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>    <span class="c1"># w: (num_seeds, in_features=num_classes, out_features)</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>    <span class="c1"># b: (num_seeds, out_features)</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>    <span class="c1"># x: (N, in_features) if multiply and (N,) if lookup.</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>    <span class="c1"># output: (num_seeds, N, out_features)</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;multiply&#39;</span><span class="p">:</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_features</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_seeds</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (num_seeds, N, in_features)</span>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>        <span class="n">out</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_sample</span><span class="p">)</span>  <span class="c1"># (num_seeds, N, out_features)</span>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>    <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;lookup&#39;</span><span class="p">:</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_sample</span><span class="p">[:,</span> <span class="n">x</span><span class="p">,</span> <span class="p">:]</span>  <span class="c1"># (num_seeds, N, out_features)</span>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;mode=</span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s1"> is not allowed.&#39;</span><span class="p">)</span>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">:</span>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a>        <span class="n">out</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_sample</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_seeds</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_features</span><span class="p">)</span>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a>
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a>    <span class="c1"># (num_seeds, N, out_features)</span>
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a>    <span class="k">return</span> <span class="n">out</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="bemb.model.bayesian_linear.BayesianLinear.log_prior" class="doc doc-heading">
<code class="highlight language-python"><span class="n">log_prior</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>Evaluate the likelihood of the provided samples of parameter under the current prior distribution.</p>

        <details class="quote">
          <summary>Source code in <code>bemb/model/bayesian_linear.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="nf">log_prior</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="sd">&quot;&quot;&quot;Evaluate the likelihood of the provided samples of parameter under the current prior distribution.&quot;&quot;&quot;</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_seeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;run BayesianLinear.rsample() or dsample() first to sample weight and bias.&#39;</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">num_seeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_sample</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">total_log_prob</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_seeds</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="c1"># log P(W_sample). shape = (num_seeds,)</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">W_prior</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">W_prior_mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_prior_logstd</span><span class="p">))</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="n">total_log_prob</span> <span class="o">+=</span> <span class="n">W_prior</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_sample</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>    <span class="c1"># log P(b_sample) if applicable.</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">:</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>        <span class="n">b_prior</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">b_prior_mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_prior_logstd</span><span class="p">))</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>        <span class="n">total_log_prob</span> <span class="o">+=</span> <span class="n">b_prior</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_sample</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>    <span class="k">assert</span> <span class="n">total_log_prob</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_seeds</span><span class="p">,)</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>    <span class="k">return</span> <span class="n">total_log_prob</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="bemb.model.bayesian_linear.BayesianLinear.log_variational" class="doc doc-heading">
<code class="highlight language-python"><span class="n">log_variational</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>Evaluate the likelihood of the provided samples of parameter under the current variational distribution.</p>

        <details class="quote">
          <summary>Source code in <code>bemb/model/bayesian_linear.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="nf">log_variational</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="sd">&quot;&quot;&quot;Evaluate the likelihood of the provided samples of parameter under the current variational distribution.&quot;&quot;&quot;</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_seeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;run BayesianLinear.rsample() or dsample() first to sample weight and bias.&#39;</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">num_seeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_sample</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">total_log_prob</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_seeds</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">total_log_prob</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_variational_distribution</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_sample</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">:</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>        <span class="n">total_log_prob</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_variational_distribution</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_sample</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>    <span class="k">assert</span> <span class="n">total_log_prob</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_seeds</span><span class="p">,)</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    <span class="k">return</span> <span class="n">total_log_prob</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="bemb.model.bayesian_linear.BayesianLinear.rsample" class="doc doc-heading">
<code class="highlight language-python"><span class="n">rsample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_seeds</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>sample all parameters using re-parameterization trick.</p>

        <details class="quote">
          <summary>Source code in <code>bemb/model/bayesian_linear.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="nf">rsample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_seeds</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]]:</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="sd">&quot;&quot;&quot;sample all parameters using re-parameterization trick.</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">num_seeds</span> <span class="o">=</span> <span class="n">num_seeds</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">W_sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_variational_distribution</span><span class="o">.</span><span class="n">rsample</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">num_seeds</span><span class="p">]))</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">:</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">b_sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_variational_distribution</span><span class="o">.</span><span class="n">rsample</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">num_seeds</span><span class="p">]))</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_sample</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_sample</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>







  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h3 id="bemb.model.bemb" class="doc doc-heading">
        <code>bemb</code>



</h3>

    <div class="doc doc-contents ">

      <p>The core class of the Bayesian EMBedding (BEMB) model.</p>
<p>Author: Tianyu Du
Update: Apr. 28, 2022</p>



  <div class="doc doc-children">








  <div class="doc doc-object doc-class">



<h4 id="bemb.model.bemb.BEMBFlex" class="doc doc-heading">
        <code>
BEMBFlex            (<span title="torch.nn.modules.module.Module">Module</span>)
        </code>



</h4>

    <div class="doc doc-contents ">


        <details class="quote">
          <summary>Source code in <code>bemb/model/bemb.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">class</span> <span class="nc">BEMBFlex</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="c1"># ==================================================================================================================</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="c1"># core function as a PyTorch module.</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="c1"># ==================================================================================================================</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>                 <span class="n">utility_formula</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>                 <span class="n">obs2prior_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">bool</span><span class="p">],</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>                 <span class="n">coef_dim_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>                 <span class="n">num_items</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>                 <span class="n">pred_item</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>                 <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>                 <span class="n">H_zero_mask_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">BoolTensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>                 <span class="n">prior_mean</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>                 <span class="n">default_prior_mean</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>                 <span class="n">prior_variance</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>                 <span class="n">num_users</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>                 <span class="n">num_sessions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>                 <span class="n">trace_log_q</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>                 <span class="n">category_to_item</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>                 <span class="c1"># number of observables.</span>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>                 <span class="n">num_user_obs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>                 <span class="n">num_item_obs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>                 <span class="n">num_session_obs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>                 <span class="n">num_price_obs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a>                 <span class="n">num_taste_obs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a>                 <span class="c1"># additional modules.</span>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a>                 <span class="n">additional_modules</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a>                 <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a>        <span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a><span class="sd">            utility_formula (str): a string representing the utility function U[user, item, session].</span>
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a><span class="sd">                See documentation for more details in the documentation for the format of formula.</span>
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a><span class="sd">                Examples:</span>
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a><span class="sd">                    lambda_item</span>
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a><span class="sd">                    lambda_item + theta_user * alpha_item + zeta_user * item_obs</span>
<a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a><span class="sd">                    lambda_item + theta_user * alpha_item + gamma_user * beta_item * price_obs</span>
<a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a><span class="sd">                See the doc-string of parse_utility for an example.</span>
<a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a>
<a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a><span class="sd">            obs2prior_dict (Dict[str, bool]): a dictionary maps coefficient name (e.g., &#39;lambda_item&#39;)</span>
<a id="__codelineno-0-40" name="__codelineno-0-40" href="#__codelineno-0-40"></a><span class="sd">                to a boolean indicating if observable (e.g., item_obs) enters the prior of the coefficient.</span>
<a id="__codelineno-0-41" name="__codelineno-0-41" href="#__codelineno-0-41"></a>
<a id="__codelineno-0-42" name="__codelineno-0-42" href="#__codelineno-0-42"></a><span class="sd">            coef_dim_dict (Dict[str, int]): a dictionary maps coefficient name (e.g., &#39;lambda_item&#39;)</span>
<a id="__codelineno-0-43" name="__codelineno-0-43" href="#__codelineno-0-43"></a><span class="sd">                to an integer indicating the dimension of coefficient.</span>
<a id="__codelineno-0-44" name="__codelineno-0-44" href="#__codelineno-0-44"></a><span class="sd">                For standalone coefficients like U = lambda_item, the dim should be 1.</span>
<a id="__codelineno-0-45" name="__codelineno-0-45" href="#__codelineno-0-45"></a><span class="sd">                For factorized coefficients like U = theta_user * alpha_item, the dim should be the</span>
<a id="__codelineno-0-46" name="__codelineno-0-46" href="#__codelineno-0-46"></a><span class="sd">                    latent dimension of theta and alpha.</span>
<a id="__codelineno-0-47" name="__codelineno-0-47" href="#__codelineno-0-47"></a><span class="sd">                For coefficients multiplied with observables like U = zeta_user * item_obs, the dim</span>
<a id="__codelineno-0-48" name="__codelineno-0-48" href="#__codelineno-0-48"></a><span class="sd">                    should be the number of observables in item_obs.</span>
<a id="__codelineno-0-49" name="__codelineno-0-49" href="#__codelineno-0-49"></a><span class="sd">                For factorized coefficient multiplied with observables like U = gamma_user * beta_item * price_obs,</span>
<a id="__codelineno-0-50" name="__codelineno-0-50" href="#__codelineno-0-50"></a><span class="sd">                    the dim should be the latent dim multiplied by number of observables in price_obs.</span>
<a id="__codelineno-0-51" name="__codelineno-0-51" href="#__codelineno-0-51"></a>
<a id="__codelineno-0-52" name="__codelineno-0-52" href="#__codelineno-0-52"></a><span class="sd">            H_zero_mask_dict (Dict[str, torch.BoolTensor]): A dictionary maps coefficient names to a boolean tensor,</span>
<a id="__codelineno-0-53" name="__codelineno-0-53" href="#__codelineno-0-53"></a><span class="sd">                you should only specify the H_zero_mask for coefficients with obs2prior turned on.</span>
<a id="__codelineno-0-54" name="__codelineno-0-54" href="#__codelineno-0-54"></a><span class="sd">                Recall that with obs2prior on, the prior of coefficient looks like N(H*X_obs, sigma * I), the H_zero_mask</span>
<a id="__codelineno-0-55" name="__codelineno-0-55" href="#__codelineno-0-55"></a><span class="sd">                the mask for this coefficient should have the same shape as H, and H[H_zero_mask] will be set to zeros</span>
<a id="__codelineno-0-56" name="__codelineno-0-56" href="#__codelineno-0-56"></a><span class="sd">                and non-learnable during the training.</span>
<a id="__codelineno-0-57" name="__codelineno-0-57" href="#__codelineno-0-57"></a><span class="sd">                Defaults to None.</span>
<a id="__codelineno-0-58" name="__codelineno-0-58" href="#__codelineno-0-58"></a>
<a id="__codelineno-0-59" name="__codelineno-0-59" href="#__codelineno-0-59"></a><span class="sd">            num_items (int): number of items.</span>
<a id="__codelineno-0-60" name="__codelineno-0-60" href="#__codelineno-0-60"></a>
<a id="__codelineno-0-61" name="__codelineno-0-61" href="#__codelineno-0-61"></a><span class="sd">            pred_item (bool): there are two use cases of this model, suppose we have `user_index[i]` and `item_index[i]`</span>
<a id="__codelineno-0-62" name="__codelineno-0-62" href="#__codelineno-0-62"></a><span class="sd">                for the i-th observation in the dataset.</span>
<a id="__codelineno-0-63" name="__codelineno-0-63" href="#__codelineno-0-63"></a><span class="sd">                Case 1: which item among all items user `user_index[i]` is going to purchase, the prediction label</span>
<a id="__codelineno-0-64" name="__codelineno-0-64" href="#__codelineno-0-64"></a><span class="sd">                    is therefore `item_index[i]`. Equivalently, we can ask what&#39;s the likelihood for user `user_index[i]`</span>
<a id="__codelineno-0-65" name="__codelineno-0-65" href="#__codelineno-0-65"></a><span class="sd">                    to purchase `item_index[i]`.</span>
<a id="__codelineno-0-66" name="__codelineno-0-66" href="#__codelineno-0-66"></a><span class="sd">                Case 2: what rating would user `user_index[i]` assign to item `item_index[i]`? In this case, the dataset</span>
<a id="__codelineno-0-67" name="__codelineno-0-67" href="#__codelineno-0-67"></a><span class="sd">                    object needs to contain a separate label.</span>
<a id="__codelineno-0-68" name="__codelineno-0-68" href="#__codelineno-0-68"></a><span class="sd">                    NOTE: for now, we only support binary labels.</span>
<a id="__codelineno-0-69" name="__codelineno-0-69" href="#__codelineno-0-69"></a>
<a id="__codelineno-0-70" name="__codelineno-0-70" href="#__codelineno-0-70"></a><span class="sd">            default_prior_mean (float): the default prior mean for coefficients,</span>
<a id="__codelineno-0-71" name="__codelineno-0-71" href="#__codelineno-0-71"></a><span class="sd">            if it is not specified in the prior_mean; defaults to 0.0.</span>
<a id="__codelineno-0-72" name="__codelineno-0-72" href="#__codelineno-0-72"></a>
<a id="__codelineno-0-73" name="__codelineno-0-73" href="#__codelineno-0-73"></a><span class="sd">            prior_mean (Union[float, Dict[str, float]]): the mean of prior</span>
<a id="__codelineno-0-74" name="__codelineno-0-74" href="#__codelineno-0-74"></a><span class="sd">                distribution for coefficients. If a float is provided, all prior</span>
<a id="__codelineno-0-75" name="__codelineno-0-75" href="#__codelineno-0-75"></a><span class="sd">                mean will be diagonal matrix with the provided value.  If a</span>
<a id="__codelineno-0-76" name="__codelineno-0-76" href="#__codelineno-0-76"></a><span class="sd">                dictionary is provided, keys of prior_mean should be coefficient</span>
<a id="__codelineno-0-77" name="__codelineno-0-77" href="#__codelineno-0-77"></a><span class="sd">                names, and the mean of prior of coef_name would the provided</span>
<a id="__codelineno-0-78" name="__codelineno-0-78" href="#__codelineno-0-78"></a><span class="sd">                value Defaults to 0.0, which means all prior means are</span>
<a id="__codelineno-0-79" name="__codelineno-0-79" href="#__codelineno-0-79"></a><span class="sd">                initialized to 0.0</span>
<a id="__codelineno-0-80" name="__codelineno-0-80" href="#__codelineno-0-80"></a>
<a id="__codelineno-0-81" name="__codelineno-0-81" href="#__codelineno-0-81"></a><span class="sd">            prior_variance (Union[float, Dict[str, float]]): the variance of prior distribution for</span>
<a id="__codelineno-0-82" name="__codelineno-0-82" href="#__codelineno-0-82"></a><span class="sd">                coefficients. If a float is provided, all priors will be diagonal matrix with</span>
<a id="__codelineno-0-83" name="__codelineno-0-83" href="#__codelineno-0-83"></a><span class="sd">                prior_variance along the diagonal. If a dictionary is provided, keys of prior_variance</span>
<a id="__codelineno-0-84" name="__codelineno-0-84" href="#__codelineno-0-84"></a><span class="sd">                should be coefficient names, and the variance of prior of coef_name would be a diagonal</span>
<a id="__codelineno-0-85" name="__codelineno-0-85" href="#__codelineno-0-85"></a><span class="sd">                matrix with prior_variance[coef_name] along the diagonal.</span>
<a id="__codelineno-0-86" name="__codelineno-0-86" href="#__codelineno-0-86"></a><span class="sd">                Defaults to 1.0, which means all prior have identity matrix as the covariance matrix.</span>
<a id="__codelineno-0-87" name="__codelineno-0-87" href="#__codelineno-0-87"></a>
<a id="__codelineno-0-88" name="__codelineno-0-88" href="#__codelineno-0-88"></a><span class="sd">            num_users (int, optional): number of users, required only if coefficient or observable</span>
<a id="__codelineno-0-89" name="__codelineno-0-89" href="#__codelineno-0-89"></a><span class="sd">                depending on user is in utility. Defaults to None.</span>
<a id="__codelineno-0-90" name="__codelineno-0-90" href="#__codelineno-0-90"></a><span class="sd">            num_sessions (int, optional): number of sessions, required only if coefficient or</span>
<a id="__codelineno-0-91" name="__codelineno-0-91" href="#__codelineno-0-91"></a><span class="sd">                observable depending on session is in utility. Defaults to None.</span>
<a id="__codelineno-0-92" name="__codelineno-0-92" href="#__codelineno-0-92"></a>
<a id="__codelineno-0-93" name="__codelineno-0-93" href="#__codelineno-0-93"></a><span class="sd">            trace_log_q (bool, optional): whether to trace the derivative of variational likelihood logQ</span>
<a id="__codelineno-0-94" name="__codelineno-0-94" href="#__codelineno-0-94"></a><span class="sd">                with respect to variational parameters in the ELBO while conducting gradient update.</span>
<a id="__codelineno-0-95" name="__codelineno-0-95" href="#__codelineno-0-95"></a><span class="sd">                Defaults to False.</span>
<a id="__codelineno-0-96" name="__codelineno-0-96" href="#__codelineno-0-96"></a>
<a id="__codelineno-0-97" name="__codelineno-0-97" href="#__codelineno-0-97"></a><span class="sd">            category_to_item (Dict[str, List[int]], optional): a dictionary with category id or name</span>
<a id="__codelineno-0-98" name="__codelineno-0-98" href="#__codelineno-0-98"></a><span class="sd">                as keys, and category_to_item[C] contains the list of item ids belonging to category C.</span>
<a id="__codelineno-0-99" name="__codelineno-0-99" href="#__codelineno-0-99"></a><span class="sd">                If None is provided, all items are assumed to be in the same category.</span>
<a id="__codelineno-0-100" name="__codelineno-0-100" href="#__codelineno-0-100"></a><span class="sd">                Defaults to None.</span>
<a id="__codelineno-0-101" name="__codelineno-0-101" href="#__codelineno-0-101"></a>
<a id="__codelineno-0-102" name="__codelineno-0-102" href="#__codelineno-0-102"></a><span class="sd">            num_{user, item, session, price, taste}_obs (int, optional): number of observables of</span>
<a id="__codelineno-0-103" name="__codelineno-0-103" href="#__codelineno-0-103"></a><span class="sd">                each type of features, only required if observable enters prior.</span>
<a id="__codelineno-0-104" name="__codelineno-0-104" href="#__codelineno-0-104"></a><span class="sd">                NOTE: currently we only allow coefficient to depend on either user or item, thus only</span>
<a id="__codelineno-0-105" name="__codelineno-0-105" href="#__codelineno-0-105"></a><span class="sd">                user and item observables can enter the prior of coefficient. Hence session, price,</span>
<a id="__codelineno-0-106" name="__codelineno-0-106" href="#__codelineno-0-106"></a><span class="sd">                and taste observables are never required, we include it here for completeness.</span>
<a id="__codelineno-0-107" name="__codelineno-0-107" href="#__codelineno-0-107"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-108" name="__codelineno-0-108" href="#__codelineno-0-108"></a>        <span class="nb">super</span><span class="p">(</span><span class="n">BEMBFlex</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-109" name="__codelineno-0-109" href="#__codelineno-0-109"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">utility_formula</span> <span class="o">=</span> <span class="n">utility_formula</span>
<a id="__codelineno-0-110" name="__codelineno-0-110" href="#__codelineno-0-110"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">obs2prior_dict</span> <span class="o">=</span> <span class="n">obs2prior_dict</span>
<a id="__codelineno-0-111" name="__codelineno-0-111" href="#__codelineno-0-111"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">coef_dim_dict</span> <span class="o">=</span> <span class="n">coef_dim_dict</span>
<a id="__codelineno-0-112" name="__codelineno-0-112" href="#__codelineno-0-112"></a>        <span class="k">if</span> <span class="n">H_zero_mask_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-113" name="__codelineno-0-113" href="#__codelineno-0-113"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">H_zero_mask_dict</span> <span class="o">=</span> <span class="n">H_zero_mask_dict</span>
<a id="__codelineno-0-114" name="__codelineno-0-114" href="#__codelineno-0-114"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-115" name="__codelineno-0-115" href="#__codelineno-0-115"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">H_zero_mask_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<a id="__codelineno-0-116" name="__codelineno-0-116" href="#__codelineno-0-116"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">prior_variance</span> <span class="o">=</span> <span class="n">prior_variance</span>
<a id="__codelineno-0-117" name="__codelineno-0-117" href="#__codelineno-0-117"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">default_prior_mean</span> <span class="o">=</span> <span class="n">default_prior_mean</span>
<a id="__codelineno-0-118" name="__codelineno-0-118" href="#__codelineno-0-118"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">prior_mean</span> <span class="o">=</span> <span class="n">prior_mean</span>
<a id="__codelineno-0-119" name="__codelineno-0-119" href="#__codelineno-0-119"></a>
<a id="__codelineno-0-120" name="__codelineno-0-120" href="#__codelineno-0-120"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">pred_item</span> <span class="o">=</span> <span class="n">pred_item</span>
<a id="__codelineno-0-121" name="__codelineno-0-121" href="#__codelineno-0-121"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">pred_item</span><span class="p">:</span>
<a id="__codelineno-0-122" name="__codelineno-0-122" href="#__codelineno-0-122"></a>            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">num_classes</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> \
<a id="__codelineno-0-123" name="__codelineno-0-123" href="#__codelineno-0-123"></a>                <span class="sa">f</span><span class="s2">&quot;With pred_item being False, the num_classes should be a positive integer, received </span><span class="si">{</span><span class="n">num_classes</span><span class="si">}</span><span class="s2"> instead.&quot;</span>
<a id="__codelineno-0-124" name="__codelineno-0-124" href="#__codelineno-0-124"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">num_classes</span>
<a id="__codelineno-0-125" name="__codelineno-0-125" href="#__codelineno-0-125"></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
<a id="__codelineno-0-126" name="__codelineno-0-126" href="#__codelineno-0-126"></a>                <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;Multi-class classification is not supported yet.&#39;</span><span class="p">)</span>
<a id="__codelineno-0-127" name="__codelineno-0-127" href="#__codelineno-0-127"></a>            <span class="c1"># we don&#39;t set the num_classes attribute when pred_item == False to avoid calling it accidentally.</span>
<a id="__codelineno-0-128" name="__codelineno-0-128" href="#__codelineno-0-128"></a>
<a id="__codelineno-0-129" name="__codelineno-0-129" href="#__codelineno-0-129"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span> <span class="o">=</span> <span class="n">num_items</span>
<a id="__codelineno-0-130" name="__codelineno-0-130" href="#__codelineno-0-130"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_users</span> <span class="o">=</span> <span class="n">num_users</span>
<a id="__codelineno-0-131" name="__codelineno-0-131" href="#__codelineno-0-131"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_sessions</span> <span class="o">=</span> <span class="n">num_sessions</span>
<a id="__codelineno-0-132" name="__codelineno-0-132" href="#__codelineno-0-132"></a>
<a id="__codelineno-0-133" name="__codelineno-0-133" href="#__codelineno-0-133"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">trace_log_q</span> <span class="o">=</span> <span class="n">trace_log_q</span>
<a id="__codelineno-0-134" name="__codelineno-0-134" href="#__codelineno-0-134"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">category_to_item</span> <span class="o">=</span> <span class="n">category_to_item</span>
<a id="__codelineno-0-135" name="__codelineno-0-135" href="#__codelineno-0-135"></a>
<a id="__codelineno-0-136" name="__codelineno-0-136" href="#__codelineno-0-136"></a>        <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-137" name="__codelineno-0-137" href="#__codelineno-0-137"></a>        <span class="c1"># Category ID to Item ID mapping.</span>
<a id="__codelineno-0-138" name="__codelineno-0-138" href="#__codelineno-0-138"></a>        <span class="c1"># Category ID to Category Size mapping.</span>
<a id="__codelineno-0-139" name="__codelineno-0-139" href="#__codelineno-0-139"></a>        <span class="c1"># Item ID to Category ID mapping.</span>
<a id="__codelineno-0-140" name="__codelineno-0-140" href="#__codelineno-0-140"></a>        <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-141" name="__codelineno-0-141" href="#__codelineno-0-141"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">category_to_item</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-142" name="__codelineno-0-142" href="#__codelineno-0-142"></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pred_item</span><span class="p">:</span>
<a id="__codelineno-0-143" name="__codelineno-0-143" href="#__codelineno-0-143"></a>                <span class="c1"># assign all items to the same category if predicting items.</span>
<a id="__codelineno-0-144" name="__codelineno-0-144" href="#__codelineno-0-144"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">category_to_item</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">))}</span>
<a id="__codelineno-0-145" name="__codelineno-0-145" href="#__codelineno-0-145"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-146" name="__codelineno-0-146" href="#__codelineno-0-146"></a>                <span class="c1"># otherwise, for the j-th observation in the dataset, the label[j]</span>
<a id="__codelineno-0-147" name="__codelineno-0-147" href="#__codelineno-0-147"></a>                <span class="c1"># only depends on user_index[j] and item_index[j], so we put each</span>
<a id="__codelineno-0-148" name="__codelineno-0-148" href="#__codelineno-0-148"></a>                <span class="c1"># item to its own category.</span>
<a id="__codelineno-0-149" name="__codelineno-0-149" href="#__codelineno-0-149"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">category_to_item</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">)}</span>
<a id="__codelineno-0-150" name="__codelineno-0-150" href="#__codelineno-0-150"></a>
<a id="__codelineno-0-151" name="__codelineno-0-151" href="#__codelineno-0-151"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_categories</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">category_to_item</span><span class="p">)</span>
<a id="__codelineno-0-152" name="__codelineno-0-152" href="#__codelineno-0-152"></a>
<a id="__codelineno-0-153" name="__codelineno-0-153" href="#__codelineno-0-153"></a>        <span class="n">max_category_size</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">category_to_item</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
<a id="__codelineno-0-154" name="__codelineno-0-154" href="#__codelineno-0-154"></a>        <span class="n">category_to_item_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
<a id="__codelineno-0-155" name="__codelineno-0-155" href="#__codelineno-0-155"></a>            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_categories</span><span class="p">,</span> <span class="n">max_category_size</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-156" name="__codelineno-0-156" href="#__codelineno-0-156"></a>        <span class="n">category_to_size_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_categories</span><span class="p">)</span>
<a id="__codelineno-0-157" name="__codelineno-0-157" href="#__codelineno-0-157"></a>
<a id="__codelineno-0-158" name="__codelineno-0-158" href="#__codelineno-0-158"></a>        <span class="k">for</span> <span class="n">c</span><span class="p">,</span> <span class="n">item_in_c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">category_to_item</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<a id="__codelineno-0-159" name="__codelineno-0-159" href="#__codelineno-0-159"></a>            <span class="n">category_to_item_tensor</span><span class="p">[</span><span class="n">c</span><span class="p">,</span> <span class="p">:</span><span class="nb">len</span><span class="p">(</span>
<a id="__codelineno-0-160" name="__codelineno-0-160" href="#__codelineno-0-160"></a>                <span class="n">item_in_c</span><span class="p">)]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">item_in_c</span><span class="p">)</span>
<a id="__codelineno-0-161" name="__codelineno-0-161" href="#__codelineno-0-161"></a>            <span class="n">category_to_size_tensor</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">scalar_tensor</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">item_in_c</span><span class="p">))</span>
<a id="__codelineno-0-162" name="__codelineno-0-162" href="#__codelineno-0-162"></a>
<a id="__codelineno-0-163" name="__codelineno-0-163" href="#__codelineno-0-163"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;category_to_item_tensor&#39;</span><span class="p">,</span>
<a id="__codelineno-0-164" name="__codelineno-0-164" href="#__codelineno-0-164"></a>                             <span class="n">category_to_item_tensor</span><span class="o">.</span><span class="n">long</span><span class="p">())</span>
<a id="__codelineno-0-165" name="__codelineno-0-165" href="#__codelineno-0-165"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;category_to_size_tensor&#39;</span><span class="p">,</span>
<a id="__codelineno-0-166" name="__codelineno-0-166" href="#__codelineno-0-166"></a>                             <span class="n">category_to_size_tensor</span><span class="o">.</span><span class="n">long</span><span class="p">())</span>
<a id="__codelineno-0-167" name="__codelineno-0-167" href="#__codelineno-0-167"></a>
<a id="__codelineno-0-168" name="__codelineno-0-168" href="#__codelineno-0-168"></a>        <span class="n">item_to_category_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">)</span>
<a id="__codelineno-0-169" name="__codelineno-0-169" href="#__codelineno-0-169"></a>        <span class="k">for</span> <span class="n">c</span><span class="p">,</span> <span class="n">items_in_c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">category_to_item</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<a id="__codelineno-0-170" name="__codelineno-0-170" href="#__codelineno-0-170"></a>            <span class="n">item_to_category_tensor</span><span class="p">[</span><span class="n">items_in_c</span><span class="p">]</span> <span class="o">=</span> <span class="n">c</span>
<a id="__codelineno-0-171" name="__codelineno-0-171" href="#__codelineno-0-171"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;item_to_category_tensor&#39;</span><span class="p">,</span>
<a id="__codelineno-0-172" name="__codelineno-0-172" href="#__codelineno-0-172"></a>                             <span class="n">item_to_category_tensor</span><span class="o">.</span><span class="n">long</span><span class="p">())</span>
<a id="__codelineno-0-173" name="__codelineno-0-173" href="#__codelineno-0-173"></a>
<a id="__codelineno-0-174" name="__codelineno-0-174" href="#__codelineno-0-174"></a>        <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-175" name="__codelineno-0-175" href="#__codelineno-0-175"></a>        <span class="c1"># Create Bayesian Coefficient Objects</span>
<a id="__codelineno-0-176" name="__codelineno-0-176" href="#__codelineno-0-176"></a>        <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-177" name="__codelineno-0-177" href="#__codelineno-0-177"></a>        <span class="c1"># model configuration.</span>
<a id="__codelineno-0-178" name="__codelineno-0-178" href="#__codelineno-0-178"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">formula</span> <span class="o">=</span> <span class="n">parse_utility</span><span class="p">(</span><span class="n">utility_formula</span><span class="p">)</span>
<a id="__codelineno-0-179" name="__codelineno-0-179" href="#__codelineno-0-179"></a>        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;BEMB: utility formula parsed:&#39;</span><span class="p">)</span>
<a id="__codelineno-0-180" name="__codelineno-0-180" href="#__codelineno-0-180"></a>        <span class="n">pprint</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">formula</span><span class="p">)</span>
<a id="__codelineno-0-181" name="__codelineno-0-181" href="#__codelineno-0-181"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">raw_formula</span> <span class="o">=</span> <span class="n">utility_formula</span>
<a id="__codelineno-0-182" name="__codelineno-0-182" href="#__codelineno-0-182"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">obs2prior_dict</span> <span class="o">=</span> <span class="n">obs2prior_dict</span>
<a id="__codelineno-0-183" name="__codelineno-0-183" href="#__codelineno-0-183"></a>
<a id="__codelineno-0-184" name="__codelineno-0-184" href="#__codelineno-0-184"></a>        <span class="c1"># dimension of each observable, this one is used only for obs2prior.</span>
<a id="__codelineno-0-185" name="__codelineno-0-185" href="#__codelineno-0-185"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_obs_dict</span> <span class="o">=</span> <span class="p">{</span>
<a id="__codelineno-0-186" name="__codelineno-0-186" href="#__codelineno-0-186"></a>            <span class="s1">&#39;user&#39;</span><span class="p">:</span> <span class="n">num_user_obs</span><span class="p">,</span>
<a id="__codelineno-0-187" name="__codelineno-0-187" href="#__codelineno-0-187"></a>            <span class="s1">&#39;item&#39;</span><span class="p">:</span> <span class="n">num_item_obs</span><span class="p">,</span>
<a id="__codelineno-0-188" name="__codelineno-0-188" href="#__codelineno-0-188"></a>            <span class="s1">&#39;category&#39;</span> <span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
<a id="__codelineno-0-189" name="__codelineno-0-189" href="#__codelineno-0-189"></a>            <span class="s1">&#39;session&#39;</span><span class="p">:</span> <span class="n">num_session_obs</span><span class="p">,</span>
<a id="__codelineno-0-190" name="__codelineno-0-190" href="#__codelineno-0-190"></a>            <span class="s1">&#39;price&#39;</span><span class="p">:</span> <span class="n">num_price_obs</span><span class="p">,</span>
<a id="__codelineno-0-191" name="__codelineno-0-191" href="#__codelineno-0-191"></a>            <span class="s1">&#39;taste&#39;</span><span class="p">:</span> <span class="n">num_taste_obs</span><span class="p">,</span>
<a id="__codelineno-0-192" name="__codelineno-0-192" href="#__codelineno-0-192"></a>            <span class="s1">&#39;constant&#39;</span><span class="p">:</span> <span class="mi">1</span>  <span class="c1"># not really used, for dummy variables.</span>
<a id="__codelineno-0-193" name="__codelineno-0-193" href="#__codelineno-0-193"></a>        <span class="p">}</span>
<a id="__codelineno-0-194" name="__codelineno-0-194" href="#__codelineno-0-194"></a>
<a id="__codelineno-0-195" name="__codelineno-0-195" href="#__codelineno-0-195"></a>        <span class="c1"># how many classes for the variational distribution.</span>
<a id="__codelineno-0-196" name="__codelineno-0-196" href="#__codelineno-0-196"></a>        <span class="c1"># for example, beta_item would be `num_items` 10-dimensional gaussian if latent dim = 10.</span>
<a id="__codelineno-0-197" name="__codelineno-0-197" href="#__codelineno-0-197"></a>        <span class="n">variation_to_num_classes</span> <span class="o">=</span> <span class="p">{</span>
<a id="__codelineno-0-198" name="__codelineno-0-198" href="#__codelineno-0-198"></a>            <span class="s1">&#39;user&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_users</span><span class="p">,</span>
<a id="__codelineno-0-199" name="__codelineno-0-199" href="#__codelineno-0-199"></a>            <span class="s1">&#39;item&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">,</span>
<a id="__codelineno-0-200" name="__codelineno-0-200" href="#__codelineno-0-200"></a>            <span class="s1">&#39;constant&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
<a id="__codelineno-0-201" name="__codelineno-0-201" href="#__codelineno-0-201"></a>            <span class="s1">&#39;category&#39;</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_categories</span><span class="p">,</span>
<a id="__codelineno-0-202" name="__codelineno-0-202" href="#__codelineno-0-202"></a>        <span class="p">}</span>
<a id="__codelineno-0-203" name="__codelineno-0-203" href="#__codelineno-0-203"></a>
<a id="__codelineno-0-204" name="__codelineno-0-204" href="#__codelineno-0-204"></a>        <span class="n">coef_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<a id="__codelineno-0-205" name="__codelineno-0-205" href="#__codelineno-0-205"></a>        <span class="k">for</span> <span class="n">additive_term</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">formula</span><span class="p">:</span>
<a id="__codelineno-0-206" name="__codelineno-0-206" href="#__codelineno-0-206"></a>            <span class="k">for</span> <span class="n">coef_name</span> <span class="ow">in</span> <span class="n">additive_term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">]:</span>
<a id="__codelineno-0-207" name="__codelineno-0-207" href="#__codelineno-0-207"></a>                <span class="n">variation</span> <span class="o">=</span> <span class="n">coef_name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<a id="__codelineno-0-208" name="__codelineno-0-208" href="#__codelineno-0-208"></a>                <span class="n">mean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_mean</span><span class="p">[</span><span class="n">coef_name</span><span class="p">]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span>
<a id="__codelineno-0-209" name="__codelineno-0-209" href="#__codelineno-0-209"></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">prior_mean</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_prior_mean</span>
<a id="__codelineno-0-210" name="__codelineno-0-210" href="#__codelineno-0-210"></a>                <span class="n">s2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_variance</span><span class="p">[</span><span class="n">coef_name</span><span class="p">]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span>
<a id="__codelineno-0-211" name="__codelineno-0-211" href="#__codelineno-0-211"></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">prior_variance</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_variance</span>
<a id="__codelineno-0-212" name="__codelineno-0-212" href="#__codelineno-0-212"></a>
<a id="__codelineno-0-213" name="__codelineno-0-213" href="#__codelineno-0-213"></a>                <span class="k">if</span> <span class="n">coef_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">H_zero_mask_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
<a id="__codelineno-0-214" name="__codelineno-0-214" href="#__codelineno-0-214"></a>                    <span class="n">H_zero_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">H_zero_mask_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">]</span>
<a id="__codelineno-0-215" name="__codelineno-0-215" href="#__codelineno-0-215"></a>                <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-216" name="__codelineno-0-216" href="#__codelineno-0-216"></a>                    <span class="n">H_zero_mask</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-217" name="__codelineno-0-217" href="#__codelineno-0-217"></a>
<a id="__codelineno-0-218" name="__codelineno-0-218" href="#__codelineno-0-218"></a>                <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">obs2prior_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">])</span> <span class="ow">and</span> <span class="p">(</span><span class="n">H_zero_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>
<a id="__codelineno-0-219" name="__codelineno-0-219" href="#__codelineno-0-219"></a>                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;You specified H_zero_mask for </span><span class="si">{</span><span class="n">coef_name</span><span class="si">}</span><span class="s1">, but obs2prior is False for this coefficient.&#39;</span><span class="p">)</span>
<a id="__codelineno-0-220" name="__codelineno-0-220" href="#__codelineno-0-220"></a>
<a id="__codelineno-0-221" name="__codelineno-0-221" href="#__codelineno-0-221"></a>                <span class="n">coef_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">BayesianCoefficient</span><span class="p">(</span><span class="n">variation</span><span class="o">=</span><span class="n">variation</span><span class="p">,</span>
<a id="__codelineno-0-222" name="__codelineno-0-222" href="#__codelineno-0-222"></a>                                                           <span class="n">num_classes</span><span class="o">=</span><span class="n">variation_to_num_classes</span><span class="p">[</span><span class="n">variation</span><span class="p">],</span>
<a id="__codelineno-0-223" name="__codelineno-0-223" href="#__codelineno-0-223"></a>                                                           <span class="n">obs2prior</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">obs2prior_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">],</span>
<a id="__codelineno-0-224" name="__codelineno-0-224" href="#__codelineno-0-224"></a>                                                           <span class="n">num_obs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_obs_dict</span><span class="p">[</span><span class="n">variation</span><span class="p">],</span>
<a id="__codelineno-0-225" name="__codelineno-0-225" href="#__codelineno-0-225"></a>                                                           <span class="n">dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">coef_dim_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">],</span>
<a id="__codelineno-0-226" name="__codelineno-0-226" href="#__codelineno-0-226"></a>                                                           <span class="n">prior_mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span>
<a id="__codelineno-0-227" name="__codelineno-0-227" href="#__codelineno-0-227"></a>                                                           <span class="n">prior_variance</span><span class="o">=</span><span class="n">s2</span><span class="p">,</span>
<a id="__codelineno-0-228" name="__codelineno-0-228" href="#__codelineno-0-228"></a>                                                           <span class="n">H_zero_mask</span><span class="o">=</span><span class="n">H_zero_mask</span><span class="p">,</span>
<a id="__codelineno-0-229" name="__codelineno-0-229" href="#__codelineno-0-229"></a>                                                           <span class="n">is_H</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-0-230" name="__codelineno-0-230" href="#__codelineno-0-230"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">coef_dict</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleDict</span><span class="p">(</span><span class="n">coef_dict</span><span class="p">)</span>
<a id="__codelineno-0-231" name="__codelineno-0-231" href="#__codelineno-0-231"></a>
<a id="__codelineno-0-232" name="__codelineno-0-232" href="#__codelineno-0-232"></a>        <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-233" name="__codelineno-0-233" href="#__codelineno-0-233"></a>        <span class="c1"># Optional: register additional modules.</span>
<a id="__codelineno-0-234" name="__codelineno-0-234" href="#__codelineno-0-234"></a>        <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-235" name="__codelineno-0-235" href="#__codelineno-0-235"></a>        <span class="k">if</span> <span class="n">additional_modules</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-236" name="__codelineno-0-236" href="#__codelineno-0-236"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">additional_modules</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-237" name="__codelineno-0-237" href="#__codelineno-0-237"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-238" name="__codelineno-0-238" href="#__codelineno-0-238"></a>            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
<a id="__codelineno-0-239" name="__codelineno-0-239" href="#__codelineno-0-239"></a>                <span class="s1">&#39;Additional modules are temporarily disabled for further development.&#39;</span><span class="p">)</span>
<a id="__codelineno-0-240" name="__codelineno-0-240" href="#__codelineno-0-240"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">additional_modules</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">additional_modules</span><span class="p">)</span>
<a id="__codelineno-0-241" name="__codelineno-0-241" href="#__codelineno-0-241"></a>
<a id="__codelineno-0-242" name="__codelineno-0-242" href="#__codelineno-0-242"></a>    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-243" name="__codelineno-0-243" href="#__codelineno-0-243"></a>        <span class="k">return</span> <span class="sa">f</span><span class="s1">&#39;Bayesian EMBedding Model with U[user, item, session] = </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_formula</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span> \
<a id="__codelineno-0-244" name="__codelineno-0-244" href="#__codelineno-0-244"></a>               <span class="o">+</span> <span class="sa">f</span><span class="s1">&#39;Total number of parameters: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_params</span><span class="si">}</span><span class="s1">.</span><span class="se">\n</span><span class="s1">&#39;</span> \
<a id="__codelineno-0-245" name="__codelineno-0-245" href="#__codelineno-0-245"></a>               <span class="o">+</span> <span class="s1">&#39;With the following coefficients:</span><span class="se">\n</span><span class="s1">&#39;</span> \
<a id="__codelineno-0-246" name="__codelineno-0-246" href="#__codelineno-0-246"></a>               <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coef_dict</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> \
<a id="__codelineno-0-247" name="__codelineno-0-247" href="#__codelineno-0-247"></a>               <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">additional_modules</span><span class="p">)</span>
<a id="__codelineno-0-248" name="__codelineno-0-248" href="#__codelineno-0-248"></a>
<a id="__codelineno-0-249" name="__codelineno-0-249" href="#__codelineno-0-249"></a>    <span class="k">def</span> <span class="nf">posterior_mean</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coef_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-250" name="__codelineno-0-250" href="#__codelineno-0-250"></a>        <span class="sd">&quot;&quot;&quot;Returns the mean of estimated posterior distribution of coefficient `coef_name`.</span>
<a id="__codelineno-0-251" name="__codelineno-0-251" href="#__codelineno-0-251"></a>
<a id="__codelineno-0-252" name="__codelineno-0-252" href="#__codelineno-0-252"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-253" name="__codelineno-0-253" href="#__codelineno-0-253"></a><span class="sd">            coef_name (str): name of the coefficient to query.</span>
<a id="__codelineno-0-254" name="__codelineno-0-254" href="#__codelineno-0-254"></a>
<a id="__codelineno-0-255" name="__codelineno-0-255" href="#__codelineno-0-255"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-256" name="__codelineno-0-256" href="#__codelineno-0-256"></a><span class="sd">            torch.Tensor: mean of the estimated posterior distribution of `coef_name`.</span>
<a id="__codelineno-0-257" name="__codelineno-0-257" href="#__codelineno-0-257"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-258" name="__codelineno-0-258" href="#__codelineno-0-258"></a>        <span class="k">if</span> <span class="n">coef_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
<a id="__codelineno-0-259" name="__codelineno-0-259" href="#__codelineno-0-259"></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">]</span><span class="o">.</span><span class="n">variational_mean</span>
<a id="__codelineno-0-260" name="__codelineno-0-260" href="#__codelineno-0-260"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-261" name="__codelineno-0-261" href="#__codelineno-0-261"></a>            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">coef_name</span><span class="si">}</span><span class="s1"> is not a valid coefficient name in </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">utility_formula</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span>
<a id="__codelineno-0-262" name="__codelineno-0-262" href="#__codelineno-0-262"></a>
<a id="__codelineno-0-263" name="__codelineno-0-263" href="#__codelineno-0-263"></a>    <span class="k">def</span> <span class="nf">posterior_distribution</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coef_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">lowrank_multivariate_normal</span><span class="o">.</span><span class="n">LowRankMultivariateNormal</span><span class="p">:</span>
<a id="__codelineno-0-264" name="__codelineno-0-264" href="#__codelineno-0-264"></a>        <span class="sd">&quot;&quot;&quot;Returns the posterior distribution of coefficient `coef_name`.</span>
<a id="__codelineno-0-265" name="__codelineno-0-265" href="#__codelineno-0-265"></a>
<a id="__codelineno-0-266" name="__codelineno-0-266" href="#__codelineno-0-266"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-267" name="__codelineno-0-267" href="#__codelineno-0-267"></a><span class="sd">            coef_name (str): name of the coefficient to query.</span>
<a id="__codelineno-0-268" name="__codelineno-0-268" href="#__codelineno-0-268"></a>
<a id="__codelineno-0-269" name="__codelineno-0-269" href="#__codelineno-0-269"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-270" name="__codelineno-0-270" href="#__codelineno-0-270"></a><span class="sd">            torch.Tensor: variance of the estimated posterior distribution of `coef_name`.</span>
<a id="__codelineno-0-271" name="__codelineno-0-271" href="#__codelineno-0-271"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-272" name="__codelineno-0-272" href="#__codelineno-0-272"></a>        <span class="k">if</span> <span class="n">coef_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
<a id="__codelineno-0-273" name="__codelineno-0-273" href="#__codelineno-0-273"></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">]</span><span class="o">.</span><span class="n">variational_distribution</span>
<a id="__codelineno-0-274" name="__codelineno-0-274" href="#__codelineno-0-274"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-275" name="__codelineno-0-275" href="#__codelineno-0-275"></a>            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">coef_name</span><span class="si">}</span><span class="s1"> is not a valid coefficient name in </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">utility_formula</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span>
<a id="__codelineno-0-276" name="__codelineno-0-276" href="#__codelineno-0-276"></a>
<a id="__codelineno-0-277" name="__codelineno-0-277" href="#__codelineno-0-277"></a>    <span class="k">def</span> <span class="nf">ivs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-278" name="__codelineno-0-278" href="#__codelineno-0-278"></a>        <span class="sd">&quot;&quot;&quot;The combined method of computing utilities and log probability.</span>
<a id="__codelineno-0-279" name="__codelineno-0-279" href="#__codelineno-0-279"></a>
<a id="__codelineno-0-280" name="__codelineno-0-280" href="#__codelineno-0-280"></a><span class="sd">            Args:</span>
<a id="__codelineno-0-281" name="__codelineno-0-281" href="#__codelineno-0-281"></a><span class="sd">                batch (dict): a batch of data.</span>
<a id="__codelineno-0-282" name="__codelineno-0-282" href="#__codelineno-0-282"></a>
<a id="__codelineno-0-283" name="__codelineno-0-283" href="#__codelineno-0-283"></a><span class="sd">            Returns:</span>
<a id="__codelineno-0-284" name="__codelineno-0-284" href="#__codelineno-0-284"></a><span class="sd">                torch.Tensor: the combined utility and log probability.</span>
<a id="__codelineno-0-285" name="__codelineno-0-285" href="#__codelineno-0-285"></a><span class="sd">            &quot;&quot;&quot;</span>
<a id="__codelineno-0-286" name="__codelineno-0-286" href="#__codelineno-0-286"></a>        <span class="c1"># Use the means of variational distributions as the sole MC sample.</span>
<a id="__codelineno-0-287" name="__codelineno-0-287" href="#__codelineno-0-287"></a>        <span class="n">sample_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<a id="__codelineno-0-288" name="__codelineno-0-288" href="#__codelineno-0-288"></a>        <span class="k">for</span> <span class="n">coef_name</span><span class="p">,</span> <span class="n">coef</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<a id="__codelineno-0-289" name="__codelineno-0-289" href="#__codelineno-0-289"></a>            <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">coef</span><span class="o">.</span><span class="n">variational_distribution</span><span class="o">.</span><span class="n">mean</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># (1, num_*, dim)</span>
<a id="__codelineno-0-290" name="__codelineno-0-290" href="#__codelineno-0-290"></a>
<a id="__codelineno-0-291" name="__codelineno-0-291" href="#__codelineno-0-291"></a>        <span class="c1"># there is 1 random seed in this case.</span>
<a id="__codelineno-0-292" name="__codelineno-0-292" href="#__codelineno-0-292"></a>        <span class="c1"># (num_seeds=1, len(batch), num_items)</span>
<a id="__codelineno-0-293" name="__codelineno-0-293" href="#__codelineno-0-293"></a>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_likelihood_all_items</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">return_logit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sample_dict</span><span class="o">=</span><span class="n">sample_dict</span><span class="p">)</span>
<a id="__codelineno-0-294" name="__codelineno-0-294" href="#__codelineno-0-294"></a>        <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-295" name="__codelineno-0-295" href="#__codelineno-0-295"></a>        <span class="c1"># import pdb; pdb.set_trace()</span>
<a id="__codelineno-0-296" name="__codelineno-0-296" href="#__codelineno-0-296"></a>        <span class="n">ivs</span> <span class="o">=</span> <span class="n">scatter_logsumexp</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_to_category_tensor</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-297" name="__codelineno-0-297" href="#__codelineno-0-297"></a>        <span class="k">return</span> <span class="n">ivs</span> <span class="c1"># (len(batch), num_categories)</span>
<a id="__codelineno-0-298" name="__codelineno-0-298" href="#__codelineno-0-298"></a>
<a id="__codelineno-0-299" name="__codelineno-0-299" href="#__codelineno-0-299"></a>    <span class="k">def</span> <span class="nf">sample_choices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span><span class="n">ChoiceDataset</span><span class="p">,</span> <span class="n">debug</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">num_seeds</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<a id="__codelineno-0-300" name="__codelineno-0-300" href="#__codelineno-0-300"></a>        <span class="sd">&quot;&quot;&quot;Samples choices given model paramaters and trips</span>
<a id="__codelineno-0-301" name="__codelineno-0-301" href="#__codelineno-0-301"></a>
<a id="__codelineno-0-302" name="__codelineno-0-302" href="#__codelineno-0-302"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-303" name="__codelineno-0-303" href="#__codelineno-0-303"></a><span class="sd">        batch(ChoiceDataset): batch data containing trip information; item choice information is discarded</span>
<a id="__codelineno-0-304" name="__codelineno-0-304" href="#__codelineno-0-304"></a><span class="sd">        debug(bool): whether to print debug information</span>
<a id="__codelineno-0-305" name="__codelineno-0-305" href="#__codelineno-0-305"></a>
<a id="__codelineno-0-306" name="__codelineno-0-306" href="#__codelineno-0-306"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-307" name="__codelineno-0-307" href="#__codelineno-0-307"></a><span class="sd">        Tuple[torch.Tensor]: sampled choices; shape: (batch_size, num_categories)</span>
<a id="__codelineno-0-308" name="__codelineno-0-308" href="#__codelineno-0-308"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-309" name="__codelineno-0-309" href="#__codelineno-0-309"></a>        <span class="c1"># Use the means of variational distributions as the sole MC sample.</span>
<a id="__codelineno-0-310" name="__codelineno-0-310" href="#__codelineno-0-310"></a>        <span class="n">sample_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<a id="__codelineno-0-311" name="__codelineno-0-311" href="#__codelineno-0-311"></a>        <span class="k">for</span> <span class="n">coef_name</span><span class="p">,</span> <span class="n">coef</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<a id="__codelineno-0-312" name="__codelineno-0-312" href="#__codelineno-0-312"></a>            <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">coef</span><span class="o">.</span><span class="n">variational_distribution</span><span class="o">.</span><span class="n">mean</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># (1, num_*, dim)</span>
<a id="__codelineno-0-313" name="__codelineno-0-313" href="#__codelineno-0-313"></a>        <span class="c1"># sample_dict = self.sample_coefficient_dictionary(num_seeds)</span>
<a id="__codelineno-0-314" name="__codelineno-0-314" href="#__codelineno-0-314"></a>        <span class="n">maxes</span><span class="p">,</span> <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_log_likelihoods</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">sample_dict</span><span class="p">)</span>
<a id="__codelineno-0-315" name="__codelineno-0-315" href="#__codelineno-0-315"></a>        <span class="k">return</span> <span class="n">maxes</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">out</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
<a id="__codelineno-0-316" name="__codelineno-0-316" href="#__codelineno-0-316"></a>
<a id="__codelineno-0-317" name="__codelineno-0-317" href="#__codelineno-0-317"></a>    <span class="k">def</span> <span class="nf">sample_log_likelihoods</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span><span class="n">ChoiceDataset</span><span class="p">,</span> <span class="n">sample_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<a id="__codelineno-0-318" name="__codelineno-0-318" href="#__codelineno-0-318"></a>        <span class="sd">&quot;&quot;&quot;Samples log likelihoods given model parameters and trips</span>
<a id="__codelineno-0-319" name="__codelineno-0-319" href="#__codelineno-0-319"></a>
<a id="__codelineno-0-320" name="__codelineno-0-320" href="#__codelineno-0-320"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-321" name="__codelineno-0-321" href="#__codelineno-0-321"></a><span class="sd">        batch(ChoiceDataset): batch data containing trip information; item choice information is discarded</span>
<a id="__codelineno-0-322" name="__codelineno-0-322" href="#__codelineno-0-322"></a><span class="sd">        sample_dict(Dict[str, torch.Tensor]): sampled coefficient values</span>
<a id="__codelineno-0-323" name="__codelineno-0-323" href="#__codelineno-0-323"></a>
<a id="__codelineno-0-324" name="__codelineno-0-324" href="#__codelineno-0-324"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-325" name="__codelineno-0-325" href="#__codelineno-0-325"></a><span class="sd">        Tuple[torch.Tensor]: sampled log likelihoods; shape: (batch_size, num_categories)</span>
<a id="__codelineno-0-326" name="__codelineno-0-326" href="#__codelineno-0-326"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-327" name="__codelineno-0-327" href="#__codelineno-0-327"></a>        <span class="c1"># get the log likelihoods for all items for all categories</span>
<a id="__codelineno-0-328" name="__codelineno-0-328" href="#__codelineno-0-328"></a>        <span class="n">utility</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_likelihood_all_items</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">return_logit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sample_dict</span><span class="o">=</span><span class="n">sample_dict</span><span class="p">)</span>
<a id="__codelineno-0-329" name="__codelineno-0-329" href="#__codelineno-0-329"></a>        <span class="n">mu_gumbel</span> <span class="o">=</span> <span class="mf">0.0</span>
<a id="__codelineno-0-330" name="__codelineno-0-330" href="#__codelineno-0-330"></a>        <span class="n">beta_gumbel</span> <span class="o">=</span> <span class="mf">1.0</span>
<a id="__codelineno-0-331" name="__codelineno-0-331" href="#__codelineno-0-331"></a>        <span class="n">EUL_MAS_CONST</span> <span class="o">=</span> <span class="mf">0.5772156649</span>
<a id="__codelineno-0-332" name="__codelineno-0-332" href="#__codelineno-0-332"></a>        <span class="n">mean_gumbel</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">mu_gumbel</span> <span class="o">+</span> <span class="n">beta_gumbel</span> <span class="o">*</span> <span class="n">EUL_MAS_CONST</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-333" name="__codelineno-0-333" href="#__codelineno-0-333"></a>        <span class="n">m</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">gumbel</span><span class="o">.</span><span class="n">Gumbel</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
<a id="__codelineno-0-334" name="__codelineno-0-334" href="#__codelineno-0-334"></a>        <span class="c1"># m = torch.distributions.gumbel.Gumbel(0.0, 1.0)</span>
<a id="__codelineno-0-335" name="__codelineno-0-335" href="#__codelineno-0-335"></a>        <span class="n">gumbel_samples</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">utility</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-336" name="__codelineno-0-336" href="#__codelineno-0-336"></a>        <span class="n">gumbel_samples</span> <span class="o">-=</span> <span class="n">mean_gumbel</span>
<a id="__codelineno-0-337" name="__codelineno-0-337" href="#__codelineno-0-337"></a>        <span class="n">utility</span> <span class="o">+=</span> <span class="n">gumbel_samples</span>
<a id="__codelineno-0-338" name="__codelineno-0-338" href="#__codelineno-0-338"></a>        <span class="n">max_by_category</span><span class="p">,</span> <span class="n">argmax_by_category</span> <span class="o">=</span> <span class="n">scatter_max</span><span class="p">(</span><span class="n">utility</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_to_category_tensor</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-339" name="__codelineno-0-339" href="#__codelineno-0-339"></a>        <span class="k">return</span> <span class="n">max_by_category</span><span class="p">,</span> <span class="n">argmax_by_category</span>
<a id="__codelineno-0-340" name="__codelineno-0-340" href="#__codelineno-0-340"></a>        <span class="n">log_likelihoods</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_log_likelihoods_per_category</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">sample_dict</span><span class="p">)</span>
<a id="__codelineno-0-341" name="__codelineno-0-341" href="#__codelineno-0-341"></a>
<a id="__codelineno-0-342" name="__codelineno-0-342" href="#__codelineno-0-342"></a>        <span class="c1"># sum over all categories.</span>
<a id="__codelineno-0-343" name="__codelineno-0-343" href="#__codelineno-0-343"></a>        <span class="n">log_likelihoods</span> <span class="o">=</span> <span class="n">log_likelihoods</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-344" name="__codelineno-0-344" href="#__codelineno-0-344"></a>
<a id="__codelineno-0-345" name="__codelineno-0-345" href="#__codelineno-0-345"></a>        <span class="k">return</span> <span class="n">log_likelihoods</span><span class="p">,</span> <span class="n">log_likelihoods</span>
<a id="__codelineno-0-346" name="__codelineno-0-346" href="#__codelineno-0-346"></a>
<a id="__codelineno-0-347" name="__codelineno-0-347" href="#__codelineno-0-347"></a>    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<a id="__codelineno-0-348" name="__codelineno-0-348" href="#__codelineno-0-348"></a>    <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">ChoiceDataset</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-349" name="__codelineno-0-349" href="#__codelineno-0-349"></a>        <span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-350" name="__codelineno-0-350" href="#__codelineno-0-350"></a><span class="sd">        Draw prediction on a given batch of dataset.</span>
<a id="__codelineno-0-351" name="__codelineno-0-351" href="#__codelineno-0-351"></a>
<a id="__codelineno-0-352" name="__codelineno-0-352" href="#__codelineno-0-352"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-353" name="__codelineno-0-353" href="#__codelineno-0-353"></a><span class="sd">        batch (ChoiceDataset): the dataset to draw inference on.</span>
<a id="__codelineno-0-354" name="__codelineno-0-354" href="#__codelineno-0-354"></a>
<a id="__codelineno-0-355" name="__codelineno-0-355" href="#__codelineno-0-355"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-356" name="__codelineno-0-356" href="#__codelineno-0-356"></a><span class="sd">        torch.Tensor: the predicted probabilities for each class, the behavior varies by self.pred_item.</span>
<a id="__codelineno-0-357" name="__codelineno-0-357" href="#__codelineno-0-357"></a><span class="sd">        (1: pred_item == True) While predicting items, the return tensor has shape (len(batch), num_items), out[i, j] is the predicted probability for choosing item j AMONG ALL ITEMS IN ITS CATEGORY in observation i. Please note that since probabilities are computed from within-category normalization, hence out.sum(dim=0) can be greater than 1 if there are multiple categories.</span>
<a id="__codelineno-0-358" name="__codelineno-0-358" href="#__codelineno-0-358"></a><span class="sd">        (2: pred_item == False) While predicting external labels for each observations, out[i, 0] is the predicted probability for label == 0 on the i-th observation, out[i, 1] is the predicted probability for label == 1 on the i-th observation. Generally, out[i, 0] + out[i, 1] = 1.0. However, this could be false if under-flowing/over-flowing issue is encountered.</span>
<a id="__codelineno-0-359" name="__codelineno-0-359" href="#__codelineno-0-359"></a>
<a id="__codelineno-0-360" name="__codelineno-0-360" href="#__codelineno-0-360"></a><span class="sd">        We highly recommend users to get log-probs as those are less prone to overflow/underflow; those can be accessed using the forward() function.</span>
<a id="__codelineno-0-361" name="__codelineno-0-361" href="#__codelineno-0-361"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-362" name="__codelineno-0-362" href="#__codelineno-0-362"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pred_item</span><span class="p">:</span>
<a id="__codelineno-0-363" name="__codelineno-0-363" href="#__codelineno-0-363"></a>            <span class="c1"># (len(batch), num_items)</span>
<a id="__codelineno-0-364" name="__codelineno-0-364" href="#__codelineno-0-364"></a>            <span class="n">log_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;log_prob&#39;</span><span class="p">,</span> <span class="n">return_scope</span><span class="o">=</span><span class="s1">&#39;all_items&#39;</span><span class="p">,</span> <span class="n">deterministic</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-365" name="__codelineno-0-365" href="#__codelineno-0-365"></a>            <span class="n">p</span> <span class="o">=</span> <span class="n">log_p</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span>
<a id="__codelineno-0-366" name="__codelineno-0-366" href="#__codelineno-0-366"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-367" name="__codelineno-0-367" href="#__codelineno-0-367"></a>            <span class="c1"># (len(batch), num_items)</span>
<a id="__codelineno-0-368" name="__codelineno-0-368" href="#__codelineno-0-368"></a>            <span class="c1"># probability of getting label = 1.</span>
<a id="__codelineno-0-369" name="__codelineno-0-369" href="#__codelineno-0-369"></a>            <span class="n">p_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;utility&#39;</span><span class="p">,</span> <span class="n">return_scope</span><span class="o">=</span><span class="s1">&#39;all_items&#39;</span><span class="p">,</span> <span class="n">deterministic</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<a id="__codelineno-0-370" name="__codelineno-0-370" href="#__codelineno-0-370"></a>            <span class="c1"># (len(batch), 1)</span>
<a id="__codelineno-0-371" name="__codelineno-0-371" href="#__codelineno-0-371"></a>            <span class="n">p_1</span> <span class="o">=</span> <span class="n">p_1</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)),</span> <span class="n">batch</span><span class="o">.</span><span class="n">item_index</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-372" name="__codelineno-0-372" href="#__codelineno-0-372"></a>            <span class="n">p_0</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">p_1</span>
<a id="__codelineno-0-373" name="__codelineno-0-373" href="#__codelineno-0-373"></a>            <span class="c1"># (len(batch), 2)</span>
<a id="__codelineno-0-374" name="__codelineno-0-374" href="#__codelineno-0-374"></a>            <span class="n">p</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">p_0</span><span class="p">,</span> <span class="n">p_1</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-375" name="__codelineno-0-375" href="#__codelineno-0-375"></a>
<a id="__codelineno-0-376" name="__codelineno-0-376" href="#__codelineno-0-376"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pred_item</span><span class="p">:</span>
<a id="__codelineno-0-377" name="__codelineno-0-377" href="#__codelineno-0-377"></a>            <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">)</span>
<a id="__codelineno-0-378" name="__codelineno-0-378" href="#__codelineno-0-378"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-379" name="__codelineno-0-379" href="#__codelineno-0-379"></a>            <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">)</span>
<a id="__codelineno-0-380" name="__codelineno-0-380" href="#__codelineno-0-380"></a>
<a id="__codelineno-0-381" name="__codelineno-0-381" href="#__codelineno-0-381"></a>        <span class="k">return</span> <span class="n">p</span>
<a id="__codelineno-0-382" name="__codelineno-0-382" href="#__codelineno-0-382"></a>
<a id="__codelineno-0-383" name="__codelineno-0-383" href="#__codelineno-0-383"></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">ChoiceDataset</span><span class="p">,</span>
<a id="__codelineno-0-384" name="__codelineno-0-384" href="#__codelineno-0-384"></a>                <span class="n">return_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<a id="__codelineno-0-385" name="__codelineno-0-385" href="#__codelineno-0-385"></a>                <span class="n">return_scope</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<a id="__codelineno-0-386" name="__codelineno-0-386" href="#__codelineno-0-386"></a>                <span class="n">deterministic</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-387" name="__codelineno-0-387" href="#__codelineno-0-387"></a>                <span class="n">sample_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-388" name="__codelineno-0-388" href="#__codelineno-0-388"></a>                <span class="n">num_seeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-389" name="__codelineno-0-389" href="#__codelineno-0-389"></a>                <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-390" name="__codelineno-0-390" href="#__codelineno-0-390"></a>        <span class="sd">&quot;&quot;&quot;A combined method for inference with the model.</span>
<a id="__codelineno-0-391" name="__codelineno-0-391" href="#__codelineno-0-391"></a>
<a id="__codelineno-0-392" name="__codelineno-0-392" href="#__codelineno-0-392"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-393" name="__codelineno-0-393" href="#__codelineno-0-393"></a><span class="sd">            batch (ChoiceDataset): batch data containing choice information.</span>
<a id="__codelineno-0-394" name="__codelineno-0-394" href="#__codelineno-0-394"></a><span class="sd">            return_type (str): either &#39;log_prob&#39; or &#39;utility&#39;.</span>
<a id="__codelineno-0-395" name="__codelineno-0-395" href="#__codelineno-0-395"></a><span class="sd">                &#39;log_prob&#39;: return the log-probability (by within-category log-softmax) for items</span>
<a id="__codelineno-0-396" name="__codelineno-0-396" href="#__codelineno-0-396"></a><span class="sd">                &#39;utility&#39;: return the utility value of items.</span>
<a id="__codelineno-0-397" name="__codelineno-0-397" href="#__codelineno-0-397"></a><span class="sd">            return_scope (str): either &#39;item_index&#39; or &#39;all_items&#39;.</span>
<a id="__codelineno-0-398" name="__codelineno-0-398" href="#__codelineno-0-398"></a><span class="sd">                &#39;item_index&#39;: for each observation i, return log-prob/utility for the chosen item batch.item_index[i] only.</span>
<a id="__codelineno-0-399" name="__codelineno-0-399" href="#__codelineno-0-399"></a><span class="sd">                &#39;all_items&#39;: for each observation i, return log-prob/utility for all items.</span>
<a id="__codelineno-0-400" name="__codelineno-0-400" href="#__codelineno-0-400"></a><span class="sd">            deterministic (bool, optional):</span>
<a id="__codelineno-0-401" name="__codelineno-0-401" href="#__codelineno-0-401"></a><span class="sd">                True: expectations of parameter variational distributions are used for inference.</span>
<a id="__codelineno-0-402" name="__codelineno-0-402" href="#__codelineno-0-402"></a><span class="sd">                False: the user needs to supply a dictionary of sampled parameters for inference.</span>
<a id="__codelineno-0-403" name="__codelineno-0-403" href="#__codelineno-0-403"></a><span class="sd">                Defaults to True.</span>
<a id="__codelineno-0-404" name="__codelineno-0-404" href="#__codelineno-0-404"></a><span class="sd">            sample_dict (Optional[Dict[str, torch.Tensor]], optional): sampled parameters for inference task.</span>
<a id="__codelineno-0-405" name="__codelineno-0-405" href="#__codelineno-0-405"></a><span class="sd">                This is not needed when `deterministic` is True.</span>
<a id="__codelineno-0-406" name="__codelineno-0-406" href="#__codelineno-0-406"></a><span class="sd">                When `deterministic` is False, the user can supply a `sample_dict`. If `sample_dict` is not provided,</span>
<a id="__codelineno-0-407" name="__codelineno-0-407" href="#__codelineno-0-407"></a><span class="sd">                this method will create `num_seeds` samples.</span>
<a id="__codelineno-0-408" name="__codelineno-0-408" href="#__codelineno-0-408"></a><span class="sd">                Defaults to None.</span>
<a id="__codelineno-0-409" name="__codelineno-0-409" href="#__codelineno-0-409"></a><span class="sd">            num_seeds (Optional[int]): the number of random samples of parameters to construct. This is only required</span>
<a id="__codelineno-0-410" name="__codelineno-0-410" href="#__codelineno-0-410"></a><span class="sd">                if `deterministic` is False (i.e., stochastic mode) and `sample_dict` is not provided.</span>
<a id="__codelineno-0-411" name="__codelineno-0-411" href="#__codelineno-0-411"></a><span class="sd">                Defaults to None.</span>
<a id="__codelineno-0-412" name="__codelineno-0-412" href="#__codelineno-0-412"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-413" name="__codelineno-0-413" href="#__codelineno-0-413"></a><span class="sd">            torch.Tensor: a tensor of log-probabilities or utilities, depending on `return_type`.</span>
<a id="__codelineno-0-414" name="__codelineno-0-414" href="#__codelineno-0-414"></a><span class="sd">                The shape of the returned tensor depends on `return_scope` and `deterministic`.</span>
<a id="__codelineno-0-415" name="__codelineno-0-415" href="#__codelineno-0-415"></a><span class="sd">                -------------------------------------------------------------------------</span>
<a id="__codelineno-0-416" name="__codelineno-0-416" href="#__codelineno-0-416"></a><span class="sd">                | `return_scope` | `deterministic` |         Output shape               |</span>
<a id="__codelineno-0-417" name="__codelineno-0-417" href="#__codelineno-0-417"></a><span class="sd">                -------------------------------------------------------------------------</span>
<a id="__codelineno-0-418" name="__codelineno-0-418" href="#__codelineno-0-418"></a><span class="sd">                |   &#39;item_index` |      True       | (len(batch),)                      |</span>
<a id="__codelineno-0-419" name="__codelineno-0-419" href="#__codelineno-0-419"></a><span class="sd">                -------------------------------------------------------------------------</span>
<a id="__codelineno-0-420" name="__codelineno-0-420" href="#__codelineno-0-420"></a><span class="sd">                |   &#39;all_items&#39;  |      True       | (len(batch), num_items)            |</span>
<a id="__codelineno-0-421" name="__codelineno-0-421" href="#__codelineno-0-421"></a><span class="sd">                -------------------------------------------------------------------------</span>
<a id="__codelineno-0-422" name="__codelineno-0-422" href="#__codelineno-0-422"></a><span class="sd">                |   &#39;item_index&#39; |      False      | (num_seeds, len(batch))            |</span>
<a id="__codelineno-0-423" name="__codelineno-0-423" href="#__codelineno-0-423"></a><span class="sd">                -------------------------------------------------------------------------</span>
<a id="__codelineno-0-424" name="__codelineno-0-424" href="#__codelineno-0-424"></a><span class="sd">                |   &#39;all_items&#39;  |      False      | (num_seeds, len(batch), num_items) |</span>
<a id="__codelineno-0-425" name="__codelineno-0-425" href="#__codelineno-0-425"></a><span class="sd">                -------------------------------------------------------------------------</span>
<a id="__codelineno-0-426" name="__codelineno-0-426" href="#__codelineno-0-426"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-427" name="__codelineno-0-427" href="#__codelineno-0-427"></a>        <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-428" name="__codelineno-0-428" href="#__codelineno-0-428"></a>        <span class="c1"># check arguments.</span>
<a id="__codelineno-0-429" name="__codelineno-0-429" href="#__codelineno-0-429"></a>        <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-430" name="__codelineno-0-430" href="#__codelineno-0-430"></a>        <span class="k">assert</span> <span class="n">return_type</span> <span class="ow">in</span> <span class="p">[</span>
<a id="__codelineno-0-431" name="__codelineno-0-431" href="#__codelineno-0-431"></a>            <span class="s1">&#39;log_prob&#39;</span><span class="p">,</span> <span class="s1">&#39;utility&#39;</span><span class="p">],</span> <span class="s2">&quot;return_type must be either &#39;log_prob&#39; or &#39;utility&#39;.&quot;</span>
<a id="__codelineno-0-432" name="__codelineno-0-432" href="#__codelineno-0-432"></a>        <span class="k">assert</span> <span class="n">return_scope</span> <span class="ow">in</span> <span class="p">[</span>
<a id="__codelineno-0-433" name="__codelineno-0-433" href="#__codelineno-0-433"></a>            <span class="s1">&#39;item_index&#39;</span><span class="p">,</span> <span class="s1">&#39;all_items&#39;</span><span class="p">],</span> <span class="s2">&quot;return_scope must be either &#39;item_index&#39; or &#39;all_items&#39;.&quot;</span>
<a id="__codelineno-0-434" name="__codelineno-0-434" href="#__codelineno-0-434"></a>        <span class="k">assert</span> <span class="n">deterministic</span> <span class="ow">in</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]</span>
<a id="__codelineno-0-435" name="__codelineno-0-435" href="#__codelineno-0-435"></a>        <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="n">deterministic</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">sample_dict</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">):</span>
<a id="__codelineno-0-436" name="__codelineno-0-436" href="#__codelineno-0-436"></a>            <span class="k">assert</span> <span class="n">num_seeds</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;A positive interger `num_seeds` is required if `deterministic` is False and no `sample_dict` is provided.&quot;</span>
<a id="__codelineno-0-437" name="__codelineno-0-437" href="#__codelineno-0-437"></a>
<a id="__codelineno-0-438" name="__codelineno-0-438" href="#__codelineno-0-438"></a>        <span class="c1"># when pred_item is true, the model is predicting which item is bought (specified by item_index).</span>
<a id="__codelineno-0-439" name="__codelineno-0-439" href="#__codelineno-0-439"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pred_item</span><span class="p">:</span>
<a id="__codelineno-0-440" name="__codelineno-0-440" href="#__codelineno-0-440"></a>            <span class="n">batch</span><span class="o">.</span><span class="n">label</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">item_index</span>
<a id="__codelineno-0-441" name="__codelineno-0-441" href="#__codelineno-0-441"></a>
<a id="__codelineno-0-442" name="__codelineno-0-442" href="#__codelineno-0-442"></a>        <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-443" name="__codelineno-0-443" href="#__codelineno-0-443"></a>        <span class="c1"># get sample_dict ready.</span>
<a id="__codelineno-0-444" name="__codelineno-0-444" href="#__codelineno-0-444"></a>        <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-445" name="__codelineno-0-445" href="#__codelineno-0-445"></a>        <span class="k">if</span> <span class="n">deterministic</span><span class="p">:</span>
<a id="__codelineno-0-446" name="__codelineno-0-446" href="#__codelineno-0-446"></a>            <span class="n">num_seeds</span> <span class="o">=</span> <span class="mi">1</span>
<a id="__codelineno-0-447" name="__codelineno-0-447" href="#__codelineno-0-447"></a>            <span class="c1"># Use the means of variational distributions as the sole deterministic MC sample.</span>
<a id="__codelineno-0-448" name="__codelineno-0-448" href="#__codelineno-0-448"></a>            <span class="c1"># NOTE: here we don&#39;t need to sample the obs2prior weight H since we only compute the log-likelihood.</span>
<a id="__codelineno-0-449" name="__codelineno-0-449" href="#__codelineno-0-449"></a>            <span class="c1"># TODO: is this correct?</span>
<a id="__codelineno-0-450" name="__codelineno-0-450" href="#__codelineno-0-450"></a>            <span class="n">sample_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<a id="__codelineno-0-451" name="__codelineno-0-451" href="#__codelineno-0-451"></a>            <span class="k">for</span> <span class="n">coef_name</span><span class="p">,</span> <span class="n">coef</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<a id="__codelineno-0-452" name="__codelineno-0-452" href="#__codelineno-0-452"></a>                <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">coef</span><span class="o">.</span><span class="n">variational_distribution</span><span class="o">.</span><span class="n">mean</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span>
<a id="__codelineno-0-453" name="__codelineno-0-453" href="#__codelineno-0-453"></a>                    <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># (1, num_*, dim)</span>
<a id="__codelineno-0-454" name="__codelineno-0-454" href="#__codelineno-0-454"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-455" name="__codelineno-0-455" href="#__codelineno-0-455"></a>            <span class="k">if</span> <span class="n">sample_dict</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-456" name="__codelineno-0-456" href="#__codelineno-0-456"></a>                <span class="c1"># sample stochastic parameters.</span>
<a id="__codelineno-0-457" name="__codelineno-0-457" href="#__codelineno-0-457"></a>                <span class="n">sample_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_coefficient_dictionary</span><span class="p">(</span><span class="n">num_seeds</span><span class="p">)</span>
<a id="__codelineno-0-458" name="__codelineno-0-458" href="#__codelineno-0-458"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-459" name="__codelineno-0-459" href="#__codelineno-0-459"></a>                <span class="c1"># use the provided sample_dict.</span>
<a id="__codelineno-0-460" name="__codelineno-0-460" href="#__codelineno-0-460"></a>                <span class="n">num_seeds</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">sample_dict</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-461" name="__codelineno-0-461" href="#__codelineno-0-461"></a>
<a id="__codelineno-0-462" name="__codelineno-0-462" href="#__codelineno-0-462"></a>        <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-463" name="__codelineno-0-463" href="#__codelineno-0-463"></a>        <span class="c1"># call the sampling method of additional modules.</span>
<a id="__codelineno-0-464" name="__codelineno-0-464" href="#__codelineno-0-464"></a>        <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-465" name="__codelineno-0-465" href="#__codelineno-0-465"></a>        <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">additional_modules</span><span class="p">:</span>
<a id="__codelineno-0-466" name="__codelineno-0-466" href="#__codelineno-0-466"></a>            <span class="c1"># deterministic sample.</span>
<a id="__codelineno-0-467" name="__codelineno-0-467" href="#__codelineno-0-467"></a>            <span class="k">if</span> <span class="n">deterministic</span><span class="p">:</span>
<a id="__codelineno-0-468" name="__codelineno-0-468" href="#__codelineno-0-468"></a>                <span class="n">module</span><span class="o">.</span><span class="n">dsample</span><span class="p">()</span>
<a id="__codelineno-0-469" name="__codelineno-0-469" href="#__codelineno-0-469"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-470" name="__codelineno-0-470" href="#__codelineno-0-470"></a>                <span class="n">module</span><span class="o">.</span><span class="n">rsample</span><span class="p">(</span><span class="n">num_seeds</span><span class="o">=</span><span class="n">num_seeds</span><span class="p">)</span>
<a id="__codelineno-0-471" name="__codelineno-0-471" href="#__codelineno-0-471"></a>
<a id="__codelineno-0-472" name="__codelineno-0-472" href="#__codelineno-0-472"></a>        <span class="c1"># if utility is requested, don&#39;t run log-softmax, simply return logit.</span>
<a id="__codelineno-0-473" name="__codelineno-0-473" href="#__codelineno-0-473"></a>        <span class="n">return_logit</span> <span class="o">=</span> <span class="p">(</span><span class="n">return_type</span> <span class="o">==</span> <span class="s1">&#39;utility&#39;</span><span class="p">)</span>
<a id="__codelineno-0-474" name="__codelineno-0-474" href="#__codelineno-0-474"></a>        <span class="k">if</span> <span class="n">return_scope</span> <span class="o">==</span> <span class="s1">&#39;all_items&#39;</span><span class="p">:</span>
<a id="__codelineno-0-475" name="__codelineno-0-475" href="#__codelineno-0-475"></a>            <span class="c1"># (num_seeds, len(batch), num_items)</span>
<a id="__codelineno-0-476" name="__codelineno-0-476" href="#__codelineno-0-476"></a>            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_likelihood_all_items</span><span class="p">(</span>
<a id="__codelineno-0-477" name="__codelineno-0-477" href="#__codelineno-0-477"></a>                <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span> <span class="n">sample_dict</span><span class="o">=</span><span class="n">sample_dict</span><span class="p">,</span> <span class="n">return_logit</span><span class="o">=</span><span class="n">return_logit</span><span class="p">)</span>
<a id="__codelineno-0-478" name="__codelineno-0-478" href="#__codelineno-0-478"></a>        <span class="k">elif</span> <span class="n">return_scope</span> <span class="o">==</span> <span class="s1">&#39;item_index&#39;</span><span class="p">:</span>
<a id="__codelineno-0-479" name="__codelineno-0-479" href="#__codelineno-0-479"></a>            <span class="c1"># (num_seeds, len(batch))</span>
<a id="__codelineno-0-480" name="__codelineno-0-480" href="#__codelineno-0-480"></a>            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_likelihood_item_index</span><span class="p">(</span>
<a id="__codelineno-0-481" name="__codelineno-0-481" href="#__codelineno-0-481"></a>                <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span> <span class="n">sample_dict</span><span class="o">=</span><span class="n">sample_dict</span><span class="p">,</span> <span class="n">return_logit</span><span class="o">=</span><span class="n">return_logit</span><span class="p">)</span>
<a id="__codelineno-0-482" name="__codelineno-0-482" href="#__codelineno-0-482"></a>
<a id="__codelineno-0-483" name="__codelineno-0-483" href="#__codelineno-0-483"></a>        <span class="k">if</span> <span class="n">deterministic</span><span class="p">:</span>
<a id="__codelineno-0-484" name="__codelineno-0-484" href="#__codelineno-0-484"></a>            <span class="c1"># drop the first dimension, which has size of `num_seeds` (equals 1 in the deterministic case).</span>
<a id="__codelineno-0-485" name="__codelineno-0-485" href="#__codelineno-0-485"></a>            <span class="c1"># (len(batch), num_items) or (len(batch),)</span>
<a id="__codelineno-0-486" name="__codelineno-0-486" href="#__codelineno-0-486"></a>            <span class="k">return</span> <span class="n">out</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-487" name="__codelineno-0-487" href="#__codelineno-0-487"></a>
<a id="__codelineno-0-488" name="__codelineno-0-488" href="#__codelineno-0-488"></a>        <span class="k">return</span> <span class="n">out</span>
<a id="__codelineno-0-489" name="__codelineno-0-489" href="#__codelineno-0-489"></a>
<a id="__codelineno-0-490" name="__codelineno-0-490" href="#__codelineno-0-490"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-491" name="__codelineno-0-491" href="#__codelineno-0-491"></a>    <span class="k">def</span> <span class="nf">num_params</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<a id="__codelineno-0-492" name="__codelineno-0-492" href="#__codelineno-0-492"></a>        <span class="k">return</span> <span class="nb">sum</span><span class="p">([</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">()])</span>
<a id="__codelineno-0-493" name="__codelineno-0-493" href="#__codelineno-0-493"></a>
<a id="__codelineno-0-494" name="__codelineno-0-494" href="#__codelineno-0-494"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-495" name="__codelineno-0-495" href="#__codelineno-0-495"></a>    <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
<a id="__codelineno-0-496" name="__codelineno-0-496" href="#__codelineno-0-496"></a>        <span class="k">for</span> <span class="n">coef</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_dict</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
<a id="__codelineno-0-497" name="__codelineno-0-497" href="#__codelineno-0-497"></a>            <span class="k">return</span> <span class="n">coef</span><span class="o">.</span><span class="n">device</span>
<a id="__codelineno-0-498" name="__codelineno-0-498" href="#__codelineno-0-498"></a>
<a id="__codelineno-0-499" name="__codelineno-0-499" href="#__codelineno-0-499"></a>    <span class="c1"># ==================================================================================================================</span>
<a id="__codelineno-0-500" name="__codelineno-0-500" href="#__codelineno-0-500"></a>    <span class="c1"># helper functions.</span>
<a id="__codelineno-0-501" name="__codelineno-0-501" href="#__codelineno-0-501"></a>    <span class="c1"># ==================================================================================================================</span>
<a id="__codelineno-0-502" name="__codelineno-0-502" href="#__codelineno-0-502"></a>    <span class="k">def</span> <span class="nf">sample_coefficient_dictionary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_seeds</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<a id="__codelineno-0-503" name="__codelineno-0-503" href="#__codelineno-0-503"></a>        <span class="sd">&quot;&quot;&quot;A helper function to sample parameters from coefficients.</span>
<a id="__codelineno-0-504" name="__codelineno-0-504" href="#__codelineno-0-504"></a>
<a id="__codelineno-0-505" name="__codelineno-0-505" href="#__codelineno-0-505"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-506" name="__codelineno-0-506" href="#__codelineno-0-506"></a><span class="sd">            num_seeds (int): number of random samples.</span>
<a id="__codelineno-0-507" name="__codelineno-0-507" href="#__codelineno-0-507"></a>
<a id="__codelineno-0-508" name="__codelineno-0-508" href="#__codelineno-0-508"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-509" name="__codelineno-0-509" href="#__codelineno-0-509"></a><span class="sd">            Dict[str, torch.Tensor]: a dictionary maps coefficient names to tensor of sampled coefficient parameters,</span>
<a id="__codelineno-0-510" name="__codelineno-0-510" href="#__codelineno-0-510"></a><span class="sd">                where the first dimension of the sampled tensor has size `num_seeds`.</span>
<a id="__codelineno-0-511" name="__codelineno-0-511" href="#__codelineno-0-511"></a><span class="sd">                Each sample tensor has shape (num_seeds, num_classes, dim).</span>
<a id="__codelineno-0-512" name="__codelineno-0-512" href="#__codelineno-0-512"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-513" name="__codelineno-0-513" href="#__codelineno-0-513"></a>        <span class="n">sample_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<a id="__codelineno-0-514" name="__codelineno-0-514" href="#__codelineno-0-514"></a>        <span class="k">for</span> <span class="n">coef_name</span><span class="p">,</span> <span class="n">coef</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<a id="__codelineno-0-515" name="__codelineno-0-515" href="#__codelineno-0-515"></a>            <span class="n">s</span> <span class="o">=</span> <span class="n">coef</span><span class="o">.</span><span class="n">rsample</span><span class="p">(</span><span class="n">num_seeds</span><span class="p">)</span>
<a id="__codelineno-0-516" name="__codelineno-0-516" href="#__codelineno-0-516"></a>            <span class="k">if</span> <span class="n">coef</span><span class="o">.</span><span class="n">obs2prior</span><span class="p">:</span>
<a id="__codelineno-0-517" name="__codelineno-0-517" href="#__codelineno-0-517"></a>                <span class="c1"># sample both obs2prior weight and realization of variable.</span>
<a id="__codelineno-0-518" name="__codelineno-0-518" href="#__codelineno-0-518"></a>                <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
<a id="__codelineno-0-519" name="__codelineno-0-519" href="#__codelineno-0-519"></a>                <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-520" name="__codelineno-0-520" href="#__codelineno-0-520"></a>                <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name</span> <span class="o">+</span> <span class="s1">&#39;.H&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<a id="__codelineno-0-521" name="__codelineno-0-521" href="#__codelineno-0-521"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-522" name="__codelineno-0-522" href="#__codelineno-0-522"></a>                <span class="c1"># only sample the realization of variable.</span>
<a id="__codelineno-0-523" name="__codelineno-0-523" href="#__codelineno-0-523"></a>                <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
<a id="__codelineno-0-524" name="__codelineno-0-524" href="#__codelineno-0-524"></a>                <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">s</span>
<a id="__codelineno-0-525" name="__codelineno-0-525" href="#__codelineno-0-525"></a>        <span class="k">return</span> <span class="n">sample_dict</span>
<a id="__codelineno-0-526" name="__codelineno-0-526" href="#__codelineno-0-526"></a>
<a id="__codelineno-0-527" name="__codelineno-0-527" href="#__codelineno-0-527"></a>    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<a id="__codelineno-0-528" name="__codelineno-0-528" href="#__codelineno-0-528"></a>    <span class="k">def</span> <span class="nf">get_within_category_accuracy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log_p_all_items</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">label</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<a id="__codelineno-0-529" name="__codelineno-0-529" href="#__codelineno-0-529"></a>        <span class="sd">&quot;&quot;&quot;A helper function for computing prediction accuracy (i.e., all non-differential metrics)</span>
<a id="__codelineno-0-530" name="__codelineno-0-530" href="#__codelineno-0-530"></a><span class="sd">        within category.</span>
<a id="__codelineno-0-531" name="__codelineno-0-531" href="#__codelineno-0-531"></a><span class="sd">        In particular, this method calculates the accuracy, precision, recall and F1 score.</span>
<a id="__codelineno-0-532" name="__codelineno-0-532" href="#__codelineno-0-532"></a>
<a id="__codelineno-0-533" name="__codelineno-0-533" href="#__codelineno-0-533"></a>
<a id="__codelineno-0-534" name="__codelineno-0-534" href="#__codelineno-0-534"></a><span class="sd">        This method has the same functionality as the following peusodcode:</span>
<a id="__codelineno-0-535" name="__codelineno-0-535" href="#__codelineno-0-535"></a><span class="sd">        for C in categories:</span>
<a id="__codelineno-0-536" name="__codelineno-0-536" href="#__codelineno-0-536"></a><span class="sd">            # get sessions in which item in category C was purchased.</span>
<a id="__codelineno-0-537" name="__codelineno-0-537" href="#__codelineno-0-537"></a><span class="sd">            T &lt;- (t for t in {0,1,..., len(label)-1} if label[t] is in C)</span>
<a id="__codelineno-0-538" name="__codelineno-0-538" href="#__codelineno-0-538"></a><span class="sd">            Y &lt;- label[T]</span>
<a id="__codelineno-0-539" name="__codelineno-0-539" href="#__codelineno-0-539"></a>
<a id="__codelineno-0-540" name="__codelineno-0-540" href="#__codelineno-0-540"></a><span class="sd">            predictions = list()</span>
<a id="__codelineno-0-541" name="__codelineno-0-541" href="#__codelineno-0-541"></a><span class="sd">            for t in T:</span>
<a id="__codelineno-0-542" name="__codelineno-0-542" href="#__codelineno-0-542"></a><span class="sd">                # get the prediction within category for this session.</span>
<a id="__codelineno-0-543" name="__codelineno-0-543" href="#__codelineno-0-543"></a><span class="sd">                y_pred = argmax_{items in C} log prob computed before.</span>
<a id="__codelineno-0-544" name="__codelineno-0-544" href="#__codelineno-0-544"></a><span class="sd">                predictions.append(y_pred)</span>
<a id="__codelineno-0-545" name="__codelineno-0-545" href="#__codelineno-0-545"></a>
<a id="__codelineno-0-546" name="__codelineno-0-546" href="#__codelineno-0-546"></a><span class="sd">            accuracy = mean(Y == predictions)</span>
<a id="__codelineno-0-547" name="__codelineno-0-547" href="#__codelineno-0-547"></a>
<a id="__codelineno-0-548" name="__codelineno-0-548" href="#__codelineno-0-548"></a><span class="sd">        Similarly, this function computes precision, recall and f1score as well.</span>
<a id="__codelineno-0-549" name="__codelineno-0-549" href="#__codelineno-0-549"></a>
<a id="__codelineno-0-550" name="__codelineno-0-550" href="#__codelineno-0-550"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-551" name="__codelineno-0-551" href="#__codelineno-0-551"></a><span class="sd">            log_p_all_items (torch.Tensor): shape (num_sessions, num_items) the log probability of</span>
<a id="__codelineno-0-552" name="__codelineno-0-552" href="#__codelineno-0-552"></a><span class="sd">                choosing each item in each session.</span>
<a id="__codelineno-0-553" name="__codelineno-0-553" href="#__codelineno-0-553"></a><span class="sd">            label (torch.LongTensor): shape (num_sessions,), the IDs of items purchased in each session.</span>
<a id="__codelineno-0-554" name="__codelineno-0-554" href="#__codelineno-0-554"></a>
<a id="__codelineno-0-555" name="__codelineno-0-555" href="#__codelineno-0-555"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-556" name="__codelineno-0-556" href="#__codelineno-0-556"></a><span class="sd">            [Dict[str, float]]: A dictionary containing performance metrics.</span>
<a id="__codelineno-0-557" name="__codelineno-0-557" href="#__codelineno-0-557"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-558" name="__codelineno-0-558" href="#__codelineno-0-558"></a>        <span class="c1"># argmax: (num_sessions, num_categories), within category argmax.</span>
<a id="__codelineno-0-559" name="__codelineno-0-559" href="#__codelineno-0-559"></a>        <span class="c1"># item IDs are consecutive, thus argmax is the same as IDs of the item with highest P.</span>
<a id="__codelineno-0-560" name="__codelineno-0-560" href="#__codelineno-0-560"></a>        <span class="n">_</span><span class="p">,</span> <span class="n">argmax_by_category</span> <span class="o">=</span> <span class="n">scatter_max</span><span class="p">(</span>
<a id="__codelineno-0-561" name="__codelineno-0-561" href="#__codelineno-0-561"></a>            <span class="n">log_p_all_items</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_to_category_tensor</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-562" name="__codelineno-0-562" href="#__codelineno-0-562"></a>
<a id="__codelineno-0-563" name="__codelineno-0-563" href="#__codelineno-0-563"></a>        <span class="c1"># category_purchased[t] = the category of item label[t].</span>
<a id="__codelineno-0-564" name="__codelineno-0-564" href="#__codelineno-0-564"></a>        <span class="c1"># (num_sessions,)</span>
<a id="__codelineno-0-565" name="__codelineno-0-565" href="#__codelineno-0-565"></a>        <span class="n">category_purchased</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_to_category_tensor</span><span class="p">[</span><span class="n">label</span><span class="p">]</span>
<a id="__codelineno-0-566" name="__codelineno-0-566" href="#__codelineno-0-566"></a>
<a id="__codelineno-0-567" name="__codelineno-0-567" href="#__codelineno-0-567"></a>        <span class="c1"># pred[t] = the item with highest utility from the category item label[t] belongs to.</span>
<a id="__codelineno-0-568" name="__codelineno-0-568" href="#__codelineno-0-568"></a>        <span class="c1"># (num_sessions,)</span>
<a id="__codelineno-0-569" name="__codelineno-0-569" href="#__codelineno-0-569"></a>        <span class="n">pred_from_category</span> <span class="o">=</span> <span class="n">argmax_by_category</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span>
<a id="__codelineno-0-570" name="__codelineno-0-570" href="#__codelineno-0-570"></a>            <span class="nb">len</span><span class="p">(</span><span class="n">label</span><span class="p">)),</span> <span class="n">category_purchased</span><span class="p">]</span>
<a id="__codelineno-0-571" name="__codelineno-0-571" href="#__codelineno-0-571"></a>
<a id="__codelineno-0-572" name="__codelineno-0-572" href="#__codelineno-0-572"></a>        <span class="n">within_category_accuracy</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-573" name="__codelineno-0-573" href="#__codelineno-0-573"></a>            <span class="n">pred_from_category</span> <span class="o">==</span> <span class="n">label</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<a id="__codelineno-0-574" name="__codelineno-0-574" href="#__codelineno-0-574"></a>
<a id="__codelineno-0-575" name="__codelineno-0-575" href="#__codelineno-0-575"></a>        <span class="c1"># precision</span>
<a id="__codelineno-0-576" name="__codelineno-0-576" href="#__codelineno-0-576"></a>        <span class="n">precision</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<a id="__codelineno-0-577" name="__codelineno-0-577" href="#__codelineno-0-577"></a>
<a id="__codelineno-0-578" name="__codelineno-0-578" href="#__codelineno-0-578"></a>        <span class="n">recall</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<a id="__codelineno-0-579" name="__codelineno-0-579" href="#__codelineno-0-579"></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">):</span>
<a id="__codelineno-0-580" name="__codelineno-0-580" href="#__codelineno-0-580"></a>            <span class="n">correct_i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
<a id="__codelineno-0-581" name="__codelineno-0-581" href="#__codelineno-0-581"></a>                <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">pred_from_category</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="o">==</span> <span class="n">i</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
<a id="__codelineno-0-582" name="__codelineno-0-582" href="#__codelineno-0-582"></a>            <span class="n">precision_i</span> <span class="o">=</span> <span class="n">correct_i</span> <span class="o">/</span> \
<a id="__codelineno-0-583" name="__codelineno-0-583" href="#__codelineno-0-583"></a>                <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">pred_from_category</span> <span class="o">==</span> <span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
<a id="__codelineno-0-584" name="__codelineno-0-584" href="#__codelineno-0-584"></a>            <span class="n">recall_i</span> <span class="o">=</span> <span class="n">correct_i</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">label</span> <span class="o">==</span> <span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
<a id="__codelineno-0-585" name="__codelineno-0-585" href="#__codelineno-0-585"></a>
<a id="__codelineno-0-586" name="__codelineno-0-586" href="#__codelineno-0-586"></a>            <span class="c1"># do not add if divided by zero.</span>
<a id="__codelineno-0-587" name="__codelineno-0-587" href="#__codelineno-0-587"></a>            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">pred_from_category</span> <span class="o">==</span> <span class="n">i</span><span class="p">):</span>
<a id="__codelineno-0-588" name="__codelineno-0-588" href="#__codelineno-0-588"></a>                <span class="n">precision</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">precision_i</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
<a id="__codelineno-0-589" name="__codelineno-0-589" href="#__codelineno-0-589"></a>            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">label</span> <span class="o">==</span> <span class="n">i</span><span class="p">):</span>
<a id="__codelineno-0-590" name="__codelineno-0-590" href="#__codelineno-0-590"></a>                <span class="n">recall</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">recall_i</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
<a id="__codelineno-0-591" name="__codelineno-0-591" href="#__codelineno-0-591"></a>
<a id="__codelineno-0-592" name="__codelineno-0-592" href="#__codelineno-0-592"></a>        <span class="n">precision</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">precision</span><span class="p">))</span>
<a id="__codelineno-0-593" name="__codelineno-0-593" href="#__codelineno-0-593"></a>        <span class="n">recall</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">recall</span><span class="p">))</span>
<a id="__codelineno-0-594" name="__codelineno-0-594" href="#__codelineno-0-594"></a>
<a id="__codelineno-0-595" name="__codelineno-0-595" href="#__codelineno-0-595"></a>        <span class="k">if</span> <span class="n">precision</span> <span class="o">==</span> <span class="n">recall</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-0-596" name="__codelineno-0-596" href="#__codelineno-0-596"></a>            <span class="n">f1</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-597" name="__codelineno-0-597" href="#__codelineno-0-597"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-598" name="__codelineno-0-598" href="#__codelineno-0-598"></a>            <span class="n">f1</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">precision</span> <span class="o">*</span> <span class="n">recall</span> <span class="o">/</span> <span class="p">(</span><span class="n">precision</span> <span class="o">+</span> <span class="n">recall</span><span class="p">)</span>
<a id="__codelineno-0-599" name="__codelineno-0-599" href="#__codelineno-0-599"></a>
<a id="__codelineno-0-600" name="__codelineno-0-600" href="#__codelineno-0-600"></a>        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">within_category_accuracy</span><span class="p">,</span>
<a id="__codelineno-0-601" name="__codelineno-0-601" href="#__codelineno-0-601"></a>                <span class="s1">&#39;precision&#39;</span><span class="p">:</span> <span class="n">precision</span><span class="p">,</span>
<a id="__codelineno-0-602" name="__codelineno-0-602" href="#__codelineno-0-602"></a>                <span class="s1">&#39;recall&#39;</span><span class="p">:</span> <span class="n">recall</span><span class="p">,</span>
<a id="__codelineno-0-603" name="__codelineno-0-603" href="#__codelineno-0-603"></a>                <span class="s1">&#39;f1score&#39;</span><span class="p">:</span> <span class="n">f1</span><span class="p">}</span>
<a id="__codelineno-0-604" name="__codelineno-0-604" href="#__codelineno-0-604"></a>
<a id="__codelineno-0-605" name="__codelineno-0-605" href="#__codelineno-0-605"></a>    <span class="c1"># ==================================================================================================================</span>
<a id="__codelineno-0-606" name="__codelineno-0-606" href="#__codelineno-0-606"></a>    <span class="c1"># Methods for terms in the ELBO: prior, likelihood, and variational.</span>
<a id="__codelineno-0-607" name="__codelineno-0-607" href="#__codelineno-0-607"></a>    <span class="c1"># ==================================================================================================================</span>
<a id="__codelineno-0-608" name="__codelineno-0-608" href="#__codelineno-0-608"></a>    <span class="k">def</span> <span class="nf">log_likelihood_all_items</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">ChoiceDataset</span><span class="p">,</span> <span class="n">return_logit</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">sample_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-609" name="__codelineno-0-609" href="#__codelineno-0-609"></a>        <span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-610" name="__codelineno-0-610" href="#__codelineno-0-610"></a><span class="sd">        NOTE to developers:</span>
<a id="__codelineno-0-611" name="__codelineno-0-611" href="#__codelineno-0-611"></a><span class="sd">        NOTE (akanodia to tianyudu): Is this really slow; even with log_likelihood you need log_prob which depends on logits of all items?</span>
<a id="__codelineno-0-612" name="__codelineno-0-612" href="#__codelineno-0-612"></a><span class="sd">        This method computes utilities for all items available, which is a relatively slow operation. For</span>
<a id="__codelineno-0-613" name="__codelineno-0-613" href="#__codelineno-0-613"></a><span class="sd">        training the model, you only need the utility/log-prob for the chosen/relevant item (i.e., item_index[i] for each i-th observation).</span>
<a id="__codelineno-0-614" name="__codelineno-0-614" href="#__codelineno-0-614"></a><span class="sd">        Use this method for inference only.</span>
<a id="__codelineno-0-615" name="__codelineno-0-615" href="#__codelineno-0-615"></a><span class="sd">        Use self.log_likelihood_item_index() for training instead.</span>
<a id="__codelineno-0-616" name="__codelineno-0-616" href="#__codelineno-0-616"></a>
<a id="__codelineno-0-617" name="__codelineno-0-617" href="#__codelineno-0-617"></a><span class="sd">        Computes the log probability of choosing `each` item in each session based on current model parameters.</span>
<a id="__codelineno-0-618" name="__codelineno-0-618" href="#__codelineno-0-618"></a><span class="sd">        NOTE (akanodiadu to tianyudu): What does the next line mean? I think it just says its allowing for samples instead of posterior mean.</span>
<a id="__codelineno-0-619" name="__codelineno-0-619" href="#__codelineno-0-619"></a><span class="sd">        This method allows for specifying {user, item}_latent_value for Monte Carlo estimation in ELBO.</span>
<a id="__codelineno-0-620" name="__codelineno-0-620" href="#__codelineno-0-620"></a><span class="sd">        For actual prediction tasks, use the forward() function, which will use means of variational</span>
<a id="__codelineno-0-621" name="__codelineno-0-621" href="#__codelineno-0-621"></a><span class="sd">        distributions for user and item latents.</span>
<a id="__codelineno-0-622" name="__codelineno-0-622" href="#__codelineno-0-622"></a>
<a id="__codelineno-0-623" name="__codelineno-0-623" href="#__codelineno-0-623"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-624" name="__codelineno-0-624" href="#__codelineno-0-624"></a><span class="sd">            batch (ChoiceDataset): a ChoiceDataset object containing relevant information.</span>
<a id="__codelineno-0-625" name="__codelineno-0-625" href="#__codelineno-0-625"></a><span class="sd">            return_logit(bool): if set to True, return the log-probability, otherwise return the logit/utility.</span>
<a id="__codelineno-0-626" name="__codelineno-0-626" href="#__codelineno-0-626"></a><span class="sd">            sample_dict(Dict[str, torch.Tensor]): Monte Carlo samples for model coefficients</span>
<a id="__codelineno-0-627" name="__codelineno-0-627" href="#__codelineno-0-627"></a><span class="sd">                (i.e., those Greek letters).</span>
<a id="__codelineno-0-628" name="__codelineno-0-628" href="#__codelineno-0-628"></a><span class="sd">                sample_dict.keys() should be the same as keys of self.obs2prior_dict, i.e., those</span>
<a id="__codelineno-0-629" name="__codelineno-0-629" href="#__codelineno-0-629"></a><span class="sd">                greek letters actually enter the functional form of utility.</span>
<a id="__codelineno-0-630" name="__codelineno-0-630" href="#__codelineno-0-630"></a><span class="sd">                The value of sample_dict should be tensors of shape (num_seeds, num_classes, dim)</span>
<a id="__codelineno-0-631" name="__codelineno-0-631" href="#__codelineno-0-631"></a><span class="sd">                where num_classes in {num_users, num_items, 1}</span>
<a id="__codelineno-0-632" name="__codelineno-0-632" href="#__codelineno-0-632"></a><span class="sd">                and dim in {latent_dim(K), num_item_obs, num_user_obs, 1}.</span>
<a id="__codelineno-0-633" name="__codelineno-0-633" href="#__codelineno-0-633"></a>
<a id="__codelineno-0-634" name="__codelineno-0-634" href="#__codelineno-0-634"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-635" name="__codelineno-0-635" href="#__codelineno-0-635"></a><span class="sd">            torch.Tensor: a tensor of shape (num_seeds, len(batch), self.num_items), where</span>
<a id="__codelineno-0-636" name="__codelineno-0-636" href="#__codelineno-0-636"></a><span class="sd">                out[x, y, z] is the probability of choosing item z in session y conditioned on</span>
<a id="__codelineno-0-637" name="__codelineno-0-637" href="#__codelineno-0-637"></a><span class="sd">                latents to be the x-th Monte Carlo sample.</span>
<a id="__codelineno-0-638" name="__codelineno-0-638" href="#__codelineno-0-638"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-639" name="__codelineno-0-639" href="#__codelineno-0-639"></a>        <span class="n">num_seeds</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">sample_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-640" name="__codelineno-0-640" href="#__codelineno-0-640"></a>
<a id="__codelineno-0-641" name="__codelineno-0-641" href="#__codelineno-0-641"></a>        <span class="c1"># avoid repeated work when user purchased several items in the same session.</span>
<a id="__codelineno-0-642" name="__codelineno-0-642" href="#__codelineno-0-642"></a>        <span class="n">user_session_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
<a id="__codelineno-0-643" name="__codelineno-0-643" href="#__codelineno-0-643"></a>            <span class="p">[</span><span class="n">batch</span><span class="o">.</span><span class="n">user_index</span><span class="p">,</span> <span class="n">batch</span><span class="o">.</span><span class="n">session_index</span><span class="p">])</span>
<a id="__codelineno-0-644" name="__codelineno-0-644" href="#__codelineno-0-644"></a>        <span class="k">assert</span> <span class="n">user_session_index</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">))</span>
<a id="__codelineno-0-645" name="__codelineno-0-645" href="#__codelineno-0-645"></a>        <span class="n">unique_user_sess</span><span class="p">,</span> <span class="n">inverse_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span>
<a id="__codelineno-0-646" name="__codelineno-0-646" href="#__codelineno-0-646"></a>            <span class="n">user_session_index</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-647" name="__codelineno-0-647" href="#__codelineno-0-647"></a>
<a id="__codelineno-0-648" name="__codelineno-0-648" href="#__codelineno-0-648"></a>        <span class="n">user_index</span> <span class="o">=</span> <span class="n">unique_user_sess</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
<a id="__codelineno-0-649" name="__codelineno-0-649" href="#__codelineno-0-649"></a>        <span class="n">session_index</span> <span class="o">=</span> <span class="n">unique_user_sess</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
<a id="__codelineno-0-650" name="__codelineno-0-650" href="#__codelineno-0-650"></a>        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">user_index</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">session_index</span><span class="p">)</span>
<a id="__codelineno-0-651" name="__codelineno-0-651" href="#__codelineno-0-651"></a>
<a id="__codelineno-0-652" name="__codelineno-0-652" href="#__codelineno-0-652"></a>        <span class="c1"># short-hands for easier shape check.</span>
<a id="__codelineno-0-653" name="__codelineno-0-653" href="#__codelineno-0-653"></a>        <span class="n">R</span> <span class="o">=</span> <span class="n">num_seeds</span>
<a id="__codelineno-0-654" name="__codelineno-0-654" href="#__codelineno-0-654"></a>        <span class="c1"># P = len(batch)  # num_purchases.</span>
<a id="__codelineno-0-655" name="__codelineno-0-655" href="#__codelineno-0-655"></a>        <span class="n">P</span> <span class="o">=</span> <span class="n">unique_user_sess</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<a id="__codelineno-0-656" name="__codelineno-0-656" href="#__codelineno-0-656"></a>        <span class="n">S</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_sessions</span>
<a id="__codelineno-0-657" name="__codelineno-0-657" href="#__codelineno-0-657"></a>        <span class="n">U</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_users</span>
<a id="__codelineno-0-658" name="__codelineno-0-658" href="#__codelineno-0-658"></a>        <span class="n">I</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span>
<a id="__codelineno-0-659" name="__codelineno-0-659" href="#__codelineno-0-659"></a>        <span class="n">NC</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_categories</span>
<a id="__codelineno-0-660" name="__codelineno-0-660" href="#__codelineno-0-660"></a>
<a id="__codelineno-0-661" name="__codelineno-0-661" href="#__codelineno-0-661"></a>        <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-662" name="__codelineno-0-662" href="#__codelineno-0-662"></a>        <span class="c1"># Helper Functions for Reshaping.</span>
<a id="__codelineno-0-663" name="__codelineno-0-663" href="#__codelineno-0-663"></a>        <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-664" name="__codelineno-0-664" href="#__codelineno-0-664"></a>        <span class="k">def</span> <span class="nf">reshape_user_coef_sample</span><span class="p">(</span><span class="n">C</span><span class="p">):</span>
<a id="__codelineno-0-665" name="__codelineno-0-665" href="#__codelineno-0-665"></a>            <span class="c1"># input shape (R, U, *)</span>
<a id="__codelineno-0-666" name="__codelineno-0-666" href="#__codelineno-0-666"></a>            <span class="n">C</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (R, U, I, *)</span>
<a id="__codelineno-0-667" name="__codelineno-0-667" href="#__codelineno-0-667"></a>            <span class="n">C</span> <span class="o">=</span> <span class="n">C</span><span class="p">[:,</span> <span class="n">user_index</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
<a id="__codelineno-0-668" name="__codelineno-0-668" href="#__codelineno-0-668"></a>            <span class="k">assert</span> <span class="n">C</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">positive_integer</span><span class="p">)</span>
<a id="__codelineno-0-669" name="__codelineno-0-669" href="#__codelineno-0-669"></a>            <span class="k">return</span> <span class="n">C</span>
<a id="__codelineno-0-670" name="__codelineno-0-670" href="#__codelineno-0-670"></a>
<a id="__codelineno-0-671" name="__codelineno-0-671" href="#__codelineno-0-671"></a>        <span class="k">def</span> <span class="nf">reshape_item_coef_sample</span><span class="p">(</span><span class="n">C</span><span class="p">):</span>
<a id="__codelineno-0-672" name="__codelineno-0-672" href="#__codelineno-0-672"></a>            <span class="c1"># input shape (R, I, *)</span>
<a id="__codelineno-0-673" name="__codelineno-0-673" href="#__codelineno-0-673"></a>            <span class="n">C</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-674" name="__codelineno-0-674" href="#__codelineno-0-674"></a>            <span class="k">assert</span> <span class="n">C</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">positive_integer</span><span class="p">)</span>
<a id="__codelineno-0-675" name="__codelineno-0-675" href="#__codelineno-0-675"></a>            <span class="k">return</span> <span class="n">C</span>
<a id="__codelineno-0-676" name="__codelineno-0-676" href="#__codelineno-0-676"></a>
<a id="__codelineno-0-677" name="__codelineno-0-677" href="#__codelineno-0-677"></a>        <span class="k">def</span> <span class="nf">reshape_category_coef_sample</span><span class="p">(</span><span class="n">C</span><span class="p">):</span>
<a id="__codelineno-0-678" name="__codelineno-0-678" href="#__codelineno-0-678"></a>            <span class="c1"># input shape (R, NC, *)</span>
<a id="__codelineno-0-679" name="__codelineno-0-679" href="#__codelineno-0-679"></a>            <span class="n">C</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">category_to_size_tensor</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-680" name="__codelineno-0-680" href="#__codelineno-0-680"></a>            <span class="c1"># input shape (R, I, *)</span>
<a id="__codelineno-0-681" name="__codelineno-0-681" href="#__codelineno-0-681"></a>            <span class="n">C</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-682" name="__codelineno-0-682" href="#__codelineno-0-682"></a>            <span class="k">assert</span> <span class="n">C</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">positive_integer</span><span class="p">)</span>
<a id="__codelineno-0-683" name="__codelineno-0-683" href="#__codelineno-0-683"></a>            <span class="k">return</span> <span class="n">C</span>
<a id="__codelineno-0-684" name="__codelineno-0-684" href="#__codelineno-0-684"></a>
<a id="__codelineno-0-685" name="__codelineno-0-685" href="#__codelineno-0-685"></a>        <span class="k">def</span> <span class="nf">reshape_constant_coef_sample</span><span class="p">(</span><span class="n">C</span><span class="p">):</span>
<a id="__codelineno-0-686" name="__codelineno-0-686" href="#__codelineno-0-686"></a>            <span class="c1"># input shape (R, *)</span>
<a id="__codelineno-0-687" name="__codelineno-0-687" href="#__codelineno-0-687"></a>            <span class="n">C</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-688" name="__codelineno-0-688" href="#__codelineno-0-688"></a>            <span class="k">assert</span> <span class="n">C</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">positive_integer</span><span class="p">)</span>
<a id="__codelineno-0-689" name="__codelineno-0-689" href="#__codelineno-0-689"></a>            <span class="k">return</span> <span class="n">C</span>
<a id="__codelineno-0-690" name="__codelineno-0-690" href="#__codelineno-0-690"></a>
<a id="__codelineno-0-691" name="__codelineno-0-691" href="#__codelineno-0-691"></a>        <span class="k">def</span> <span class="nf">reshape_coef_sample</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
<a id="__codelineno-0-692" name="__codelineno-0-692" href="#__codelineno-0-692"></a>            <span class="c1"># reshape the monte carlo sample of coefficients to (R, P, I, *).</span>
<a id="__codelineno-0-693" name="__codelineno-0-693" href="#__codelineno-0-693"></a>            <span class="k">if</span> <span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;_user&#39;</span><span class="p">):</span>
<a id="__codelineno-0-694" name="__codelineno-0-694" href="#__codelineno-0-694"></a>                <span class="c1"># (R, U, *) --&gt; (R, P, I, *)</span>
<a id="__codelineno-0-695" name="__codelineno-0-695" href="#__codelineno-0-695"></a>                <span class="k">return</span> <span class="n">reshape_user_coef_sample</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
<a id="__codelineno-0-696" name="__codelineno-0-696" href="#__codelineno-0-696"></a>            <span class="k">elif</span> <span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;_item&#39;</span><span class="p">):</span>
<a id="__codelineno-0-697" name="__codelineno-0-697" href="#__codelineno-0-697"></a>                <span class="c1"># (R, I, *) --&gt; (R, P, I, *)</span>
<a id="__codelineno-0-698" name="__codelineno-0-698" href="#__codelineno-0-698"></a>                <span class="k">return</span> <span class="n">reshape_item_coef_sample</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
<a id="__codelineno-0-699" name="__codelineno-0-699" href="#__codelineno-0-699"></a>            <span class="k">elif</span> <span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;_category&#39;</span><span class="p">):</span>
<a id="__codelineno-0-700" name="__codelineno-0-700" href="#__codelineno-0-700"></a>                <span class="c1"># (R, NC, *) --&gt; (R, P, NC, *)</span>
<a id="__codelineno-0-701" name="__codelineno-0-701" href="#__codelineno-0-701"></a>                <span class="k">return</span> <span class="n">reshape_category_coef_sample</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
<a id="__codelineno-0-702" name="__codelineno-0-702" href="#__codelineno-0-702"></a>            <span class="k">elif</span> <span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;_constant&#39;</span><span class="p">):</span>
<a id="__codelineno-0-703" name="__codelineno-0-703" href="#__codelineno-0-703"></a>                <span class="c1"># (R, *) --&gt; (R, P, I, *)</span>
<a id="__codelineno-0-704" name="__codelineno-0-704" href="#__codelineno-0-704"></a>                <span class="k">return</span> <span class="n">reshape_constant_coef_sample</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
<a id="__codelineno-0-705" name="__codelineno-0-705" href="#__codelineno-0-705"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-706" name="__codelineno-0-706" href="#__codelineno-0-706"></a>                <span class="k">raise</span> <span class="ne">ValueError</span>
<a id="__codelineno-0-707" name="__codelineno-0-707" href="#__codelineno-0-707"></a>
<a id="__codelineno-0-708" name="__codelineno-0-708" href="#__codelineno-0-708"></a>        <span class="k">def</span> <span class="nf">reshape_observable</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
<a id="__codelineno-0-709" name="__codelineno-0-709" href="#__codelineno-0-709"></a>            <span class="c1"># reshape observable to (R, P, I, *) so that it can be multiplied with monte carlo</span>
<a id="__codelineno-0-710" name="__codelineno-0-710" href="#__codelineno-0-710"></a>            <span class="c1"># samples of coefficients.</span>
<a id="__codelineno-0-711" name="__codelineno-0-711" href="#__codelineno-0-711"></a>            <span class="n">O</span> <span class="o">=</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># number of observables.</span>
<a id="__codelineno-0-712" name="__codelineno-0-712" href="#__codelineno-0-712"></a>            <span class="k">assert</span> <span class="n">O</span> <span class="o">==</span> <span class="n">positive_integer</span>
<a id="__codelineno-0-713" name="__codelineno-0-713" href="#__codelineno-0-713"></a>            <span class="k">if</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;item_&#39;</span><span class="p">):</span>
<a id="__codelineno-0-714" name="__codelineno-0-714" href="#__codelineno-0-714"></a>                <span class="k">assert</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">O</span><span class="p">)</span>
<a id="__codelineno-0-715" name="__codelineno-0-715" href="#__codelineno-0-715"></a>                <span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">O</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-716" name="__codelineno-0-716" href="#__codelineno-0-716"></a>            <span class="k">elif</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;user_&#39;</span><span class="p">):</span>
<a id="__codelineno-0-717" name="__codelineno-0-717" href="#__codelineno-0-717"></a>                <span class="k">assert</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">O</span><span class="p">)</span>
<a id="__codelineno-0-718" name="__codelineno-0-718" href="#__codelineno-0-718"></a>                <span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span><span class="p">[</span><span class="n">user_index</span><span class="p">,</span> <span class="p">:]</span>  <span class="c1"># (P, O)</span>
<a id="__codelineno-0-719" name="__codelineno-0-719" href="#__codelineno-0-719"></a>                <span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">O</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-720" name="__codelineno-0-720" href="#__codelineno-0-720"></a>            <span class="k">elif</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;session_&#39;</span><span class="p">):</span>
<a id="__codelineno-0-721" name="__codelineno-0-721" href="#__codelineno-0-721"></a>                <span class="k">assert</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">O</span><span class="p">)</span>
<a id="__codelineno-0-722" name="__codelineno-0-722" href="#__codelineno-0-722"></a>                <span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span><span class="p">[</span><span class="n">session_index</span><span class="p">,</span> <span class="p">:]</span>  <span class="c1"># (P, O)</span>
<a id="__codelineno-0-723" name="__codelineno-0-723" href="#__codelineno-0-723"></a>                <span class="k">return</span> <span class="n">obs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">O</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-724" name="__codelineno-0-724" href="#__codelineno-0-724"></a>            <span class="k">elif</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;price_&#39;</span><span class="p">):</span>
<a id="__codelineno-0-725" name="__codelineno-0-725" href="#__codelineno-0-725"></a>                <span class="k">assert</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">O</span><span class="p">)</span>
<a id="__codelineno-0-726" name="__codelineno-0-726" href="#__codelineno-0-726"></a>                <span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span><span class="p">[</span><span class="n">session_index</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>  <span class="c1"># (P, I, O)</span>
<a id="__codelineno-0-727" name="__codelineno-0-727" href="#__codelineno-0-727"></a>                <span class="k">return</span> <span class="n">obs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">O</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-728" name="__codelineno-0-728" href="#__codelineno-0-728"></a>            <span class="k">elif</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;taste_&#39;</span><span class="p">):</span>
<a id="__codelineno-0-729" name="__codelineno-0-729" href="#__codelineno-0-729"></a>                <span class="k">assert</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">O</span><span class="p">)</span>
<a id="__codelineno-0-730" name="__codelineno-0-730" href="#__codelineno-0-730"></a>                <span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span><span class="p">[</span><span class="n">user_index</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>  <span class="c1"># (P, I, O)</span>
<a id="__codelineno-0-731" name="__codelineno-0-731" href="#__codelineno-0-731"></a>                <span class="k">return</span> <span class="n">obs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">O</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-732" name="__codelineno-0-732" href="#__codelineno-0-732"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-733" name="__codelineno-0-733" href="#__codelineno-0-733"></a>                <span class="k">raise</span> <span class="ne">ValueError</span>
<a id="__codelineno-0-734" name="__codelineno-0-734" href="#__codelineno-0-734"></a>            <span class="k">assert</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">O</span><span class="p">)</span>
<a id="__codelineno-0-735" name="__codelineno-0-735" href="#__codelineno-0-735"></a>            <span class="k">return</span> <span class="n">obs</span>
<a id="__codelineno-0-736" name="__codelineno-0-736" href="#__codelineno-0-736"></a>
<a id="__codelineno-0-737" name="__codelineno-0-737" href="#__codelineno-0-737"></a>        <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-738" name="__codelineno-0-738" href="#__codelineno-0-738"></a>        <span class="c1"># Compute the Utility Term by Term.</span>
<a id="__codelineno-0-739" name="__codelineno-0-739" href="#__codelineno-0-739"></a>        <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-740" name="__codelineno-0-740" href="#__codelineno-0-740"></a>        <span class="c1"># P is the number of unique (user, session) pairs.</span>
<a id="__codelineno-0-741" name="__codelineno-0-741" href="#__codelineno-0-741"></a>        <span class="c1"># (random_seeds, P, num_items).</span>
<a id="__codelineno-0-742" name="__codelineno-0-742" href="#__codelineno-0-742"></a>        <span class="n">utility</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-743" name="__codelineno-0-743" href="#__codelineno-0-743"></a>
<a id="__codelineno-0-744" name="__codelineno-0-744" href="#__codelineno-0-744"></a>        <span class="c1"># loop over additive term to utility</span>
<a id="__codelineno-0-745" name="__codelineno-0-745" href="#__codelineno-0-745"></a>        <span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">formula</span><span class="p">:</span>
<a id="__codelineno-0-746" name="__codelineno-0-746" href="#__codelineno-0-746"></a>            <span class="c1"># Type I: single coefficient, e.g., lambda_item or lambda_user.</span>
<a id="__codelineno-0-747" name="__codelineno-0-747" href="#__codelineno-0-747"></a>            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;observable&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-748" name="__codelineno-0-748" href="#__codelineno-0-748"></a>                <span class="c1"># E.g., lambda_item or lambda_user</span>
<a id="__codelineno-0-749" name="__codelineno-0-749" href="#__codelineno-0-749"></a>                <span class="n">coef_name</span> <span class="o">=</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-750" name="__codelineno-0-750" href="#__codelineno-0-750"></a>                <span class="n">coef_sample</span> <span class="o">=</span> <span class="n">reshape_coef_sample</span><span class="p">(</span>
<a id="__codelineno-0-751" name="__codelineno-0-751" href="#__codelineno-0-751"></a>                    <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">],</span> <span class="n">coef_name</span><span class="p">)</span>
<a id="__codelineno-0-752" name="__codelineno-0-752" href="#__codelineno-0-752"></a>                <span class="k">assert</span> <span class="n">coef_sample</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-753" name="__codelineno-0-753" href="#__codelineno-0-753"></a>                <span class="n">additive_term</span> <span class="o">=</span> <span class="n">coef_sample</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">)</span>
<a id="__codelineno-0-754" name="__codelineno-0-754" href="#__codelineno-0-754"></a>
<a id="__codelineno-0-755" name="__codelineno-0-755" href="#__codelineno-0-755"></a>            <span class="c1"># Type II: factorized coefficient, e.g., &lt;theta_user, lambda_item&gt;.</span>
<a id="__codelineno-0-756" name="__codelineno-0-756" href="#__codelineno-0-756"></a>            <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;observable&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-757" name="__codelineno-0-757" href="#__codelineno-0-757"></a>                <span class="n">coef_name_0</span> <span class="o">=</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-758" name="__codelineno-0-758" href="#__codelineno-0-758"></a>                <span class="n">coef_name_1</span> <span class="o">=</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
<a id="__codelineno-0-759" name="__codelineno-0-759" href="#__codelineno-0-759"></a>
<a id="__codelineno-0-760" name="__codelineno-0-760" href="#__codelineno-0-760"></a>                <span class="n">coef_sample_0</span> <span class="o">=</span> <span class="n">reshape_coef_sample</span><span class="p">(</span>
<a id="__codelineno-0-761" name="__codelineno-0-761" href="#__codelineno-0-761"></a>                    <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name_0</span><span class="p">],</span> <span class="n">coef_name_0</span><span class="p">)</span>
<a id="__codelineno-0-762" name="__codelineno-0-762" href="#__codelineno-0-762"></a>                <span class="n">coef_sample_1</span> <span class="o">=</span> <span class="n">reshape_coef_sample</span><span class="p">(</span>
<a id="__codelineno-0-763" name="__codelineno-0-763" href="#__codelineno-0-763"></a>                    <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name_1</span><span class="p">],</span> <span class="n">coef_name_1</span><span class="p">)</span>
<a id="__codelineno-0-764" name="__codelineno-0-764" href="#__codelineno-0-764"></a>
<a id="__codelineno-0-765" name="__codelineno-0-765" href="#__codelineno-0-765"></a>                <span class="k">assert</span> <span class="n">coef_sample_0</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">coef_sample_1</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span>
<a id="__codelineno-0-766" name="__codelineno-0-766" href="#__codelineno-0-766"></a>                    <span class="n">R</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">positive_integer</span><span class="p">)</span>
<a id="__codelineno-0-767" name="__codelineno-0-767" href="#__codelineno-0-767"></a>
<a id="__codelineno-0-768" name="__codelineno-0-768" href="#__codelineno-0-768"></a>                <span class="n">additive_term</span> <span class="o">=</span> <span class="p">(</span><span class="n">coef_sample_0</span> <span class="o">*</span> <span class="n">coef_sample_1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-769" name="__codelineno-0-769" href="#__codelineno-0-769"></a>
<a id="__codelineno-0-770" name="__codelineno-0-770" href="#__codelineno-0-770"></a>            <span class="c1"># Type III: single coefficient multiplied by observable, e.g., theta_user * x_obs_item.</span>
<a id="__codelineno-0-771" name="__codelineno-0-771" href="#__codelineno-0-771"></a>            <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;observable&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-772" name="__codelineno-0-772" href="#__codelineno-0-772"></a>                <span class="n">coef_name</span> <span class="o">=</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-773" name="__codelineno-0-773" href="#__codelineno-0-773"></a>                <span class="n">coef_sample</span> <span class="o">=</span> <span class="n">reshape_coef_sample</span><span class="p">(</span>
<a id="__codelineno-0-774" name="__codelineno-0-774" href="#__codelineno-0-774"></a>                    <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">],</span> <span class="n">coef_name</span><span class="p">)</span>
<a id="__codelineno-0-775" name="__codelineno-0-775" href="#__codelineno-0-775"></a>                <span class="k">assert</span> <span class="n">coef_sample</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">positive_integer</span><span class="p">)</span>
<a id="__codelineno-0-776" name="__codelineno-0-776" href="#__codelineno-0-776"></a>
<a id="__codelineno-0-777" name="__codelineno-0-777" href="#__codelineno-0-777"></a>                <span class="n">obs_name</span> <span class="o">=</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;observable&#39;</span><span class="p">]</span>
<a id="__codelineno-0-778" name="__codelineno-0-778" href="#__codelineno-0-778"></a>                <span class="n">obs</span> <span class="o">=</span> <span class="n">reshape_observable</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">obs_name</span><span class="p">),</span> <span class="n">obs_name</span><span class="p">)</span>
<a id="__codelineno-0-779" name="__codelineno-0-779" href="#__codelineno-0-779"></a>                <span class="k">assert</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">positive_integer</span><span class="p">)</span>
<a id="__codelineno-0-780" name="__codelineno-0-780" href="#__codelineno-0-780"></a>
<a id="__codelineno-0-781" name="__codelineno-0-781" href="#__codelineno-0-781"></a>                <span class="n">additive_term</span> <span class="o">=</span> <span class="p">(</span><span class="n">coef_sample</span> <span class="o">*</span> <span class="n">obs</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-782" name="__codelineno-0-782" href="#__codelineno-0-782"></a>
<a id="__codelineno-0-783" name="__codelineno-0-783" href="#__codelineno-0-783"></a>            <span class="c1"># Type IV: factorized coefficient multiplied by observable.</span>
<a id="__codelineno-0-784" name="__codelineno-0-784" href="#__codelineno-0-784"></a>            <span class="c1"># e.g., gamma_user * beta_item * price_obs.</span>
<a id="__codelineno-0-785" name="__codelineno-0-785" href="#__codelineno-0-785"></a>            <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;observable&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-786" name="__codelineno-0-786" href="#__codelineno-0-786"></a>                <span class="n">coef_name_0</span><span class="p">,</span> <span class="n">coef_name_1</span> <span class="o">=</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
<a id="__codelineno-0-787" name="__codelineno-0-787" href="#__codelineno-0-787"></a>
<a id="__codelineno-0-788" name="__codelineno-0-788" href="#__codelineno-0-788"></a>                <span class="n">coef_sample_0</span> <span class="o">=</span> <span class="n">reshape_coef_sample</span><span class="p">(</span>
<a id="__codelineno-0-789" name="__codelineno-0-789" href="#__codelineno-0-789"></a>                    <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name_0</span><span class="p">],</span> <span class="n">coef_name_0</span><span class="p">)</span>
<a id="__codelineno-0-790" name="__codelineno-0-790" href="#__codelineno-0-790"></a>                <span class="n">coef_sample_1</span> <span class="o">=</span> <span class="n">reshape_coef_sample</span><span class="p">(</span>
<a id="__codelineno-0-791" name="__codelineno-0-791" href="#__codelineno-0-791"></a>                    <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name_1</span><span class="p">],</span> <span class="n">coef_name_1</span><span class="p">)</span>
<a id="__codelineno-0-792" name="__codelineno-0-792" href="#__codelineno-0-792"></a>                <span class="k">assert</span> <span class="n">coef_sample_0</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">coef_sample_1</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span>
<a id="__codelineno-0-793" name="__codelineno-0-793" href="#__codelineno-0-793"></a>                    <span class="n">R</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">positive_integer</span><span class="p">)</span>
<a id="__codelineno-0-794" name="__codelineno-0-794" href="#__codelineno-0-794"></a>                <span class="n">num_obs_times_latent_dim</span> <span class="o">=</span> <span class="n">coef_sample_0</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<a id="__codelineno-0-795" name="__codelineno-0-795" href="#__codelineno-0-795"></a>
<a id="__codelineno-0-796" name="__codelineno-0-796" href="#__codelineno-0-796"></a>                <span class="n">obs_name</span> <span class="o">=</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;observable&#39;</span><span class="p">]</span>
<a id="__codelineno-0-797" name="__codelineno-0-797" href="#__codelineno-0-797"></a>                <span class="n">obs</span> <span class="o">=</span> <span class="n">reshape_observable</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">obs_name</span><span class="p">),</span> <span class="n">obs_name</span><span class="p">)</span>
<a id="__codelineno-0-798" name="__codelineno-0-798" href="#__codelineno-0-798"></a>                <span class="k">assert</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">positive_integer</span><span class="p">)</span>
<a id="__codelineno-0-799" name="__codelineno-0-799" href="#__codelineno-0-799"></a>                <span class="n">num_obs</span> <span class="o">=</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># number of observables.</span>
<a id="__codelineno-0-800" name="__codelineno-0-800" href="#__codelineno-0-800"></a>
<a id="__codelineno-0-801" name="__codelineno-0-801" href="#__codelineno-0-801"></a>                <span class="k">assert</span> <span class="p">(</span><span class="n">num_obs_times_latent_dim</span> <span class="o">%</span> <span class="n">num_obs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>
<a id="__codelineno-0-802" name="__codelineno-0-802" href="#__codelineno-0-802"></a>                <span class="n">latent_dim</span> <span class="o">=</span> <span class="n">num_obs_times_latent_dim</span> <span class="o">//</span> <span class="n">num_obs</span>
<a id="__codelineno-0-803" name="__codelineno-0-803" href="#__codelineno-0-803"></a>
<a id="__codelineno-0-804" name="__codelineno-0-804" href="#__codelineno-0-804"></a>                <span class="n">coef_sample_0</span> <span class="o">=</span> <span class="n">coef_sample_0</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
<a id="__codelineno-0-805" name="__codelineno-0-805" href="#__codelineno-0-805"></a>                    <span class="n">R</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">num_obs</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>
<a id="__codelineno-0-806" name="__codelineno-0-806" href="#__codelineno-0-806"></a>                <span class="n">coef_sample_1</span> <span class="o">=</span> <span class="n">coef_sample_1</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
<a id="__codelineno-0-807" name="__codelineno-0-807" href="#__codelineno-0-807"></a>                    <span class="n">R</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">num_obs</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>
<a id="__codelineno-0-808" name="__codelineno-0-808" href="#__codelineno-0-808"></a>                <span class="c1"># compute the factorized coefficient with shape (R, P, I, O).</span>
<a id="__codelineno-0-809" name="__codelineno-0-809" href="#__codelineno-0-809"></a>                <span class="n">coef</span> <span class="o">=</span> <span class="p">(</span><span class="n">coef_sample_0</span> <span class="o">*</span> <span class="n">coef_sample_1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-810" name="__codelineno-0-810" href="#__codelineno-0-810"></a>
<a id="__codelineno-0-811" name="__codelineno-0-811" href="#__codelineno-0-811"></a>                <span class="n">additive_term</span> <span class="o">=</span> <span class="p">(</span><span class="n">coef</span> <span class="o">*</span> <span class="n">obs</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-812" name="__codelineno-0-812" href="#__codelineno-0-812"></a>
<a id="__codelineno-0-813" name="__codelineno-0-813" href="#__codelineno-0-813"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-814" name="__codelineno-0-814" href="#__codelineno-0-814"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Undefined term type: </span><span class="si">{</span><span class="n">term</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<a id="__codelineno-0-815" name="__codelineno-0-815" href="#__codelineno-0-815"></a>
<a id="__codelineno-0-816" name="__codelineno-0-816" href="#__codelineno-0-816"></a>            <span class="k">assert</span> <span class="n">additive_term</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">)</span>
<a id="__codelineno-0-817" name="__codelineno-0-817" href="#__codelineno-0-817"></a>            <span class="n">utility</span> <span class="o">+=</span> <span class="n">additive_term</span>
<a id="__codelineno-0-818" name="__codelineno-0-818" href="#__codelineno-0-818"></a>
<a id="__codelineno-0-819" name="__codelineno-0-819" href="#__codelineno-0-819"></a>        <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-820" name="__codelineno-0-820" href="#__codelineno-0-820"></a>        <span class="c1"># Mask Out Unavailable Items in Each Session.</span>
<a id="__codelineno-0-821" name="__codelineno-0-821" href="#__codelineno-0-821"></a>        <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-822" name="__codelineno-0-822" href="#__codelineno-0-822"></a>
<a id="__codelineno-0-823" name="__codelineno-0-823" href="#__codelineno-0-823"></a>        <span class="k">if</span> <span class="n">batch</span><span class="o">.</span><span class="n">item_availability</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-824" name="__codelineno-0-824" href="#__codelineno-0-824"></a>            <span class="c1"># expand to the Monte Carlo sample dimension.</span>
<a id="__codelineno-0-825" name="__codelineno-0-825" href="#__codelineno-0-825"></a>            <span class="c1"># (S, I) -&gt; (P, I) -&gt; (1, P, I) -&gt; (R, P, I)</span>
<a id="__codelineno-0-826" name="__codelineno-0-826" href="#__codelineno-0-826"></a>            <span class="n">A</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">item_availability</span><span class="p">[</span><span class="n">session_index</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span>
<a id="__codelineno-0-827" name="__codelineno-0-827" href="#__codelineno-0-827"></a>                <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-828" name="__codelineno-0-828" href="#__codelineno-0-828"></a>            <span class="n">utility</span><span class="p">[</span><span class="o">~</span><span class="n">A</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">utility</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">max</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-0-829" name="__codelineno-0-829" href="#__codelineno-0-829"></a>
<a id="__codelineno-0-830" name="__codelineno-0-830" href="#__codelineno-0-830"></a>        <span class="n">utility</span> <span class="o">=</span> <span class="n">utility</span><span class="p">[:,</span> <span class="n">inverse_indices</span><span class="p">,</span> <span class="p">:]</span>
<a id="__codelineno-0-831" name="__codelineno-0-831" href="#__codelineno-0-831"></a>        <span class="k">assert</span> <span class="n">utility</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="n">I</span><span class="p">)</span>
<a id="__codelineno-0-832" name="__codelineno-0-832" href="#__codelineno-0-832"></a>
<a id="__codelineno-0-833" name="__codelineno-0-833" href="#__codelineno-0-833"></a>        <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">additional_modules</span><span class="p">:</span>
<a id="__codelineno-0-834" name="__codelineno-0-834" href="#__codelineno-0-834"></a>            <span class="n">additive_term</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
<a id="__codelineno-0-835" name="__codelineno-0-835" href="#__codelineno-0-835"></a>            <span class="k">assert</span> <span class="n">additive_term</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-836" name="__codelineno-0-836" href="#__codelineno-0-836"></a>            <span class="n">utility</span> <span class="o">+=</span> <span class="n">additive_term</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">I</span><span class="p">)</span>
<a id="__codelineno-0-837" name="__codelineno-0-837" href="#__codelineno-0-837"></a>
<a id="__codelineno-0-838" name="__codelineno-0-838" href="#__codelineno-0-838"></a>        <span class="k">if</span> <span class="n">return_logit</span><span class="p">:</span>
<a id="__codelineno-0-839" name="__codelineno-0-839" href="#__codelineno-0-839"></a>            <span class="c1"># output shape: (num_seeds, len(batch), num_items)</span>
<a id="__codelineno-0-840" name="__codelineno-0-840" href="#__codelineno-0-840"></a>            <span class="k">assert</span> <span class="n">utility</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_seeds</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">)</span>
<a id="__codelineno-0-841" name="__codelineno-0-841" href="#__codelineno-0-841"></a>            <span class="k">return</span> <span class="n">utility</span>
<a id="__codelineno-0-842" name="__codelineno-0-842" href="#__codelineno-0-842"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-843" name="__codelineno-0-843" href="#__codelineno-0-843"></a>            <span class="c1"># compute log likelihood log p(choosing item i | user, item latents)</span>
<a id="__codelineno-0-844" name="__codelineno-0-844" href="#__codelineno-0-844"></a>            <span class="c1"># compute log softmax separately within each category.</span>
<a id="__codelineno-0-845" name="__codelineno-0-845" href="#__codelineno-0-845"></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pred_item</span><span class="p">:</span>
<a id="__codelineno-0-846" name="__codelineno-0-846" href="#__codelineno-0-846"></a>                <span class="c1"># output shape: (num_seeds, len(batch), num_items)</span>
<a id="__codelineno-0-847" name="__codelineno-0-847" href="#__codelineno-0-847"></a>                <span class="n">log_p</span> <span class="o">=</span> <span class="n">scatter_log_softmax</span><span class="p">(</span><span class="n">utility</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_to_category_tensor</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-848" name="__codelineno-0-848" href="#__codelineno-0-848"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-849" name="__codelineno-0-849" href="#__codelineno-0-849"></a>                <span class="n">label_expanded</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">label</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">num_seeds</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">)</span>
<a id="__codelineno-0-850" name="__codelineno-0-850" href="#__codelineno-0-850"></a>                <span class="k">assert</span> <span class="n">label_expanded</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_seeds</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">)</span>
<a id="__codelineno-0-851" name="__codelineno-0-851" href="#__codelineno-0-851"></a>                <span class="n">bce</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
<a id="__codelineno-0-852" name="__codelineno-0-852" href="#__codelineno-0-852"></a>                <span class="n">log_p</span> <span class="o">=</span> <span class="o">-</span> <span class="n">bce</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">utility</span><span class="p">),</span> <span class="n">label_expanded</span><span class="p">)</span>
<a id="__codelineno-0-853" name="__codelineno-0-853" href="#__codelineno-0-853"></a>            <span class="k">assert</span> <span class="n">log_p</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_seeds</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">)</span>
<a id="__codelineno-0-854" name="__codelineno-0-854" href="#__codelineno-0-854"></a>            <span class="k">return</span> <span class="n">log_p</span>
<a id="__codelineno-0-855" name="__codelineno-0-855" href="#__codelineno-0-855"></a>
<a id="__codelineno-0-856" name="__codelineno-0-856" href="#__codelineno-0-856"></a>    <span class="k">def</span> <span class="nf">log_likelihood_item_index</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">ChoiceDataset</span><span class="p">,</span> <span class="n">return_logit</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">sample_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-857" name="__codelineno-0-857" href="#__codelineno-0-857"></a>        <span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-858" name="__codelineno-0-858" href="#__codelineno-0-858"></a><span class="sd">        NOTE for developers:</span>
<a id="__codelineno-0-859" name="__codelineno-0-859" href="#__codelineno-0-859"></a><span class="sd">        This method is more efficient and only computes log-likelihood/logit(utility) for item in item_index[i] for each</span>
<a id="__codelineno-0-860" name="__codelineno-0-860" href="#__codelineno-0-860"></a><span class="sd">        i-th observation.</span>
<a id="__codelineno-0-861" name="__codelineno-0-861" href="#__codelineno-0-861"></a><span class="sd">        Developers should use use `log_likelihood_all_items` for inference purpose and to computes log-likelihoods/utilities</span>
<a id="__codelineno-0-862" name="__codelineno-0-862" href="#__codelineno-0-862"></a><span class="sd">        for ALL items for the i-th observation.</span>
<a id="__codelineno-0-863" name="__codelineno-0-863" href="#__codelineno-0-863"></a>
<a id="__codelineno-0-864" name="__codelineno-0-864" href="#__codelineno-0-864"></a><span class="sd">        Computes the log probability of choosing item_index[i] in each session based on current model parameters.</span>
<a id="__codelineno-0-865" name="__codelineno-0-865" href="#__codelineno-0-865"></a><span class="sd">        This method allows for specifying {user, item}_latent_value for Monte Carlo estimation in ELBO.</span>
<a id="__codelineno-0-866" name="__codelineno-0-866" href="#__codelineno-0-866"></a><span class="sd">        For actual prediction tasks, use the forward() function, which will use means of variational</span>
<a id="__codelineno-0-867" name="__codelineno-0-867" href="#__codelineno-0-867"></a><span class="sd">        distributions for user and item latents.</span>
<a id="__codelineno-0-868" name="__codelineno-0-868" href="#__codelineno-0-868"></a>
<a id="__codelineno-0-869" name="__codelineno-0-869" href="#__codelineno-0-869"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-870" name="__codelineno-0-870" href="#__codelineno-0-870"></a><span class="sd">            batch (ChoiceDataset): a ChoiceDataset object containing relevant information.</span>
<a id="__codelineno-0-871" name="__codelineno-0-871" href="#__codelineno-0-871"></a><span class="sd">            return_logit(bool): if set to True, return the logit/utility, otherwise return the log-probability.</span>
<a id="__codelineno-0-872" name="__codelineno-0-872" href="#__codelineno-0-872"></a><span class="sd">            sample_dict(Dict[str, torch.Tensor]): Monte Carlo samples for model coefficients</span>
<a id="__codelineno-0-873" name="__codelineno-0-873" href="#__codelineno-0-873"></a><span class="sd">                (i.e., those Greek letters).</span>
<a id="__codelineno-0-874" name="__codelineno-0-874" href="#__codelineno-0-874"></a><span class="sd">                sample_dict.keys() should be the same as keys of self.obs2prior_dict, i.e., those</span>
<a id="__codelineno-0-875" name="__codelineno-0-875" href="#__codelineno-0-875"></a><span class="sd">                greek letters actually enter the functional form of utility.</span>
<a id="__codelineno-0-876" name="__codelineno-0-876" href="#__codelineno-0-876"></a><span class="sd">                The value of sample_dict should be tensors of shape (num_seeds, num_classes, dim)</span>
<a id="__codelineno-0-877" name="__codelineno-0-877" href="#__codelineno-0-877"></a><span class="sd">                where num_classes in {num_users, num_items, 1}</span>
<a id="__codelineno-0-878" name="__codelineno-0-878" href="#__codelineno-0-878"></a><span class="sd">                and dim in {latent_dim(K), num_item_obs, num_user_obs, 1}.</span>
<a id="__codelineno-0-879" name="__codelineno-0-879" href="#__codelineno-0-879"></a>
<a id="__codelineno-0-880" name="__codelineno-0-880" href="#__codelineno-0-880"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-881" name="__codelineno-0-881" href="#__codelineno-0-881"></a><span class="sd">            torch.Tensor: a tensor of shape (num_seeds, len(batch)), where</span>
<a id="__codelineno-0-882" name="__codelineno-0-882" href="#__codelineno-0-882"></a><span class="sd">                out[x, y] is the probabilities of choosing item batch.item[y] in session y</span>
<a id="__codelineno-0-883" name="__codelineno-0-883" href="#__codelineno-0-883"></a><span class="sd">                conditioned on latents to be the x-th Monte Carlo sample.</span>
<a id="__codelineno-0-884" name="__codelineno-0-884" href="#__codelineno-0-884"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-885" name="__codelineno-0-885" href="#__codelineno-0-885"></a>        <span class="n">num_seeds</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">sample_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-886" name="__codelineno-0-886" href="#__codelineno-0-886"></a>
<a id="__codelineno-0-887" name="__codelineno-0-887" href="#__codelineno-0-887"></a>        <span class="c1"># get category id of the item bought in each row of batch.</span>
<a id="__codelineno-0-888" name="__codelineno-0-888" href="#__codelineno-0-888"></a>        <span class="n">cate_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_to_category_tensor</span><span class="p">[</span><span class="n">batch</span><span class="o">.</span><span class="n">item_index</span><span class="p">]</span>
<a id="__codelineno-0-889" name="__codelineno-0-889" href="#__codelineno-0-889"></a>
<a id="__codelineno-0-890" name="__codelineno-0-890" href="#__codelineno-0-890"></a>        <span class="c1"># get item ids of all items from the same category of each item bought.</span>
<a id="__codelineno-0-891" name="__codelineno-0-891" href="#__codelineno-0-891"></a>        <span class="n">relevant_item_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">category_to_item_tensor</span><span class="p">[</span><span class="n">cate_index</span><span class="p">,</span> <span class="p">:]</span>
<a id="__codelineno-0-892" name="__codelineno-0-892" href="#__codelineno-0-892"></a>        <span class="n">relevant_item_index</span> <span class="o">=</span> <span class="n">relevant_item_index</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,)</span>
<a id="__codelineno-0-893" name="__codelineno-0-893" href="#__codelineno-0-893"></a>        <span class="c1"># index were padded with -1&#39;s, drop those dummy entries.</span>
<a id="__codelineno-0-894" name="__codelineno-0-894" href="#__codelineno-0-894"></a>        <span class="n">relevant_item_index</span> <span class="o">=</span> <span class="n">relevant_item_index</span><span class="p">[</span><span class="n">relevant_item_index</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<a id="__codelineno-0-895" name="__codelineno-0-895" href="#__codelineno-0-895"></a>
<a id="__codelineno-0-896" name="__codelineno-0-896" href="#__codelineno-0-896"></a>        <span class="c1"># the first repeats[0] entries in relevant_item_index are for the category of item_index[0]</span>
<a id="__codelineno-0-897" name="__codelineno-0-897" href="#__codelineno-0-897"></a>        <span class="n">repeats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">category_to_size_tensor</span><span class="p">[</span><span class="n">cate_index</span><span class="p">]</span>
<a id="__codelineno-0-898" name="__codelineno-0-898" href="#__codelineno-0-898"></a>        <span class="c1"># argwhere(reverse_indices == k) are positions in relevant_item_index for the category of item_index[k].</span>
<a id="__codelineno-0-899" name="__codelineno-0-899" href="#__codelineno-0-899"></a>        <span class="n">reverse_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span>
<a id="__codelineno-0-900" name="__codelineno-0-900" href="#__codelineno-0-900"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">repeats</span><span class="p">)</span>
<a id="__codelineno-0-901" name="__codelineno-0-901" href="#__codelineno-0-901"></a>        <span class="c1"># expand the user_index and session_index.</span>
<a id="__codelineno-0-902" name="__codelineno-0-902" href="#__codelineno-0-902"></a>        <span class="n">user_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">user_index</span><span class="p">,</span> <span class="n">repeats</span><span class="p">)</span>
<a id="__codelineno-0-903" name="__codelineno-0-903" href="#__codelineno-0-903"></a>        <span class="n">repeat_category_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">cate_index</span><span class="p">,</span> <span class="n">repeats</span><span class="p">)</span>
<a id="__codelineno-0-904" name="__codelineno-0-904" href="#__codelineno-0-904"></a>        <span class="n">session_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">session_index</span><span class="p">,</span> <span class="n">repeats</span><span class="p">)</span>
<a id="__codelineno-0-905" name="__codelineno-0-905" href="#__codelineno-0-905"></a>        <span class="c1"># duplicate the item focused to match.</span>
<a id="__codelineno-0-906" name="__codelineno-0-906" href="#__codelineno-0-906"></a>        <span class="n">item_index_expanded</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span>
<a id="__codelineno-0-907" name="__codelineno-0-907" href="#__codelineno-0-907"></a>            <span class="n">batch</span><span class="o">.</span><span class="n">item_index</span><span class="p">,</span> <span class="n">repeats</span><span class="p">)</span>
<a id="__codelineno-0-908" name="__codelineno-0-908" href="#__codelineno-0-908"></a>
<a id="__codelineno-0-909" name="__codelineno-0-909" href="#__codelineno-0-909"></a>        <span class="c1"># short-hands for easier shape check.</span>
<a id="__codelineno-0-910" name="__codelineno-0-910" href="#__codelineno-0-910"></a>        <span class="n">R</span> <span class="o">=</span> <span class="n">num_seeds</span>
<a id="__codelineno-0-911" name="__codelineno-0-911" href="#__codelineno-0-911"></a>        <span class="c1"># total number of relevant items.</span>
<a id="__codelineno-0-912" name="__codelineno-0-912" href="#__codelineno-0-912"></a>        <span class="n">total_computation</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">session_index</span><span class="p">)</span>
<a id="__codelineno-0-913" name="__codelineno-0-913" href="#__codelineno-0-913"></a>        <span class="n">S</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_sessions</span>
<a id="__codelineno-0-914" name="__codelineno-0-914" href="#__codelineno-0-914"></a>        <span class="n">U</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_users</span>
<a id="__codelineno-0-915" name="__codelineno-0-915" href="#__codelineno-0-915"></a>        <span class="n">I</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span>
<a id="__codelineno-0-916" name="__codelineno-0-916" href="#__codelineno-0-916"></a>        <span class="n">NC</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_categories</span>
<a id="__codelineno-0-917" name="__codelineno-0-917" href="#__codelineno-0-917"></a>        <span class="c1"># ==========================================================================================</span>
<a id="__codelineno-0-918" name="__codelineno-0-918" href="#__codelineno-0-918"></a>        <span class="c1"># Helper Functions for Reshaping.</span>
<a id="__codelineno-0-919" name="__codelineno-0-919" href="#__codelineno-0-919"></a>        <span class="c1"># ==========================================================================================</span>
<a id="__codelineno-0-920" name="__codelineno-0-920" href="#__codelineno-0-920"></a>
<a id="__codelineno-0-921" name="__codelineno-0-921" href="#__codelineno-0-921"></a>        <span class="k">def</span> <span class="nf">reshape_coef_sample</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
<a id="__codelineno-0-922" name="__codelineno-0-922" href="#__codelineno-0-922"></a>            <span class="c1"># reshape the monte carlo sample of coefficients to (R, P, I, *).</span>
<a id="__codelineno-0-923" name="__codelineno-0-923" href="#__codelineno-0-923"></a>            <span class="k">if</span> <span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;_user&#39;</span><span class="p">):</span>
<a id="__codelineno-0-924" name="__codelineno-0-924" href="#__codelineno-0-924"></a>                <span class="c1"># (R, U, *) --&gt; (R, total_computation, *)</span>
<a id="__codelineno-0-925" name="__codelineno-0-925" href="#__codelineno-0-925"></a>                <span class="k">return</span> <span class="n">sample</span><span class="p">[:,</span> <span class="n">user_index</span><span class="p">,</span> <span class="p">:]</span>
<a id="__codelineno-0-926" name="__codelineno-0-926" href="#__codelineno-0-926"></a>            <span class="k">elif</span> <span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;_item&#39;</span><span class="p">):</span>
<a id="__codelineno-0-927" name="__codelineno-0-927" href="#__codelineno-0-927"></a>                <span class="c1"># (R, I, *) --&gt; (R, total_computation, *)</span>
<a id="__codelineno-0-928" name="__codelineno-0-928" href="#__codelineno-0-928"></a>                <span class="k">return</span> <span class="n">sample</span><span class="p">[:,</span> <span class="n">relevant_item_index</span><span class="p">,</span> <span class="p">:]</span>
<a id="__codelineno-0-929" name="__codelineno-0-929" href="#__codelineno-0-929"></a>            <span class="k">elif</span> <span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;_category&#39;</span><span class="p">):</span>
<a id="__codelineno-0-930" name="__codelineno-0-930" href="#__codelineno-0-930"></a>                <span class="c1"># (R, NC, *) --&gt; (R, total_computation, *)</span>
<a id="__codelineno-0-931" name="__codelineno-0-931" href="#__codelineno-0-931"></a>                <span class="k">return</span> <span class="n">sample</span><span class="p">[:,</span> <span class="n">repeat_category_index</span><span class="p">,</span> <span class="p">:]</span>
<a id="__codelineno-0-932" name="__codelineno-0-932" href="#__codelineno-0-932"></a>            <span class="k">elif</span> <span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;_constant&#39;</span><span class="p">):</span>
<a id="__codelineno-0-933" name="__codelineno-0-933" href="#__codelineno-0-933"></a>                <span class="c1"># (R, *) --&gt; (R, total_computation, *)</span>
<a id="__codelineno-0-934" name="__codelineno-0-934" href="#__codelineno-0-934"></a>                <span class="k">return</span> <span class="n">sample</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">total_computation</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-935" name="__codelineno-0-935" href="#__codelineno-0-935"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-936" name="__codelineno-0-936" href="#__codelineno-0-936"></a>                <span class="k">raise</span> <span class="ne">ValueError</span>
<a id="__codelineno-0-937" name="__codelineno-0-937" href="#__codelineno-0-937"></a>
<a id="__codelineno-0-938" name="__codelineno-0-938" href="#__codelineno-0-938"></a>        <span class="k">def</span> <span class="nf">reshape_observable</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
<a id="__codelineno-0-939" name="__codelineno-0-939" href="#__codelineno-0-939"></a>            <span class="c1"># reshape observable to (R, P, I, *) so that it can be multiplied with monte carlo</span>
<a id="__codelineno-0-940" name="__codelineno-0-940" href="#__codelineno-0-940"></a>            <span class="c1"># samples of coefficients.</span>
<a id="__codelineno-0-941" name="__codelineno-0-941" href="#__codelineno-0-941"></a>            <span class="n">O</span> <span class="o">=</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># number of observables.</span>
<a id="__codelineno-0-942" name="__codelineno-0-942" href="#__codelineno-0-942"></a>            <span class="k">assert</span> <span class="n">O</span> <span class="o">==</span> <span class="n">positive_integer</span>
<a id="__codelineno-0-943" name="__codelineno-0-943" href="#__codelineno-0-943"></a>            <span class="k">if</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;item_&#39;</span><span class="p">):</span>
<a id="__codelineno-0-944" name="__codelineno-0-944" href="#__codelineno-0-944"></a>                <span class="k">assert</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">O</span><span class="p">)</span>
<a id="__codelineno-0-945" name="__codelineno-0-945" href="#__codelineno-0-945"></a>                <span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span><span class="p">[</span><span class="n">relevant_item_index</span><span class="p">,</span> <span class="p">:]</span>
<a id="__codelineno-0-946" name="__codelineno-0-946" href="#__codelineno-0-946"></a>            <span class="k">elif</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;user_&#39;</span><span class="p">):</span>
<a id="__codelineno-0-947" name="__codelineno-0-947" href="#__codelineno-0-947"></a>                <span class="k">assert</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">O</span><span class="p">)</span>
<a id="__codelineno-0-948" name="__codelineno-0-948" href="#__codelineno-0-948"></a>                <span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span><span class="p">[</span><span class="n">user_index</span><span class="p">,</span> <span class="p">:]</span>
<a id="__codelineno-0-949" name="__codelineno-0-949" href="#__codelineno-0-949"></a>            <span class="k">elif</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;session_&#39;</span><span class="p">):</span>
<a id="__codelineno-0-950" name="__codelineno-0-950" href="#__codelineno-0-950"></a>                <span class="k">assert</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">O</span><span class="p">)</span>
<a id="__codelineno-0-951" name="__codelineno-0-951" href="#__codelineno-0-951"></a>                <span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span><span class="p">[</span><span class="n">session_index</span><span class="p">,</span> <span class="p">:]</span>
<a id="__codelineno-0-952" name="__codelineno-0-952" href="#__codelineno-0-952"></a>            <span class="k">elif</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;price_&#39;</span><span class="p">):</span>
<a id="__codelineno-0-953" name="__codelineno-0-953" href="#__codelineno-0-953"></a>                <span class="k">assert</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">O</span><span class="p">)</span>
<a id="__codelineno-0-954" name="__codelineno-0-954" href="#__codelineno-0-954"></a>                <span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span><span class="p">[</span><span class="n">session_index</span><span class="p">,</span> <span class="n">relevant_item_index</span><span class="p">,</span> <span class="p">:]</span>
<a id="__codelineno-0-955" name="__codelineno-0-955" href="#__codelineno-0-955"></a>            <span class="k">elif</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;taste_&#39;</span><span class="p">):</span>
<a id="__codelineno-0-956" name="__codelineno-0-956" href="#__codelineno-0-956"></a>                <span class="k">assert</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">O</span><span class="p">)</span>
<a id="__codelineno-0-957" name="__codelineno-0-957" href="#__codelineno-0-957"></a>                <span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span><span class="p">[</span><span class="n">user_index</span><span class="p">,</span> <span class="n">relevant_item_index</span><span class="p">,</span> <span class="p">:]</span>
<a id="__codelineno-0-958" name="__codelineno-0-958" href="#__codelineno-0-958"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-959" name="__codelineno-0-959" href="#__codelineno-0-959"></a>                <span class="k">raise</span> <span class="ne">ValueError</span>
<a id="__codelineno-0-960" name="__codelineno-0-960" href="#__codelineno-0-960"></a>            <span class="k">assert</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">total_computation</span><span class="p">,</span> <span class="n">O</span><span class="p">)</span>
<a id="__codelineno-0-961" name="__codelineno-0-961" href="#__codelineno-0-961"></a>            <span class="k">return</span> <span class="n">obs</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-962" name="__codelineno-0-962" href="#__codelineno-0-962"></a>
<a id="__codelineno-0-963" name="__codelineno-0-963" href="#__codelineno-0-963"></a>        <span class="c1"># ==========================================================================================</span>
<a id="__codelineno-0-964" name="__codelineno-0-964" href="#__codelineno-0-964"></a>        <span class="c1"># Compute Components related to users and items only.</span>
<a id="__codelineno-0-965" name="__codelineno-0-965" href="#__codelineno-0-965"></a>        <span class="c1"># ==========================================================================================</span>
<a id="__codelineno-0-966" name="__codelineno-0-966" href="#__codelineno-0-966"></a>        <span class="n">utility</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">total_computation</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-967" name="__codelineno-0-967" href="#__codelineno-0-967"></a>
<a id="__codelineno-0-968" name="__codelineno-0-968" href="#__codelineno-0-968"></a>        <span class="c1"># loop over additive term to utility</span>
<a id="__codelineno-0-969" name="__codelineno-0-969" href="#__codelineno-0-969"></a>        <span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">formula</span><span class="p">:</span>
<a id="__codelineno-0-970" name="__codelineno-0-970" href="#__codelineno-0-970"></a>            <span class="c1"># Type I: single coefficient, e.g., lambda_item or lambda_user.</span>
<a id="__codelineno-0-971" name="__codelineno-0-971" href="#__codelineno-0-971"></a>            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;observable&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-972" name="__codelineno-0-972" href="#__codelineno-0-972"></a>                <span class="c1"># E.g., lambda_item or lambda_user</span>
<a id="__codelineno-0-973" name="__codelineno-0-973" href="#__codelineno-0-973"></a>                <span class="n">coef_name</span> <span class="o">=</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-974" name="__codelineno-0-974" href="#__codelineno-0-974"></a>                <span class="n">coef_sample</span> <span class="o">=</span> <span class="n">reshape_coef_sample</span><span class="p">(</span>
<a id="__codelineno-0-975" name="__codelineno-0-975" href="#__codelineno-0-975"></a>                    <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">],</span> <span class="n">coef_name</span><span class="p">)</span>
<a id="__codelineno-0-976" name="__codelineno-0-976" href="#__codelineno-0-976"></a>                <span class="k">assert</span> <span class="n">coef_sample</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">total_computation</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-977" name="__codelineno-0-977" href="#__codelineno-0-977"></a>                <span class="n">additive_term</span> <span class="o">=</span> <span class="n">coef_sample</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">total_computation</span><span class="p">)</span>
<a id="__codelineno-0-978" name="__codelineno-0-978" href="#__codelineno-0-978"></a>
<a id="__codelineno-0-979" name="__codelineno-0-979" href="#__codelineno-0-979"></a>            <span class="c1"># Type II: factorized coefficient, e.g., &lt;theta_user, lambda_item&gt;.</span>
<a id="__codelineno-0-980" name="__codelineno-0-980" href="#__codelineno-0-980"></a>            <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;observable&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-981" name="__codelineno-0-981" href="#__codelineno-0-981"></a>                <span class="n">coef_name_0</span> <span class="o">=</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-982" name="__codelineno-0-982" href="#__codelineno-0-982"></a>                <span class="n">coef_name_1</span> <span class="o">=</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
<a id="__codelineno-0-983" name="__codelineno-0-983" href="#__codelineno-0-983"></a>
<a id="__codelineno-0-984" name="__codelineno-0-984" href="#__codelineno-0-984"></a>                <span class="n">coef_sample_0</span> <span class="o">=</span> <span class="n">reshape_coef_sample</span><span class="p">(</span>
<a id="__codelineno-0-985" name="__codelineno-0-985" href="#__codelineno-0-985"></a>                    <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name_0</span><span class="p">],</span> <span class="n">coef_name_0</span><span class="p">)</span>
<a id="__codelineno-0-986" name="__codelineno-0-986" href="#__codelineno-0-986"></a>                <span class="n">coef_sample_1</span> <span class="o">=</span> <span class="n">reshape_coef_sample</span><span class="p">(</span>
<a id="__codelineno-0-987" name="__codelineno-0-987" href="#__codelineno-0-987"></a>                    <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name_1</span><span class="p">],</span> <span class="n">coef_name_1</span><span class="p">)</span>
<a id="__codelineno-0-988" name="__codelineno-0-988" href="#__codelineno-0-988"></a>
<a id="__codelineno-0-989" name="__codelineno-0-989" href="#__codelineno-0-989"></a>                <span class="k">assert</span> <span class="n">coef_sample_0</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">coef_sample_1</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span>
<a id="__codelineno-0-990" name="__codelineno-0-990" href="#__codelineno-0-990"></a>                    <span class="n">R</span><span class="p">,</span> <span class="n">total_computation</span><span class="p">,</span> <span class="n">positive_integer</span><span class="p">)</span>
<a id="__codelineno-0-991" name="__codelineno-0-991" href="#__codelineno-0-991"></a>
<a id="__codelineno-0-992" name="__codelineno-0-992" href="#__codelineno-0-992"></a>                <span class="n">additive_term</span> <span class="o">=</span> <span class="p">(</span><span class="n">coef_sample_0</span> <span class="o">*</span> <span class="n">coef_sample_1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-993" name="__codelineno-0-993" href="#__codelineno-0-993"></a>
<a id="__codelineno-0-994" name="__codelineno-0-994" href="#__codelineno-0-994"></a>            <span class="c1"># Type III: single coefficient multiplied by observable, e.g., theta_user * x_obs_item.</span>
<a id="__codelineno-0-995" name="__codelineno-0-995" href="#__codelineno-0-995"></a>            <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;observable&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-996" name="__codelineno-0-996" href="#__codelineno-0-996"></a>                <span class="n">coef_name</span> <span class="o">=</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-997" name="__codelineno-0-997" href="#__codelineno-0-997"></a>                <span class="n">coef_sample</span> <span class="o">=</span> <span class="n">reshape_coef_sample</span><span class="p">(</span>
<a id="__codelineno-0-998" name="__codelineno-0-998" href="#__codelineno-0-998"></a>                    <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">],</span> <span class="n">coef_name</span><span class="p">)</span>
<a id="__codelineno-0-999" name="__codelineno-0-999" href="#__codelineno-0-999"></a>                <span class="k">assert</span> <span class="n">coef_sample</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span>
<a id="__codelineno-0-1000" name="__codelineno-0-1000" href="#__codelineno-0-1000"></a>                    <span class="n">R</span><span class="p">,</span> <span class="n">total_computation</span><span class="p">,</span> <span class="n">positive_integer</span><span class="p">)</span>
<a id="__codelineno-0-1001" name="__codelineno-0-1001" href="#__codelineno-0-1001"></a>
<a id="__codelineno-0-1002" name="__codelineno-0-1002" href="#__codelineno-0-1002"></a>                <span class="n">obs_name</span> <span class="o">=</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;observable&#39;</span><span class="p">]</span>
<a id="__codelineno-0-1003" name="__codelineno-0-1003" href="#__codelineno-0-1003"></a>                <span class="n">obs</span> <span class="o">=</span> <span class="n">reshape_observable</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">obs_name</span><span class="p">),</span> <span class="n">obs_name</span><span class="p">)</span>
<a id="__codelineno-0-1004" name="__codelineno-0-1004" href="#__codelineno-0-1004"></a>                <span class="k">assert</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">total_computation</span><span class="p">,</span> <span class="n">positive_integer</span><span class="p">)</span>
<a id="__codelineno-0-1005" name="__codelineno-0-1005" href="#__codelineno-0-1005"></a>
<a id="__codelineno-0-1006" name="__codelineno-0-1006" href="#__codelineno-0-1006"></a>                <span class="n">additive_term</span> <span class="o">=</span> <span class="p">(</span><span class="n">coef_sample</span> <span class="o">*</span> <span class="n">obs</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-1007" name="__codelineno-0-1007" href="#__codelineno-0-1007"></a>
<a id="__codelineno-0-1008" name="__codelineno-0-1008" href="#__codelineno-0-1008"></a>            <span class="c1"># Type IV: factorized coefficient multiplied by observable.</span>
<a id="__codelineno-0-1009" name="__codelineno-0-1009" href="#__codelineno-0-1009"></a>            <span class="c1"># e.g., gamma_user * beta_item * price_obs.</span>
<a id="__codelineno-0-1010" name="__codelineno-0-1010" href="#__codelineno-0-1010"></a>            <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;observable&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-1011" name="__codelineno-0-1011" href="#__codelineno-0-1011"></a>                <span class="n">coef_name_0</span><span class="p">,</span> <span class="n">coef_name_1</span> <span class="o">=</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
<a id="__codelineno-0-1012" name="__codelineno-0-1012" href="#__codelineno-0-1012"></a>                <span class="n">coef_sample_0</span> <span class="o">=</span> <span class="n">reshape_coef_sample</span><span class="p">(</span>
<a id="__codelineno-0-1013" name="__codelineno-0-1013" href="#__codelineno-0-1013"></a>                    <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name_0</span><span class="p">],</span> <span class="n">coef_name_0</span><span class="p">)</span>
<a id="__codelineno-0-1014" name="__codelineno-0-1014" href="#__codelineno-0-1014"></a>                <span class="n">coef_sample_1</span> <span class="o">=</span> <span class="n">reshape_coef_sample</span><span class="p">(</span>
<a id="__codelineno-0-1015" name="__codelineno-0-1015" href="#__codelineno-0-1015"></a>                    <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name_1</span><span class="p">],</span> <span class="n">coef_name_1</span><span class="p">)</span>
<a id="__codelineno-0-1016" name="__codelineno-0-1016" href="#__codelineno-0-1016"></a>                <span class="k">assert</span> <span class="n">coef_sample_0</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">coef_sample_1</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span>
<a id="__codelineno-0-1017" name="__codelineno-0-1017" href="#__codelineno-0-1017"></a>                    <span class="n">R</span><span class="p">,</span> <span class="n">total_computation</span><span class="p">,</span> <span class="n">positive_integer</span><span class="p">)</span>
<a id="__codelineno-0-1018" name="__codelineno-0-1018" href="#__codelineno-0-1018"></a>                <span class="n">num_obs_times_latent_dim</span> <span class="o">=</span> <span class="n">coef_sample_0</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<a id="__codelineno-0-1019" name="__codelineno-0-1019" href="#__codelineno-0-1019"></a>
<a id="__codelineno-0-1020" name="__codelineno-0-1020" href="#__codelineno-0-1020"></a>                <span class="n">obs_name</span> <span class="o">=</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;observable&#39;</span><span class="p">]</span>
<a id="__codelineno-0-1021" name="__codelineno-0-1021" href="#__codelineno-0-1021"></a>                <span class="n">obs</span> <span class="o">=</span> <span class="n">reshape_observable</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">obs_name</span><span class="p">),</span> <span class="n">obs_name</span><span class="p">)</span>
<a id="__codelineno-0-1022" name="__codelineno-0-1022" href="#__codelineno-0-1022"></a>                <span class="k">assert</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">total_computation</span><span class="p">,</span> <span class="n">positive_integer</span><span class="p">)</span>
<a id="__codelineno-0-1023" name="__codelineno-0-1023" href="#__codelineno-0-1023"></a>                <span class="n">num_obs</span> <span class="o">=</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># number of observables.</span>
<a id="__codelineno-0-1024" name="__codelineno-0-1024" href="#__codelineno-0-1024"></a>
<a id="__codelineno-0-1025" name="__codelineno-0-1025" href="#__codelineno-0-1025"></a>                <span class="k">assert</span> <span class="p">(</span><span class="n">num_obs_times_latent_dim</span> <span class="o">%</span> <span class="n">num_obs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>
<a id="__codelineno-0-1026" name="__codelineno-0-1026" href="#__codelineno-0-1026"></a>                <span class="n">latent_dim</span> <span class="o">=</span> <span class="n">num_obs_times_latent_dim</span> <span class="o">//</span> <span class="n">num_obs</span>
<a id="__codelineno-0-1027" name="__codelineno-0-1027" href="#__codelineno-0-1027"></a>
<a id="__codelineno-0-1028" name="__codelineno-0-1028" href="#__codelineno-0-1028"></a>                <span class="n">coef_sample_0</span> <span class="o">=</span> <span class="n">coef_sample_0</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
<a id="__codelineno-0-1029" name="__codelineno-0-1029" href="#__codelineno-0-1029"></a>                    <span class="n">R</span><span class="p">,</span> <span class="n">total_computation</span><span class="p">,</span> <span class="n">num_obs</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>
<a id="__codelineno-0-1030" name="__codelineno-0-1030" href="#__codelineno-0-1030"></a>                <span class="n">coef_sample_1</span> <span class="o">=</span> <span class="n">coef_sample_1</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
<a id="__codelineno-0-1031" name="__codelineno-0-1031" href="#__codelineno-0-1031"></a>                    <span class="n">R</span><span class="p">,</span> <span class="n">total_computation</span><span class="p">,</span> <span class="n">num_obs</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>
<a id="__codelineno-0-1032" name="__codelineno-0-1032" href="#__codelineno-0-1032"></a>                <span class="c1"># compute the factorized coefficient with shape (R, P, I, O).</span>
<a id="__codelineno-0-1033" name="__codelineno-0-1033" href="#__codelineno-0-1033"></a>                <span class="n">coef</span> <span class="o">=</span> <span class="p">(</span><span class="n">coef_sample_0</span> <span class="o">*</span> <span class="n">coef_sample_1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-1034" name="__codelineno-0-1034" href="#__codelineno-0-1034"></a>
<a id="__codelineno-0-1035" name="__codelineno-0-1035" href="#__codelineno-0-1035"></a>                <span class="n">additive_term</span> <span class="o">=</span> <span class="p">(</span><span class="n">coef</span> <span class="o">*</span> <span class="n">obs</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-1036" name="__codelineno-0-1036" href="#__codelineno-0-1036"></a>
<a id="__codelineno-0-1037" name="__codelineno-0-1037" href="#__codelineno-0-1037"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-1038" name="__codelineno-0-1038" href="#__codelineno-0-1038"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Undefined term type: </span><span class="si">{</span><span class="n">term</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<a id="__codelineno-0-1039" name="__codelineno-0-1039" href="#__codelineno-0-1039"></a>
<a id="__codelineno-0-1040" name="__codelineno-0-1040" href="#__codelineno-0-1040"></a>            <span class="k">assert</span> <span class="n">additive_term</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">total_computation</span><span class="p">)</span>
<a id="__codelineno-0-1041" name="__codelineno-0-1041" href="#__codelineno-0-1041"></a>            <span class="n">utility</span> <span class="o">+=</span> <span class="n">additive_term</span>
<a id="__codelineno-0-1042" name="__codelineno-0-1042" href="#__codelineno-0-1042"></a>
<a id="__codelineno-0-1043" name="__codelineno-0-1043" href="#__codelineno-0-1043"></a>        <span class="c1"># ==========================================================================================</span>
<a id="__codelineno-0-1044" name="__codelineno-0-1044" href="#__codelineno-0-1044"></a>        <span class="c1"># Mask Out Unavailable Items in Each Session.</span>
<a id="__codelineno-0-1045" name="__codelineno-0-1045" href="#__codelineno-0-1045"></a>        <span class="c1"># ==========================================================================================</span>
<a id="__codelineno-0-1046" name="__codelineno-0-1046" href="#__codelineno-0-1046"></a>
<a id="__codelineno-0-1047" name="__codelineno-0-1047" href="#__codelineno-0-1047"></a>        <span class="k">if</span> <span class="n">batch</span><span class="o">.</span><span class="n">item_availability</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-1048" name="__codelineno-0-1048" href="#__codelineno-0-1048"></a>            <span class="c1"># expand to the Monte Carlo sample dimension.</span>
<a id="__codelineno-0-1049" name="__codelineno-0-1049" href="#__codelineno-0-1049"></a>            <span class="n">A</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">item_availability</span><span class="p">[</span><span class="n">session_index</span><span class="p">,</span> <span class="n">relevant_item_index</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span>
<a id="__codelineno-0-1050" name="__codelineno-0-1050" href="#__codelineno-0-1050"></a>                <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-1051" name="__codelineno-0-1051" href="#__codelineno-0-1051"></a>            <span class="n">utility</span><span class="p">[</span><span class="o">~</span><span class="n">A</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">utility</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">max</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-0-1052" name="__codelineno-0-1052" href="#__codelineno-0-1052"></a>
<a id="__codelineno-0-1053" name="__codelineno-0-1053" href="#__codelineno-0-1053"></a>        <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">additional_modules</span><span class="p">:</span>
<a id="__codelineno-0-1054" name="__codelineno-0-1054" href="#__codelineno-0-1054"></a>            <span class="c1"># current utility shape: (R, total_computation)</span>
<a id="__codelineno-0-1055" name="__codelineno-0-1055" href="#__codelineno-0-1055"></a>            <span class="n">additive_term</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
<a id="__codelineno-0-1056" name="__codelineno-0-1056" href="#__codelineno-0-1056"></a>            <span class="k">assert</span> <span class="n">additive_term</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span>
<a id="__codelineno-0-1057" name="__codelineno-0-1057" href="#__codelineno-0-1057"></a>                <span class="n">R</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">))</span> <span class="ow">or</span> <span class="n">additive_term</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-1058" name="__codelineno-0-1058" href="#__codelineno-0-1058"></a>            <span class="k">if</span> <span class="n">additive_term</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="mi">1</span><span class="p">):</span>
<a id="__codelineno-0-1059" name="__codelineno-0-1059" href="#__codelineno-0-1059"></a>                <span class="c1"># TODO: need to make this consistent with log_likelihood_all.</span>
<a id="__codelineno-0-1060" name="__codelineno-0-1060" href="#__codelineno-0-1060"></a>                <span class="c1"># be tolerant for some customized module with BayesianLinear that returns (R, len(batch), 1).</span>
<a id="__codelineno-0-1061" name="__codelineno-0-1061" href="#__codelineno-0-1061"></a>                <span class="n">additive_term</span> <span class="o">=</span> <span class="n">additive_term</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">))</span>
<a id="__codelineno-0-1062" name="__codelineno-0-1062" href="#__codelineno-0-1062"></a>            <span class="c1"># expand to total number of computation, query by reverse_indices.</span>
<a id="__codelineno-0-1063" name="__codelineno-0-1063" href="#__codelineno-0-1063"></a>            <span class="c1"># reverse_indices has length total_computation, and reverse_indices[i] correspond to the row-id that this</span>
<a id="__codelineno-0-1064" name="__codelineno-0-1064" href="#__codelineno-0-1064"></a>            <span class="c1"># computation is responsible for.</span>
<a id="__codelineno-0-1065" name="__codelineno-0-1065" href="#__codelineno-0-1065"></a>            <span class="n">additive_term</span> <span class="o">=</span> <span class="n">additive_term</span><span class="p">[:,</span> <span class="n">reverse_indices</span><span class="p">]</span>
<a id="__codelineno-0-1066" name="__codelineno-0-1066" href="#__codelineno-0-1066"></a>            <span class="k">assert</span> <span class="n">additive_term</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">total_computation</span><span class="p">)</span>
<a id="__codelineno-0-1067" name="__codelineno-0-1067" href="#__codelineno-0-1067"></a>
<a id="__codelineno-0-1068" name="__codelineno-0-1068" href="#__codelineno-0-1068"></a>        <span class="k">if</span> <span class="n">return_logit</span><span class="p">:</span>
<a id="__codelineno-0-1069" name="__codelineno-0-1069" href="#__codelineno-0-1069"></a>            <span class="c1"># (num_seeds, len(batch))</span>
<a id="__codelineno-0-1070" name="__codelineno-0-1070" href="#__codelineno-0-1070"></a>            <span class="n">u</span> <span class="o">=</span> <span class="n">utility</span><span class="p">[:,</span> <span class="n">item_index_expanded</span> <span class="o">==</span> <span class="n">relevant_item_index</span><span class="p">]</span>
<a id="__codelineno-0-1071" name="__codelineno-0-1071" href="#__codelineno-0-1071"></a>            <span class="k">assert</span> <span class="n">u</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">))</span>
<a id="__codelineno-0-1072" name="__codelineno-0-1072" href="#__codelineno-0-1072"></a>            <span class="k">return</span> <span class="n">u</span>
<a id="__codelineno-0-1073" name="__codelineno-0-1073" href="#__codelineno-0-1073"></a>
<a id="__codelineno-0-1074" name="__codelineno-0-1074" href="#__codelineno-0-1074"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pred_item</span><span class="p">:</span>
<a id="__codelineno-0-1075" name="__codelineno-0-1075" href="#__codelineno-0-1075"></a>            <span class="c1"># compute log likelihood log p(choosing item i | user, item latents)</span>
<a id="__codelineno-0-1076" name="__codelineno-0-1076" href="#__codelineno-0-1076"></a>            <span class="c1"># compute the log probability from logits/utilities.</span>
<a id="__codelineno-0-1077" name="__codelineno-0-1077" href="#__codelineno-0-1077"></a>            <span class="c1"># output shape: (num_seeds, len(batch), num_items)</span>
<a id="__codelineno-0-1078" name="__codelineno-0-1078" href="#__codelineno-0-1078"></a>            <span class="n">log_p</span> <span class="o">=</span> <span class="n">scatter_log_softmax</span><span class="p">(</span><span class="n">utility</span><span class="p">,</span> <span class="n">reverse_indices</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-1079" name="__codelineno-0-1079" href="#__codelineno-0-1079"></a>            <span class="c1"># select the log-P of the item actually bought.</span>
<a id="__codelineno-0-1080" name="__codelineno-0-1080" href="#__codelineno-0-1080"></a>            <span class="n">log_p</span> <span class="o">=</span> <span class="n">log_p</span><span class="p">[:,</span> <span class="n">item_index_expanded</span> <span class="o">==</span> <span class="n">relevant_item_index</span><span class="p">]</span>
<a id="__codelineno-0-1081" name="__codelineno-0-1081" href="#__codelineno-0-1081"></a>            <span class="k">assert</span> <span class="n">log_p</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">))</span>
<a id="__codelineno-0-1082" name="__codelineno-0-1082" href="#__codelineno-0-1082"></a>            <span class="k">return</span> <span class="n">log_p</span>
<a id="__codelineno-0-1083" name="__codelineno-0-1083" href="#__codelineno-0-1083"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-1084" name="__codelineno-0-1084" href="#__codelineno-0-1084"></a>            <span class="c1"># This is the binomial choice situation in which case we just report sigmoid log likelihood</span>
<a id="__codelineno-0-1085" name="__codelineno-0-1085" href="#__codelineno-0-1085"></a>            <span class="n">utility</span> <span class="o">=</span> <span class="n">utility</span><span class="p">[:,</span> <span class="n">item_index_expanded</span> <span class="o">==</span> <span class="n">relevant_item_index</span><span class="p">]</span>
<a id="__codelineno-0-1086" name="__codelineno-0-1086" href="#__codelineno-0-1086"></a>            <span class="k">assert</span> <span class="n">utility</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">))</span>
<a id="__codelineno-0-1087" name="__codelineno-0-1087" href="#__codelineno-0-1087"></a>            <span class="n">bce</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
<a id="__codelineno-0-1088" name="__codelineno-0-1088" href="#__codelineno-0-1088"></a>            <span class="c1"># make num_seeds copies of the label, expand to (R, len(batch))</span>
<a id="__codelineno-0-1089" name="__codelineno-0-1089" href="#__codelineno-0-1089"></a>            <span class="n">label_expanded</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">label</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">))</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-1090" name="__codelineno-0-1090" href="#__codelineno-0-1090"></a>            <span class="k">assert</span> <span class="n">label_expanded</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">))</span>
<a id="__codelineno-0-1091" name="__codelineno-0-1091" href="#__codelineno-0-1091"></a>            <span class="n">log_p</span> <span class="o">=</span> <span class="o">-</span> <span class="n">bce</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">utility</span><span class="p">),</span> <span class="n">label_expanded</span><span class="p">)</span>
<a id="__codelineno-0-1092" name="__codelineno-0-1092" href="#__codelineno-0-1092"></a>            <span class="k">assert</span> <span class="n">log_p</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">))</span>
<a id="__codelineno-0-1093" name="__codelineno-0-1093" href="#__codelineno-0-1093"></a>            <span class="k">return</span> <span class="n">log_p</span>
<a id="__codelineno-0-1094" name="__codelineno-0-1094" href="#__codelineno-0-1094"></a>
<a id="__codelineno-0-1095" name="__codelineno-0-1095" href="#__codelineno-0-1095"></a>    <span class="k">def</span> <span class="nf">log_prior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">ChoiceDataset</span><span class="p">,</span> <span class="n">sample_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-1096" name="__codelineno-0-1096" href="#__codelineno-0-1096"></a>        <span class="sd">&quot;&quot;&quot;Calculates the log-likelihood of Monte Carlo samples of Bayesian coefficients under their</span>
<a id="__codelineno-0-1097" name="__codelineno-0-1097" href="#__codelineno-0-1097"></a><span class="sd">        prior distribution. This method assume coefficients are statistically independent.</span>
<a id="__codelineno-0-1098" name="__codelineno-0-1098" href="#__codelineno-0-1098"></a>
<a id="__codelineno-0-1099" name="__codelineno-0-1099" href="#__codelineno-0-1099"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-1100" name="__codelineno-0-1100" href="#__codelineno-0-1100"></a><span class="sd">            batch (ChoiceDataset): a dataset object contains observables for computing the prior distribution</span>
<a id="__codelineno-0-1101" name="__codelineno-0-1101" href="#__codelineno-0-1101"></a><span class="sd">                if obs2prior is True.</span>
<a id="__codelineno-0-1102" name="__codelineno-0-1102" href="#__codelineno-0-1102"></a><span class="sd">            sample_dict (Dict[str, torch.Tensor]): a dictionary coefficient names to Monte Carlo samples.</span>
<a id="__codelineno-0-1103" name="__codelineno-0-1103" href="#__codelineno-0-1103"></a>
<a id="__codelineno-0-1104" name="__codelineno-0-1104" href="#__codelineno-0-1104"></a><span class="sd">        Raises:</span>
<a id="__codelineno-0-1105" name="__codelineno-0-1105" href="#__codelineno-0-1105"></a><span class="sd">            ValueError: [description]</span>
<a id="__codelineno-0-1106" name="__codelineno-0-1106" href="#__codelineno-0-1106"></a>
<a id="__codelineno-0-1107" name="__codelineno-0-1107" href="#__codelineno-0-1107"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-1108" name="__codelineno-0-1108" href="#__codelineno-0-1108"></a><span class="sd">            torch.scalar_tensor: a tensor with shape (num_seeds,) of [ log P_{prior_distribution}(param[i]) ],</span>
<a id="__codelineno-0-1109" name="__codelineno-0-1109" href="#__codelineno-0-1109"></a><span class="sd">                where param[i] is the i-th Monte Carlo sample.</span>
<a id="__codelineno-0-1110" name="__codelineno-0-1110" href="#__codelineno-0-1110"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-1111" name="__codelineno-0-1111" href="#__codelineno-0-1111"></a>        <span class="c1"># assert sample_dict.keys() == self.coef_dict.keys()</span>
<a id="__codelineno-0-1112" name="__codelineno-0-1112" href="#__codelineno-0-1112"></a>        <span class="n">num_seeds</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">sample_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-1113" name="__codelineno-0-1113" href="#__codelineno-0-1113"></a>
<a id="__codelineno-0-1114" name="__codelineno-0-1114" href="#__codelineno-0-1114"></a>        <span class="n">total</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_seeds</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-1115" name="__codelineno-0-1115" href="#__codelineno-0-1115"></a>
<a id="__codelineno-0-1116" name="__codelineno-0-1116" href="#__codelineno-0-1116"></a>        <span class="k">for</span> <span class="n">coef_name</span><span class="p">,</span> <span class="n">coef</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<a id="__codelineno-0-1117" name="__codelineno-0-1117" href="#__codelineno-0-1117"></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">obs2prior_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">]:</span>
<a id="__codelineno-0-1118" name="__codelineno-0-1118" href="#__codelineno-0-1118"></a>                <span class="k">if</span> <span class="n">coef_name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;_item&#39;</span><span class="p">):</span>
<a id="__codelineno-0-1119" name="__codelineno-0-1119" href="#__codelineno-0-1119"></a>                    <span class="n">x_obs</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">item_obs</span>
<a id="__codelineno-0-1120" name="__codelineno-0-1120" href="#__codelineno-0-1120"></a>                <span class="k">elif</span> <span class="n">coef_name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;_user&#39;</span><span class="p">):</span>
<a id="__codelineno-0-1121" name="__codelineno-0-1121" href="#__codelineno-0-1121"></a>                    <span class="n">x_obs</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">user_obs</span>
<a id="__codelineno-0-1122" name="__codelineno-0-1122" href="#__codelineno-0-1122"></a>                <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-1123" name="__codelineno-0-1123" href="#__codelineno-0-1123"></a>                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-1124" name="__codelineno-0-1124" href="#__codelineno-0-1124"></a>                        <span class="sa">f</span><span class="s1">&#39;No observable found to support obs2prior for </span><span class="si">{</span><span class="n">coef_name</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span>
<a id="__codelineno-0-1125" name="__codelineno-0-1125" href="#__codelineno-0-1125"></a>
<a id="__codelineno-0-1126" name="__codelineno-0-1126" href="#__codelineno-0-1126"></a>                <span class="n">total</span> <span class="o">+=</span> <span class="n">coef</span><span class="o">.</span><span class="n">log_prior</span><span class="p">(</span><span class="n">sample</span><span class="o">=</span><span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">],</span>
<a id="__codelineno-0-1127" name="__codelineno-0-1127" href="#__codelineno-0-1127"></a>                                        <span class="n">H_sample</span><span class="o">=</span><span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name</span> <span class="o">+</span> <span class="s1">&#39;.H&#39;</span><span class="p">],</span>
<a id="__codelineno-0-1128" name="__codelineno-0-1128" href="#__codelineno-0-1128"></a>                                        <span class="n">x_obs</span><span class="o">=</span><span class="n">x_obs</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-1129" name="__codelineno-0-1129" href="#__codelineno-0-1129"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-1130" name="__codelineno-0-1130" href="#__codelineno-0-1130"></a>                <span class="c1"># log_prob outputs (num_seeds, num_{items, users}), sum to (num_seeds).</span>
<a id="__codelineno-0-1131" name="__codelineno-0-1131" href="#__codelineno-0-1131"></a>                <span class="n">total</span> <span class="o">+=</span> <span class="n">coef</span><span class="o">.</span><span class="n">log_prior</span><span class="p">(</span>
<a id="__codelineno-0-1132" name="__codelineno-0-1132" href="#__codelineno-0-1132"></a>                    <span class="n">sample</span><span class="o">=</span><span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">],</span> <span class="n">H_sample</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">x_obs</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-1133" name="__codelineno-0-1133" href="#__codelineno-0-1133"></a>
<a id="__codelineno-0-1134" name="__codelineno-0-1134" href="#__codelineno-0-1134"></a>        <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">additional_modules</span><span class="p">:</span>
<a id="__codelineno-0-1135" name="__codelineno-0-1135" href="#__codelineno-0-1135"></a>            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
<a id="__codelineno-0-1136" name="__codelineno-0-1136" href="#__codelineno-0-1136"></a>            <span class="n">total</span> <span class="o">+=</span> <span class="n">module</span><span class="o">.</span><span class="n">log_prior</span><span class="p">()</span>
<a id="__codelineno-0-1137" name="__codelineno-0-1137" href="#__codelineno-0-1137"></a>
<a id="__codelineno-0-1138" name="__codelineno-0-1138" href="#__codelineno-0-1138"></a>        <span class="k">return</span> <span class="n">total</span>
<a id="__codelineno-0-1139" name="__codelineno-0-1139" href="#__codelineno-0-1139"></a>
<a id="__codelineno-0-1140" name="__codelineno-0-1140" href="#__codelineno-0-1140"></a>    <span class="k">def</span> <span class="nf">log_variational</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-1141" name="__codelineno-0-1141" href="#__codelineno-0-1141"></a>        <span class="sd">&quot;&quot;&quot;Calculate the log-likelihood of samples in sample_dict under the current variational</span>
<a id="__codelineno-0-1142" name="__codelineno-0-1142" href="#__codelineno-0-1142"></a><span class="sd">        distribution.</span>
<a id="__codelineno-0-1143" name="__codelineno-0-1143" href="#__codelineno-0-1143"></a>
<a id="__codelineno-0-1144" name="__codelineno-0-1144" href="#__codelineno-0-1144"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-1145" name="__codelineno-0-1145" href="#__codelineno-0-1145"></a><span class="sd">            sample_dict (Dict[str, torch.Tensor]):  a dictionary coefficient names to Monte Carlo</span>
<a id="__codelineno-0-1146" name="__codelineno-0-1146" href="#__codelineno-0-1146"></a><span class="sd">                samples.</span>
<a id="__codelineno-0-1147" name="__codelineno-0-1147" href="#__codelineno-0-1147"></a>
<a id="__codelineno-0-1148" name="__codelineno-0-1148" href="#__codelineno-0-1148"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-1149" name="__codelineno-0-1149" href="#__codelineno-0-1149"></a><span class="sd">            torch.Tensor: a tensor of shape (num_seeds) of [ log P_{variational_distribution}(param[i]) ],</span>
<a id="__codelineno-0-1150" name="__codelineno-0-1150" href="#__codelineno-0-1150"></a><span class="sd">                where param[i] is the i-th Monte Carlo sample.</span>
<a id="__codelineno-0-1151" name="__codelineno-0-1151" href="#__codelineno-0-1151"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-1152" name="__codelineno-0-1152" href="#__codelineno-0-1152"></a>        <span class="n">num_seeds</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">sample_dict</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-1153" name="__codelineno-0-1153" href="#__codelineno-0-1153"></a>        <span class="n">total</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_seeds</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-1154" name="__codelineno-0-1154" href="#__codelineno-0-1154"></a>
<a id="__codelineno-0-1155" name="__codelineno-0-1155" href="#__codelineno-0-1155"></a>        <span class="k">for</span> <span class="n">coef_name</span><span class="p">,</span> <span class="n">coef</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<a id="__codelineno-0-1156" name="__codelineno-0-1156" href="#__codelineno-0-1156"></a>            <span class="c1"># log_prob outputs (num_seeds, num_{items, users}), sum to (num_seeds).</span>
<a id="__codelineno-0-1157" name="__codelineno-0-1157" href="#__codelineno-0-1157"></a>            <span class="n">total</span> <span class="o">+=</span> <span class="n">coef</span><span class="o">.</span><span class="n">log_variational</span><span class="p">(</span><span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-1158" name="__codelineno-0-1158" href="#__codelineno-0-1158"></a>
<a id="__codelineno-0-1159" name="__codelineno-0-1159" href="#__codelineno-0-1159"></a>        <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">additional_modules</span><span class="p">:</span>
<a id="__codelineno-0-1160" name="__codelineno-0-1160" href="#__codelineno-0-1160"></a>            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
<a id="__codelineno-0-1161" name="__codelineno-0-1161" href="#__codelineno-0-1161"></a>            <span class="c1"># with shape (num_seeds,)</span>
<a id="__codelineno-0-1162" name="__codelineno-0-1162" href="#__codelineno-0-1162"></a>            <span class="n">total</span> <span class="o">+=</span> <span class="n">module</span><span class="o">.</span><span class="n">log_variational</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<a id="__codelineno-0-1163" name="__codelineno-0-1163" href="#__codelineno-0-1163"></a>
<a id="__codelineno-0-1164" name="__codelineno-0-1164" href="#__codelineno-0-1164"></a>        <span class="k">return</span> <span class="n">total</span>
<a id="__codelineno-0-1165" name="__codelineno-0-1165" href="#__codelineno-0-1165"></a>
<a id="__codelineno-0-1166" name="__codelineno-0-1166" href="#__codelineno-0-1166"></a>    <span class="k">def</span> <span class="nf">elbo</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">ChoiceDataset</span><span class="p">,</span> <span class="n">num_seeds</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-1167" name="__codelineno-0-1167" href="#__codelineno-0-1167"></a>        <span class="sd">&quot;&quot;&quot;A combined method to computes the current ELBO given a batch, this method is used for training the model.</span>
<a id="__codelineno-0-1168" name="__codelineno-0-1168" href="#__codelineno-0-1168"></a>
<a id="__codelineno-0-1169" name="__codelineno-0-1169" href="#__codelineno-0-1169"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-1170" name="__codelineno-0-1170" href="#__codelineno-0-1170"></a><span class="sd">            batch (ChoiceDataset): a ChoiceDataset containing necessary information.</span>
<a id="__codelineno-0-1171" name="__codelineno-0-1171" href="#__codelineno-0-1171"></a><span class="sd">            num_seeds (int, optional): the number of Monte Carlo samples from variational distributions</span>
<a id="__codelineno-0-1172" name="__codelineno-0-1172" href="#__codelineno-0-1172"></a><span class="sd">                to evaluate the expectation in ELBO.</span>
<a id="__codelineno-0-1173" name="__codelineno-0-1173" href="#__codelineno-0-1173"></a><span class="sd">                Defaults to 1.</span>
<a id="__codelineno-0-1174" name="__codelineno-0-1174" href="#__codelineno-0-1174"></a>
<a id="__codelineno-0-1175" name="__codelineno-0-1175" href="#__codelineno-0-1175"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-1176" name="__codelineno-0-1176" href="#__codelineno-0-1176"></a><span class="sd">            torch.Tensor: a scalar tensor of the ELBO estimated from num_seeds Monte Carlo samples.</span>
<a id="__codelineno-0-1177" name="__codelineno-0-1177" href="#__codelineno-0-1177"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-1178" name="__codelineno-0-1178" href="#__codelineno-0-1178"></a>        <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-1179" name="__codelineno-0-1179" href="#__codelineno-0-1179"></a>        <span class="c1"># 1. sample latent variables from their variational distributions.</span>
<a id="__codelineno-0-1180" name="__codelineno-0-1180" href="#__codelineno-0-1180"></a>        <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-1181" name="__codelineno-0-1181" href="#__codelineno-0-1181"></a>        <span class="n">sample_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_coefficient_dictionary</span><span class="p">(</span><span class="n">num_seeds</span><span class="p">)</span>
<a id="__codelineno-0-1182" name="__codelineno-0-1182" href="#__codelineno-0-1182"></a>
<a id="__codelineno-0-1183" name="__codelineno-0-1183" href="#__codelineno-0-1183"></a>        <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-1184" name="__codelineno-0-1184" href="#__codelineno-0-1184"></a>        <span class="c1"># 2. compute log p(latent) prior.</span>
<a id="__codelineno-0-1185" name="__codelineno-0-1185" href="#__codelineno-0-1185"></a>        <span class="c1"># (num_seeds,) --mean--&gt; scalar.</span>
<a id="__codelineno-0-1186" name="__codelineno-0-1186" href="#__codelineno-0-1186"></a>        <span class="n">elbo</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_prior</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">sample_dict</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-1187" name="__codelineno-0-1187" href="#__codelineno-0-1187"></a>        <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-1188" name="__codelineno-0-1188" href="#__codelineno-0-1188"></a>
<a id="__codelineno-0-1189" name="__codelineno-0-1189" href="#__codelineno-0-1189"></a>        <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-1190" name="__codelineno-0-1190" href="#__codelineno-0-1190"></a>        <span class="c1"># 3. compute the log likelihood log p(obs|latent).</span>
<a id="__codelineno-0-1191" name="__codelineno-0-1191" href="#__codelineno-0-1191"></a>        <span class="c1"># sum over independent purchase decision for individual observations, mean over MC seeds.</span>
<a id="__codelineno-0-1192" name="__codelineno-0-1192" href="#__codelineno-0-1192"></a>        <span class="c1"># the forward() function calls module.rsample(num_seeds) for module in self.additional_modules.</span>
<a id="__codelineno-0-1193" name="__codelineno-0-1193" href="#__codelineno-0-1193"></a>        <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-1194" name="__codelineno-0-1194" href="#__codelineno-0-1194"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pred_item</span><span class="p">:</span>
<a id="__codelineno-0-1195" name="__codelineno-0-1195" href="#__codelineno-0-1195"></a>            <span class="c1"># the prediction target is item_index.</span>
<a id="__codelineno-0-1196" name="__codelineno-0-1196" href="#__codelineno-0-1196"></a>            <span class="n">elbo</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span>
<a id="__codelineno-0-1197" name="__codelineno-0-1197" href="#__codelineno-0-1197"></a>                                 <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;log_prob&#39;</span><span class="p">,</span>
<a id="__codelineno-0-1198" name="__codelineno-0-1198" href="#__codelineno-0-1198"></a>                                 <span class="n">return_scope</span><span class="o">=</span><span class="s1">&#39;item_index&#39;</span><span class="p">,</span>
<a id="__codelineno-0-1199" name="__codelineno-0-1199" href="#__codelineno-0-1199"></a>                                 <span class="n">deterministic</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-1200" name="__codelineno-0-1200" href="#__codelineno-0-1200"></a>                                 <span class="n">sample_dict</span><span class="o">=</span><span class="n">sample_dict</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># (num_seeds, len(batch)) --&gt; scalar.</span>
<a id="__codelineno-0-1201" name="__codelineno-0-1201" href="#__codelineno-0-1201"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-1202" name="__codelineno-0-1202" href="#__codelineno-0-1202"></a>            <span class="c1"># the prediction target is binary.</span>
<a id="__codelineno-0-1203" name="__codelineno-0-1203" href="#__codelineno-0-1203"></a>            <span class="c1"># TODO: update the prediction function.</span>
<a id="__codelineno-0-1204" name="__codelineno-0-1204" href="#__codelineno-0-1204"></a>            <span class="n">utility</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span>
<a id="__codelineno-0-1205" name="__codelineno-0-1205" href="#__codelineno-0-1205"></a>                                   <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;utility&#39;</span><span class="p">,</span>
<a id="__codelineno-0-1206" name="__codelineno-0-1206" href="#__codelineno-0-1206"></a>                                   <span class="n">return_scope</span><span class="o">=</span><span class="s1">&#39;item_index&#39;</span><span class="p">,</span>
<a id="__codelineno-0-1207" name="__codelineno-0-1207" href="#__codelineno-0-1207"></a>                                   <span class="n">deterministic</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-1208" name="__codelineno-0-1208" href="#__codelineno-0-1208"></a>                                   <span class="n">sample_dict</span><span class="o">=</span><span class="n">sample_dict</span><span class="p">)</span>  <span class="c1"># (num_seeds, len(batch))</span>
<a id="__codelineno-0-1209" name="__codelineno-0-1209" href="#__codelineno-0-1209"></a>
<a id="__codelineno-0-1210" name="__codelineno-0-1210" href="#__codelineno-0-1210"></a>            <span class="c1"># compute the log-likelihood for binary label.</span>
<a id="__codelineno-0-1211" name="__codelineno-0-1211" href="#__codelineno-0-1211"></a>            <span class="c1"># (num_seeds, len(batch))</span>
<a id="__codelineno-0-1212" name="__codelineno-0-1212" href="#__codelineno-0-1212"></a>            <span class="n">y_stacked</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">batch</span><span class="o">.</span><span class="n">label</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_seeds</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<a id="__codelineno-0-1213" name="__codelineno-0-1213" href="#__codelineno-0-1213"></a>            <span class="k">assert</span> <span class="n">y_stacked</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">utility</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-1214" name="__codelineno-0-1214" href="#__codelineno-0-1214"></a>            <span class="n">bce</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
<a id="__codelineno-0-1215" name="__codelineno-0-1215" href="#__codelineno-0-1215"></a>            <span class="c1"># scalar.</span>
<a id="__codelineno-0-1216" name="__codelineno-0-1216" href="#__codelineno-0-1216"></a>            <span class="n">ll</span> <span class="o">=</span> <span class="o">-</span> <span class="n">bce</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">utility</span><span class="p">),</span>
<a id="__codelineno-0-1217" name="__codelineno-0-1217" href="#__codelineno-0-1217"></a>                       <span class="n">y_stacked</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-1218" name="__codelineno-0-1218" href="#__codelineno-0-1218"></a>            <span class="n">elbo</span> <span class="o">+=</span> <span class="n">ll</span>
<a id="__codelineno-0-1219" name="__codelineno-0-1219" href="#__codelineno-0-1219"></a>
<a id="__codelineno-0-1220" name="__codelineno-0-1220" href="#__codelineno-0-1220"></a>        <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-1221" name="__codelineno-0-1221" href="#__codelineno-0-1221"></a>        <span class="c1"># 4. optionally add log likelihood under variational distributions q(latent).</span>
<a id="__codelineno-0-1222" name="__codelineno-0-1222" href="#__codelineno-0-1222"></a>        <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-1223" name="__codelineno-0-1223" href="#__codelineno-0-1223"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trace_log_q</span><span class="p">:</span>
<a id="__codelineno-0-1224" name="__codelineno-0-1224" href="#__codelineno-0-1224"></a>            <span class="n">elbo</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_variational</span><span class="p">(</span><span class="n">sample_dict</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-1225" name="__codelineno-0-1225" href="#__codelineno-0-1225"></a>
<a id="__codelineno-0-1226" name="__codelineno-0-1226" href="#__codelineno-0-1226"></a>        <span class="k">return</span> <span class="n">elbo</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">











  <div class="doc doc-object doc-method">



<h5 id="bemb.model.bemb.BEMBFlex.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">utility_formula</span><span class="p">,</span> <span class="n">obs2prior_dict</span><span class="p">,</span> <span class="n">coef_dim_dict</span><span class="p">,</span> <span class="n">num_items</span><span class="p">,</span> <span class="n">pred_item</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">H_zero_mask_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prior_mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">default_prior_mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">prior_variance</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">num_users</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_sessions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">trace_log_q</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">category_to_item</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_user_obs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_item_obs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_session_obs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_price_obs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_taste_obs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">additional_modules</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h5>

    <div class="doc doc-contents ">


<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>utility_formula</code></td>
        <td><code>str</code></td>
        <td><p>a string representing the utility function U[user, item, session].
See documentation for more details in the documentation for the format of formula.
Examples:
    lambda_item
    lambda_item + theta_user * alpha_item + zeta_user * item_obs
    lambda_item + theta_user * alpha_item + gamma_user * beta_item * price_obs
See the doc-string of parse_utility for an example.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>obs2prior_dict</code></td>
        <td><code>Dict[str, bool]</code></td>
        <td><p>a dictionary maps coefficient name (e.g., 'lambda_item')
to a boolean indicating if observable (e.g., item_obs) enters the prior of the coefficient.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>coef_dim_dict</code></td>
        <td><code>Dict[str, int]</code></td>
        <td><p>a dictionary maps coefficient name (e.g., 'lambda_item')
to an integer indicating the dimension of coefficient.
For standalone coefficients like U = lambda_item, the dim should be 1.
For factorized coefficients like U = theta_user * alpha_item, the dim should be the
    latent dimension of theta and alpha.
For coefficients multiplied with observables like U = zeta_user * item_obs, the dim
    should be the number of observables in item_obs.
For factorized coefficient multiplied with observables like U = gamma_user * beta_item * price_obs,
    the dim should be the latent dim multiplied by number of observables in price_obs.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>H_zero_mask_dict</code></td>
        <td><code>Dict[str, torch.BoolTensor]</code></td>
        <td><p>A dictionary maps coefficient names to a boolean tensor,
you should only specify the H_zero_mask for coefficients with obs2prior turned on.
Recall that with obs2prior on, the prior of coefficient looks like N(H*X_obs, sigma * I), the H_zero_mask
the mask for this coefficient should have the same shape as H, and H[H_zero_mask] will be set to zeros
and non-learnable during the training.
Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>num_items</code></td>
        <td><code>int</code></td>
        <td><p>number of items.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>pred_item</code></td>
        <td><code>bool</code></td>
        <td><p>there are two use cases of this model, suppose we have <code>user_index[i]</code> and <code>item_index[i]</code>
for the i-th observation in the dataset.
Case 1: which item among all items user <code>user_index[i]</code> is going to purchase, the prediction label
    is therefore <code>item_index[i]</code>. Equivalently, we can ask what's the likelihood for user <code>user_index[i]</code>
    to purchase <code>item_index[i]</code>.
Case 2: what rating would user <code>user_index[i]</code> assign to item <code>item_index[i]</code>? In this case, the dataset
    object needs to contain a separate label.
    NOTE: for now, we only support binary labels.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>default_prior_mean</code></td>
        <td><code>float</code></td>
        <td><p>the default prior mean for coefficients,</p></td>
        <td><code>0.0</code></td>
      </tr>
      <tr>
        <td><code>prior_mean</code></td>
        <td><code>Union[float, Dict[str, float]]</code></td>
        <td><p>the mean of prior
distribution for coefficients. If a float is provided, all prior
mean will be diagonal matrix with the provided value.  If a
dictionary is provided, keys of prior_mean should be coefficient
names, and the mean of prior of coef_name would the provided
value Defaults to 0.0, which means all prior means are
initialized to 0.0</p></td>
        <td><code>0.0</code></td>
      </tr>
      <tr>
        <td><code>prior_variance</code></td>
        <td><code>Union[float, Dict[str, float]]</code></td>
        <td><p>the variance of prior distribution for
coefficients. If a float is provided, all priors will be diagonal matrix with
prior_variance along the diagonal. If a dictionary is provided, keys of prior_variance
should be coefficient names, and the variance of prior of coef_name would be a diagonal
matrix with prior_variance[coef_name] along the diagonal.
Defaults to 1.0, which means all prior have identity matrix as the covariance matrix.</p></td>
        <td><code>1.0</code></td>
      </tr>
      <tr>
        <td><code>num_users</code></td>
        <td><code>int</code></td>
        <td><p>number of users, required only if coefficient or observable
depending on user is in utility. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>num_sessions</code></td>
        <td><code>int</code></td>
        <td><p>number of sessions, required only if coefficient or
observable depending on session is in utility. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>trace_log_q</code></td>
        <td><code>bool</code></td>
        <td><p>whether to trace the derivative of variational likelihood logQ
with respect to variational parameters in the ELBO while conducting gradient update.
Defaults to False.</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>category_to_item</code></td>
        <td><code>Dict[str, List[int]]</code></td>
        <td><p>a dictionary with category id or name
as keys, and category_to_item[C] contains the list of item ids belonging to category C.
If None is provided, all items are assumed to be in the same category.
Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>num_{user,</code></td>
        <td><code>item, session, price, taste}_obs (int</code></td>
        <td><p>number of observables of
each type of features, only required if observable enters prior.
NOTE: currently we only allow coefficient to depend on either user or item, thus only
user and item observables can enter the prior of coefficient. Hence session, price,
and taste observables are never required, we include it here for completeness.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>bemb/model/bemb.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>             <span class="n">utility_formula</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>             <span class="n">obs2prior_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">bool</span><span class="p">],</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>             <span class="n">coef_dim_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>             <span class="n">num_items</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>             <span class="n">pred_item</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>             <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>             <span class="n">H_zero_mask_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">BoolTensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>             <span class="n">prior_mean</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>             <span class="n">default_prior_mean</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>             <span class="n">prior_variance</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>             <span class="n">num_users</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>             <span class="n">num_sessions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>             <span class="n">trace_log_q</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>             <span class="n">category_to_item</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>             <span class="c1"># number of observables.</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>             <span class="n">num_user_obs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>             <span class="n">num_item_obs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>             <span class="n">num_session_obs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>             <span class="n">num_price_obs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>             <span class="n">num_taste_obs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>             <span class="c1"># additional modules.</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>             <span class="n">additional_modules</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>             <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a>    <span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a><span class="sd">        utility_formula (str): a string representing the utility function U[user, item, session].</span>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a><span class="sd">            See documentation for more details in the documentation for the format of formula.</span>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a><span class="sd">            Examples:</span>
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a><span class="sd">                lambda_item</span>
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a><span class="sd">                lambda_item + theta_user * alpha_item + zeta_user * item_obs</span>
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a><span class="sd">                lambda_item + theta_user * alpha_item + gamma_user * beta_item * price_obs</span>
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a><span class="sd">            See the doc-string of parse_utility for an example.</span>
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a>
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a><span class="sd">        obs2prior_dict (Dict[str, bool]): a dictionary maps coefficient name (e.g., &#39;lambda_item&#39;)</span>
<a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a><span class="sd">            to a boolean indicating if observable (e.g., item_obs) enters the prior of the coefficient.</span>
<a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a>
<a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a><span class="sd">        coef_dim_dict (Dict[str, int]): a dictionary maps coefficient name (e.g., &#39;lambda_item&#39;)</span>
<a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a><span class="sd">            to an integer indicating the dimension of coefficient.</span>
<a id="__codelineno-0-40" name="__codelineno-0-40" href="#__codelineno-0-40"></a><span class="sd">            For standalone coefficients like U = lambda_item, the dim should be 1.</span>
<a id="__codelineno-0-41" name="__codelineno-0-41" href="#__codelineno-0-41"></a><span class="sd">            For factorized coefficients like U = theta_user * alpha_item, the dim should be the</span>
<a id="__codelineno-0-42" name="__codelineno-0-42" href="#__codelineno-0-42"></a><span class="sd">                latent dimension of theta and alpha.</span>
<a id="__codelineno-0-43" name="__codelineno-0-43" href="#__codelineno-0-43"></a><span class="sd">            For coefficients multiplied with observables like U = zeta_user * item_obs, the dim</span>
<a id="__codelineno-0-44" name="__codelineno-0-44" href="#__codelineno-0-44"></a><span class="sd">                should be the number of observables in item_obs.</span>
<a id="__codelineno-0-45" name="__codelineno-0-45" href="#__codelineno-0-45"></a><span class="sd">            For factorized coefficient multiplied with observables like U = gamma_user * beta_item * price_obs,</span>
<a id="__codelineno-0-46" name="__codelineno-0-46" href="#__codelineno-0-46"></a><span class="sd">                the dim should be the latent dim multiplied by number of observables in price_obs.</span>
<a id="__codelineno-0-47" name="__codelineno-0-47" href="#__codelineno-0-47"></a>
<a id="__codelineno-0-48" name="__codelineno-0-48" href="#__codelineno-0-48"></a><span class="sd">        H_zero_mask_dict (Dict[str, torch.BoolTensor]): A dictionary maps coefficient names to a boolean tensor,</span>
<a id="__codelineno-0-49" name="__codelineno-0-49" href="#__codelineno-0-49"></a><span class="sd">            you should only specify the H_zero_mask for coefficients with obs2prior turned on.</span>
<a id="__codelineno-0-50" name="__codelineno-0-50" href="#__codelineno-0-50"></a><span class="sd">            Recall that with obs2prior on, the prior of coefficient looks like N(H*X_obs, sigma * I), the H_zero_mask</span>
<a id="__codelineno-0-51" name="__codelineno-0-51" href="#__codelineno-0-51"></a><span class="sd">            the mask for this coefficient should have the same shape as H, and H[H_zero_mask] will be set to zeros</span>
<a id="__codelineno-0-52" name="__codelineno-0-52" href="#__codelineno-0-52"></a><span class="sd">            and non-learnable during the training.</span>
<a id="__codelineno-0-53" name="__codelineno-0-53" href="#__codelineno-0-53"></a><span class="sd">            Defaults to None.</span>
<a id="__codelineno-0-54" name="__codelineno-0-54" href="#__codelineno-0-54"></a>
<a id="__codelineno-0-55" name="__codelineno-0-55" href="#__codelineno-0-55"></a><span class="sd">        num_items (int): number of items.</span>
<a id="__codelineno-0-56" name="__codelineno-0-56" href="#__codelineno-0-56"></a>
<a id="__codelineno-0-57" name="__codelineno-0-57" href="#__codelineno-0-57"></a><span class="sd">        pred_item (bool): there are two use cases of this model, suppose we have `user_index[i]` and `item_index[i]`</span>
<a id="__codelineno-0-58" name="__codelineno-0-58" href="#__codelineno-0-58"></a><span class="sd">            for the i-th observation in the dataset.</span>
<a id="__codelineno-0-59" name="__codelineno-0-59" href="#__codelineno-0-59"></a><span class="sd">            Case 1: which item among all items user `user_index[i]` is going to purchase, the prediction label</span>
<a id="__codelineno-0-60" name="__codelineno-0-60" href="#__codelineno-0-60"></a><span class="sd">                is therefore `item_index[i]`. Equivalently, we can ask what&#39;s the likelihood for user `user_index[i]`</span>
<a id="__codelineno-0-61" name="__codelineno-0-61" href="#__codelineno-0-61"></a><span class="sd">                to purchase `item_index[i]`.</span>
<a id="__codelineno-0-62" name="__codelineno-0-62" href="#__codelineno-0-62"></a><span class="sd">            Case 2: what rating would user `user_index[i]` assign to item `item_index[i]`? In this case, the dataset</span>
<a id="__codelineno-0-63" name="__codelineno-0-63" href="#__codelineno-0-63"></a><span class="sd">                object needs to contain a separate label.</span>
<a id="__codelineno-0-64" name="__codelineno-0-64" href="#__codelineno-0-64"></a><span class="sd">                NOTE: for now, we only support binary labels.</span>
<a id="__codelineno-0-65" name="__codelineno-0-65" href="#__codelineno-0-65"></a>
<a id="__codelineno-0-66" name="__codelineno-0-66" href="#__codelineno-0-66"></a><span class="sd">        default_prior_mean (float): the default prior mean for coefficients,</span>
<a id="__codelineno-0-67" name="__codelineno-0-67" href="#__codelineno-0-67"></a><span class="sd">        if it is not specified in the prior_mean; defaults to 0.0.</span>
<a id="__codelineno-0-68" name="__codelineno-0-68" href="#__codelineno-0-68"></a>
<a id="__codelineno-0-69" name="__codelineno-0-69" href="#__codelineno-0-69"></a><span class="sd">        prior_mean (Union[float, Dict[str, float]]): the mean of prior</span>
<a id="__codelineno-0-70" name="__codelineno-0-70" href="#__codelineno-0-70"></a><span class="sd">            distribution for coefficients. If a float is provided, all prior</span>
<a id="__codelineno-0-71" name="__codelineno-0-71" href="#__codelineno-0-71"></a><span class="sd">            mean will be diagonal matrix with the provided value.  If a</span>
<a id="__codelineno-0-72" name="__codelineno-0-72" href="#__codelineno-0-72"></a><span class="sd">            dictionary is provided, keys of prior_mean should be coefficient</span>
<a id="__codelineno-0-73" name="__codelineno-0-73" href="#__codelineno-0-73"></a><span class="sd">            names, and the mean of prior of coef_name would the provided</span>
<a id="__codelineno-0-74" name="__codelineno-0-74" href="#__codelineno-0-74"></a><span class="sd">            value Defaults to 0.0, which means all prior means are</span>
<a id="__codelineno-0-75" name="__codelineno-0-75" href="#__codelineno-0-75"></a><span class="sd">            initialized to 0.0</span>
<a id="__codelineno-0-76" name="__codelineno-0-76" href="#__codelineno-0-76"></a>
<a id="__codelineno-0-77" name="__codelineno-0-77" href="#__codelineno-0-77"></a><span class="sd">        prior_variance (Union[float, Dict[str, float]]): the variance of prior distribution for</span>
<a id="__codelineno-0-78" name="__codelineno-0-78" href="#__codelineno-0-78"></a><span class="sd">            coefficients. If a float is provided, all priors will be diagonal matrix with</span>
<a id="__codelineno-0-79" name="__codelineno-0-79" href="#__codelineno-0-79"></a><span class="sd">            prior_variance along the diagonal. If a dictionary is provided, keys of prior_variance</span>
<a id="__codelineno-0-80" name="__codelineno-0-80" href="#__codelineno-0-80"></a><span class="sd">            should be coefficient names, and the variance of prior of coef_name would be a diagonal</span>
<a id="__codelineno-0-81" name="__codelineno-0-81" href="#__codelineno-0-81"></a><span class="sd">            matrix with prior_variance[coef_name] along the diagonal.</span>
<a id="__codelineno-0-82" name="__codelineno-0-82" href="#__codelineno-0-82"></a><span class="sd">            Defaults to 1.0, which means all prior have identity matrix as the covariance matrix.</span>
<a id="__codelineno-0-83" name="__codelineno-0-83" href="#__codelineno-0-83"></a>
<a id="__codelineno-0-84" name="__codelineno-0-84" href="#__codelineno-0-84"></a><span class="sd">        num_users (int, optional): number of users, required only if coefficient or observable</span>
<a id="__codelineno-0-85" name="__codelineno-0-85" href="#__codelineno-0-85"></a><span class="sd">            depending on user is in utility. Defaults to None.</span>
<a id="__codelineno-0-86" name="__codelineno-0-86" href="#__codelineno-0-86"></a><span class="sd">        num_sessions (int, optional): number of sessions, required only if coefficient or</span>
<a id="__codelineno-0-87" name="__codelineno-0-87" href="#__codelineno-0-87"></a><span class="sd">            observable depending on session is in utility. Defaults to None.</span>
<a id="__codelineno-0-88" name="__codelineno-0-88" href="#__codelineno-0-88"></a>
<a id="__codelineno-0-89" name="__codelineno-0-89" href="#__codelineno-0-89"></a><span class="sd">        trace_log_q (bool, optional): whether to trace the derivative of variational likelihood logQ</span>
<a id="__codelineno-0-90" name="__codelineno-0-90" href="#__codelineno-0-90"></a><span class="sd">            with respect to variational parameters in the ELBO while conducting gradient update.</span>
<a id="__codelineno-0-91" name="__codelineno-0-91" href="#__codelineno-0-91"></a><span class="sd">            Defaults to False.</span>
<a id="__codelineno-0-92" name="__codelineno-0-92" href="#__codelineno-0-92"></a>
<a id="__codelineno-0-93" name="__codelineno-0-93" href="#__codelineno-0-93"></a><span class="sd">        category_to_item (Dict[str, List[int]], optional): a dictionary with category id or name</span>
<a id="__codelineno-0-94" name="__codelineno-0-94" href="#__codelineno-0-94"></a><span class="sd">            as keys, and category_to_item[C] contains the list of item ids belonging to category C.</span>
<a id="__codelineno-0-95" name="__codelineno-0-95" href="#__codelineno-0-95"></a><span class="sd">            If None is provided, all items are assumed to be in the same category.</span>
<a id="__codelineno-0-96" name="__codelineno-0-96" href="#__codelineno-0-96"></a><span class="sd">            Defaults to None.</span>
<a id="__codelineno-0-97" name="__codelineno-0-97" href="#__codelineno-0-97"></a>
<a id="__codelineno-0-98" name="__codelineno-0-98" href="#__codelineno-0-98"></a><span class="sd">        num_{user, item, session, price, taste}_obs (int, optional): number of observables of</span>
<a id="__codelineno-0-99" name="__codelineno-0-99" href="#__codelineno-0-99"></a><span class="sd">            each type of features, only required if observable enters prior.</span>
<a id="__codelineno-0-100" name="__codelineno-0-100" href="#__codelineno-0-100"></a><span class="sd">            NOTE: currently we only allow coefficient to depend on either user or item, thus only</span>
<a id="__codelineno-0-101" name="__codelineno-0-101" href="#__codelineno-0-101"></a><span class="sd">            user and item observables can enter the prior of coefficient. Hence session, price,</span>
<a id="__codelineno-0-102" name="__codelineno-0-102" href="#__codelineno-0-102"></a><span class="sd">            and taste observables are never required, we include it here for completeness.</span>
<a id="__codelineno-0-103" name="__codelineno-0-103" href="#__codelineno-0-103"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-104" name="__codelineno-0-104" href="#__codelineno-0-104"></a>    <span class="nb">super</span><span class="p">(</span><span class="n">BEMBFlex</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-105" name="__codelineno-0-105" href="#__codelineno-0-105"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">utility_formula</span> <span class="o">=</span> <span class="n">utility_formula</span>
<a id="__codelineno-0-106" name="__codelineno-0-106" href="#__codelineno-0-106"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">obs2prior_dict</span> <span class="o">=</span> <span class="n">obs2prior_dict</span>
<a id="__codelineno-0-107" name="__codelineno-0-107" href="#__codelineno-0-107"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">coef_dim_dict</span> <span class="o">=</span> <span class="n">coef_dim_dict</span>
<a id="__codelineno-0-108" name="__codelineno-0-108" href="#__codelineno-0-108"></a>    <span class="k">if</span> <span class="n">H_zero_mask_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-109" name="__codelineno-0-109" href="#__codelineno-0-109"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">H_zero_mask_dict</span> <span class="o">=</span> <span class="n">H_zero_mask_dict</span>
<a id="__codelineno-0-110" name="__codelineno-0-110" href="#__codelineno-0-110"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-111" name="__codelineno-0-111" href="#__codelineno-0-111"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">H_zero_mask_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<a id="__codelineno-0-112" name="__codelineno-0-112" href="#__codelineno-0-112"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">prior_variance</span> <span class="o">=</span> <span class="n">prior_variance</span>
<a id="__codelineno-0-113" name="__codelineno-0-113" href="#__codelineno-0-113"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">default_prior_mean</span> <span class="o">=</span> <span class="n">default_prior_mean</span>
<a id="__codelineno-0-114" name="__codelineno-0-114" href="#__codelineno-0-114"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">prior_mean</span> <span class="o">=</span> <span class="n">prior_mean</span>
<a id="__codelineno-0-115" name="__codelineno-0-115" href="#__codelineno-0-115"></a>
<a id="__codelineno-0-116" name="__codelineno-0-116" href="#__codelineno-0-116"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">pred_item</span> <span class="o">=</span> <span class="n">pred_item</span>
<a id="__codelineno-0-117" name="__codelineno-0-117" href="#__codelineno-0-117"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">pred_item</span><span class="p">:</span>
<a id="__codelineno-0-118" name="__codelineno-0-118" href="#__codelineno-0-118"></a>        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">num_classes</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> \
<a id="__codelineno-0-119" name="__codelineno-0-119" href="#__codelineno-0-119"></a>            <span class="sa">f</span><span class="s2">&quot;With pred_item being False, the num_classes should be a positive integer, received </span><span class="si">{</span><span class="n">num_classes</span><span class="si">}</span><span class="s2"> instead.&quot;</span>
<a id="__codelineno-0-120" name="__codelineno-0-120" href="#__codelineno-0-120"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">num_classes</span>
<a id="__codelineno-0-121" name="__codelineno-0-121" href="#__codelineno-0-121"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
<a id="__codelineno-0-122" name="__codelineno-0-122" href="#__codelineno-0-122"></a>            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;Multi-class classification is not supported yet.&#39;</span><span class="p">)</span>
<a id="__codelineno-0-123" name="__codelineno-0-123" href="#__codelineno-0-123"></a>        <span class="c1"># we don&#39;t set the num_classes attribute when pred_item == False to avoid calling it accidentally.</span>
<a id="__codelineno-0-124" name="__codelineno-0-124" href="#__codelineno-0-124"></a>
<a id="__codelineno-0-125" name="__codelineno-0-125" href="#__codelineno-0-125"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span> <span class="o">=</span> <span class="n">num_items</span>
<a id="__codelineno-0-126" name="__codelineno-0-126" href="#__codelineno-0-126"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">num_users</span> <span class="o">=</span> <span class="n">num_users</span>
<a id="__codelineno-0-127" name="__codelineno-0-127" href="#__codelineno-0-127"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">num_sessions</span> <span class="o">=</span> <span class="n">num_sessions</span>
<a id="__codelineno-0-128" name="__codelineno-0-128" href="#__codelineno-0-128"></a>
<a id="__codelineno-0-129" name="__codelineno-0-129" href="#__codelineno-0-129"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">trace_log_q</span> <span class="o">=</span> <span class="n">trace_log_q</span>
<a id="__codelineno-0-130" name="__codelineno-0-130" href="#__codelineno-0-130"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">category_to_item</span> <span class="o">=</span> <span class="n">category_to_item</span>
<a id="__codelineno-0-131" name="__codelineno-0-131" href="#__codelineno-0-131"></a>
<a id="__codelineno-0-132" name="__codelineno-0-132" href="#__codelineno-0-132"></a>    <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-133" name="__codelineno-0-133" href="#__codelineno-0-133"></a>    <span class="c1"># Category ID to Item ID mapping.</span>
<a id="__codelineno-0-134" name="__codelineno-0-134" href="#__codelineno-0-134"></a>    <span class="c1"># Category ID to Category Size mapping.</span>
<a id="__codelineno-0-135" name="__codelineno-0-135" href="#__codelineno-0-135"></a>    <span class="c1"># Item ID to Category ID mapping.</span>
<a id="__codelineno-0-136" name="__codelineno-0-136" href="#__codelineno-0-136"></a>    <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-137" name="__codelineno-0-137" href="#__codelineno-0-137"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">category_to_item</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-138" name="__codelineno-0-138" href="#__codelineno-0-138"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pred_item</span><span class="p">:</span>
<a id="__codelineno-0-139" name="__codelineno-0-139" href="#__codelineno-0-139"></a>            <span class="c1"># assign all items to the same category if predicting items.</span>
<a id="__codelineno-0-140" name="__codelineno-0-140" href="#__codelineno-0-140"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">category_to_item</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">))}</span>
<a id="__codelineno-0-141" name="__codelineno-0-141" href="#__codelineno-0-141"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-142" name="__codelineno-0-142" href="#__codelineno-0-142"></a>            <span class="c1"># otherwise, for the j-th observation in the dataset, the label[j]</span>
<a id="__codelineno-0-143" name="__codelineno-0-143" href="#__codelineno-0-143"></a>            <span class="c1"># only depends on user_index[j] and item_index[j], so we put each</span>
<a id="__codelineno-0-144" name="__codelineno-0-144" href="#__codelineno-0-144"></a>            <span class="c1"># item to its own category.</span>
<a id="__codelineno-0-145" name="__codelineno-0-145" href="#__codelineno-0-145"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">category_to_item</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">)}</span>
<a id="__codelineno-0-146" name="__codelineno-0-146" href="#__codelineno-0-146"></a>
<a id="__codelineno-0-147" name="__codelineno-0-147" href="#__codelineno-0-147"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">num_categories</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">category_to_item</span><span class="p">)</span>
<a id="__codelineno-0-148" name="__codelineno-0-148" href="#__codelineno-0-148"></a>
<a id="__codelineno-0-149" name="__codelineno-0-149" href="#__codelineno-0-149"></a>    <span class="n">max_category_size</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">category_to_item</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
<a id="__codelineno-0-150" name="__codelineno-0-150" href="#__codelineno-0-150"></a>    <span class="n">category_to_item_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
<a id="__codelineno-0-151" name="__codelineno-0-151" href="#__codelineno-0-151"></a>        <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_categories</span><span class="p">,</span> <span class="n">max_category_size</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-152" name="__codelineno-0-152" href="#__codelineno-0-152"></a>    <span class="n">category_to_size_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_categories</span><span class="p">)</span>
<a id="__codelineno-0-153" name="__codelineno-0-153" href="#__codelineno-0-153"></a>
<a id="__codelineno-0-154" name="__codelineno-0-154" href="#__codelineno-0-154"></a>    <span class="k">for</span> <span class="n">c</span><span class="p">,</span> <span class="n">item_in_c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">category_to_item</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<a id="__codelineno-0-155" name="__codelineno-0-155" href="#__codelineno-0-155"></a>        <span class="n">category_to_item_tensor</span><span class="p">[</span><span class="n">c</span><span class="p">,</span> <span class="p">:</span><span class="nb">len</span><span class="p">(</span>
<a id="__codelineno-0-156" name="__codelineno-0-156" href="#__codelineno-0-156"></a>            <span class="n">item_in_c</span><span class="p">)]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">item_in_c</span><span class="p">)</span>
<a id="__codelineno-0-157" name="__codelineno-0-157" href="#__codelineno-0-157"></a>        <span class="n">category_to_size_tensor</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">scalar_tensor</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">item_in_c</span><span class="p">))</span>
<a id="__codelineno-0-158" name="__codelineno-0-158" href="#__codelineno-0-158"></a>
<a id="__codelineno-0-159" name="__codelineno-0-159" href="#__codelineno-0-159"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;category_to_item_tensor&#39;</span><span class="p">,</span>
<a id="__codelineno-0-160" name="__codelineno-0-160" href="#__codelineno-0-160"></a>                         <span class="n">category_to_item_tensor</span><span class="o">.</span><span class="n">long</span><span class="p">())</span>
<a id="__codelineno-0-161" name="__codelineno-0-161" href="#__codelineno-0-161"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;category_to_size_tensor&#39;</span><span class="p">,</span>
<a id="__codelineno-0-162" name="__codelineno-0-162" href="#__codelineno-0-162"></a>                         <span class="n">category_to_size_tensor</span><span class="o">.</span><span class="n">long</span><span class="p">())</span>
<a id="__codelineno-0-163" name="__codelineno-0-163" href="#__codelineno-0-163"></a>
<a id="__codelineno-0-164" name="__codelineno-0-164" href="#__codelineno-0-164"></a>    <span class="n">item_to_category_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">)</span>
<a id="__codelineno-0-165" name="__codelineno-0-165" href="#__codelineno-0-165"></a>    <span class="k">for</span> <span class="n">c</span><span class="p">,</span> <span class="n">items_in_c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">category_to_item</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<a id="__codelineno-0-166" name="__codelineno-0-166" href="#__codelineno-0-166"></a>        <span class="n">item_to_category_tensor</span><span class="p">[</span><span class="n">items_in_c</span><span class="p">]</span> <span class="o">=</span> <span class="n">c</span>
<a id="__codelineno-0-167" name="__codelineno-0-167" href="#__codelineno-0-167"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;item_to_category_tensor&#39;</span><span class="p">,</span>
<a id="__codelineno-0-168" name="__codelineno-0-168" href="#__codelineno-0-168"></a>                         <span class="n">item_to_category_tensor</span><span class="o">.</span><span class="n">long</span><span class="p">())</span>
<a id="__codelineno-0-169" name="__codelineno-0-169" href="#__codelineno-0-169"></a>
<a id="__codelineno-0-170" name="__codelineno-0-170" href="#__codelineno-0-170"></a>    <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-171" name="__codelineno-0-171" href="#__codelineno-0-171"></a>    <span class="c1"># Create Bayesian Coefficient Objects</span>
<a id="__codelineno-0-172" name="__codelineno-0-172" href="#__codelineno-0-172"></a>    <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-173" name="__codelineno-0-173" href="#__codelineno-0-173"></a>    <span class="c1"># model configuration.</span>
<a id="__codelineno-0-174" name="__codelineno-0-174" href="#__codelineno-0-174"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">formula</span> <span class="o">=</span> <span class="n">parse_utility</span><span class="p">(</span><span class="n">utility_formula</span><span class="p">)</span>
<a id="__codelineno-0-175" name="__codelineno-0-175" href="#__codelineno-0-175"></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;BEMB: utility formula parsed:&#39;</span><span class="p">)</span>
<a id="__codelineno-0-176" name="__codelineno-0-176" href="#__codelineno-0-176"></a>    <span class="n">pprint</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">formula</span><span class="p">)</span>
<a id="__codelineno-0-177" name="__codelineno-0-177" href="#__codelineno-0-177"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">raw_formula</span> <span class="o">=</span> <span class="n">utility_formula</span>
<a id="__codelineno-0-178" name="__codelineno-0-178" href="#__codelineno-0-178"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">obs2prior_dict</span> <span class="o">=</span> <span class="n">obs2prior_dict</span>
<a id="__codelineno-0-179" name="__codelineno-0-179" href="#__codelineno-0-179"></a>
<a id="__codelineno-0-180" name="__codelineno-0-180" href="#__codelineno-0-180"></a>    <span class="c1"># dimension of each observable, this one is used only for obs2prior.</span>
<a id="__codelineno-0-181" name="__codelineno-0-181" href="#__codelineno-0-181"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">num_obs_dict</span> <span class="o">=</span> <span class="p">{</span>
<a id="__codelineno-0-182" name="__codelineno-0-182" href="#__codelineno-0-182"></a>        <span class="s1">&#39;user&#39;</span><span class="p">:</span> <span class="n">num_user_obs</span><span class="p">,</span>
<a id="__codelineno-0-183" name="__codelineno-0-183" href="#__codelineno-0-183"></a>        <span class="s1">&#39;item&#39;</span><span class="p">:</span> <span class="n">num_item_obs</span><span class="p">,</span>
<a id="__codelineno-0-184" name="__codelineno-0-184" href="#__codelineno-0-184"></a>        <span class="s1">&#39;category&#39;</span> <span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
<a id="__codelineno-0-185" name="__codelineno-0-185" href="#__codelineno-0-185"></a>        <span class="s1">&#39;session&#39;</span><span class="p">:</span> <span class="n">num_session_obs</span><span class="p">,</span>
<a id="__codelineno-0-186" name="__codelineno-0-186" href="#__codelineno-0-186"></a>        <span class="s1">&#39;price&#39;</span><span class="p">:</span> <span class="n">num_price_obs</span><span class="p">,</span>
<a id="__codelineno-0-187" name="__codelineno-0-187" href="#__codelineno-0-187"></a>        <span class="s1">&#39;taste&#39;</span><span class="p">:</span> <span class="n">num_taste_obs</span><span class="p">,</span>
<a id="__codelineno-0-188" name="__codelineno-0-188" href="#__codelineno-0-188"></a>        <span class="s1">&#39;constant&#39;</span><span class="p">:</span> <span class="mi">1</span>  <span class="c1"># not really used, for dummy variables.</span>
<a id="__codelineno-0-189" name="__codelineno-0-189" href="#__codelineno-0-189"></a>    <span class="p">}</span>
<a id="__codelineno-0-190" name="__codelineno-0-190" href="#__codelineno-0-190"></a>
<a id="__codelineno-0-191" name="__codelineno-0-191" href="#__codelineno-0-191"></a>    <span class="c1"># how many classes for the variational distribution.</span>
<a id="__codelineno-0-192" name="__codelineno-0-192" href="#__codelineno-0-192"></a>    <span class="c1"># for example, beta_item would be `num_items` 10-dimensional gaussian if latent dim = 10.</span>
<a id="__codelineno-0-193" name="__codelineno-0-193" href="#__codelineno-0-193"></a>    <span class="n">variation_to_num_classes</span> <span class="o">=</span> <span class="p">{</span>
<a id="__codelineno-0-194" name="__codelineno-0-194" href="#__codelineno-0-194"></a>        <span class="s1">&#39;user&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_users</span><span class="p">,</span>
<a id="__codelineno-0-195" name="__codelineno-0-195" href="#__codelineno-0-195"></a>        <span class="s1">&#39;item&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">,</span>
<a id="__codelineno-0-196" name="__codelineno-0-196" href="#__codelineno-0-196"></a>        <span class="s1">&#39;constant&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
<a id="__codelineno-0-197" name="__codelineno-0-197" href="#__codelineno-0-197"></a>        <span class="s1">&#39;category&#39;</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_categories</span><span class="p">,</span>
<a id="__codelineno-0-198" name="__codelineno-0-198" href="#__codelineno-0-198"></a>    <span class="p">}</span>
<a id="__codelineno-0-199" name="__codelineno-0-199" href="#__codelineno-0-199"></a>
<a id="__codelineno-0-200" name="__codelineno-0-200" href="#__codelineno-0-200"></a>    <span class="n">coef_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<a id="__codelineno-0-201" name="__codelineno-0-201" href="#__codelineno-0-201"></a>    <span class="k">for</span> <span class="n">additive_term</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">formula</span><span class="p">:</span>
<a id="__codelineno-0-202" name="__codelineno-0-202" href="#__codelineno-0-202"></a>        <span class="k">for</span> <span class="n">coef_name</span> <span class="ow">in</span> <span class="n">additive_term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">]:</span>
<a id="__codelineno-0-203" name="__codelineno-0-203" href="#__codelineno-0-203"></a>            <span class="n">variation</span> <span class="o">=</span> <span class="n">coef_name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<a id="__codelineno-0-204" name="__codelineno-0-204" href="#__codelineno-0-204"></a>            <span class="n">mean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_mean</span><span class="p">[</span><span class="n">coef_name</span><span class="p">]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span>
<a id="__codelineno-0-205" name="__codelineno-0-205" href="#__codelineno-0-205"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">prior_mean</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_prior_mean</span>
<a id="__codelineno-0-206" name="__codelineno-0-206" href="#__codelineno-0-206"></a>            <span class="n">s2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_variance</span><span class="p">[</span><span class="n">coef_name</span><span class="p">]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span>
<a id="__codelineno-0-207" name="__codelineno-0-207" href="#__codelineno-0-207"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">prior_variance</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_variance</span>
<a id="__codelineno-0-208" name="__codelineno-0-208" href="#__codelineno-0-208"></a>
<a id="__codelineno-0-209" name="__codelineno-0-209" href="#__codelineno-0-209"></a>            <span class="k">if</span> <span class="n">coef_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">H_zero_mask_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
<a id="__codelineno-0-210" name="__codelineno-0-210" href="#__codelineno-0-210"></a>                <span class="n">H_zero_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">H_zero_mask_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">]</span>
<a id="__codelineno-0-211" name="__codelineno-0-211" href="#__codelineno-0-211"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-212" name="__codelineno-0-212" href="#__codelineno-0-212"></a>                <span class="n">H_zero_mask</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-213" name="__codelineno-0-213" href="#__codelineno-0-213"></a>
<a id="__codelineno-0-214" name="__codelineno-0-214" href="#__codelineno-0-214"></a>            <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">obs2prior_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">])</span> <span class="ow">and</span> <span class="p">(</span><span class="n">H_zero_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>
<a id="__codelineno-0-215" name="__codelineno-0-215" href="#__codelineno-0-215"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;You specified H_zero_mask for </span><span class="si">{</span><span class="n">coef_name</span><span class="si">}</span><span class="s1">, but obs2prior is False for this coefficient.&#39;</span><span class="p">)</span>
<a id="__codelineno-0-216" name="__codelineno-0-216" href="#__codelineno-0-216"></a>
<a id="__codelineno-0-217" name="__codelineno-0-217" href="#__codelineno-0-217"></a>            <span class="n">coef_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">BayesianCoefficient</span><span class="p">(</span><span class="n">variation</span><span class="o">=</span><span class="n">variation</span><span class="p">,</span>
<a id="__codelineno-0-218" name="__codelineno-0-218" href="#__codelineno-0-218"></a>                                                       <span class="n">num_classes</span><span class="o">=</span><span class="n">variation_to_num_classes</span><span class="p">[</span><span class="n">variation</span><span class="p">],</span>
<a id="__codelineno-0-219" name="__codelineno-0-219" href="#__codelineno-0-219"></a>                                                       <span class="n">obs2prior</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">obs2prior_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">],</span>
<a id="__codelineno-0-220" name="__codelineno-0-220" href="#__codelineno-0-220"></a>                                                       <span class="n">num_obs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_obs_dict</span><span class="p">[</span><span class="n">variation</span><span class="p">],</span>
<a id="__codelineno-0-221" name="__codelineno-0-221" href="#__codelineno-0-221"></a>                                                       <span class="n">dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">coef_dim_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">],</span>
<a id="__codelineno-0-222" name="__codelineno-0-222" href="#__codelineno-0-222"></a>                                                       <span class="n">prior_mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span>
<a id="__codelineno-0-223" name="__codelineno-0-223" href="#__codelineno-0-223"></a>                                                       <span class="n">prior_variance</span><span class="o">=</span><span class="n">s2</span><span class="p">,</span>
<a id="__codelineno-0-224" name="__codelineno-0-224" href="#__codelineno-0-224"></a>                                                       <span class="n">H_zero_mask</span><span class="o">=</span><span class="n">H_zero_mask</span><span class="p">,</span>
<a id="__codelineno-0-225" name="__codelineno-0-225" href="#__codelineno-0-225"></a>                                                       <span class="n">is_H</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-0-226" name="__codelineno-0-226" href="#__codelineno-0-226"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">coef_dict</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleDict</span><span class="p">(</span><span class="n">coef_dict</span><span class="p">)</span>
<a id="__codelineno-0-227" name="__codelineno-0-227" href="#__codelineno-0-227"></a>
<a id="__codelineno-0-228" name="__codelineno-0-228" href="#__codelineno-0-228"></a>    <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-229" name="__codelineno-0-229" href="#__codelineno-0-229"></a>    <span class="c1"># Optional: register additional modules.</span>
<a id="__codelineno-0-230" name="__codelineno-0-230" href="#__codelineno-0-230"></a>    <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-231" name="__codelineno-0-231" href="#__codelineno-0-231"></a>    <span class="k">if</span> <span class="n">additional_modules</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-232" name="__codelineno-0-232" href="#__codelineno-0-232"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">additional_modules</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-233" name="__codelineno-0-233" href="#__codelineno-0-233"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-234" name="__codelineno-0-234" href="#__codelineno-0-234"></a>        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
<a id="__codelineno-0-235" name="__codelineno-0-235" href="#__codelineno-0-235"></a>            <span class="s1">&#39;Additional modules are temporarily disabled for further development.&#39;</span><span class="p">)</span>
<a id="__codelineno-0-236" name="__codelineno-0-236" href="#__codelineno-0-236"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">additional_modules</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">additional_modules</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>




  <div class="doc doc-object doc-method">



<h5 id="bemb.model.bemb.BEMBFlex.elbo" class="doc doc-heading">
<code class="highlight language-python"><span class="n">elbo</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">num_seeds</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>A combined method to computes the current ELBO given a batch, this method is used for training the model.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>batch</code></td>
        <td><code>ChoiceDataset</code></td>
        <td><p>a ChoiceDataset containing necessary information.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>num_seeds</code></td>
        <td><code>int</code></td>
        <td><p>the number of Monte Carlo samples from variational distributions
to evaluate the expectation in ELBO.
Defaults to 1.</p></td>
        <td><code>1</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>torch.Tensor</code></td>
      <td><p>a scalar tensor of the ELBO estimated from num_seeds Monte Carlo samples.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>bemb/model/bemb.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="nf">elbo</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">ChoiceDataset</span><span class="p">,</span> <span class="n">num_seeds</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="sd">&quot;&quot;&quot;A combined method to computes the current ELBO given a batch, this method is used for training the model.</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="sd">        batch (ChoiceDataset): a ChoiceDataset containing necessary information.</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="sd">        num_seeds (int, optional): the number of Monte Carlo samples from variational distributions</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="sd">            to evaluate the expectation in ELBO.</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="sd">            Defaults to 1.</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a><span class="sd">        torch.Tensor: a scalar tensor of the ELBO estimated from num_seeds Monte Carlo samples.</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>    <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>    <span class="c1"># 1. sample latent variables from their variational distributions.</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>    <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>    <span class="n">sample_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_coefficient_dictionary</span><span class="p">(</span><span class="n">num_seeds</span><span class="p">)</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>    <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>    <span class="c1"># 2. compute log p(latent) prior.</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>    <span class="c1"># (num_seeds,) --mean--&gt; scalar.</span>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>    <span class="n">elbo</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_prior</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">sample_dict</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>    <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>    <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a>    <span class="c1"># 3. compute the log likelihood log p(obs|latent).</span>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a>    <span class="c1"># sum over independent purchase decision for individual observations, mean over MC seeds.</span>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a>    <span class="c1"># the forward() function calls module.rsample(num_seeds) for module in self.additional_modules.</span>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a>    <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pred_item</span><span class="p">:</span>
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a>        <span class="c1"># the prediction target is item_index.</span>
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a>        <span class="n">elbo</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span>
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a>                             <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;log_prob&#39;</span><span class="p">,</span>
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a>                             <span class="n">return_scope</span><span class="o">=</span><span class="s1">&#39;item_index&#39;</span><span class="p">,</span>
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a>                             <span class="n">deterministic</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a>                             <span class="n">sample_dict</span><span class="o">=</span><span class="n">sample_dict</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># (num_seeds, len(batch)) --&gt; scalar.</span>
<a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a>        <span class="c1"># the prediction target is binary.</span>
<a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a>        <span class="c1"># TODO: update the prediction function.</span>
<a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a>        <span class="n">utility</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span>
<a id="__codelineno-0-40" name="__codelineno-0-40" href="#__codelineno-0-40"></a>                               <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;utility&#39;</span><span class="p">,</span>
<a id="__codelineno-0-41" name="__codelineno-0-41" href="#__codelineno-0-41"></a>                               <span class="n">return_scope</span><span class="o">=</span><span class="s1">&#39;item_index&#39;</span><span class="p">,</span>
<a id="__codelineno-0-42" name="__codelineno-0-42" href="#__codelineno-0-42"></a>                               <span class="n">deterministic</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-43" name="__codelineno-0-43" href="#__codelineno-0-43"></a>                               <span class="n">sample_dict</span><span class="o">=</span><span class="n">sample_dict</span><span class="p">)</span>  <span class="c1"># (num_seeds, len(batch))</span>
<a id="__codelineno-0-44" name="__codelineno-0-44" href="#__codelineno-0-44"></a>
<a id="__codelineno-0-45" name="__codelineno-0-45" href="#__codelineno-0-45"></a>        <span class="c1"># compute the log-likelihood for binary label.</span>
<a id="__codelineno-0-46" name="__codelineno-0-46" href="#__codelineno-0-46"></a>        <span class="c1"># (num_seeds, len(batch))</span>
<a id="__codelineno-0-47" name="__codelineno-0-47" href="#__codelineno-0-47"></a>        <span class="n">y_stacked</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">batch</span><span class="o">.</span><span class="n">label</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_seeds</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<a id="__codelineno-0-48" name="__codelineno-0-48" href="#__codelineno-0-48"></a>        <span class="k">assert</span> <span class="n">y_stacked</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">utility</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-49" name="__codelineno-0-49" href="#__codelineno-0-49"></a>        <span class="n">bce</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
<a id="__codelineno-0-50" name="__codelineno-0-50" href="#__codelineno-0-50"></a>        <span class="c1"># scalar.</span>
<a id="__codelineno-0-51" name="__codelineno-0-51" href="#__codelineno-0-51"></a>        <span class="n">ll</span> <span class="o">=</span> <span class="o">-</span> <span class="n">bce</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">utility</span><span class="p">),</span>
<a id="__codelineno-0-52" name="__codelineno-0-52" href="#__codelineno-0-52"></a>                   <span class="n">y_stacked</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-53" name="__codelineno-0-53" href="#__codelineno-0-53"></a>        <span class="n">elbo</span> <span class="o">+=</span> <span class="n">ll</span>
<a id="__codelineno-0-54" name="__codelineno-0-54" href="#__codelineno-0-54"></a>
<a id="__codelineno-0-55" name="__codelineno-0-55" href="#__codelineno-0-55"></a>    <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-56" name="__codelineno-0-56" href="#__codelineno-0-56"></a>    <span class="c1"># 4. optionally add log likelihood under variational distributions q(latent).</span>
<a id="__codelineno-0-57" name="__codelineno-0-57" href="#__codelineno-0-57"></a>    <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-58" name="__codelineno-0-58" href="#__codelineno-0-58"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trace_log_q</span><span class="p">:</span>
<a id="__codelineno-0-59" name="__codelineno-0-59" href="#__codelineno-0-59"></a>        <span class="n">elbo</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_variational</span><span class="p">(</span><span class="n">sample_dict</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-60" name="__codelineno-0-60" href="#__codelineno-0-60"></a>
<a id="__codelineno-0-61" name="__codelineno-0-61" href="#__codelineno-0-61"></a>    <span class="k">return</span> <span class="n">elbo</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="bemb.model.bemb.BEMBFlex.forward" class="doc doc-heading">
<code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">return_type</span><span class="p">,</span> <span class="n">return_scope</span><span class="p">,</span> <span class="n">deterministic</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sample_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_seeds</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>A combined method for inference with the model.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>batch</code></td>
        <td><code>ChoiceDataset</code></td>
        <td><p>batch data containing choice information.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>return_type</code></td>
        <td><code>str</code></td>
        <td><p>either 'log_prob' or 'utility'.
'log_prob': return the log-probability (by within-category log-softmax) for items
'utility': return the utility value of items.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>return_scope</code></td>
        <td><code>str</code></td>
        <td><p>either 'item_index' or 'all_items'.
'item_index': for each observation i, return log-prob/utility for the chosen item batch.item_index[i] only.
'all_items': for each observation i, return log-prob/utility for all items.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>deterministic</code></td>
        <td><code>bool</code></td>
        <td><p>True: expectations of parameter variational distributions are used for inference.
False: the user needs to supply a dictionary of sampled parameters for inference.
Defaults to True.</p></td>
        <td><code>True</code></td>
      </tr>
      <tr>
        <td><code>sample_dict</code></td>
        <td><code>Optional[Dict[str, torch.Tensor]]</code></td>
        <td><p>sampled parameters for inference task.
This is not needed when <code>deterministic</code> is True.
When <code>deterministic</code> is False, the user can supply a <code>sample_dict</code>. If <code>sample_dict</code> is not provided,
this method will create <code>num_seeds</code> samples.
Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>num_seeds</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>the number of random samples of parameters to construct. This is only required
if <code>deterministic</code> is False (i.e., stochastic mode) and <code>sample_dict</code> is not provided.
Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>torch.Tensor</code></td>
      <td><p>a tensor of log-probabilities or utilities, depending on <code>return_type</code>.
    The shape of the returned tensor depends on <code>return_scope</code> and <code>deterministic</code>.
    -------------------------------------------------------------------------
    | <code>return_scope</code> | <code>deterministic</code> |         Output shape               |
    -------------------------------------------------------------------------
    |   'item_index` |      True       | (len(batch),)                      |
    -------------------------------------------------------------------------
    |   'all_items'  |      True       | (len(batch), num_items)            |
    -------------------------------------------------------------------------
    |   'item_index' |      False      | (num_seeds, len(batch))            |
    -------------------------------------------------------------------------
    |   'all_items'  |      False      | (num_seeds, len(batch), num_items) |
    -------------------------------------------------------------------------</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>bemb/model/bemb.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">ChoiceDataset</span><span class="p">,</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>            <span class="n">return_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>            <span class="n">return_scope</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>            <span class="n">deterministic</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>            <span class="n">sample_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>            <span class="n">num_seeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>            <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="sd">&quot;&quot;&quot;A combined method for inference with the model.</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a><span class="sd">        batch (ChoiceDataset): batch data containing choice information.</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a><span class="sd">        return_type (str): either &#39;log_prob&#39; or &#39;utility&#39;.</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a><span class="sd">            &#39;log_prob&#39;: return the log-probability (by within-category log-softmax) for items</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a><span class="sd">            &#39;utility&#39;: return the utility value of items.</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a><span class="sd">        return_scope (str): either &#39;item_index&#39; or &#39;all_items&#39;.</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a><span class="sd">            &#39;item_index&#39;: for each observation i, return log-prob/utility for the chosen item batch.item_index[i] only.</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a><span class="sd">            &#39;all_items&#39;: for each observation i, return log-prob/utility for all items.</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a><span class="sd">        deterministic (bool, optional):</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a><span class="sd">            True: expectations of parameter variational distributions are used for inference.</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a><span class="sd">            False: the user needs to supply a dictionary of sampled parameters for inference.</span>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a><span class="sd">            Defaults to True.</span>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a><span class="sd">        sample_dict (Optional[Dict[str, torch.Tensor]], optional): sampled parameters for inference task.</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a><span class="sd">            This is not needed when `deterministic` is True.</span>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a><span class="sd">            When `deterministic` is False, the user can supply a `sample_dict`. If `sample_dict` is not provided,</span>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a><span class="sd">            this method will create `num_seeds` samples.</span>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a><span class="sd">            Defaults to None.</span>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a><span class="sd">        num_seeds (Optional[int]): the number of random samples of parameters to construct. This is only required</span>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a><span class="sd">            if `deterministic` is False (i.e., stochastic mode) and `sample_dict` is not provided.</span>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a><span class="sd">            Defaults to None.</span>
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a><span class="sd">        torch.Tensor: a tensor of log-probabilities or utilities, depending on `return_type`.</span>
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a><span class="sd">            The shape of the returned tensor depends on `return_scope` and `deterministic`.</span>
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a><span class="sd">            -------------------------------------------------------------------------</span>
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a><span class="sd">            | `return_scope` | `deterministic` |         Output shape               |</span>
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a><span class="sd">            -------------------------------------------------------------------------</span>
<a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a><span class="sd">            |   &#39;item_index` |      True       | (len(batch),)                      |</span>
<a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a><span class="sd">            -------------------------------------------------------------------------</span>
<a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a><span class="sd">            |   &#39;all_items&#39;  |      True       | (len(batch), num_items)            |</span>
<a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a><span class="sd">            -------------------------------------------------------------------------</span>
<a id="__codelineno-0-40" name="__codelineno-0-40" href="#__codelineno-0-40"></a><span class="sd">            |   &#39;item_index&#39; |      False      | (num_seeds, len(batch))            |</span>
<a id="__codelineno-0-41" name="__codelineno-0-41" href="#__codelineno-0-41"></a><span class="sd">            -------------------------------------------------------------------------</span>
<a id="__codelineno-0-42" name="__codelineno-0-42" href="#__codelineno-0-42"></a><span class="sd">            |   &#39;all_items&#39;  |      False      | (num_seeds, len(batch), num_items) |</span>
<a id="__codelineno-0-43" name="__codelineno-0-43" href="#__codelineno-0-43"></a><span class="sd">            -------------------------------------------------------------------------</span>
<a id="__codelineno-0-44" name="__codelineno-0-44" href="#__codelineno-0-44"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-45" name="__codelineno-0-45" href="#__codelineno-0-45"></a>    <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-46" name="__codelineno-0-46" href="#__codelineno-0-46"></a>    <span class="c1"># check arguments.</span>
<a id="__codelineno-0-47" name="__codelineno-0-47" href="#__codelineno-0-47"></a>    <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-48" name="__codelineno-0-48" href="#__codelineno-0-48"></a>    <span class="k">assert</span> <span class="n">return_type</span> <span class="ow">in</span> <span class="p">[</span>
<a id="__codelineno-0-49" name="__codelineno-0-49" href="#__codelineno-0-49"></a>        <span class="s1">&#39;log_prob&#39;</span><span class="p">,</span> <span class="s1">&#39;utility&#39;</span><span class="p">],</span> <span class="s2">&quot;return_type must be either &#39;log_prob&#39; or &#39;utility&#39;.&quot;</span>
<a id="__codelineno-0-50" name="__codelineno-0-50" href="#__codelineno-0-50"></a>    <span class="k">assert</span> <span class="n">return_scope</span> <span class="ow">in</span> <span class="p">[</span>
<a id="__codelineno-0-51" name="__codelineno-0-51" href="#__codelineno-0-51"></a>        <span class="s1">&#39;item_index&#39;</span><span class="p">,</span> <span class="s1">&#39;all_items&#39;</span><span class="p">],</span> <span class="s2">&quot;return_scope must be either &#39;item_index&#39; or &#39;all_items&#39;.&quot;</span>
<a id="__codelineno-0-52" name="__codelineno-0-52" href="#__codelineno-0-52"></a>    <span class="k">assert</span> <span class="n">deterministic</span> <span class="ow">in</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]</span>
<a id="__codelineno-0-53" name="__codelineno-0-53" href="#__codelineno-0-53"></a>    <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="n">deterministic</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">sample_dict</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">):</span>
<a id="__codelineno-0-54" name="__codelineno-0-54" href="#__codelineno-0-54"></a>        <span class="k">assert</span> <span class="n">num_seeds</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;A positive interger `num_seeds` is required if `deterministic` is False and no `sample_dict` is provided.&quot;</span>
<a id="__codelineno-0-55" name="__codelineno-0-55" href="#__codelineno-0-55"></a>
<a id="__codelineno-0-56" name="__codelineno-0-56" href="#__codelineno-0-56"></a>    <span class="c1"># when pred_item is true, the model is predicting which item is bought (specified by item_index).</span>
<a id="__codelineno-0-57" name="__codelineno-0-57" href="#__codelineno-0-57"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pred_item</span><span class="p">:</span>
<a id="__codelineno-0-58" name="__codelineno-0-58" href="#__codelineno-0-58"></a>        <span class="n">batch</span><span class="o">.</span><span class="n">label</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">item_index</span>
<a id="__codelineno-0-59" name="__codelineno-0-59" href="#__codelineno-0-59"></a>
<a id="__codelineno-0-60" name="__codelineno-0-60" href="#__codelineno-0-60"></a>    <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-61" name="__codelineno-0-61" href="#__codelineno-0-61"></a>    <span class="c1"># get sample_dict ready.</span>
<a id="__codelineno-0-62" name="__codelineno-0-62" href="#__codelineno-0-62"></a>    <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-63" name="__codelineno-0-63" href="#__codelineno-0-63"></a>    <span class="k">if</span> <span class="n">deterministic</span><span class="p">:</span>
<a id="__codelineno-0-64" name="__codelineno-0-64" href="#__codelineno-0-64"></a>        <span class="n">num_seeds</span> <span class="o">=</span> <span class="mi">1</span>
<a id="__codelineno-0-65" name="__codelineno-0-65" href="#__codelineno-0-65"></a>        <span class="c1"># Use the means of variational distributions as the sole deterministic MC sample.</span>
<a id="__codelineno-0-66" name="__codelineno-0-66" href="#__codelineno-0-66"></a>        <span class="c1"># NOTE: here we don&#39;t need to sample the obs2prior weight H since we only compute the log-likelihood.</span>
<a id="__codelineno-0-67" name="__codelineno-0-67" href="#__codelineno-0-67"></a>        <span class="c1"># TODO: is this correct?</span>
<a id="__codelineno-0-68" name="__codelineno-0-68" href="#__codelineno-0-68"></a>        <span class="n">sample_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<a id="__codelineno-0-69" name="__codelineno-0-69" href="#__codelineno-0-69"></a>        <span class="k">for</span> <span class="n">coef_name</span><span class="p">,</span> <span class="n">coef</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<a id="__codelineno-0-70" name="__codelineno-0-70" href="#__codelineno-0-70"></a>            <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">coef</span><span class="o">.</span><span class="n">variational_distribution</span><span class="o">.</span><span class="n">mean</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span>
<a id="__codelineno-0-71" name="__codelineno-0-71" href="#__codelineno-0-71"></a>                <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># (1, num_*, dim)</span>
<a id="__codelineno-0-72" name="__codelineno-0-72" href="#__codelineno-0-72"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-73" name="__codelineno-0-73" href="#__codelineno-0-73"></a>        <span class="k">if</span> <span class="n">sample_dict</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-74" name="__codelineno-0-74" href="#__codelineno-0-74"></a>            <span class="c1"># sample stochastic parameters.</span>
<a id="__codelineno-0-75" name="__codelineno-0-75" href="#__codelineno-0-75"></a>            <span class="n">sample_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_coefficient_dictionary</span><span class="p">(</span><span class="n">num_seeds</span><span class="p">)</span>
<a id="__codelineno-0-76" name="__codelineno-0-76" href="#__codelineno-0-76"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-77" name="__codelineno-0-77" href="#__codelineno-0-77"></a>            <span class="c1"># use the provided sample_dict.</span>
<a id="__codelineno-0-78" name="__codelineno-0-78" href="#__codelineno-0-78"></a>            <span class="n">num_seeds</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">sample_dict</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-79" name="__codelineno-0-79" href="#__codelineno-0-79"></a>
<a id="__codelineno-0-80" name="__codelineno-0-80" href="#__codelineno-0-80"></a>    <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-81" name="__codelineno-0-81" href="#__codelineno-0-81"></a>    <span class="c1"># call the sampling method of additional modules.</span>
<a id="__codelineno-0-82" name="__codelineno-0-82" href="#__codelineno-0-82"></a>    <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-83" name="__codelineno-0-83" href="#__codelineno-0-83"></a>    <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">additional_modules</span><span class="p">:</span>
<a id="__codelineno-0-84" name="__codelineno-0-84" href="#__codelineno-0-84"></a>        <span class="c1"># deterministic sample.</span>
<a id="__codelineno-0-85" name="__codelineno-0-85" href="#__codelineno-0-85"></a>        <span class="k">if</span> <span class="n">deterministic</span><span class="p">:</span>
<a id="__codelineno-0-86" name="__codelineno-0-86" href="#__codelineno-0-86"></a>            <span class="n">module</span><span class="o">.</span><span class="n">dsample</span><span class="p">()</span>
<a id="__codelineno-0-87" name="__codelineno-0-87" href="#__codelineno-0-87"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-88" name="__codelineno-0-88" href="#__codelineno-0-88"></a>            <span class="n">module</span><span class="o">.</span><span class="n">rsample</span><span class="p">(</span><span class="n">num_seeds</span><span class="o">=</span><span class="n">num_seeds</span><span class="p">)</span>
<a id="__codelineno-0-89" name="__codelineno-0-89" href="#__codelineno-0-89"></a>
<a id="__codelineno-0-90" name="__codelineno-0-90" href="#__codelineno-0-90"></a>    <span class="c1"># if utility is requested, don&#39;t run log-softmax, simply return logit.</span>
<a id="__codelineno-0-91" name="__codelineno-0-91" href="#__codelineno-0-91"></a>    <span class="n">return_logit</span> <span class="o">=</span> <span class="p">(</span><span class="n">return_type</span> <span class="o">==</span> <span class="s1">&#39;utility&#39;</span><span class="p">)</span>
<a id="__codelineno-0-92" name="__codelineno-0-92" href="#__codelineno-0-92"></a>    <span class="k">if</span> <span class="n">return_scope</span> <span class="o">==</span> <span class="s1">&#39;all_items&#39;</span><span class="p">:</span>
<a id="__codelineno-0-93" name="__codelineno-0-93" href="#__codelineno-0-93"></a>        <span class="c1"># (num_seeds, len(batch), num_items)</span>
<a id="__codelineno-0-94" name="__codelineno-0-94" href="#__codelineno-0-94"></a>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_likelihood_all_items</span><span class="p">(</span>
<a id="__codelineno-0-95" name="__codelineno-0-95" href="#__codelineno-0-95"></a>            <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span> <span class="n">sample_dict</span><span class="o">=</span><span class="n">sample_dict</span><span class="p">,</span> <span class="n">return_logit</span><span class="o">=</span><span class="n">return_logit</span><span class="p">)</span>
<a id="__codelineno-0-96" name="__codelineno-0-96" href="#__codelineno-0-96"></a>    <span class="k">elif</span> <span class="n">return_scope</span> <span class="o">==</span> <span class="s1">&#39;item_index&#39;</span><span class="p">:</span>
<a id="__codelineno-0-97" name="__codelineno-0-97" href="#__codelineno-0-97"></a>        <span class="c1"># (num_seeds, len(batch))</span>
<a id="__codelineno-0-98" name="__codelineno-0-98" href="#__codelineno-0-98"></a>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_likelihood_item_index</span><span class="p">(</span>
<a id="__codelineno-0-99" name="__codelineno-0-99" href="#__codelineno-0-99"></a>            <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span> <span class="n">sample_dict</span><span class="o">=</span><span class="n">sample_dict</span><span class="p">,</span> <span class="n">return_logit</span><span class="o">=</span><span class="n">return_logit</span><span class="p">)</span>
<a id="__codelineno-0-100" name="__codelineno-0-100" href="#__codelineno-0-100"></a>
<a id="__codelineno-0-101" name="__codelineno-0-101" href="#__codelineno-0-101"></a>    <span class="k">if</span> <span class="n">deterministic</span><span class="p">:</span>
<a id="__codelineno-0-102" name="__codelineno-0-102" href="#__codelineno-0-102"></a>        <span class="c1"># drop the first dimension, which has size of `num_seeds` (equals 1 in the deterministic case).</span>
<a id="__codelineno-0-103" name="__codelineno-0-103" href="#__codelineno-0-103"></a>        <span class="c1"># (len(batch), num_items) or (len(batch),)</span>
<a id="__codelineno-0-104" name="__codelineno-0-104" href="#__codelineno-0-104"></a>        <span class="k">return</span> <span class="n">out</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-105" name="__codelineno-0-105" href="#__codelineno-0-105"></a>
<a id="__codelineno-0-106" name="__codelineno-0-106" href="#__codelineno-0-106"></a>    <span class="k">return</span> <span class="n">out</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="bemb.model.bemb.BEMBFlex.get_within_category_accuracy" class="doc doc-heading">
<code class="highlight language-python"><span class="n">get_within_category_accuracy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log_p_all_items</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>A helper function for computing prediction accuracy (i.e., all non-differential metrics)
within category.
In particular, this method calculates the accuracy, precision, recall and F1 score.</p>
<p>This method has the same functionality as the following peusodcode:
for C in categories:
    # get sessions in which item in category C was purchased.
    T &lt;- (t for t in {0,1,..., len(label)-1} if label[t] is in C)
    Y &lt;- label[T]</p>
<div class="highlight"><pre><span></span><code>predictions = list()
for t in T:
    # get the prediction within category for this session.
    y_pred = argmax_{items in C} log prob computed before.
    predictions.append(y_pred)

accuracy = mean(Y == predictions)
</code></pre></div>
<p>Similarly, this function computes precision, recall and f1score as well.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>log_p_all_items</code></td>
        <td><code>torch.Tensor</code></td>
        <td><p>shape (num_sessions, num_items) the log probability of
choosing each item in each session.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>label</code></td>
        <td><code>torch.LongTensor</code></td>
        <td><p>shape (num_sessions,), the IDs of items purchased in each session.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>[Dict[str, float]]</code></td>
      <td><p>A dictionary containing performance metrics.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>bemb/model/bemb.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="k">def</span> <span class="nf">get_within_category_accuracy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log_p_all_items</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">label</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="sd">&quot;&quot;&quot;A helper function for computing prediction accuracy (i.e., all non-differential metrics)</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="sd">    within category.</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="sd">    In particular, this method calculates the accuracy, precision, recall and F1 score.</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="sd">    This method has the same functionality as the following peusodcode:</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="sd">    for C in categories:</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a><span class="sd">        # get sessions in which item in category C was purchased.</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a><span class="sd">        T &lt;- (t for t in {0,1,..., len(label)-1} if label[t] is in C)</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a><span class="sd">        Y &lt;- label[T]</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a><span class="sd">        predictions = list()</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a><span class="sd">        for t in T:</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a><span class="sd">            # get the prediction within category for this session.</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a><span class="sd">            y_pred = argmax_{items in C} log prob computed before.</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a><span class="sd">            predictions.append(y_pred)</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a><span class="sd">        accuracy = mean(Y == predictions)</span>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a><span class="sd">    Similarly, this function computes precision, recall and f1score as well.</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a><span class="sd">        log_p_all_items (torch.Tensor): shape (num_sessions, num_items) the log probability of</span>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a><span class="sd">            choosing each item in each session.</span>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a><span class="sd">        label (torch.LongTensor): shape (num_sessions,), the IDs of items purchased in each session.</span>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a><span class="sd">        [Dict[str, float]]: A dictionary containing performance metrics.</span>
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a>    <span class="c1"># argmax: (num_sessions, num_categories), within category argmax.</span>
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a>    <span class="c1"># item IDs are consecutive, thus argmax is the same as IDs of the item with highest P.</span>
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a>    <span class="n">_</span><span class="p">,</span> <span class="n">argmax_by_category</span> <span class="o">=</span> <span class="n">scatter_max</span><span class="p">(</span>
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a>        <span class="n">log_p_all_items</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_to_category_tensor</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a>
<a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a>    <span class="c1"># category_purchased[t] = the category of item label[t].</span>
<a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a>    <span class="c1"># (num_sessions,)</span>
<a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a>    <span class="n">category_purchased</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_to_category_tensor</span><span class="p">[</span><span class="n">label</span><span class="p">]</span>
<a id="__codelineno-0-40" name="__codelineno-0-40" href="#__codelineno-0-40"></a>
<a id="__codelineno-0-41" name="__codelineno-0-41" href="#__codelineno-0-41"></a>    <span class="c1"># pred[t] = the item with highest utility from the category item label[t] belongs to.</span>
<a id="__codelineno-0-42" name="__codelineno-0-42" href="#__codelineno-0-42"></a>    <span class="c1"># (num_sessions,)</span>
<a id="__codelineno-0-43" name="__codelineno-0-43" href="#__codelineno-0-43"></a>    <span class="n">pred_from_category</span> <span class="o">=</span> <span class="n">argmax_by_category</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span>
<a id="__codelineno-0-44" name="__codelineno-0-44" href="#__codelineno-0-44"></a>        <span class="nb">len</span><span class="p">(</span><span class="n">label</span><span class="p">)),</span> <span class="n">category_purchased</span><span class="p">]</span>
<a id="__codelineno-0-45" name="__codelineno-0-45" href="#__codelineno-0-45"></a>
<a id="__codelineno-0-46" name="__codelineno-0-46" href="#__codelineno-0-46"></a>    <span class="n">within_category_accuracy</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-47" name="__codelineno-0-47" href="#__codelineno-0-47"></a>        <span class="n">pred_from_category</span> <span class="o">==</span> <span class="n">label</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<a id="__codelineno-0-48" name="__codelineno-0-48" href="#__codelineno-0-48"></a>
<a id="__codelineno-0-49" name="__codelineno-0-49" href="#__codelineno-0-49"></a>    <span class="c1"># precision</span>
<a id="__codelineno-0-50" name="__codelineno-0-50" href="#__codelineno-0-50"></a>    <span class="n">precision</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<a id="__codelineno-0-51" name="__codelineno-0-51" href="#__codelineno-0-51"></a>
<a id="__codelineno-0-52" name="__codelineno-0-52" href="#__codelineno-0-52"></a>    <span class="n">recall</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<a id="__codelineno-0-53" name="__codelineno-0-53" href="#__codelineno-0-53"></a>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">):</span>
<a id="__codelineno-0-54" name="__codelineno-0-54" href="#__codelineno-0-54"></a>        <span class="n">correct_i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
<a id="__codelineno-0-55" name="__codelineno-0-55" href="#__codelineno-0-55"></a>            <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">pred_from_category</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="o">==</span> <span class="n">i</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
<a id="__codelineno-0-56" name="__codelineno-0-56" href="#__codelineno-0-56"></a>        <span class="n">precision_i</span> <span class="o">=</span> <span class="n">correct_i</span> <span class="o">/</span> \
<a id="__codelineno-0-57" name="__codelineno-0-57" href="#__codelineno-0-57"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">pred_from_category</span> <span class="o">==</span> <span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
<a id="__codelineno-0-58" name="__codelineno-0-58" href="#__codelineno-0-58"></a>        <span class="n">recall_i</span> <span class="o">=</span> <span class="n">correct_i</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">label</span> <span class="o">==</span> <span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
<a id="__codelineno-0-59" name="__codelineno-0-59" href="#__codelineno-0-59"></a>
<a id="__codelineno-0-60" name="__codelineno-0-60" href="#__codelineno-0-60"></a>        <span class="c1"># do not add if divided by zero.</span>
<a id="__codelineno-0-61" name="__codelineno-0-61" href="#__codelineno-0-61"></a>        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">pred_from_category</span> <span class="o">==</span> <span class="n">i</span><span class="p">):</span>
<a id="__codelineno-0-62" name="__codelineno-0-62" href="#__codelineno-0-62"></a>            <span class="n">precision</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">precision_i</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
<a id="__codelineno-0-63" name="__codelineno-0-63" href="#__codelineno-0-63"></a>        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">label</span> <span class="o">==</span> <span class="n">i</span><span class="p">):</span>
<a id="__codelineno-0-64" name="__codelineno-0-64" href="#__codelineno-0-64"></a>            <span class="n">recall</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">recall_i</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
<a id="__codelineno-0-65" name="__codelineno-0-65" href="#__codelineno-0-65"></a>
<a id="__codelineno-0-66" name="__codelineno-0-66" href="#__codelineno-0-66"></a>    <span class="n">precision</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">precision</span><span class="p">))</span>
<a id="__codelineno-0-67" name="__codelineno-0-67" href="#__codelineno-0-67"></a>    <span class="n">recall</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">recall</span><span class="p">))</span>
<a id="__codelineno-0-68" name="__codelineno-0-68" href="#__codelineno-0-68"></a>
<a id="__codelineno-0-69" name="__codelineno-0-69" href="#__codelineno-0-69"></a>    <span class="k">if</span> <span class="n">precision</span> <span class="o">==</span> <span class="n">recall</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-0-70" name="__codelineno-0-70" href="#__codelineno-0-70"></a>        <span class="n">f1</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-71" name="__codelineno-0-71" href="#__codelineno-0-71"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-72" name="__codelineno-0-72" href="#__codelineno-0-72"></a>        <span class="n">f1</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">precision</span> <span class="o">*</span> <span class="n">recall</span> <span class="o">/</span> <span class="p">(</span><span class="n">precision</span> <span class="o">+</span> <span class="n">recall</span><span class="p">)</span>
<a id="__codelineno-0-73" name="__codelineno-0-73" href="#__codelineno-0-73"></a>
<a id="__codelineno-0-74" name="__codelineno-0-74" href="#__codelineno-0-74"></a>    <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">within_category_accuracy</span><span class="p">,</span>
<a id="__codelineno-0-75" name="__codelineno-0-75" href="#__codelineno-0-75"></a>            <span class="s1">&#39;precision&#39;</span><span class="p">:</span> <span class="n">precision</span><span class="p">,</span>
<a id="__codelineno-0-76" name="__codelineno-0-76" href="#__codelineno-0-76"></a>            <span class="s1">&#39;recall&#39;</span><span class="p">:</span> <span class="n">recall</span><span class="p">,</span>
<a id="__codelineno-0-77" name="__codelineno-0-77" href="#__codelineno-0-77"></a>            <span class="s1">&#39;f1score&#39;</span><span class="p">:</span> <span class="n">f1</span><span class="p">}</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="bemb.model.bemb.BEMBFlex.ivs" class="doc doc-heading">
<code class="highlight language-python"><span class="n">ivs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>The combined method of computing utilities and log probability.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>batch</code></td>
        <td><code>dict</code></td>
        <td><p>a batch of data.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>torch.Tensor</code></td>
      <td><p>the combined utility and log probability.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>bemb/model/bemb.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="nf">ivs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="sd">&quot;&quot;&quot;The combined method of computing utilities and log probability.</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="sd">            batch (dict): a batch of data.</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="sd">            torch.Tensor: the combined utility and log probability.</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>    <span class="c1"># Use the means of variational distributions as the sole MC sample.</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    <span class="n">sample_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>    <span class="k">for</span> <span class="n">coef_name</span><span class="p">,</span> <span class="n">coef</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>        <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">coef</span><span class="o">.</span><span class="n">variational_distribution</span><span class="o">.</span><span class="n">mean</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># (1, num_*, dim)</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>    <span class="c1"># there is 1 random seed in this case.</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>    <span class="c1"># (num_seeds=1, len(batch), num_items)</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_likelihood_all_items</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">return_logit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sample_dict</span><span class="o">=</span><span class="n">sample_dict</span><span class="p">)</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>    <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>    <span class="c1"># import pdb; pdb.set_trace()</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>    <span class="n">ivs</span> <span class="o">=</span> <span class="n">scatter_logsumexp</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_to_category_tensor</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>    <span class="k">return</span> <span class="n">ivs</span> <span class="c1"># (len(batch), num_categories)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="bemb.model.bemb.BEMBFlex.log_likelihood_all_items" class="doc doc-heading">
<code class="highlight language-python"><span class="n">log_likelihood_all_items</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">return_logit</span><span class="p">,</span> <span class="n">sample_dict</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>NOTE to developers:
NOTE (akanodia to tianyudu): Is this really slow; even with log_likelihood you need log_prob which depends on logits of all items?
This method computes utilities for all items available, which is a relatively slow operation. For
training the model, you only need the utility/log-prob for the chosen/relevant item (i.e., item_index[i] for each i-th observation).
Use this method for inference only.
Use self.log_likelihood_item_index() for training instead.</p>
<p>Computes the log probability of choosing <code>each</code> item in each session based on current model parameters.
NOTE (akanodiadu to tianyudu): What does the next line mean? I think it just says its allowing for samples instead of posterior mean.
This method allows for specifying {user, item}_latent_value for Monte Carlo estimation in ELBO.
For actual prediction tasks, use the forward() function, which will use means of variational
distributions for user and item latents.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>batch</code></td>
        <td><code>ChoiceDataset</code></td>
        <td><p>a ChoiceDataset object containing relevant information.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>return_logit(bool)</code></td>
        <td></td>
        <td><p>if set to True, return the log-probability, otherwise return the logit/utility.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>sample_dict(Dict[str,</code></td>
        <td><code>torch.Tensor]</code></td>
        <td><p>Monte Carlo samples for model coefficients
(i.e., those Greek letters).
sample_dict.keys() should be the same as keys of self.obs2prior_dict, i.e., those
greek letters actually enter the functional form of utility.
The value of sample_dict should be tensors of shape (num_seeds, num_classes, dim)
where num_classes in {num_users, num_items, 1}
and dim in {latent_dim(K), num_item_obs, num_user_obs, 1}.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>torch.Tensor</code></td>
      <td><p>a tensor of shape (num_seeds, len(batch), self.num_items), where
    out[x, y, z] is the probability of choosing item z in session y conditioned on
    latents to be the x-th Monte Carlo sample.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>bemb/model/bemb.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="nf">log_likelihood_all_items</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">ChoiceDataset</span><span class="p">,</span> <span class="n">return_logit</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">sample_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="sd">    NOTE to developers:</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="sd">    NOTE (akanodia to tianyudu): Is this really slow; even with log_likelihood you need log_prob which depends on logits of all items?</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="sd">    This method computes utilities for all items available, which is a relatively slow operation. For</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="sd">    training the model, you only need the utility/log-prob for the chosen/relevant item (i.e., item_index[i] for each i-th observation).</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="sd">    Use this method for inference only.</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="sd">    Use self.log_likelihood_item_index() for training instead.</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a><span class="sd">    Computes the log probability of choosing `each` item in each session based on current model parameters.</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a><span class="sd">    NOTE (akanodiadu to tianyudu): What does the next line mean? I think it just says its allowing for samples instead of posterior mean.</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a><span class="sd">    This method allows for specifying {user, item}_latent_value for Monte Carlo estimation in ELBO.</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a><span class="sd">    For actual prediction tasks, use the forward() function, which will use means of variational</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a><span class="sd">    distributions for user and item latents.</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a><span class="sd">        batch (ChoiceDataset): a ChoiceDataset object containing relevant information.</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a><span class="sd">        return_logit(bool): if set to True, return the log-probability, otherwise return the logit/utility.</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a><span class="sd">        sample_dict(Dict[str, torch.Tensor]): Monte Carlo samples for model coefficients</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a><span class="sd">            (i.e., those Greek letters).</span>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a><span class="sd">            sample_dict.keys() should be the same as keys of self.obs2prior_dict, i.e., those</span>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a><span class="sd">            greek letters actually enter the functional form of utility.</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a><span class="sd">            The value of sample_dict should be tensors of shape (num_seeds, num_classes, dim)</span>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a><span class="sd">            where num_classes in {num_users, num_items, 1}</span>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a><span class="sd">            and dim in {latent_dim(K), num_item_obs, num_user_obs, 1}.</span>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a><span class="sd">        torch.Tensor: a tensor of shape (num_seeds, len(batch), self.num_items), where</span>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a><span class="sd">            out[x, y, z] is the probability of choosing item z in session y conditioned on</span>
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a><span class="sd">            latents to be the x-th Monte Carlo sample.</span>
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a>    <span class="n">num_seeds</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">sample_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a>
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a>    <span class="c1"># avoid repeated work when user purchased several items in the same session.</span>
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a>    <span class="n">user_session_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
<a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a>        <span class="p">[</span><span class="n">batch</span><span class="o">.</span><span class="n">user_index</span><span class="p">,</span> <span class="n">batch</span><span class="o">.</span><span class="n">session_index</span><span class="p">])</span>
<a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a>    <span class="k">assert</span> <span class="n">user_session_index</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">))</span>
<a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a>    <span class="n">unique_user_sess</span><span class="p">,</span> <span class="n">inverse_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span>
<a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a>        <span class="n">user_session_index</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-40" name="__codelineno-0-40" href="#__codelineno-0-40"></a>
<a id="__codelineno-0-41" name="__codelineno-0-41" href="#__codelineno-0-41"></a>    <span class="n">user_index</span> <span class="o">=</span> <span class="n">unique_user_sess</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
<a id="__codelineno-0-42" name="__codelineno-0-42" href="#__codelineno-0-42"></a>    <span class="n">session_index</span> <span class="o">=</span> <span class="n">unique_user_sess</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
<a id="__codelineno-0-43" name="__codelineno-0-43" href="#__codelineno-0-43"></a>    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">user_index</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">session_index</span><span class="p">)</span>
<a id="__codelineno-0-44" name="__codelineno-0-44" href="#__codelineno-0-44"></a>
<a id="__codelineno-0-45" name="__codelineno-0-45" href="#__codelineno-0-45"></a>    <span class="c1"># short-hands for easier shape check.</span>
<a id="__codelineno-0-46" name="__codelineno-0-46" href="#__codelineno-0-46"></a>    <span class="n">R</span> <span class="o">=</span> <span class="n">num_seeds</span>
<a id="__codelineno-0-47" name="__codelineno-0-47" href="#__codelineno-0-47"></a>    <span class="c1"># P = len(batch)  # num_purchases.</span>
<a id="__codelineno-0-48" name="__codelineno-0-48" href="#__codelineno-0-48"></a>    <span class="n">P</span> <span class="o">=</span> <span class="n">unique_user_sess</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<a id="__codelineno-0-49" name="__codelineno-0-49" href="#__codelineno-0-49"></a>    <span class="n">S</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_sessions</span>
<a id="__codelineno-0-50" name="__codelineno-0-50" href="#__codelineno-0-50"></a>    <span class="n">U</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_users</span>
<a id="__codelineno-0-51" name="__codelineno-0-51" href="#__codelineno-0-51"></a>    <span class="n">I</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span>
<a id="__codelineno-0-52" name="__codelineno-0-52" href="#__codelineno-0-52"></a>    <span class="n">NC</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_categories</span>
<a id="__codelineno-0-53" name="__codelineno-0-53" href="#__codelineno-0-53"></a>
<a id="__codelineno-0-54" name="__codelineno-0-54" href="#__codelineno-0-54"></a>    <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-55" name="__codelineno-0-55" href="#__codelineno-0-55"></a>    <span class="c1"># Helper Functions for Reshaping.</span>
<a id="__codelineno-0-56" name="__codelineno-0-56" href="#__codelineno-0-56"></a>    <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-57" name="__codelineno-0-57" href="#__codelineno-0-57"></a>    <span class="k">def</span> <span class="nf">reshape_user_coef_sample</span><span class="p">(</span><span class="n">C</span><span class="p">):</span>
<a id="__codelineno-0-58" name="__codelineno-0-58" href="#__codelineno-0-58"></a>        <span class="c1"># input shape (R, U, *)</span>
<a id="__codelineno-0-59" name="__codelineno-0-59" href="#__codelineno-0-59"></a>        <span class="n">C</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (R, U, I, *)</span>
<a id="__codelineno-0-60" name="__codelineno-0-60" href="#__codelineno-0-60"></a>        <span class="n">C</span> <span class="o">=</span> <span class="n">C</span><span class="p">[:,</span> <span class="n">user_index</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
<a id="__codelineno-0-61" name="__codelineno-0-61" href="#__codelineno-0-61"></a>        <span class="k">assert</span> <span class="n">C</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">positive_integer</span><span class="p">)</span>
<a id="__codelineno-0-62" name="__codelineno-0-62" href="#__codelineno-0-62"></a>        <span class="k">return</span> <span class="n">C</span>
<a id="__codelineno-0-63" name="__codelineno-0-63" href="#__codelineno-0-63"></a>
<a id="__codelineno-0-64" name="__codelineno-0-64" href="#__codelineno-0-64"></a>    <span class="k">def</span> <span class="nf">reshape_item_coef_sample</span><span class="p">(</span><span class="n">C</span><span class="p">):</span>
<a id="__codelineno-0-65" name="__codelineno-0-65" href="#__codelineno-0-65"></a>        <span class="c1"># input shape (R, I, *)</span>
<a id="__codelineno-0-66" name="__codelineno-0-66" href="#__codelineno-0-66"></a>        <span class="n">C</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-67" name="__codelineno-0-67" href="#__codelineno-0-67"></a>        <span class="k">assert</span> <span class="n">C</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">positive_integer</span><span class="p">)</span>
<a id="__codelineno-0-68" name="__codelineno-0-68" href="#__codelineno-0-68"></a>        <span class="k">return</span> <span class="n">C</span>
<a id="__codelineno-0-69" name="__codelineno-0-69" href="#__codelineno-0-69"></a>
<a id="__codelineno-0-70" name="__codelineno-0-70" href="#__codelineno-0-70"></a>    <span class="k">def</span> <span class="nf">reshape_category_coef_sample</span><span class="p">(</span><span class="n">C</span><span class="p">):</span>
<a id="__codelineno-0-71" name="__codelineno-0-71" href="#__codelineno-0-71"></a>        <span class="c1"># input shape (R, NC, *)</span>
<a id="__codelineno-0-72" name="__codelineno-0-72" href="#__codelineno-0-72"></a>        <span class="n">C</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">category_to_size_tensor</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-73" name="__codelineno-0-73" href="#__codelineno-0-73"></a>        <span class="c1"># input shape (R, I, *)</span>
<a id="__codelineno-0-74" name="__codelineno-0-74" href="#__codelineno-0-74"></a>        <span class="n">C</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-75" name="__codelineno-0-75" href="#__codelineno-0-75"></a>        <span class="k">assert</span> <span class="n">C</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">positive_integer</span><span class="p">)</span>
<a id="__codelineno-0-76" name="__codelineno-0-76" href="#__codelineno-0-76"></a>        <span class="k">return</span> <span class="n">C</span>
<a id="__codelineno-0-77" name="__codelineno-0-77" href="#__codelineno-0-77"></a>
<a id="__codelineno-0-78" name="__codelineno-0-78" href="#__codelineno-0-78"></a>    <span class="k">def</span> <span class="nf">reshape_constant_coef_sample</span><span class="p">(</span><span class="n">C</span><span class="p">):</span>
<a id="__codelineno-0-79" name="__codelineno-0-79" href="#__codelineno-0-79"></a>        <span class="c1"># input shape (R, *)</span>
<a id="__codelineno-0-80" name="__codelineno-0-80" href="#__codelineno-0-80"></a>        <span class="n">C</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-81" name="__codelineno-0-81" href="#__codelineno-0-81"></a>        <span class="k">assert</span> <span class="n">C</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">positive_integer</span><span class="p">)</span>
<a id="__codelineno-0-82" name="__codelineno-0-82" href="#__codelineno-0-82"></a>        <span class="k">return</span> <span class="n">C</span>
<a id="__codelineno-0-83" name="__codelineno-0-83" href="#__codelineno-0-83"></a>
<a id="__codelineno-0-84" name="__codelineno-0-84" href="#__codelineno-0-84"></a>    <span class="k">def</span> <span class="nf">reshape_coef_sample</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
<a id="__codelineno-0-85" name="__codelineno-0-85" href="#__codelineno-0-85"></a>        <span class="c1"># reshape the monte carlo sample of coefficients to (R, P, I, *).</span>
<a id="__codelineno-0-86" name="__codelineno-0-86" href="#__codelineno-0-86"></a>        <span class="k">if</span> <span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;_user&#39;</span><span class="p">):</span>
<a id="__codelineno-0-87" name="__codelineno-0-87" href="#__codelineno-0-87"></a>            <span class="c1"># (R, U, *) --&gt; (R, P, I, *)</span>
<a id="__codelineno-0-88" name="__codelineno-0-88" href="#__codelineno-0-88"></a>            <span class="k">return</span> <span class="n">reshape_user_coef_sample</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
<a id="__codelineno-0-89" name="__codelineno-0-89" href="#__codelineno-0-89"></a>        <span class="k">elif</span> <span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;_item&#39;</span><span class="p">):</span>
<a id="__codelineno-0-90" name="__codelineno-0-90" href="#__codelineno-0-90"></a>            <span class="c1"># (R, I, *) --&gt; (R, P, I, *)</span>
<a id="__codelineno-0-91" name="__codelineno-0-91" href="#__codelineno-0-91"></a>            <span class="k">return</span> <span class="n">reshape_item_coef_sample</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
<a id="__codelineno-0-92" name="__codelineno-0-92" href="#__codelineno-0-92"></a>        <span class="k">elif</span> <span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;_category&#39;</span><span class="p">):</span>
<a id="__codelineno-0-93" name="__codelineno-0-93" href="#__codelineno-0-93"></a>            <span class="c1"># (R, NC, *) --&gt; (R, P, NC, *)</span>
<a id="__codelineno-0-94" name="__codelineno-0-94" href="#__codelineno-0-94"></a>            <span class="k">return</span> <span class="n">reshape_category_coef_sample</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
<a id="__codelineno-0-95" name="__codelineno-0-95" href="#__codelineno-0-95"></a>        <span class="k">elif</span> <span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;_constant&#39;</span><span class="p">):</span>
<a id="__codelineno-0-96" name="__codelineno-0-96" href="#__codelineno-0-96"></a>            <span class="c1"># (R, *) --&gt; (R, P, I, *)</span>
<a id="__codelineno-0-97" name="__codelineno-0-97" href="#__codelineno-0-97"></a>            <span class="k">return</span> <span class="n">reshape_constant_coef_sample</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
<a id="__codelineno-0-98" name="__codelineno-0-98" href="#__codelineno-0-98"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-99" name="__codelineno-0-99" href="#__codelineno-0-99"></a>            <span class="k">raise</span> <span class="ne">ValueError</span>
<a id="__codelineno-0-100" name="__codelineno-0-100" href="#__codelineno-0-100"></a>
<a id="__codelineno-0-101" name="__codelineno-0-101" href="#__codelineno-0-101"></a>    <span class="k">def</span> <span class="nf">reshape_observable</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
<a id="__codelineno-0-102" name="__codelineno-0-102" href="#__codelineno-0-102"></a>        <span class="c1"># reshape observable to (R, P, I, *) so that it can be multiplied with monte carlo</span>
<a id="__codelineno-0-103" name="__codelineno-0-103" href="#__codelineno-0-103"></a>        <span class="c1"># samples of coefficients.</span>
<a id="__codelineno-0-104" name="__codelineno-0-104" href="#__codelineno-0-104"></a>        <span class="n">O</span> <span class="o">=</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># number of observables.</span>
<a id="__codelineno-0-105" name="__codelineno-0-105" href="#__codelineno-0-105"></a>        <span class="k">assert</span> <span class="n">O</span> <span class="o">==</span> <span class="n">positive_integer</span>
<a id="__codelineno-0-106" name="__codelineno-0-106" href="#__codelineno-0-106"></a>        <span class="k">if</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;item_&#39;</span><span class="p">):</span>
<a id="__codelineno-0-107" name="__codelineno-0-107" href="#__codelineno-0-107"></a>            <span class="k">assert</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">O</span><span class="p">)</span>
<a id="__codelineno-0-108" name="__codelineno-0-108" href="#__codelineno-0-108"></a>            <span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">O</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-109" name="__codelineno-0-109" href="#__codelineno-0-109"></a>        <span class="k">elif</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;user_&#39;</span><span class="p">):</span>
<a id="__codelineno-0-110" name="__codelineno-0-110" href="#__codelineno-0-110"></a>            <span class="k">assert</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">O</span><span class="p">)</span>
<a id="__codelineno-0-111" name="__codelineno-0-111" href="#__codelineno-0-111"></a>            <span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span><span class="p">[</span><span class="n">user_index</span><span class="p">,</span> <span class="p">:]</span>  <span class="c1"># (P, O)</span>
<a id="__codelineno-0-112" name="__codelineno-0-112" href="#__codelineno-0-112"></a>            <span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">O</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-113" name="__codelineno-0-113" href="#__codelineno-0-113"></a>        <span class="k">elif</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;session_&#39;</span><span class="p">):</span>
<a id="__codelineno-0-114" name="__codelineno-0-114" href="#__codelineno-0-114"></a>            <span class="k">assert</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">O</span><span class="p">)</span>
<a id="__codelineno-0-115" name="__codelineno-0-115" href="#__codelineno-0-115"></a>            <span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span><span class="p">[</span><span class="n">session_index</span><span class="p">,</span> <span class="p">:]</span>  <span class="c1"># (P, O)</span>
<a id="__codelineno-0-116" name="__codelineno-0-116" href="#__codelineno-0-116"></a>            <span class="k">return</span> <span class="n">obs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">O</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-117" name="__codelineno-0-117" href="#__codelineno-0-117"></a>        <span class="k">elif</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;price_&#39;</span><span class="p">):</span>
<a id="__codelineno-0-118" name="__codelineno-0-118" href="#__codelineno-0-118"></a>            <span class="k">assert</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">O</span><span class="p">)</span>
<a id="__codelineno-0-119" name="__codelineno-0-119" href="#__codelineno-0-119"></a>            <span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span><span class="p">[</span><span class="n">session_index</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>  <span class="c1"># (P, I, O)</span>
<a id="__codelineno-0-120" name="__codelineno-0-120" href="#__codelineno-0-120"></a>            <span class="k">return</span> <span class="n">obs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">O</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-121" name="__codelineno-0-121" href="#__codelineno-0-121"></a>        <span class="k">elif</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;taste_&#39;</span><span class="p">):</span>
<a id="__codelineno-0-122" name="__codelineno-0-122" href="#__codelineno-0-122"></a>            <span class="k">assert</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">O</span><span class="p">)</span>
<a id="__codelineno-0-123" name="__codelineno-0-123" href="#__codelineno-0-123"></a>            <span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span><span class="p">[</span><span class="n">user_index</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>  <span class="c1"># (P, I, O)</span>
<a id="__codelineno-0-124" name="__codelineno-0-124" href="#__codelineno-0-124"></a>            <span class="k">return</span> <span class="n">obs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">O</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-125" name="__codelineno-0-125" href="#__codelineno-0-125"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-126" name="__codelineno-0-126" href="#__codelineno-0-126"></a>            <span class="k">raise</span> <span class="ne">ValueError</span>
<a id="__codelineno-0-127" name="__codelineno-0-127" href="#__codelineno-0-127"></a>        <span class="k">assert</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">O</span><span class="p">)</span>
<a id="__codelineno-0-128" name="__codelineno-0-128" href="#__codelineno-0-128"></a>        <span class="k">return</span> <span class="n">obs</span>
<a id="__codelineno-0-129" name="__codelineno-0-129" href="#__codelineno-0-129"></a>
<a id="__codelineno-0-130" name="__codelineno-0-130" href="#__codelineno-0-130"></a>    <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-131" name="__codelineno-0-131" href="#__codelineno-0-131"></a>    <span class="c1"># Compute the Utility Term by Term.</span>
<a id="__codelineno-0-132" name="__codelineno-0-132" href="#__codelineno-0-132"></a>    <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-133" name="__codelineno-0-133" href="#__codelineno-0-133"></a>    <span class="c1"># P is the number of unique (user, session) pairs.</span>
<a id="__codelineno-0-134" name="__codelineno-0-134" href="#__codelineno-0-134"></a>    <span class="c1"># (random_seeds, P, num_items).</span>
<a id="__codelineno-0-135" name="__codelineno-0-135" href="#__codelineno-0-135"></a>    <span class="n">utility</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-136" name="__codelineno-0-136" href="#__codelineno-0-136"></a>
<a id="__codelineno-0-137" name="__codelineno-0-137" href="#__codelineno-0-137"></a>    <span class="c1"># loop over additive term to utility</span>
<a id="__codelineno-0-138" name="__codelineno-0-138" href="#__codelineno-0-138"></a>    <span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">formula</span><span class="p">:</span>
<a id="__codelineno-0-139" name="__codelineno-0-139" href="#__codelineno-0-139"></a>        <span class="c1"># Type I: single coefficient, e.g., lambda_item or lambda_user.</span>
<a id="__codelineno-0-140" name="__codelineno-0-140" href="#__codelineno-0-140"></a>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;observable&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-141" name="__codelineno-0-141" href="#__codelineno-0-141"></a>            <span class="c1"># E.g., lambda_item or lambda_user</span>
<a id="__codelineno-0-142" name="__codelineno-0-142" href="#__codelineno-0-142"></a>            <span class="n">coef_name</span> <span class="o">=</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-143" name="__codelineno-0-143" href="#__codelineno-0-143"></a>            <span class="n">coef_sample</span> <span class="o">=</span> <span class="n">reshape_coef_sample</span><span class="p">(</span>
<a id="__codelineno-0-144" name="__codelineno-0-144" href="#__codelineno-0-144"></a>                <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">],</span> <span class="n">coef_name</span><span class="p">)</span>
<a id="__codelineno-0-145" name="__codelineno-0-145" href="#__codelineno-0-145"></a>            <span class="k">assert</span> <span class="n">coef_sample</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-146" name="__codelineno-0-146" href="#__codelineno-0-146"></a>            <span class="n">additive_term</span> <span class="o">=</span> <span class="n">coef_sample</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">)</span>
<a id="__codelineno-0-147" name="__codelineno-0-147" href="#__codelineno-0-147"></a>
<a id="__codelineno-0-148" name="__codelineno-0-148" href="#__codelineno-0-148"></a>        <span class="c1"># Type II: factorized coefficient, e.g., &lt;theta_user, lambda_item&gt;.</span>
<a id="__codelineno-0-149" name="__codelineno-0-149" href="#__codelineno-0-149"></a>        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;observable&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-150" name="__codelineno-0-150" href="#__codelineno-0-150"></a>            <span class="n">coef_name_0</span> <span class="o">=</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-151" name="__codelineno-0-151" href="#__codelineno-0-151"></a>            <span class="n">coef_name_1</span> <span class="o">=</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
<a id="__codelineno-0-152" name="__codelineno-0-152" href="#__codelineno-0-152"></a>
<a id="__codelineno-0-153" name="__codelineno-0-153" href="#__codelineno-0-153"></a>            <span class="n">coef_sample_0</span> <span class="o">=</span> <span class="n">reshape_coef_sample</span><span class="p">(</span>
<a id="__codelineno-0-154" name="__codelineno-0-154" href="#__codelineno-0-154"></a>                <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name_0</span><span class="p">],</span> <span class="n">coef_name_0</span><span class="p">)</span>
<a id="__codelineno-0-155" name="__codelineno-0-155" href="#__codelineno-0-155"></a>            <span class="n">coef_sample_1</span> <span class="o">=</span> <span class="n">reshape_coef_sample</span><span class="p">(</span>
<a id="__codelineno-0-156" name="__codelineno-0-156" href="#__codelineno-0-156"></a>                <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name_1</span><span class="p">],</span> <span class="n">coef_name_1</span><span class="p">)</span>
<a id="__codelineno-0-157" name="__codelineno-0-157" href="#__codelineno-0-157"></a>
<a id="__codelineno-0-158" name="__codelineno-0-158" href="#__codelineno-0-158"></a>            <span class="k">assert</span> <span class="n">coef_sample_0</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">coef_sample_1</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span>
<a id="__codelineno-0-159" name="__codelineno-0-159" href="#__codelineno-0-159"></a>                <span class="n">R</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">positive_integer</span><span class="p">)</span>
<a id="__codelineno-0-160" name="__codelineno-0-160" href="#__codelineno-0-160"></a>
<a id="__codelineno-0-161" name="__codelineno-0-161" href="#__codelineno-0-161"></a>            <span class="n">additive_term</span> <span class="o">=</span> <span class="p">(</span><span class="n">coef_sample_0</span> <span class="o">*</span> <span class="n">coef_sample_1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-162" name="__codelineno-0-162" href="#__codelineno-0-162"></a>
<a id="__codelineno-0-163" name="__codelineno-0-163" href="#__codelineno-0-163"></a>        <span class="c1"># Type III: single coefficient multiplied by observable, e.g., theta_user * x_obs_item.</span>
<a id="__codelineno-0-164" name="__codelineno-0-164" href="#__codelineno-0-164"></a>        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;observable&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-165" name="__codelineno-0-165" href="#__codelineno-0-165"></a>            <span class="n">coef_name</span> <span class="o">=</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-166" name="__codelineno-0-166" href="#__codelineno-0-166"></a>            <span class="n">coef_sample</span> <span class="o">=</span> <span class="n">reshape_coef_sample</span><span class="p">(</span>
<a id="__codelineno-0-167" name="__codelineno-0-167" href="#__codelineno-0-167"></a>                <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">],</span> <span class="n">coef_name</span><span class="p">)</span>
<a id="__codelineno-0-168" name="__codelineno-0-168" href="#__codelineno-0-168"></a>            <span class="k">assert</span> <span class="n">coef_sample</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">positive_integer</span><span class="p">)</span>
<a id="__codelineno-0-169" name="__codelineno-0-169" href="#__codelineno-0-169"></a>
<a id="__codelineno-0-170" name="__codelineno-0-170" href="#__codelineno-0-170"></a>            <span class="n">obs_name</span> <span class="o">=</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;observable&#39;</span><span class="p">]</span>
<a id="__codelineno-0-171" name="__codelineno-0-171" href="#__codelineno-0-171"></a>            <span class="n">obs</span> <span class="o">=</span> <span class="n">reshape_observable</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">obs_name</span><span class="p">),</span> <span class="n">obs_name</span><span class="p">)</span>
<a id="__codelineno-0-172" name="__codelineno-0-172" href="#__codelineno-0-172"></a>            <span class="k">assert</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">positive_integer</span><span class="p">)</span>
<a id="__codelineno-0-173" name="__codelineno-0-173" href="#__codelineno-0-173"></a>
<a id="__codelineno-0-174" name="__codelineno-0-174" href="#__codelineno-0-174"></a>            <span class="n">additive_term</span> <span class="o">=</span> <span class="p">(</span><span class="n">coef_sample</span> <span class="o">*</span> <span class="n">obs</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-175" name="__codelineno-0-175" href="#__codelineno-0-175"></a>
<a id="__codelineno-0-176" name="__codelineno-0-176" href="#__codelineno-0-176"></a>        <span class="c1"># Type IV: factorized coefficient multiplied by observable.</span>
<a id="__codelineno-0-177" name="__codelineno-0-177" href="#__codelineno-0-177"></a>        <span class="c1"># e.g., gamma_user * beta_item * price_obs.</span>
<a id="__codelineno-0-178" name="__codelineno-0-178" href="#__codelineno-0-178"></a>        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;observable&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-179" name="__codelineno-0-179" href="#__codelineno-0-179"></a>            <span class="n">coef_name_0</span><span class="p">,</span> <span class="n">coef_name_1</span> <span class="o">=</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
<a id="__codelineno-0-180" name="__codelineno-0-180" href="#__codelineno-0-180"></a>
<a id="__codelineno-0-181" name="__codelineno-0-181" href="#__codelineno-0-181"></a>            <span class="n">coef_sample_0</span> <span class="o">=</span> <span class="n">reshape_coef_sample</span><span class="p">(</span>
<a id="__codelineno-0-182" name="__codelineno-0-182" href="#__codelineno-0-182"></a>                <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name_0</span><span class="p">],</span> <span class="n">coef_name_0</span><span class="p">)</span>
<a id="__codelineno-0-183" name="__codelineno-0-183" href="#__codelineno-0-183"></a>            <span class="n">coef_sample_1</span> <span class="o">=</span> <span class="n">reshape_coef_sample</span><span class="p">(</span>
<a id="__codelineno-0-184" name="__codelineno-0-184" href="#__codelineno-0-184"></a>                <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name_1</span><span class="p">],</span> <span class="n">coef_name_1</span><span class="p">)</span>
<a id="__codelineno-0-185" name="__codelineno-0-185" href="#__codelineno-0-185"></a>            <span class="k">assert</span> <span class="n">coef_sample_0</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">coef_sample_1</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span>
<a id="__codelineno-0-186" name="__codelineno-0-186" href="#__codelineno-0-186"></a>                <span class="n">R</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">positive_integer</span><span class="p">)</span>
<a id="__codelineno-0-187" name="__codelineno-0-187" href="#__codelineno-0-187"></a>            <span class="n">num_obs_times_latent_dim</span> <span class="o">=</span> <span class="n">coef_sample_0</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<a id="__codelineno-0-188" name="__codelineno-0-188" href="#__codelineno-0-188"></a>
<a id="__codelineno-0-189" name="__codelineno-0-189" href="#__codelineno-0-189"></a>            <span class="n">obs_name</span> <span class="o">=</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;observable&#39;</span><span class="p">]</span>
<a id="__codelineno-0-190" name="__codelineno-0-190" href="#__codelineno-0-190"></a>            <span class="n">obs</span> <span class="o">=</span> <span class="n">reshape_observable</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">obs_name</span><span class="p">),</span> <span class="n">obs_name</span><span class="p">)</span>
<a id="__codelineno-0-191" name="__codelineno-0-191" href="#__codelineno-0-191"></a>            <span class="k">assert</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">positive_integer</span><span class="p">)</span>
<a id="__codelineno-0-192" name="__codelineno-0-192" href="#__codelineno-0-192"></a>            <span class="n">num_obs</span> <span class="o">=</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># number of observables.</span>
<a id="__codelineno-0-193" name="__codelineno-0-193" href="#__codelineno-0-193"></a>
<a id="__codelineno-0-194" name="__codelineno-0-194" href="#__codelineno-0-194"></a>            <span class="k">assert</span> <span class="p">(</span><span class="n">num_obs_times_latent_dim</span> <span class="o">%</span> <span class="n">num_obs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>
<a id="__codelineno-0-195" name="__codelineno-0-195" href="#__codelineno-0-195"></a>            <span class="n">latent_dim</span> <span class="o">=</span> <span class="n">num_obs_times_latent_dim</span> <span class="o">//</span> <span class="n">num_obs</span>
<a id="__codelineno-0-196" name="__codelineno-0-196" href="#__codelineno-0-196"></a>
<a id="__codelineno-0-197" name="__codelineno-0-197" href="#__codelineno-0-197"></a>            <span class="n">coef_sample_0</span> <span class="o">=</span> <span class="n">coef_sample_0</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
<a id="__codelineno-0-198" name="__codelineno-0-198" href="#__codelineno-0-198"></a>                <span class="n">R</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">num_obs</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>
<a id="__codelineno-0-199" name="__codelineno-0-199" href="#__codelineno-0-199"></a>            <span class="n">coef_sample_1</span> <span class="o">=</span> <span class="n">coef_sample_1</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
<a id="__codelineno-0-200" name="__codelineno-0-200" href="#__codelineno-0-200"></a>                <span class="n">R</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">num_obs</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>
<a id="__codelineno-0-201" name="__codelineno-0-201" href="#__codelineno-0-201"></a>            <span class="c1"># compute the factorized coefficient with shape (R, P, I, O).</span>
<a id="__codelineno-0-202" name="__codelineno-0-202" href="#__codelineno-0-202"></a>            <span class="n">coef</span> <span class="o">=</span> <span class="p">(</span><span class="n">coef_sample_0</span> <span class="o">*</span> <span class="n">coef_sample_1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-203" name="__codelineno-0-203" href="#__codelineno-0-203"></a>
<a id="__codelineno-0-204" name="__codelineno-0-204" href="#__codelineno-0-204"></a>            <span class="n">additive_term</span> <span class="o">=</span> <span class="p">(</span><span class="n">coef</span> <span class="o">*</span> <span class="n">obs</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-205" name="__codelineno-0-205" href="#__codelineno-0-205"></a>
<a id="__codelineno-0-206" name="__codelineno-0-206" href="#__codelineno-0-206"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-207" name="__codelineno-0-207" href="#__codelineno-0-207"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Undefined term type: </span><span class="si">{</span><span class="n">term</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<a id="__codelineno-0-208" name="__codelineno-0-208" href="#__codelineno-0-208"></a>
<a id="__codelineno-0-209" name="__codelineno-0-209" href="#__codelineno-0-209"></a>        <span class="k">assert</span> <span class="n">additive_term</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">I</span><span class="p">)</span>
<a id="__codelineno-0-210" name="__codelineno-0-210" href="#__codelineno-0-210"></a>        <span class="n">utility</span> <span class="o">+=</span> <span class="n">additive_term</span>
<a id="__codelineno-0-211" name="__codelineno-0-211" href="#__codelineno-0-211"></a>
<a id="__codelineno-0-212" name="__codelineno-0-212" href="#__codelineno-0-212"></a>    <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-213" name="__codelineno-0-213" href="#__codelineno-0-213"></a>    <span class="c1"># Mask Out Unavailable Items in Each Session.</span>
<a id="__codelineno-0-214" name="__codelineno-0-214" href="#__codelineno-0-214"></a>    <span class="c1"># ==============================================================================================================</span>
<a id="__codelineno-0-215" name="__codelineno-0-215" href="#__codelineno-0-215"></a>
<a id="__codelineno-0-216" name="__codelineno-0-216" href="#__codelineno-0-216"></a>    <span class="k">if</span> <span class="n">batch</span><span class="o">.</span><span class="n">item_availability</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-217" name="__codelineno-0-217" href="#__codelineno-0-217"></a>        <span class="c1"># expand to the Monte Carlo sample dimension.</span>
<a id="__codelineno-0-218" name="__codelineno-0-218" href="#__codelineno-0-218"></a>        <span class="c1"># (S, I) -&gt; (P, I) -&gt; (1, P, I) -&gt; (R, P, I)</span>
<a id="__codelineno-0-219" name="__codelineno-0-219" href="#__codelineno-0-219"></a>        <span class="n">A</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">item_availability</span><span class="p">[</span><span class="n">session_index</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span>
<a id="__codelineno-0-220" name="__codelineno-0-220" href="#__codelineno-0-220"></a>            <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-221" name="__codelineno-0-221" href="#__codelineno-0-221"></a>        <span class="n">utility</span><span class="p">[</span><span class="o">~</span><span class="n">A</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">utility</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">max</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-0-222" name="__codelineno-0-222" href="#__codelineno-0-222"></a>
<a id="__codelineno-0-223" name="__codelineno-0-223" href="#__codelineno-0-223"></a>    <span class="n">utility</span> <span class="o">=</span> <span class="n">utility</span><span class="p">[:,</span> <span class="n">inverse_indices</span><span class="p">,</span> <span class="p">:]</span>
<a id="__codelineno-0-224" name="__codelineno-0-224" href="#__codelineno-0-224"></a>    <span class="k">assert</span> <span class="n">utility</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="n">I</span><span class="p">)</span>
<a id="__codelineno-0-225" name="__codelineno-0-225" href="#__codelineno-0-225"></a>
<a id="__codelineno-0-226" name="__codelineno-0-226" href="#__codelineno-0-226"></a>    <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">additional_modules</span><span class="p">:</span>
<a id="__codelineno-0-227" name="__codelineno-0-227" href="#__codelineno-0-227"></a>        <span class="n">additive_term</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
<a id="__codelineno-0-228" name="__codelineno-0-228" href="#__codelineno-0-228"></a>        <span class="k">assert</span> <span class="n">additive_term</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-229" name="__codelineno-0-229" href="#__codelineno-0-229"></a>        <span class="n">utility</span> <span class="o">+=</span> <span class="n">additive_term</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">I</span><span class="p">)</span>
<a id="__codelineno-0-230" name="__codelineno-0-230" href="#__codelineno-0-230"></a>
<a id="__codelineno-0-231" name="__codelineno-0-231" href="#__codelineno-0-231"></a>    <span class="k">if</span> <span class="n">return_logit</span><span class="p">:</span>
<a id="__codelineno-0-232" name="__codelineno-0-232" href="#__codelineno-0-232"></a>        <span class="c1"># output shape: (num_seeds, len(batch), num_items)</span>
<a id="__codelineno-0-233" name="__codelineno-0-233" href="#__codelineno-0-233"></a>        <span class="k">assert</span> <span class="n">utility</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_seeds</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">)</span>
<a id="__codelineno-0-234" name="__codelineno-0-234" href="#__codelineno-0-234"></a>        <span class="k">return</span> <span class="n">utility</span>
<a id="__codelineno-0-235" name="__codelineno-0-235" href="#__codelineno-0-235"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-236" name="__codelineno-0-236" href="#__codelineno-0-236"></a>        <span class="c1"># compute log likelihood log p(choosing item i | user, item latents)</span>
<a id="__codelineno-0-237" name="__codelineno-0-237" href="#__codelineno-0-237"></a>        <span class="c1"># compute log softmax separately within each category.</span>
<a id="__codelineno-0-238" name="__codelineno-0-238" href="#__codelineno-0-238"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pred_item</span><span class="p">:</span>
<a id="__codelineno-0-239" name="__codelineno-0-239" href="#__codelineno-0-239"></a>            <span class="c1"># output shape: (num_seeds, len(batch), num_items)</span>
<a id="__codelineno-0-240" name="__codelineno-0-240" href="#__codelineno-0-240"></a>            <span class="n">log_p</span> <span class="o">=</span> <span class="n">scatter_log_softmax</span><span class="p">(</span><span class="n">utility</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_to_category_tensor</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-241" name="__codelineno-0-241" href="#__codelineno-0-241"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-242" name="__codelineno-0-242" href="#__codelineno-0-242"></a>            <span class="n">label_expanded</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">label</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">num_seeds</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">)</span>
<a id="__codelineno-0-243" name="__codelineno-0-243" href="#__codelineno-0-243"></a>            <span class="k">assert</span> <span class="n">label_expanded</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_seeds</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">)</span>
<a id="__codelineno-0-244" name="__codelineno-0-244" href="#__codelineno-0-244"></a>            <span class="n">bce</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
<a id="__codelineno-0-245" name="__codelineno-0-245" href="#__codelineno-0-245"></a>            <span class="n">log_p</span> <span class="o">=</span> <span class="o">-</span> <span class="n">bce</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">utility</span><span class="p">),</span> <span class="n">label_expanded</span><span class="p">)</span>
<a id="__codelineno-0-246" name="__codelineno-0-246" href="#__codelineno-0-246"></a>        <span class="k">assert</span> <span class="n">log_p</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_seeds</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">)</span>
<a id="__codelineno-0-247" name="__codelineno-0-247" href="#__codelineno-0-247"></a>        <span class="k">return</span> <span class="n">log_p</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="bemb.model.bemb.BEMBFlex.log_likelihood_item_index" class="doc doc-heading">
<code class="highlight language-python"><span class="n">log_likelihood_item_index</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">return_logit</span><span class="p">,</span> <span class="n">sample_dict</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>NOTE for developers:
This method is more efficient and only computes log-likelihood/logit(utility) for item in item_index[i] for each
i-th observation.
Developers should use use <code>log_likelihood_all_items</code> for inference purpose and to computes log-likelihoods/utilities
for ALL items for the i-th observation.</p>
<p>Computes the log probability of choosing item_index[i] in each session based on current model parameters.
This method allows for specifying {user, item}_latent_value for Monte Carlo estimation in ELBO.
For actual prediction tasks, use the forward() function, which will use means of variational
distributions for user and item latents.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>batch</code></td>
        <td><code>ChoiceDataset</code></td>
        <td><p>a ChoiceDataset object containing relevant information.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>return_logit(bool)</code></td>
        <td></td>
        <td><p>if set to True, return the logit/utility, otherwise return the log-probability.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>sample_dict(Dict[str,</code></td>
        <td><code>torch.Tensor]</code></td>
        <td><p>Monte Carlo samples for model coefficients
(i.e., those Greek letters).
sample_dict.keys() should be the same as keys of self.obs2prior_dict, i.e., those
greek letters actually enter the functional form of utility.
The value of sample_dict should be tensors of shape (num_seeds, num_classes, dim)
where num_classes in {num_users, num_items, 1}
and dim in {latent_dim(K), num_item_obs, num_user_obs, 1}.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>torch.Tensor</code></td>
      <td><p>a tensor of shape (num_seeds, len(batch)), where
    out[x, y] is the probabilities of choosing item batch.item[y] in session y
    conditioned on latents to be the x-th Monte Carlo sample.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>bemb/model/bemb.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="nf">log_likelihood_item_index</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">ChoiceDataset</span><span class="p">,</span> <span class="n">return_logit</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">sample_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="sd">    NOTE for developers:</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="sd">    This method is more efficient and only computes log-likelihood/logit(utility) for item in item_index[i] for each</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="sd">    i-th observation.</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="sd">    Developers should use use `log_likelihood_all_items` for inference purpose and to computes log-likelihoods/utilities</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="sd">    for ALL items for the i-th observation.</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="sd">    Computes the log probability of choosing item_index[i] in each session based on current model parameters.</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a><span class="sd">    This method allows for specifying {user, item}_latent_value for Monte Carlo estimation in ELBO.</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a><span class="sd">    For actual prediction tasks, use the forward() function, which will use means of variational</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a><span class="sd">    distributions for user and item latents.</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a><span class="sd">        batch (ChoiceDataset): a ChoiceDataset object containing relevant information.</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a><span class="sd">        return_logit(bool): if set to True, return the logit/utility, otherwise return the log-probability.</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a><span class="sd">        sample_dict(Dict[str, torch.Tensor]): Monte Carlo samples for model coefficients</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a><span class="sd">            (i.e., those Greek letters).</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a><span class="sd">            sample_dict.keys() should be the same as keys of self.obs2prior_dict, i.e., those</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a><span class="sd">            greek letters actually enter the functional form of utility.</span>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a><span class="sd">            The value of sample_dict should be tensors of shape (num_seeds, num_classes, dim)</span>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a><span class="sd">            where num_classes in {num_users, num_items, 1}</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a><span class="sd">            and dim in {latent_dim(K), num_item_obs, num_user_obs, 1}.</span>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a><span class="sd">        torch.Tensor: a tensor of shape (num_seeds, len(batch)), where</span>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a><span class="sd">            out[x, y] is the probabilities of choosing item batch.item[y] in session y</span>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a><span class="sd">            conditioned on latents to be the x-th Monte Carlo sample.</span>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a>    <span class="n">num_seeds</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">sample_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a>
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a>    <span class="c1"># get category id of the item bought in each row of batch.</span>
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a>    <span class="n">cate_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_to_category_tensor</span><span class="p">[</span><span class="n">batch</span><span class="o">.</span><span class="n">item_index</span><span class="p">]</span>
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a>
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a>    <span class="c1"># get item ids of all items from the same category of each item bought.</span>
<a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a>    <span class="n">relevant_item_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">category_to_item_tensor</span><span class="p">[</span><span class="n">cate_index</span><span class="p">,</span> <span class="p">:]</span>
<a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a>    <span class="n">relevant_item_index</span> <span class="o">=</span> <span class="n">relevant_item_index</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,)</span>
<a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a>    <span class="c1"># index were padded with -1&#39;s, drop those dummy entries.</span>
<a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a>    <span class="n">relevant_item_index</span> <span class="o">=</span> <span class="n">relevant_item_index</span><span class="p">[</span><span class="n">relevant_item_index</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<a id="__codelineno-0-40" name="__codelineno-0-40" href="#__codelineno-0-40"></a>
<a id="__codelineno-0-41" name="__codelineno-0-41" href="#__codelineno-0-41"></a>    <span class="c1"># the first repeats[0] entries in relevant_item_index are for the category of item_index[0]</span>
<a id="__codelineno-0-42" name="__codelineno-0-42" href="#__codelineno-0-42"></a>    <span class="n">repeats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">category_to_size_tensor</span><span class="p">[</span><span class="n">cate_index</span><span class="p">]</span>
<a id="__codelineno-0-43" name="__codelineno-0-43" href="#__codelineno-0-43"></a>    <span class="c1"># argwhere(reverse_indices == k) are positions in relevant_item_index for the category of item_index[k].</span>
<a id="__codelineno-0-44" name="__codelineno-0-44" href="#__codelineno-0-44"></a>    <span class="n">reverse_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span>
<a id="__codelineno-0-45" name="__codelineno-0-45" href="#__codelineno-0-45"></a>        <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">repeats</span><span class="p">)</span>
<a id="__codelineno-0-46" name="__codelineno-0-46" href="#__codelineno-0-46"></a>    <span class="c1"># expand the user_index and session_index.</span>
<a id="__codelineno-0-47" name="__codelineno-0-47" href="#__codelineno-0-47"></a>    <span class="n">user_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">user_index</span><span class="p">,</span> <span class="n">repeats</span><span class="p">)</span>
<a id="__codelineno-0-48" name="__codelineno-0-48" href="#__codelineno-0-48"></a>    <span class="n">repeat_category_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">cate_index</span><span class="p">,</span> <span class="n">repeats</span><span class="p">)</span>
<a id="__codelineno-0-49" name="__codelineno-0-49" href="#__codelineno-0-49"></a>    <span class="n">session_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">session_index</span><span class="p">,</span> <span class="n">repeats</span><span class="p">)</span>
<a id="__codelineno-0-50" name="__codelineno-0-50" href="#__codelineno-0-50"></a>    <span class="c1"># duplicate the item focused to match.</span>
<a id="__codelineno-0-51" name="__codelineno-0-51" href="#__codelineno-0-51"></a>    <span class="n">item_index_expanded</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span>
<a id="__codelineno-0-52" name="__codelineno-0-52" href="#__codelineno-0-52"></a>        <span class="n">batch</span><span class="o">.</span><span class="n">item_index</span><span class="p">,</span> <span class="n">repeats</span><span class="p">)</span>
<a id="__codelineno-0-53" name="__codelineno-0-53" href="#__codelineno-0-53"></a>
<a id="__codelineno-0-54" name="__codelineno-0-54" href="#__codelineno-0-54"></a>    <span class="c1"># short-hands for easier shape check.</span>
<a id="__codelineno-0-55" name="__codelineno-0-55" href="#__codelineno-0-55"></a>    <span class="n">R</span> <span class="o">=</span> <span class="n">num_seeds</span>
<a id="__codelineno-0-56" name="__codelineno-0-56" href="#__codelineno-0-56"></a>    <span class="c1"># total number of relevant items.</span>
<a id="__codelineno-0-57" name="__codelineno-0-57" href="#__codelineno-0-57"></a>    <span class="n">total_computation</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">session_index</span><span class="p">)</span>
<a id="__codelineno-0-58" name="__codelineno-0-58" href="#__codelineno-0-58"></a>    <span class="n">S</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_sessions</span>
<a id="__codelineno-0-59" name="__codelineno-0-59" href="#__codelineno-0-59"></a>    <span class="n">U</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_users</span>
<a id="__codelineno-0-60" name="__codelineno-0-60" href="#__codelineno-0-60"></a>    <span class="n">I</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span>
<a id="__codelineno-0-61" name="__codelineno-0-61" href="#__codelineno-0-61"></a>    <span class="n">NC</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_categories</span>
<a id="__codelineno-0-62" name="__codelineno-0-62" href="#__codelineno-0-62"></a>    <span class="c1"># ==========================================================================================</span>
<a id="__codelineno-0-63" name="__codelineno-0-63" href="#__codelineno-0-63"></a>    <span class="c1"># Helper Functions for Reshaping.</span>
<a id="__codelineno-0-64" name="__codelineno-0-64" href="#__codelineno-0-64"></a>    <span class="c1"># ==========================================================================================</span>
<a id="__codelineno-0-65" name="__codelineno-0-65" href="#__codelineno-0-65"></a>
<a id="__codelineno-0-66" name="__codelineno-0-66" href="#__codelineno-0-66"></a>    <span class="k">def</span> <span class="nf">reshape_coef_sample</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
<a id="__codelineno-0-67" name="__codelineno-0-67" href="#__codelineno-0-67"></a>        <span class="c1"># reshape the monte carlo sample of coefficients to (R, P, I, *).</span>
<a id="__codelineno-0-68" name="__codelineno-0-68" href="#__codelineno-0-68"></a>        <span class="k">if</span> <span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;_user&#39;</span><span class="p">):</span>
<a id="__codelineno-0-69" name="__codelineno-0-69" href="#__codelineno-0-69"></a>            <span class="c1"># (R, U, *) --&gt; (R, total_computation, *)</span>
<a id="__codelineno-0-70" name="__codelineno-0-70" href="#__codelineno-0-70"></a>            <span class="k">return</span> <span class="n">sample</span><span class="p">[:,</span> <span class="n">user_index</span><span class="p">,</span> <span class="p">:]</span>
<a id="__codelineno-0-71" name="__codelineno-0-71" href="#__codelineno-0-71"></a>        <span class="k">elif</span> <span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;_item&#39;</span><span class="p">):</span>
<a id="__codelineno-0-72" name="__codelineno-0-72" href="#__codelineno-0-72"></a>            <span class="c1"># (R, I, *) --&gt; (R, total_computation, *)</span>
<a id="__codelineno-0-73" name="__codelineno-0-73" href="#__codelineno-0-73"></a>            <span class="k">return</span> <span class="n">sample</span><span class="p">[:,</span> <span class="n">relevant_item_index</span><span class="p">,</span> <span class="p">:]</span>
<a id="__codelineno-0-74" name="__codelineno-0-74" href="#__codelineno-0-74"></a>        <span class="k">elif</span> <span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;_category&#39;</span><span class="p">):</span>
<a id="__codelineno-0-75" name="__codelineno-0-75" href="#__codelineno-0-75"></a>            <span class="c1"># (R, NC, *) --&gt; (R, total_computation, *)</span>
<a id="__codelineno-0-76" name="__codelineno-0-76" href="#__codelineno-0-76"></a>            <span class="k">return</span> <span class="n">sample</span><span class="p">[:,</span> <span class="n">repeat_category_index</span><span class="p">,</span> <span class="p">:]</span>
<a id="__codelineno-0-77" name="__codelineno-0-77" href="#__codelineno-0-77"></a>        <span class="k">elif</span> <span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;_constant&#39;</span><span class="p">):</span>
<a id="__codelineno-0-78" name="__codelineno-0-78" href="#__codelineno-0-78"></a>            <span class="c1"># (R, *) --&gt; (R, total_computation, *)</span>
<a id="__codelineno-0-79" name="__codelineno-0-79" href="#__codelineno-0-79"></a>            <span class="k">return</span> <span class="n">sample</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">total_computation</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-80" name="__codelineno-0-80" href="#__codelineno-0-80"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-81" name="__codelineno-0-81" href="#__codelineno-0-81"></a>            <span class="k">raise</span> <span class="ne">ValueError</span>
<a id="__codelineno-0-82" name="__codelineno-0-82" href="#__codelineno-0-82"></a>
<a id="__codelineno-0-83" name="__codelineno-0-83" href="#__codelineno-0-83"></a>    <span class="k">def</span> <span class="nf">reshape_observable</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
<a id="__codelineno-0-84" name="__codelineno-0-84" href="#__codelineno-0-84"></a>        <span class="c1"># reshape observable to (R, P, I, *) so that it can be multiplied with monte carlo</span>
<a id="__codelineno-0-85" name="__codelineno-0-85" href="#__codelineno-0-85"></a>        <span class="c1"># samples of coefficients.</span>
<a id="__codelineno-0-86" name="__codelineno-0-86" href="#__codelineno-0-86"></a>        <span class="n">O</span> <span class="o">=</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># number of observables.</span>
<a id="__codelineno-0-87" name="__codelineno-0-87" href="#__codelineno-0-87"></a>        <span class="k">assert</span> <span class="n">O</span> <span class="o">==</span> <span class="n">positive_integer</span>
<a id="__codelineno-0-88" name="__codelineno-0-88" href="#__codelineno-0-88"></a>        <span class="k">if</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;item_&#39;</span><span class="p">):</span>
<a id="__codelineno-0-89" name="__codelineno-0-89" href="#__codelineno-0-89"></a>            <span class="k">assert</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">O</span><span class="p">)</span>
<a id="__codelineno-0-90" name="__codelineno-0-90" href="#__codelineno-0-90"></a>            <span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span><span class="p">[</span><span class="n">relevant_item_index</span><span class="p">,</span> <span class="p">:]</span>
<a id="__codelineno-0-91" name="__codelineno-0-91" href="#__codelineno-0-91"></a>        <span class="k">elif</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;user_&#39;</span><span class="p">):</span>
<a id="__codelineno-0-92" name="__codelineno-0-92" href="#__codelineno-0-92"></a>            <span class="k">assert</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">O</span><span class="p">)</span>
<a id="__codelineno-0-93" name="__codelineno-0-93" href="#__codelineno-0-93"></a>            <span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span><span class="p">[</span><span class="n">user_index</span><span class="p">,</span> <span class="p">:]</span>
<a id="__codelineno-0-94" name="__codelineno-0-94" href="#__codelineno-0-94"></a>        <span class="k">elif</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;session_&#39;</span><span class="p">):</span>
<a id="__codelineno-0-95" name="__codelineno-0-95" href="#__codelineno-0-95"></a>            <span class="k">assert</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">O</span><span class="p">)</span>
<a id="__codelineno-0-96" name="__codelineno-0-96" href="#__codelineno-0-96"></a>            <span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span><span class="p">[</span><span class="n">session_index</span><span class="p">,</span> <span class="p">:]</span>
<a id="__codelineno-0-97" name="__codelineno-0-97" href="#__codelineno-0-97"></a>        <span class="k">elif</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;price_&#39;</span><span class="p">):</span>
<a id="__codelineno-0-98" name="__codelineno-0-98" href="#__codelineno-0-98"></a>            <span class="k">assert</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">O</span><span class="p">)</span>
<a id="__codelineno-0-99" name="__codelineno-0-99" href="#__codelineno-0-99"></a>            <span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span><span class="p">[</span><span class="n">session_index</span><span class="p">,</span> <span class="n">relevant_item_index</span><span class="p">,</span> <span class="p">:]</span>
<a id="__codelineno-0-100" name="__codelineno-0-100" href="#__codelineno-0-100"></a>        <span class="k">elif</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;taste_&#39;</span><span class="p">):</span>
<a id="__codelineno-0-101" name="__codelineno-0-101" href="#__codelineno-0-101"></a>            <span class="k">assert</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">O</span><span class="p">)</span>
<a id="__codelineno-0-102" name="__codelineno-0-102" href="#__codelineno-0-102"></a>            <span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span><span class="p">[</span><span class="n">user_index</span><span class="p">,</span> <span class="n">relevant_item_index</span><span class="p">,</span> <span class="p">:]</span>
<a id="__codelineno-0-103" name="__codelineno-0-103" href="#__codelineno-0-103"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-104" name="__codelineno-0-104" href="#__codelineno-0-104"></a>            <span class="k">raise</span> <span class="ne">ValueError</span>
<a id="__codelineno-0-105" name="__codelineno-0-105" href="#__codelineno-0-105"></a>        <span class="k">assert</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">total_computation</span><span class="p">,</span> <span class="n">O</span><span class="p">)</span>
<a id="__codelineno-0-106" name="__codelineno-0-106" href="#__codelineno-0-106"></a>        <span class="k">return</span> <span class="n">obs</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-107" name="__codelineno-0-107" href="#__codelineno-0-107"></a>
<a id="__codelineno-0-108" name="__codelineno-0-108" href="#__codelineno-0-108"></a>    <span class="c1"># ==========================================================================================</span>
<a id="__codelineno-0-109" name="__codelineno-0-109" href="#__codelineno-0-109"></a>    <span class="c1"># Compute Components related to users and items only.</span>
<a id="__codelineno-0-110" name="__codelineno-0-110" href="#__codelineno-0-110"></a>    <span class="c1"># ==========================================================================================</span>
<a id="__codelineno-0-111" name="__codelineno-0-111" href="#__codelineno-0-111"></a>    <span class="n">utility</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">total_computation</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-112" name="__codelineno-0-112" href="#__codelineno-0-112"></a>
<a id="__codelineno-0-113" name="__codelineno-0-113" href="#__codelineno-0-113"></a>    <span class="c1"># loop over additive term to utility</span>
<a id="__codelineno-0-114" name="__codelineno-0-114" href="#__codelineno-0-114"></a>    <span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">formula</span><span class="p">:</span>
<a id="__codelineno-0-115" name="__codelineno-0-115" href="#__codelineno-0-115"></a>        <span class="c1"># Type I: single coefficient, e.g., lambda_item or lambda_user.</span>
<a id="__codelineno-0-116" name="__codelineno-0-116" href="#__codelineno-0-116"></a>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;observable&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-117" name="__codelineno-0-117" href="#__codelineno-0-117"></a>            <span class="c1"># E.g., lambda_item or lambda_user</span>
<a id="__codelineno-0-118" name="__codelineno-0-118" href="#__codelineno-0-118"></a>            <span class="n">coef_name</span> <span class="o">=</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-119" name="__codelineno-0-119" href="#__codelineno-0-119"></a>            <span class="n">coef_sample</span> <span class="o">=</span> <span class="n">reshape_coef_sample</span><span class="p">(</span>
<a id="__codelineno-0-120" name="__codelineno-0-120" href="#__codelineno-0-120"></a>                <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">],</span> <span class="n">coef_name</span><span class="p">)</span>
<a id="__codelineno-0-121" name="__codelineno-0-121" href="#__codelineno-0-121"></a>            <span class="k">assert</span> <span class="n">coef_sample</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">total_computation</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-122" name="__codelineno-0-122" href="#__codelineno-0-122"></a>            <span class="n">additive_term</span> <span class="o">=</span> <span class="n">coef_sample</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">total_computation</span><span class="p">)</span>
<a id="__codelineno-0-123" name="__codelineno-0-123" href="#__codelineno-0-123"></a>
<a id="__codelineno-0-124" name="__codelineno-0-124" href="#__codelineno-0-124"></a>        <span class="c1"># Type II: factorized coefficient, e.g., &lt;theta_user, lambda_item&gt;.</span>
<a id="__codelineno-0-125" name="__codelineno-0-125" href="#__codelineno-0-125"></a>        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;observable&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-126" name="__codelineno-0-126" href="#__codelineno-0-126"></a>            <span class="n">coef_name_0</span> <span class="o">=</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-127" name="__codelineno-0-127" href="#__codelineno-0-127"></a>            <span class="n">coef_name_1</span> <span class="o">=</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
<a id="__codelineno-0-128" name="__codelineno-0-128" href="#__codelineno-0-128"></a>
<a id="__codelineno-0-129" name="__codelineno-0-129" href="#__codelineno-0-129"></a>            <span class="n">coef_sample_0</span> <span class="o">=</span> <span class="n">reshape_coef_sample</span><span class="p">(</span>
<a id="__codelineno-0-130" name="__codelineno-0-130" href="#__codelineno-0-130"></a>                <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name_0</span><span class="p">],</span> <span class="n">coef_name_0</span><span class="p">)</span>
<a id="__codelineno-0-131" name="__codelineno-0-131" href="#__codelineno-0-131"></a>            <span class="n">coef_sample_1</span> <span class="o">=</span> <span class="n">reshape_coef_sample</span><span class="p">(</span>
<a id="__codelineno-0-132" name="__codelineno-0-132" href="#__codelineno-0-132"></a>                <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name_1</span><span class="p">],</span> <span class="n">coef_name_1</span><span class="p">)</span>
<a id="__codelineno-0-133" name="__codelineno-0-133" href="#__codelineno-0-133"></a>
<a id="__codelineno-0-134" name="__codelineno-0-134" href="#__codelineno-0-134"></a>            <span class="k">assert</span> <span class="n">coef_sample_0</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">coef_sample_1</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span>
<a id="__codelineno-0-135" name="__codelineno-0-135" href="#__codelineno-0-135"></a>                <span class="n">R</span><span class="p">,</span> <span class="n">total_computation</span><span class="p">,</span> <span class="n">positive_integer</span><span class="p">)</span>
<a id="__codelineno-0-136" name="__codelineno-0-136" href="#__codelineno-0-136"></a>
<a id="__codelineno-0-137" name="__codelineno-0-137" href="#__codelineno-0-137"></a>            <span class="n">additive_term</span> <span class="o">=</span> <span class="p">(</span><span class="n">coef_sample_0</span> <span class="o">*</span> <span class="n">coef_sample_1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-138" name="__codelineno-0-138" href="#__codelineno-0-138"></a>
<a id="__codelineno-0-139" name="__codelineno-0-139" href="#__codelineno-0-139"></a>        <span class="c1"># Type III: single coefficient multiplied by observable, e.g., theta_user * x_obs_item.</span>
<a id="__codelineno-0-140" name="__codelineno-0-140" href="#__codelineno-0-140"></a>        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;observable&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-141" name="__codelineno-0-141" href="#__codelineno-0-141"></a>            <span class="n">coef_name</span> <span class="o">=</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-142" name="__codelineno-0-142" href="#__codelineno-0-142"></a>            <span class="n">coef_sample</span> <span class="o">=</span> <span class="n">reshape_coef_sample</span><span class="p">(</span>
<a id="__codelineno-0-143" name="__codelineno-0-143" href="#__codelineno-0-143"></a>                <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">],</span> <span class="n">coef_name</span><span class="p">)</span>
<a id="__codelineno-0-144" name="__codelineno-0-144" href="#__codelineno-0-144"></a>            <span class="k">assert</span> <span class="n">coef_sample</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span>
<a id="__codelineno-0-145" name="__codelineno-0-145" href="#__codelineno-0-145"></a>                <span class="n">R</span><span class="p">,</span> <span class="n">total_computation</span><span class="p">,</span> <span class="n">positive_integer</span><span class="p">)</span>
<a id="__codelineno-0-146" name="__codelineno-0-146" href="#__codelineno-0-146"></a>
<a id="__codelineno-0-147" name="__codelineno-0-147" href="#__codelineno-0-147"></a>            <span class="n">obs_name</span> <span class="o">=</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;observable&#39;</span><span class="p">]</span>
<a id="__codelineno-0-148" name="__codelineno-0-148" href="#__codelineno-0-148"></a>            <span class="n">obs</span> <span class="o">=</span> <span class="n">reshape_observable</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">obs_name</span><span class="p">),</span> <span class="n">obs_name</span><span class="p">)</span>
<a id="__codelineno-0-149" name="__codelineno-0-149" href="#__codelineno-0-149"></a>            <span class="k">assert</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">total_computation</span><span class="p">,</span> <span class="n">positive_integer</span><span class="p">)</span>
<a id="__codelineno-0-150" name="__codelineno-0-150" href="#__codelineno-0-150"></a>
<a id="__codelineno-0-151" name="__codelineno-0-151" href="#__codelineno-0-151"></a>            <span class="n">additive_term</span> <span class="o">=</span> <span class="p">(</span><span class="n">coef_sample</span> <span class="o">*</span> <span class="n">obs</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-152" name="__codelineno-0-152" href="#__codelineno-0-152"></a>
<a id="__codelineno-0-153" name="__codelineno-0-153" href="#__codelineno-0-153"></a>        <span class="c1"># Type IV: factorized coefficient multiplied by observable.</span>
<a id="__codelineno-0-154" name="__codelineno-0-154" href="#__codelineno-0-154"></a>        <span class="c1"># e.g., gamma_user * beta_item * price_obs.</span>
<a id="__codelineno-0-155" name="__codelineno-0-155" href="#__codelineno-0-155"></a>        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;observable&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-156" name="__codelineno-0-156" href="#__codelineno-0-156"></a>            <span class="n">coef_name_0</span><span class="p">,</span> <span class="n">coef_name_1</span> <span class="o">=</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
<a id="__codelineno-0-157" name="__codelineno-0-157" href="#__codelineno-0-157"></a>            <span class="n">coef_sample_0</span> <span class="o">=</span> <span class="n">reshape_coef_sample</span><span class="p">(</span>
<a id="__codelineno-0-158" name="__codelineno-0-158" href="#__codelineno-0-158"></a>                <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name_0</span><span class="p">],</span> <span class="n">coef_name_0</span><span class="p">)</span>
<a id="__codelineno-0-159" name="__codelineno-0-159" href="#__codelineno-0-159"></a>            <span class="n">coef_sample_1</span> <span class="o">=</span> <span class="n">reshape_coef_sample</span><span class="p">(</span>
<a id="__codelineno-0-160" name="__codelineno-0-160" href="#__codelineno-0-160"></a>                <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name_1</span><span class="p">],</span> <span class="n">coef_name_1</span><span class="p">)</span>
<a id="__codelineno-0-161" name="__codelineno-0-161" href="#__codelineno-0-161"></a>            <span class="k">assert</span> <span class="n">coef_sample_0</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">coef_sample_1</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span>
<a id="__codelineno-0-162" name="__codelineno-0-162" href="#__codelineno-0-162"></a>                <span class="n">R</span><span class="p">,</span> <span class="n">total_computation</span><span class="p">,</span> <span class="n">positive_integer</span><span class="p">)</span>
<a id="__codelineno-0-163" name="__codelineno-0-163" href="#__codelineno-0-163"></a>            <span class="n">num_obs_times_latent_dim</span> <span class="o">=</span> <span class="n">coef_sample_0</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<a id="__codelineno-0-164" name="__codelineno-0-164" href="#__codelineno-0-164"></a>
<a id="__codelineno-0-165" name="__codelineno-0-165" href="#__codelineno-0-165"></a>            <span class="n">obs_name</span> <span class="o">=</span> <span class="n">term</span><span class="p">[</span><span class="s1">&#39;observable&#39;</span><span class="p">]</span>
<a id="__codelineno-0-166" name="__codelineno-0-166" href="#__codelineno-0-166"></a>            <span class="n">obs</span> <span class="o">=</span> <span class="n">reshape_observable</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">obs_name</span><span class="p">),</span> <span class="n">obs_name</span><span class="p">)</span>
<a id="__codelineno-0-167" name="__codelineno-0-167" href="#__codelineno-0-167"></a>            <span class="k">assert</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">total_computation</span><span class="p">,</span> <span class="n">positive_integer</span><span class="p">)</span>
<a id="__codelineno-0-168" name="__codelineno-0-168" href="#__codelineno-0-168"></a>            <span class="n">num_obs</span> <span class="o">=</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># number of observables.</span>
<a id="__codelineno-0-169" name="__codelineno-0-169" href="#__codelineno-0-169"></a>
<a id="__codelineno-0-170" name="__codelineno-0-170" href="#__codelineno-0-170"></a>            <span class="k">assert</span> <span class="p">(</span><span class="n">num_obs_times_latent_dim</span> <span class="o">%</span> <span class="n">num_obs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>
<a id="__codelineno-0-171" name="__codelineno-0-171" href="#__codelineno-0-171"></a>            <span class="n">latent_dim</span> <span class="o">=</span> <span class="n">num_obs_times_latent_dim</span> <span class="o">//</span> <span class="n">num_obs</span>
<a id="__codelineno-0-172" name="__codelineno-0-172" href="#__codelineno-0-172"></a>
<a id="__codelineno-0-173" name="__codelineno-0-173" href="#__codelineno-0-173"></a>            <span class="n">coef_sample_0</span> <span class="o">=</span> <span class="n">coef_sample_0</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
<a id="__codelineno-0-174" name="__codelineno-0-174" href="#__codelineno-0-174"></a>                <span class="n">R</span><span class="p">,</span> <span class="n">total_computation</span><span class="p">,</span> <span class="n">num_obs</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>
<a id="__codelineno-0-175" name="__codelineno-0-175" href="#__codelineno-0-175"></a>            <span class="n">coef_sample_1</span> <span class="o">=</span> <span class="n">coef_sample_1</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
<a id="__codelineno-0-176" name="__codelineno-0-176" href="#__codelineno-0-176"></a>                <span class="n">R</span><span class="p">,</span> <span class="n">total_computation</span><span class="p">,</span> <span class="n">num_obs</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>
<a id="__codelineno-0-177" name="__codelineno-0-177" href="#__codelineno-0-177"></a>            <span class="c1"># compute the factorized coefficient with shape (R, P, I, O).</span>
<a id="__codelineno-0-178" name="__codelineno-0-178" href="#__codelineno-0-178"></a>            <span class="n">coef</span> <span class="o">=</span> <span class="p">(</span><span class="n">coef_sample_0</span> <span class="o">*</span> <span class="n">coef_sample_1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-179" name="__codelineno-0-179" href="#__codelineno-0-179"></a>
<a id="__codelineno-0-180" name="__codelineno-0-180" href="#__codelineno-0-180"></a>            <span class="n">additive_term</span> <span class="o">=</span> <span class="p">(</span><span class="n">coef</span> <span class="o">*</span> <span class="n">obs</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-181" name="__codelineno-0-181" href="#__codelineno-0-181"></a>
<a id="__codelineno-0-182" name="__codelineno-0-182" href="#__codelineno-0-182"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-183" name="__codelineno-0-183" href="#__codelineno-0-183"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Undefined term type: </span><span class="si">{</span><span class="n">term</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<a id="__codelineno-0-184" name="__codelineno-0-184" href="#__codelineno-0-184"></a>
<a id="__codelineno-0-185" name="__codelineno-0-185" href="#__codelineno-0-185"></a>        <span class="k">assert</span> <span class="n">additive_term</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">total_computation</span><span class="p">)</span>
<a id="__codelineno-0-186" name="__codelineno-0-186" href="#__codelineno-0-186"></a>        <span class="n">utility</span> <span class="o">+=</span> <span class="n">additive_term</span>
<a id="__codelineno-0-187" name="__codelineno-0-187" href="#__codelineno-0-187"></a>
<a id="__codelineno-0-188" name="__codelineno-0-188" href="#__codelineno-0-188"></a>    <span class="c1"># ==========================================================================================</span>
<a id="__codelineno-0-189" name="__codelineno-0-189" href="#__codelineno-0-189"></a>    <span class="c1"># Mask Out Unavailable Items in Each Session.</span>
<a id="__codelineno-0-190" name="__codelineno-0-190" href="#__codelineno-0-190"></a>    <span class="c1"># ==========================================================================================</span>
<a id="__codelineno-0-191" name="__codelineno-0-191" href="#__codelineno-0-191"></a>
<a id="__codelineno-0-192" name="__codelineno-0-192" href="#__codelineno-0-192"></a>    <span class="k">if</span> <span class="n">batch</span><span class="o">.</span><span class="n">item_availability</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-193" name="__codelineno-0-193" href="#__codelineno-0-193"></a>        <span class="c1"># expand to the Monte Carlo sample dimension.</span>
<a id="__codelineno-0-194" name="__codelineno-0-194" href="#__codelineno-0-194"></a>        <span class="n">A</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">item_availability</span><span class="p">[</span><span class="n">session_index</span><span class="p">,</span> <span class="n">relevant_item_index</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span>
<a id="__codelineno-0-195" name="__codelineno-0-195" href="#__codelineno-0-195"></a>            <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-196" name="__codelineno-0-196" href="#__codelineno-0-196"></a>        <span class="n">utility</span><span class="p">[</span><span class="o">~</span><span class="n">A</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">utility</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">max</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-0-197" name="__codelineno-0-197" href="#__codelineno-0-197"></a>
<a id="__codelineno-0-198" name="__codelineno-0-198" href="#__codelineno-0-198"></a>    <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">additional_modules</span><span class="p">:</span>
<a id="__codelineno-0-199" name="__codelineno-0-199" href="#__codelineno-0-199"></a>        <span class="c1"># current utility shape: (R, total_computation)</span>
<a id="__codelineno-0-200" name="__codelineno-0-200" href="#__codelineno-0-200"></a>        <span class="n">additive_term</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
<a id="__codelineno-0-201" name="__codelineno-0-201" href="#__codelineno-0-201"></a>        <span class="k">assert</span> <span class="n">additive_term</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span>
<a id="__codelineno-0-202" name="__codelineno-0-202" href="#__codelineno-0-202"></a>            <span class="n">R</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">))</span> <span class="ow">or</span> <span class="n">additive_term</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-203" name="__codelineno-0-203" href="#__codelineno-0-203"></a>        <span class="k">if</span> <span class="n">additive_term</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="mi">1</span><span class="p">):</span>
<a id="__codelineno-0-204" name="__codelineno-0-204" href="#__codelineno-0-204"></a>            <span class="c1"># TODO: need to make this consistent with log_likelihood_all.</span>
<a id="__codelineno-0-205" name="__codelineno-0-205" href="#__codelineno-0-205"></a>            <span class="c1"># be tolerant for some customized module with BayesianLinear that returns (R, len(batch), 1).</span>
<a id="__codelineno-0-206" name="__codelineno-0-206" href="#__codelineno-0-206"></a>            <span class="n">additive_term</span> <span class="o">=</span> <span class="n">additive_term</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">))</span>
<a id="__codelineno-0-207" name="__codelineno-0-207" href="#__codelineno-0-207"></a>        <span class="c1"># expand to total number of computation, query by reverse_indices.</span>
<a id="__codelineno-0-208" name="__codelineno-0-208" href="#__codelineno-0-208"></a>        <span class="c1"># reverse_indices has length total_computation, and reverse_indices[i] correspond to the row-id that this</span>
<a id="__codelineno-0-209" name="__codelineno-0-209" href="#__codelineno-0-209"></a>        <span class="c1"># computation is responsible for.</span>
<a id="__codelineno-0-210" name="__codelineno-0-210" href="#__codelineno-0-210"></a>        <span class="n">additive_term</span> <span class="o">=</span> <span class="n">additive_term</span><span class="p">[:,</span> <span class="n">reverse_indices</span><span class="p">]</span>
<a id="__codelineno-0-211" name="__codelineno-0-211" href="#__codelineno-0-211"></a>        <span class="k">assert</span> <span class="n">additive_term</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">total_computation</span><span class="p">)</span>
<a id="__codelineno-0-212" name="__codelineno-0-212" href="#__codelineno-0-212"></a>
<a id="__codelineno-0-213" name="__codelineno-0-213" href="#__codelineno-0-213"></a>    <span class="k">if</span> <span class="n">return_logit</span><span class="p">:</span>
<a id="__codelineno-0-214" name="__codelineno-0-214" href="#__codelineno-0-214"></a>        <span class="c1"># (num_seeds, len(batch))</span>
<a id="__codelineno-0-215" name="__codelineno-0-215" href="#__codelineno-0-215"></a>        <span class="n">u</span> <span class="o">=</span> <span class="n">utility</span><span class="p">[:,</span> <span class="n">item_index_expanded</span> <span class="o">==</span> <span class="n">relevant_item_index</span><span class="p">]</span>
<a id="__codelineno-0-216" name="__codelineno-0-216" href="#__codelineno-0-216"></a>        <span class="k">assert</span> <span class="n">u</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">))</span>
<a id="__codelineno-0-217" name="__codelineno-0-217" href="#__codelineno-0-217"></a>        <span class="k">return</span> <span class="n">u</span>
<a id="__codelineno-0-218" name="__codelineno-0-218" href="#__codelineno-0-218"></a>
<a id="__codelineno-0-219" name="__codelineno-0-219" href="#__codelineno-0-219"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pred_item</span><span class="p">:</span>
<a id="__codelineno-0-220" name="__codelineno-0-220" href="#__codelineno-0-220"></a>        <span class="c1"># compute log likelihood log p(choosing item i | user, item latents)</span>
<a id="__codelineno-0-221" name="__codelineno-0-221" href="#__codelineno-0-221"></a>        <span class="c1"># compute the log probability from logits/utilities.</span>
<a id="__codelineno-0-222" name="__codelineno-0-222" href="#__codelineno-0-222"></a>        <span class="c1"># output shape: (num_seeds, len(batch), num_items)</span>
<a id="__codelineno-0-223" name="__codelineno-0-223" href="#__codelineno-0-223"></a>        <span class="n">log_p</span> <span class="o">=</span> <span class="n">scatter_log_softmax</span><span class="p">(</span><span class="n">utility</span><span class="p">,</span> <span class="n">reverse_indices</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-224" name="__codelineno-0-224" href="#__codelineno-0-224"></a>        <span class="c1"># select the log-P of the item actually bought.</span>
<a id="__codelineno-0-225" name="__codelineno-0-225" href="#__codelineno-0-225"></a>        <span class="n">log_p</span> <span class="o">=</span> <span class="n">log_p</span><span class="p">[:,</span> <span class="n">item_index_expanded</span> <span class="o">==</span> <span class="n">relevant_item_index</span><span class="p">]</span>
<a id="__codelineno-0-226" name="__codelineno-0-226" href="#__codelineno-0-226"></a>        <span class="k">assert</span> <span class="n">log_p</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">))</span>
<a id="__codelineno-0-227" name="__codelineno-0-227" href="#__codelineno-0-227"></a>        <span class="k">return</span> <span class="n">log_p</span>
<a id="__codelineno-0-228" name="__codelineno-0-228" href="#__codelineno-0-228"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-229" name="__codelineno-0-229" href="#__codelineno-0-229"></a>        <span class="c1"># This is the binomial choice situation in which case we just report sigmoid log likelihood</span>
<a id="__codelineno-0-230" name="__codelineno-0-230" href="#__codelineno-0-230"></a>        <span class="n">utility</span> <span class="o">=</span> <span class="n">utility</span><span class="p">[:,</span> <span class="n">item_index_expanded</span> <span class="o">==</span> <span class="n">relevant_item_index</span><span class="p">]</span>
<a id="__codelineno-0-231" name="__codelineno-0-231" href="#__codelineno-0-231"></a>        <span class="k">assert</span> <span class="n">utility</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">))</span>
<a id="__codelineno-0-232" name="__codelineno-0-232" href="#__codelineno-0-232"></a>        <span class="n">bce</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
<a id="__codelineno-0-233" name="__codelineno-0-233" href="#__codelineno-0-233"></a>        <span class="c1"># make num_seeds copies of the label, expand to (R, len(batch))</span>
<a id="__codelineno-0-234" name="__codelineno-0-234" href="#__codelineno-0-234"></a>        <span class="n">label_expanded</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">label</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">))</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-235" name="__codelineno-0-235" href="#__codelineno-0-235"></a>        <span class="k">assert</span> <span class="n">label_expanded</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">))</span>
<a id="__codelineno-0-236" name="__codelineno-0-236" href="#__codelineno-0-236"></a>        <span class="n">log_p</span> <span class="o">=</span> <span class="o">-</span> <span class="n">bce</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">utility</span><span class="p">),</span> <span class="n">label_expanded</span><span class="p">)</span>
<a id="__codelineno-0-237" name="__codelineno-0-237" href="#__codelineno-0-237"></a>        <span class="k">assert</span> <span class="n">log_p</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">))</span>
<a id="__codelineno-0-238" name="__codelineno-0-238" href="#__codelineno-0-238"></a>        <span class="k">return</span> <span class="n">log_p</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="bemb.model.bemb.BEMBFlex.log_prior" class="doc doc-heading">
<code class="highlight language-python"><span class="n">log_prior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">sample_dict</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>Calculates the log-likelihood of Monte Carlo samples of Bayesian coefficients under their
prior distribution. This method assume coefficients are statistically independent.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>batch</code></td>
        <td><code>ChoiceDataset</code></td>
        <td><p>a dataset object contains observables for computing the prior distribution
if obs2prior is True.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>sample_dict</code></td>
        <td><code>Dict[str, torch.Tensor]</code></td>
        <td><p>a dictionary coefficient names to Monte Carlo samples.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>[description]</p></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>torch.scalar_tensor</code></td>
      <td><p>a tensor with shape (num_seeds,) of [ log P_{prior_distribution}(param[i]) ],
    where param[i] is the i-th Monte Carlo sample.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>bemb/model/bemb.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="nf">log_prior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">ChoiceDataset</span><span class="p">,</span> <span class="n">sample_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="sd">&quot;&quot;&quot;Calculates the log-likelihood of Monte Carlo samples of Bayesian coefficients under their</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="sd">    prior distribution. This method assume coefficients are statistically independent.</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="sd">        batch (ChoiceDataset): a dataset object contains observables for computing the prior distribution</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="sd">            if obs2prior is True.</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="sd">        sample_dict (Dict[str, torch.Tensor]): a dictionary coefficient names to Monte Carlo samples.</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a><span class="sd">    Raises:</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a><span class="sd">        ValueError: [description]</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a><span class="sd">        torch.scalar_tensor: a tensor with shape (num_seeds,) of [ log P_{prior_distribution}(param[i]) ],</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a><span class="sd">            where param[i] is the i-th Monte Carlo sample.</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>    <span class="c1"># assert sample_dict.keys() == self.coef_dict.keys()</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>    <span class="n">num_seeds</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">sample_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>    <span class="n">total</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_seeds</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>    <span class="k">for</span> <span class="n">coef_name</span><span class="p">,</span> <span class="n">coef</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">obs2prior_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">]:</span>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>            <span class="k">if</span> <span class="n">coef_name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;_item&#39;</span><span class="p">):</span>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a>                <span class="n">x_obs</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">item_obs</span>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a>            <span class="k">elif</span> <span class="n">coef_name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;_user&#39;</span><span class="p">):</span>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a>                <span class="n">x_obs</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">user_obs</span>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a>                    <span class="sa">f</span><span class="s1">&#39;No observable found to support obs2prior for </span><span class="si">{</span><span class="n">coef_name</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span>
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a>
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a>            <span class="n">total</span> <span class="o">+=</span> <span class="n">coef</span><span class="o">.</span><span class="n">log_prior</span><span class="p">(</span><span class="n">sample</span><span class="o">=</span><span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">],</span>
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a>                                    <span class="n">H_sample</span><span class="o">=</span><span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name</span> <span class="o">+</span> <span class="s1">&#39;.H&#39;</span><span class="p">],</span>
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a>                                    <span class="n">x_obs</span><span class="o">=</span><span class="n">x_obs</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a>            <span class="c1"># log_prob outputs (num_seeds, num_{items, users}), sum to (num_seeds).</span>
<a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a>            <span class="n">total</span> <span class="o">+=</span> <span class="n">coef</span><span class="o">.</span><span class="n">log_prior</span><span class="p">(</span>
<a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a>                <span class="n">sample</span><span class="o">=</span><span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">],</span> <span class="n">H_sample</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">x_obs</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a>
<a id="__codelineno-0-40" name="__codelineno-0-40" href="#__codelineno-0-40"></a>    <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">additional_modules</span><span class="p">:</span>
<a id="__codelineno-0-41" name="__codelineno-0-41" href="#__codelineno-0-41"></a>        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
<a id="__codelineno-0-42" name="__codelineno-0-42" href="#__codelineno-0-42"></a>        <span class="n">total</span> <span class="o">+=</span> <span class="n">module</span><span class="o">.</span><span class="n">log_prior</span><span class="p">()</span>
<a id="__codelineno-0-43" name="__codelineno-0-43" href="#__codelineno-0-43"></a>
<a id="__codelineno-0-44" name="__codelineno-0-44" href="#__codelineno-0-44"></a>    <span class="k">return</span> <span class="n">total</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="bemb.model.bemb.BEMBFlex.log_variational" class="doc doc-heading">
<code class="highlight language-python"><span class="n">log_variational</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_dict</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>Calculate the log-likelihood of samples in sample_dict under the current variational
distribution.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>sample_dict</code></td>
        <td><code>Dict[str, torch.Tensor]</code></td>
        <td><p>a dictionary coefficient names to Monte Carlo
samples.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>torch.Tensor</code></td>
      <td><p>a tensor of shape (num_seeds) of [ log P_{variational_distribution}(param[i]) ],
    where param[i] is the i-th Monte Carlo sample.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>bemb/model/bemb.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="nf">log_variational</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="sd">&quot;&quot;&quot;Calculate the log-likelihood of samples in sample_dict under the current variational</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="sd">    distribution.</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="sd">        sample_dict (Dict[str, torch.Tensor]):  a dictionary coefficient names to Monte Carlo</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="sd">            samples.</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a><span class="sd">        torch.Tensor: a tensor of shape (num_seeds) of [ log P_{variational_distribution}(param[i]) ],</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a><span class="sd">            where param[i] is the i-th Monte Carlo sample.</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>    <span class="n">num_seeds</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">sample_dict</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>    <span class="n">total</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_seeds</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>    <span class="k">for</span> <span class="n">coef_name</span><span class="p">,</span> <span class="n">coef</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>        <span class="c1"># log_prob outputs (num_seeds, num_{items, users}), sum to (num_seeds).</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>        <span class="n">total</span> <span class="o">+=</span> <span class="n">coef</span><span class="o">.</span><span class="n">log_variational</span><span class="p">(</span><span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>    <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">additional_modules</span><span class="p">:</span>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>        <span class="c1"># with shape (num_seeds,)</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>        <span class="n">total</span> <span class="o">+=</span> <span class="n">module</span><span class="o">.</span><span class="n">log_variational</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a>    <span class="k">return</span> <span class="n">total</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="bemb.model.bemb.BEMBFlex.posterior_distribution" class="doc doc-heading">
<code class="highlight language-python"><span class="n">posterior_distribution</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coef_name</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>Returns the posterior distribution of coefficient <code>coef_name</code>.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>coef_name</code></td>
        <td><code>str</code></td>
        <td><p>name of the coefficient to query.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>torch.Tensor</code></td>
      <td><p>variance of the estimated posterior distribution of <code>coef_name</code>.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>bemb/model/bemb.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="nf">posterior_distribution</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coef_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">lowrank_multivariate_normal</span><span class="o">.</span><span class="n">LowRankMultivariateNormal</span><span class="p">:</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="sd">&quot;&quot;&quot;Returns the posterior distribution of coefficient `coef_name`.</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="sd">        coef_name (str): name of the coefficient to query.</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="sd">        torch.Tensor: variance of the estimated posterior distribution of `coef_name`.</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>    <span class="k">if</span> <span class="n">coef_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">]</span><span class="o">.</span><span class="n">variational_distribution</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>        <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">coef_name</span><span class="si">}</span><span class="s1"> is not a valid coefficient name in </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">utility_formula</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="bemb.model.bemb.BEMBFlex.posterior_mean" class="doc doc-heading">
<code class="highlight language-python"><span class="n">posterior_mean</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coef_name</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>Returns the mean of estimated posterior distribution of coefficient <code>coef_name</code>.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>coef_name</code></td>
        <td><code>str</code></td>
        <td><p>name of the coefficient to query.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>torch.Tensor</code></td>
      <td><p>mean of the estimated posterior distribution of <code>coef_name</code>.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>bemb/model/bemb.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="nf">posterior_mean</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coef_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="sd">&quot;&quot;&quot;Returns the mean of estimated posterior distribution of coefficient `coef_name`.</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="sd">        coef_name (str): name of the coefficient to query.</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="sd">        torch.Tensor: mean of the estimated posterior distribution of `coef_name`.</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>    <span class="k">if</span> <span class="n">coef_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">]</span><span class="o">.</span><span class="n">variational_mean</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>        <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">coef_name</span><span class="si">}</span><span class="s1"> is not a valid coefficient name in </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">utility_formula</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="bemb.model.bemb.BEMBFlex.predict_proba" class="doc doc-heading">
<code class="highlight language-python"><span class="n">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>Draw prediction on a given batch of dataset.</p>
      <p>batch (ChoiceDataset): the dataset to draw inference on.</p>
      <p>torch.Tensor: the predicted probabilities for each class, the behavior varies by self.pred_item.
(1: pred_item == True) While predicting items, the return tensor has shape (len(batch), num_items), out[i, j] is the predicted probability for choosing item j AMONG ALL ITEMS IN ITS CATEGORY in observation i. Please note that since probabilities are computed from within-category normalization, hence out.sum(dim=0) can be greater than 1 if there are multiple categories.
(2: pred_item == False) While predicting external labels for each observations, out[i, 0] is the predicted probability for label == 0 on the i-th observation, out[i, 1] is the predicted probability for label == 1 on the i-th observation. Generally, out[i, 0] + out[i, 1] = 1.0. However, this could be false if under-flowing/over-flowing issue is encountered.</p>
<p>We highly recommend users to get log-probs as those are less prone to overflow/underflow; those can be accessed using the forward() function.</p>

        <details class="quote">
          <summary>Source code in <code>bemb/model/bemb.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">ChoiceDataset</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="sd">    Draw prediction on a given batch of dataset.</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="sd">    batch (ChoiceDataset): the dataset to draw inference on.</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a><span class="sd">    torch.Tensor: the predicted probabilities for each class, the behavior varies by self.pred_item.</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a><span class="sd">    (1: pred_item == True) While predicting items, the return tensor has shape (len(batch), num_items), out[i, j] is the predicted probability for choosing item j AMONG ALL ITEMS IN ITS CATEGORY in observation i. Please note that since probabilities are computed from within-category normalization, hence out.sum(dim=0) can be greater than 1 if there are multiple categories.</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a><span class="sd">    (2: pred_item == False) While predicting external labels for each observations, out[i, 0] is the predicted probability for label == 0 on the i-th observation, out[i, 1] is the predicted probability for label == 1 on the i-th observation. Generally, out[i, 0] + out[i, 1] = 1.0. However, this could be false if under-flowing/over-flowing issue is encountered.</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a><span class="sd">    We highly recommend users to get log-probs as those are less prone to overflow/underflow; those can be accessed using the forward() function.</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pred_item</span><span class="p">:</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>        <span class="c1"># (len(batch), num_items)</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>        <span class="n">log_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;log_prob&#39;</span><span class="p">,</span> <span class="n">return_scope</span><span class="o">=</span><span class="s1">&#39;all_items&#39;</span><span class="p">,</span> <span class="n">deterministic</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>        <span class="n">p</span> <span class="o">=</span> <span class="n">log_p</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>        <span class="c1"># (len(batch), num_items)</span>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>        <span class="c1"># probability of getting label = 1.</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>        <span class="n">p_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;utility&#39;</span><span class="p">,</span> <span class="n">return_scope</span><span class="o">=</span><span class="s1">&#39;all_items&#39;</span><span class="p">,</span> <span class="n">deterministic</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>        <span class="c1"># (len(batch), 1)</span>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a>        <span class="n">p_1</span> <span class="o">=</span> <span class="n">p_1</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)),</span> <span class="n">batch</span><span class="o">.</span><span class="n">item_index</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a>        <span class="n">p_0</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">p_1</span>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a>        <span class="c1"># (len(batch), 2)</span>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a>        <span class="n">p</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">p_0</span><span class="p">,</span> <span class="n">p_1</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a>
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pred_item</span><span class="p">:</span>
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a>        <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">)</span>
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a>        <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">)</span>
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a>
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a>    <span class="k">return</span> <span class="n">p</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="bemb.model.bemb.BEMBFlex.sample_choices" class="doc doc-heading">
<code class="highlight language-python"><span class="n">sample_choices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">debug</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_seeds</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>Samples choices given model paramaters and trips</p>
      <p>batch(ChoiceDataset): batch data containing trip information; item choice information is discarded
debug(bool): whether to print debug information</p>
      <p>Tuple[torch.Tensor]: sampled choices; shape: (batch_size, num_categories)</p>

        <details class="quote">
          <summary>Source code in <code>bemb/model/bemb.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="nf">sample_choices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span><span class="n">ChoiceDataset</span><span class="p">,</span> <span class="n">debug</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">num_seeds</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="sd">&quot;&quot;&quot;Samples choices given model paramaters and trips</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="sd">    batch(ChoiceDataset): batch data containing trip information; item choice information is discarded</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="sd">    debug(bool): whether to print debug information</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="sd">    Tuple[torch.Tensor]: sampled choices; shape: (batch_size, num_categories)</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    <span class="c1"># Use the means of variational distributions as the sole MC sample.</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>    <span class="n">sample_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>    <span class="k">for</span> <span class="n">coef_name</span><span class="p">,</span> <span class="n">coef</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>        <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">coef</span><span class="o">.</span><span class="n">variational_distribution</span><span class="o">.</span><span class="n">mean</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># (1, num_*, dim)</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>    <span class="c1"># sample_dict = self.sample_coefficient_dictionary(num_seeds)</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>    <span class="n">maxes</span><span class="p">,</span> <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_log_likelihoods</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">sample_dict</span><span class="p">)</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>    <span class="k">return</span> <span class="n">maxes</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">out</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="bemb.model.bemb.BEMBFlex.sample_coefficient_dictionary" class="doc doc-heading">
<code class="highlight language-python"><span class="n">sample_coefficient_dictionary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_seeds</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>A helper function to sample parameters from coefficients.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>num_seeds</code></td>
        <td><code>int</code></td>
        <td><p>number of random samples.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Dict[str, torch.Tensor]</code></td>
      <td><p>a dictionary maps coefficient names to tensor of sampled coefficient parameters,
    where the first dimension of the sampled tensor has size <code>num_seeds</code>.
    Each sample tensor has shape (num_seeds, num_classes, dim).</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>bemb/model/bemb.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="nf">sample_coefficient_dictionary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_seeds</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="sd">&quot;&quot;&quot;A helper function to sample parameters from coefficients.</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="sd">        num_seeds (int): number of random samples.</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="sd">        Dict[str, torch.Tensor]: a dictionary maps coefficient names to tensor of sampled coefficient parameters,</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="sd">            where the first dimension of the sampled tensor has size `num_seeds`.</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a><span class="sd">            Each sample tensor has shape (num_seeds, num_classes, dim).</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>    <span class="n">sample_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>    <span class="k">for</span> <span class="n">coef_name</span><span class="p">,</span> <span class="n">coef</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>        <span class="n">s</span> <span class="o">=</span> <span class="n">coef</span><span class="o">.</span><span class="n">rsample</span><span class="p">(</span><span class="n">num_seeds</span><span class="p">)</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>        <span class="k">if</span> <span class="n">coef</span><span class="o">.</span><span class="n">obs2prior</span><span class="p">:</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>            <span class="c1"># sample both obs2prior weight and realization of variable.</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>            <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>            <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name</span> <span class="o">+</span> <span class="s1">&#39;.H&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>            <span class="c1"># only sample the realization of variable.</span>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>            <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>            <span class="n">sample_dict</span><span class="p">[</span><span class="n">coef_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">s</span>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>    <span class="k">return</span> <span class="n">sample_dict</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="bemb.model.bemb.BEMBFlex.sample_log_likelihoods" class="doc doc-heading">
<code class="highlight language-python"><span class="n">sample_log_likelihoods</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">sample_dict</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>Samples log likelihoods given model parameters and trips</p>
      <p>batch(ChoiceDataset): batch data containing trip information; item choice information is discarded
sample_dict(Dict[str, torch.Tensor]): sampled coefficient values</p>
      <p>Tuple[torch.Tensor]: sampled log likelihoods; shape: (batch_size, num_categories)</p>

        <details class="quote">
          <summary>Source code in <code>bemb/model/bemb.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="nf">sample_log_likelihoods</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span><span class="n">ChoiceDataset</span><span class="p">,</span> <span class="n">sample_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="sd">&quot;&quot;&quot;Samples log likelihoods given model parameters and trips</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="sd">    batch(ChoiceDataset): batch data containing trip information; item choice information is discarded</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="sd">    sample_dict(Dict[str, torch.Tensor]): sampled coefficient values</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="sd">    Tuple[torch.Tensor]: sampled log likelihoods; shape: (batch_size, num_categories)</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    <span class="c1"># get the log likelihoods for all items for all categories</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>    <span class="n">utility</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_likelihood_all_items</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">return_logit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sample_dict</span><span class="o">=</span><span class="n">sample_dict</span><span class="p">)</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>    <span class="n">mu_gumbel</span> <span class="o">=</span> <span class="mf">0.0</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>    <span class="n">beta_gumbel</span> <span class="o">=</span> <span class="mf">1.0</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>    <span class="n">EUL_MAS_CONST</span> <span class="o">=</span> <span class="mf">0.5772156649</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>    <span class="n">mean_gumbel</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">mu_gumbel</span> <span class="o">+</span> <span class="n">beta_gumbel</span> <span class="o">*</span> <span class="n">EUL_MAS_CONST</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>    <span class="n">m</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">gumbel</span><span class="o">.</span><span class="n">Gumbel</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>    <span class="c1"># m = torch.distributions.gumbel.Gumbel(0.0, 1.0)</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>    <span class="n">gumbel_samples</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">utility</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>    <span class="n">gumbel_samples</span> <span class="o">-=</span> <span class="n">mean_gumbel</span>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>    <span class="n">utility</span> <span class="o">+=</span> <span class="n">gumbel_samples</span>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>    <span class="n">max_by_category</span><span class="p">,</span> <span class="n">argmax_by_category</span> <span class="o">=</span> <span class="n">scatter_max</span><span class="p">(</span><span class="n">utility</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_to_category_tensor</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>    <span class="k">return</span> <span class="n">max_by_category</span><span class="p">,</span> <span class="n">argmax_by_category</span>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>    <span class="n">log_likelihoods</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_log_likelihoods_per_category</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">sample_dict</span><span class="p">)</span>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a>    <span class="c1"># sum over all categories.</span>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a>    <span class="n">log_likelihoods</span> <span class="o">=</span> <span class="n">log_likelihoods</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a>    <span class="k">return</span> <span class="n">log_likelihoods</span><span class="p">,</span> <span class="n">log_likelihoods</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>





  <div class="doc doc-object doc-function">



<h4 id="bemb.model.bemb.parse_utility" class="doc doc-heading">
<code class="highlight language-python"><span class="n">parse_utility</span><span class="p">(</span><span class="n">utility_string</span><span class="p">)</span></code>


</h4>

    <div class="doc doc-contents ">

      <p>A helper function parse utility string into a list of additive terms.</p>

<p><strong>Examples:</strong></p>
    <p>utility_string = 'lambda_item + theta_user * alpha_item + gamma_user * beta_item * price_obs'
output = [
    {
        'coefficient': ['lambda_item'],
        'observable': None
    },
    {
        'coefficient': ['theta_user', 'alpha_item'],
        'observable': None
    },
    {
        'coefficient': ['gamma_user', 'beta_item'],
        'observable': 'price_obs'
    }
    ]</p>

        <details class="quote">
          <summary>Source code in <code>bemb/model/bemb.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="nf">parse_utility</span><span class="p">(</span><span class="n">utility_string</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="kc">None</span><span class="p">]]]:</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="sd">    A helper function parse utility string into a list of additive terms.</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="sd">    Example:</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="sd">        utility_string = &#39;lambda_item + theta_user * alpha_item + gamma_user * beta_item * price_obs&#39;</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="sd">        output = [</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="sd">            {</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="sd">                &#39;coefficient&#39;: [&#39;lambda_item&#39;],</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a><span class="sd">                &#39;observable&#39;: None</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a><span class="sd">            },</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a><span class="sd">            {</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a><span class="sd">                &#39;coefficient&#39;: [&#39;theta_user&#39;, &#39;alpha_item&#39;],</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a><span class="sd">                &#39;observable&#39;: None</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a><span class="sd">            },</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a><span class="sd">            {</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a><span class="sd">                &#39;coefficient&#39;: [&#39;gamma_user&#39;, &#39;beta_item&#39;],</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a><span class="sd">                &#39;observable&#39;: &#39;price_obs&#39;</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a><span class="sd">            }</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a><span class="sd">            ]</span>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>    <span class="c1"># split additive terms</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>    <span class="n">coefficient_suffix</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;_item&#39;</span><span class="p">,</span> <span class="s1">&#39;_user&#39;</span><span class="p">,</span> <span class="s1">&#39;_constant&#39;</span><span class="p">,</span> <span class="s1">&#39;_category&#39;</span><span class="p">)</span>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>    <span class="n">observable_prefix</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;item_&#39;</span><span class="p">,</span> <span class="s1">&#39;user_&#39;</span><span class="p">,</span> <span class="s1">&#39;session_&#39;</span><span class="p">,</span> <span class="s1">&#39;price_&#39;</span><span class="p">,</span> <span class="s1">&#39;taste_&#39;</span><span class="p">)</span>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a>    <span class="c1"># Programmers can now specify itemsession for price observables, this enables easier understanding.</span>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a>    <span class="n">utility_string</span> <span class="o">=</span> <span class="n">utility_string</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;itemsession_&#39;</span><span class="p">,</span> <span class="s1">&#39;price_&#39;</span><span class="p">)</span>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a>    <span class="k">def</span> <span class="nf">is_coefficient</span><span class="p">(</span><span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a>        <span class="k">return</span> <span class="nb">any</span><span class="p">(</span><span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="n">suffix</span><span class="p">)</span> <span class="k">for</span> <span class="n">suffix</span> <span class="ow">in</span> <span class="n">coefficient_suffix</span><span class="p">)</span>
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a>
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a>    <span class="k">def</span> <span class="nf">is_observable</span><span class="p">(</span><span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a>        <span class="k">return</span> <span class="nb">any</span><span class="p">(</span><span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">prefix</span><span class="p">)</span> <span class="k">for</span> <span class="n">prefix</span> <span class="ow">in</span> <span class="n">observable_prefix</span><span class="p">)</span>
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a>
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a>    <span class="n">additive_terms</span> <span class="o">=</span> <span class="n">utility_string</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; + &#39;</span><span class="p">)</span>
<a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a>    <span class="n">additive_decomposition</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a>    <span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="n">additive_terms</span><span class="p">:</span>
<a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a>        <span class="n">atom</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;coefficient&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;observable&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">}</span>
<a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a>        <span class="c1"># split multiplicative terms.</span>
<a id="__codelineno-0-40" name="__codelineno-0-40" href="#__codelineno-0-40"></a>        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">term</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; * &#39;</span><span class="p">):</span>
<a id="__codelineno-0-41" name="__codelineno-0-41" href="#__codelineno-0-41"></a>            <span class="k">if</span> <span class="n">is_coefficient</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<a id="__codelineno-0-42" name="__codelineno-0-42" href="#__codelineno-0-42"></a>                <span class="n">atom</span><span class="p">[</span><span class="s1">&#39;coefficient&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-43" name="__codelineno-0-43" href="#__codelineno-0-43"></a>            <span class="k">elif</span> <span class="n">is_observable</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<a id="__codelineno-0-44" name="__codelineno-0-44" href="#__codelineno-0-44"></a>                <span class="n">atom</span><span class="p">[</span><span class="s1">&#39;observable&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
<a id="__codelineno-0-45" name="__codelineno-0-45" href="#__codelineno-0-45"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-46" name="__codelineno-0-46" href="#__codelineno-0-46"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s1"> term cannot be classified.&#39;</span><span class="p">)</span>
<a id="__codelineno-0-47" name="__codelineno-0-47" href="#__codelineno-0-47"></a>        <span class="n">additive_decomposition</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">atom</span><span class="p">)</span>
<a id="__codelineno-0-48" name="__codelineno-0-48" href="#__codelineno-0-48"></a>    <span class="k">return</span> <span class="n">additive_decomposition</span>
</code></pre></div>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h3 id="bemb.model.bemb_flex_lightning" class="doc doc-heading">
        <code>bemb_flex_lightning</code>



</h3>

    <div class="doc doc-contents ">

      <p>PyTorch lightning wrapper for the BEMB Flex model, allows for more smooth model training and inference. You can still
use this package without using LitBEMBFlex.</p>
<p>Author: Tianyu Du
Update: Apr. 29, 2022</p>



  <div class="doc doc-children">







  <div class="doc doc-object doc-class">



<h4 id="bemb.model.bemb_flex_lightning.LitBEMBFlex" class="doc doc-heading">
        <code>
LitBEMBFlex            (<span title="pytorch_lightning.core.lightning.LightningModule">LightningModule</span>)
        </code>



</h4>

    <div class="doc doc-contents ">


        <details class="quote">
          <summary>Source code in <code>bemb/model/bemb_flex_lightning.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">class</span> <span class="nc">LitBEMBFlex</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">):</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">,</span> <span class="n">num_seeds</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>        <span class="sd">&quot;&quot;&quot;The initialization method of the wrapper model.</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="sd">            learning_rate (float, optional): the learning rate of optimization. Defaults to 0.3.</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="sd">            num_seeds (int, optional): number of random seeds for the Monte Carlo estimation in the variational inference.</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="sd">                Defaults to 1.</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a><span class="sd">            **kwargs: all keyword arguments used for constructing the wrapped BEMB model.</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>        <span class="c1"># use kwargs to pass parameter to BEMB Torch.</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">BEMBFlex</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_needs</span> <span class="o">=</span> <span class="n">num_seeds</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>        <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">):</span>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>        <span class="sd">&quot;&quot;&quot;Calls the forward method of the wrapped BEMB model, please refer to the documentaton of the BEMB class</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a><span class="sd">            for detailed definitions of the arguments.</span>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a><span class="sd">            args (_type_): arguments passed to the forward method of the wrapped BEMB model.</span>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a><span class="sd">            kwargs (_type_): keyword arguments passed to the forward method of the wrapped BEMB model.</span>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a><span class="sd">            _type_: returns whatever the wrapped BEMB model returns.</span>
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a>
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a>    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a>        <span class="n">elbo</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">elbo</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">num_seeds</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_needs</span><span class="p">)</span>
<a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s1">&#39;train_elbo&#39;</span><span class="p">,</span> <span class="n">elbo</span><span class="p">)</span>
<a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a>        <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span> <span class="n">elbo</span>
<a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a>        <span class="k">return</span> <span class="n">loss</span>
<a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a>
<a id="__codelineno-0-40" name="__codelineno-0-40" href="#__codelineno-0-40"></a>    <span class="k">def</span> <span class="nf">_get_performance_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
<a id="__codelineno-0-41" name="__codelineno-0-41" href="#__codelineno-0-41"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">pred_item</span><span class="p">:</span>
<a id="__codelineno-0-42" name="__codelineno-0-42" href="#__codelineno-0-42"></a>            <span class="n">log_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;log_prob&#39;</span><span class="p">,</span>
<a id="__codelineno-0-43" name="__codelineno-0-43" href="#__codelineno-0-43"></a>                               <span class="n">return_scope</span><span class="o">=</span><span class="s1">&#39;all_items&#39;</span><span class="p">,</span> <span class="n">deterministic</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<a id="__codelineno-0-44" name="__codelineno-0-44" href="#__codelineno-0-44"></a>            <span class="n">num_classes</span> <span class="o">=</span> <span class="n">log_p</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<a id="__codelineno-0-45" name="__codelineno-0-45" href="#__codelineno-0-45"></a>            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">log_p</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-46" name="__codelineno-0-46" href="#__codelineno-0-46"></a>            <span class="n">y_true</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">item_index</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<a id="__codelineno-0-47" name="__codelineno-0-47" href="#__codelineno-0-47"></a>            <span class="n">performance</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;acc&#39;</span><span class="p">:</span> <span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">),</span>
<a id="__codelineno-0-48" name="__codelineno-0-48" href="#__codelineno-0-48"></a>                           <span class="s1">&#39;ll&#39;</span><span class="p">:</span> <span class="o">-</span> <span class="n">metrics</span><span class="o">.</span><span class="n">log_loss</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_p</span><span class="p">),</span> <span class="n">labels</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_classes</span><span class="p">))}</span>
<a id="__codelineno-0-49" name="__codelineno-0-49" href="#__codelineno-0-49"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-50" name="__codelineno-0-50" href="#__codelineno-0-50"></a>            <span class="c1"># making binary station.</span>
<a id="__codelineno-0-51" name="__codelineno-0-51" href="#__codelineno-0-51"></a>            <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;utility&#39;</span><span class="p">,</span>
<a id="__codelineno-0-52" name="__codelineno-0-52" href="#__codelineno-0-52"></a>                              <span class="n">return_scope</span><span class="o">=</span><span class="s1">&#39;item_index&#39;</span><span class="p">,</span> <span class="n">deterministic</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-53" name="__codelineno-0-53" href="#__codelineno-0-53"></a>            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<a id="__codelineno-0-54" name="__codelineno-0-54" href="#__codelineno-0-54"></a>            <span class="n">y_true</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">label</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<a id="__codelineno-0-55" name="__codelineno-0-55" href="#__codelineno-0-55"></a>            <span class="n">performance</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;acc&#39;</span><span class="p">:</span> <span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="p">(</span><span class="n">y_pred</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)),</span>
<a id="__codelineno-0-56" name="__codelineno-0-56" href="#__codelineno-0-56"></a>                           <span class="s1">&#39;ll&#39;</span><span class="p">:</span> <span class="o">-</span> <span class="n">metrics</span><span class="o">.</span><span class="n">log_loss</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1E-5</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span>
<a id="__codelineno-0-57" name="__codelineno-0-57" href="#__codelineno-0-57"></a>                           <span class="c1">#    &#39;auc&#39;: metrics.roc_auc_score(y_true=y_true, y_score=y_pred),</span>
<a id="__codelineno-0-58" name="__codelineno-0-58" href="#__codelineno-0-58"></a>                           <span class="c1">#    &#39;f1&#39;: metrics.f1_score(y_true=y_true, y_pred=(y_pred &gt;= 0.5).astype(int))</span>
<a id="__codelineno-0-59" name="__codelineno-0-59" href="#__codelineno-0-59"></a>                           <span class="p">}</span>
<a id="__codelineno-0-60" name="__codelineno-0-60" href="#__codelineno-0-60"></a>        <span class="k">return</span> <span class="n">performance</span>
<a id="__codelineno-0-61" name="__codelineno-0-61" href="#__codelineno-0-61"></a>
<a id="__codelineno-0-62" name="__codelineno-0-62" href="#__codelineno-0-62"></a>    <span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
<a id="__codelineno-0-63" name="__codelineno-0-63" href="#__codelineno-0-63"></a>        <span class="c1"># LL = self.model.forward(batch, return_type=&#39;log_prob&#39;, return_scope=&#39;item_index&#39;, deterministic=True).mean()</span>
<a id="__codelineno-0-64" name="__codelineno-0-64" href="#__codelineno-0-64"></a>        <span class="c1"># self.log(&#39;val_log_likelihood&#39;, LL, prog_bar=True)</span>
<a id="__codelineno-0-65" name="__codelineno-0-65" href="#__codelineno-0-65"></a>        <span class="c1"># pred = self.model(batch)</span>
<a id="__codelineno-0-66" name="__codelineno-0-66" href="#__codelineno-0-66"></a>        <span class="c1"># performance = self.model.get_within_category_accuracy(pred, batch.label)</span>
<a id="__codelineno-0-67" name="__codelineno-0-67" href="#__codelineno-0-67"></a>
<a id="__codelineno-0-68" name="__codelineno-0-68" href="#__codelineno-0-68"></a>        <span class="c1"># utility.</span>
<a id="__codelineno-0-69" name="__codelineno-0-69" href="#__codelineno-0-69"></a>
<a id="__codelineno-0-70" name="__codelineno-0-70" href="#__codelineno-0-70"></a>        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_performance_dict</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<a id="__codelineno-0-71" name="__codelineno-0-71" href="#__codelineno-0-71"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s1">&#39;val_&#39;</span> <span class="o">+</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">prog_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">))</span>
<a id="__codelineno-0-72" name="__codelineno-0-72" href="#__codelineno-0-72"></a>
<a id="__codelineno-0-73" name="__codelineno-0-73" href="#__codelineno-0-73"></a>    <span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
<a id="__codelineno-0-74" name="__codelineno-0-74" href="#__codelineno-0-74"></a>        <span class="c1"># LL = self.model.forward(batch, return_logit=False, all_items=False).mean()</span>
<a id="__codelineno-0-75" name="__codelineno-0-75" href="#__codelineno-0-75"></a>        <span class="c1"># self.log(&#39;test_log_likelihood&#39;, LL)</span>
<a id="__codelineno-0-76" name="__codelineno-0-76" href="#__codelineno-0-76"></a>
<a id="__codelineno-0-77" name="__codelineno-0-77" href="#__codelineno-0-77"></a>        <span class="c1"># pred = self.model(batch, return_type=&#39;utility&#39;, return_scope=&#39;item_index&#39;, deterministic=True)</span>
<a id="__codelineno-0-78" name="__codelineno-0-78" href="#__codelineno-0-78"></a>        <span class="c1"># y_pred = torch.sigmoid(pred).cpu().numpy()</span>
<a id="__codelineno-0-79" name="__codelineno-0-79" href="#__codelineno-0-79"></a>        <span class="c1"># y_true = batch.label.cpu().numpy()</span>
<a id="__codelineno-0-80" name="__codelineno-0-80" href="#__codelineno-0-80"></a>        <span class="c1"># performance = {&#39;acc&#39;: metrics.accuracy_score(y_true=y_true, y_pred=(y_pred &gt;= 0.5).astype(int)),</span>
<a id="__codelineno-0-81" name="__codelineno-0-81" href="#__codelineno-0-81"></a>        <span class="c1">#                &#39;ll&#39;: - metrics.log_loss(y_true=y_true, y_pred=y_pred, eps=1E-5, labels=[0, 1]),</span>
<a id="__codelineno-0-82" name="__codelineno-0-82" href="#__codelineno-0-82"></a>        <span class="c1">#             #    &#39;auc&#39;: metrics.roc_auc_score(y_true=y_true, y_score=y_pred),</span>
<a id="__codelineno-0-83" name="__codelineno-0-83" href="#__codelineno-0-83"></a>        <span class="c1">#             #    &#39;f1&#39;: metrics.f1_score(y_true=y_true, y_pred=(y_pred &gt;= 0.5).astype(int))</span>
<a id="__codelineno-0-84" name="__codelineno-0-84" href="#__codelineno-0-84"></a>        <span class="c1">#                }</span>
<a id="__codelineno-0-85" name="__codelineno-0-85" href="#__codelineno-0-85"></a>
<a id="__codelineno-0-86" name="__codelineno-0-86" href="#__codelineno-0-86"></a>        <span class="c1"># pred = self.model(batch)</span>
<a id="__codelineno-0-87" name="__codelineno-0-87" href="#__codelineno-0-87"></a>        <span class="c1"># performance = self.model.get_within_category_accuracy(pred, batch.label)</span>
<a id="__codelineno-0-88" name="__codelineno-0-88" href="#__codelineno-0-88"></a>        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_performance_dict</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<a id="__codelineno-0-89" name="__codelineno-0-89" href="#__codelineno-0-89"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s1">&#39;test_&#39;</span> <span class="o">+</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">prog_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">))</span>
<a id="__codelineno-0-90" name="__codelineno-0-90" href="#__codelineno-0-90"></a>
<a id="__codelineno-0-91" name="__codelineno-0-91" href="#__codelineno-0-91"></a>    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-92" name="__codelineno-0-92" href="#__codelineno-0-92"></a>        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span>
<a id="__codelineno-0-93" name="__codelineno-0-93" href="#__codelineno-0-93"></a>        <span class="k">return</span> <span class="n">optimizer</span>
<a id="__codelineno-0-94" name="__codelineno-0-94" href="#__codelineno-0-94"></a>
<a id="__codelineno-0-95" name="__codelineno-0-95" href="#__codelineno-0-95"></a>    <span class="k">def</span> <span class="nf">fit_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ChoiceDataset</span><span class="p">],</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;LitBEMBFlex&quot;</span><span class="p">:</span>
<a id="__codelineno-0-96" name="__codelineno-0-96" href="#__codelineno-0-96"></a>        <span class="sd">&quot;&quot;&quot;A standard pipeline of model training and evaluation.</span>
<a id="__codelineno-0-97" name="__codelineno-0-97" href="#__codelineno-0-97"></a>
<a id="__codelineno-0-98" name="__codelineno-0-98" href="#__codelineno-0-98"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-99" name="__codelineno-0-99" href="#__codelineno-0-99"></a><span class="sd">            dataset_list (List[ChoiceDataset]): train_dataset, validation_test, and test_dataset in a list of length 3.</span>
<a id="__codelineno-0-100" name="__codelineno-0-100" href="#__codelineno-0-100"></a><span class="sd">            batch_size (int, optional): batch_size for training and evaluation. Defaults to -1, which indicates full-batch training.</span>
<a id="__codelineno-0-101" name="__codelineno-0-101" href="#__codelineno-0-101"></a><span class="sd">            num_epochs (int, optional): number of epochs for training. Defaults to 10.</span>
<a id="__codelineno-0-102" name="__codelineno-0-102" href="#__codelineno-0-102"></a><span class="sd">            **kwargs: additional keyword argument for the pytorch-lightning Trainer.</span>
<a id="__codelineno-0-103" name="__codelineno-0-103" href="#__codelineno-0-103"></a>
<a id="__codelineno-0-104" name="__codelineno-0-104" href="#__codelineno-0-104"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-105" name="__codelineno-0-105" href="#__codelineno-0-105"></a><span class="sd">            LitBEMBFlex: the trained bemb model.</span>
<a id="__codelineno-0-106" name="__codelineno-0-106" href="#__codelineno-0-106"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-107" name="__codelineno-0-107" href="#__codelineno-0-107"></a>
<a id="__codelineno-0-108" name="__codelineno-0-108" href="#__codelineno-0-108"></a>        <span class="k">def</span> <span class="nf">section_print</span><span class="p">(</span><span class="n">input_text</span><span class="p">):</span>
<a id="__codelineno-0-109" name="__codelineno-0-109" href="#__codelineno-0-109"></a>            <span class="sd">&quot;&quot;&quot;Helper function for printing&quot;&quot;&quot;</span>
<a id="__codelineno-0-110" name="__codelineno-0-110" href="#__codelineno-0-110"></a>            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;=&#39;</span> <span class="o">*</span> <span class="mi">20</span><span class="p">,</span> <span class="n">input_text</span><span class="p">,</span> <span class="s1">&#39;=&#39;</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<a id="__codelineno-0-111" name="__codelineno-0-111" href="#__codelineno-0-111"></a>        <span class="c1"># present a summary of the model received.</span>
<a id="__codelineno-0-112" name="__codelineno-0-112" href="#__codelineno-0-112"></a>        <span class="n">section_print</span><span class="p">(</span><span class="s1">&#39;model received&#39;</span><span class="p">)</span>
<a id="__codelineno-0-113" name="__codelineno-0-113" href="#__codelineno-0-113"></a>        <span class="nb">print</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
<a id="__codelineno-0-114" name="__codelineno-0-114" href="#__codelineno-0-114"></a>
<a id="__codelineno-0-115" name="__codelineno-0-115" href="#__codelineno-0-115"></a>        <span class="c1"># present a summary of datasets received.</span>
<a id="__codelineno-0-116" name="__codelineno-0-116" href="#__codelineno-0-116"></a>        <span class="n">section_print</span><span class="p">(</span><span class="s1">&#39;data set received&#39;</span><span class="p">)</span>
<a id="__codelineno-0-117" name="__codelineno-0-117" href="#__codelineno-0-117"></a>        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[Training dataset]&#39;</span><span class="p">,</span> <span class="n">dataset_list</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<a id="__codelineno-0-118" name="__codelineno-0-118" href="#__codelineno-0-118"></a>        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[Validation dataset]&#39;</span><span class="p">,</span> <span class="n">dataset_list</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<a id="__codelineno-0-119" name="__codelineno-0-119" href="#__codelineno-0-119"></a>        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[Testing dataset]&#39;</span><span class="p">,</span> <span class="n">dataset_list</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<a id="__codelineno-0-120" name="__codelineno-0-120" href="#__codelineno-0-120"></a>
<a id="__codelineno-0-121" name="__codelineno-0-121" href="#__codelineno-0-121"></a>        <span class="c1"># create pytorch dataloader objects.</span>
<a id="__codelineno-0-122" name="__codelineno-0-122" href="#__codelineno-0-122"></a>        <span class="n">train</span> <span class="o">=</span> <span class="n">create_data_loader</span><span class="p">(</span><span class="n">dataset_list</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">)</span>
<a id="__codelineno-0-123" name="__codelineno-0-123" href="#__codelineno-0-123"></a>        <span class="n">validation</span> <span class="o">=</span> <span class="n">create_data_loader</span><span class="p">(</span><span class="n">dataset_list</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">)</span>
<a id="__codelineno-0-124" name="__codelineno-0-124" href="#__codelineno-0-124"></a>        <span class="c1"># WARNING: the test step takes extensive memory cost since it computes likelihood for all items.</span>
<a id="__codelineno-0-125" name="__codelineno-0-125" href="#__codelineno-0-125"></a>        <span class="c1"># we run the test step with a much smaller batch_size.</span>
<a id="__codelineno-0-126" name="__codelineno-0-126" href="#__codelineno-0-126"></a>        <span class="n">test</span> <span class="o">=</span> <span class="n">create_data_loader</span><span class="p">(</span><span class="n">dataset_list</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span> <span class="o">//</span> <span class="mi">10</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">)</span>
<a id="__codelineno-0-127" name="__codelineno-0-127" href="#__codelineno-0-127"></a>
<a id="__codelineno-0-128" name="__codelineno-0-128" href="#__codelineno-0-128"></a>        <span class="n">section_print</span><span class="p">(</span><span class="s1">&#39;train the model&#39;</span><span class="p">)</span>
<a id="__codelineno-0-129" name="__codelineno-0-129" href="#__codelineno-0-129"></a>        <span class="n">trainer</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">gpus</span><span class="o">=</span><span class="mi">1</span> <span class="k">if</span> <span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>  <span class="c1"># use GPU if the model is currently on the GPU.</span>
<a id="__codelineno-0-130" name="__codelineno-0-130" href="#__codelineno-0-130"></a>                            <span class="n">max_epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">,</span>
<a id="__codelineno-0-131" name="__codelineno-0-131" href="#__codelineno-0-131"></a>                            <span class="n">check_val_every_n_epoch</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<a id="__codelineno-0-132" name="__codelineno-0-132" href="#__codelineno-0-132"></a>                            <span class="n">log_every_n_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<a id="__codelineno-0-133" name="__codelineno-0-133" href="#__codelineno-0-133"></a>                            <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<a id="__codelineno-0-134" name="__codelineno-0-134" href="#__codelineno-0-134"></a>        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<a id="__codelineno-0-135" name="__codelineno-0-135" href="#__codelineno-0-135"></a>        <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_dataloaders</span><span class="o">=</span><span class="n">train</span><span class="p">,</span> <span class="n">val_dataloaders</span><span class="o">=</span><span class="n">validation</span><span class="p">)</span>
<a id="__codelineno-0-136" name="__codelineno-0-136" href="#__codelineno-0-136"></a>        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;time taken: </span><span class="si">{</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<a id="__codelineno-0-137" name="__codelineno-0-137" href="#__codelineno-0-137"></a>
<a id="__codelineno-0-138" name="__codelineno-0-138" href="#__codelineno-0-138"></a>        <span class="n">section_print</span><span class="p">(</span><span class="s1">&#39;test performance&#39;</span><span class="p">)</span>
<a id="__codelineno-0-139" name="__codelineno-0-139" href="#__codelineno-0-139"></a>        <span class="n">trainer</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataloaders</span><span class="o">=</span><span class="n">test</span><span class="p">)</span>
<a id="__codelineno-0-140" name="__codelineno-0-140" href="#__codelineno-0-140"></a>        <span class="k">return</span> <span class="bp">self</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">









  <div class="doc doc-object doc-method">



<h5 id="bemb.model.bemb_flex_lightning.LitBEMBFlex.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">num_seeds</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h5>

    <div class="doc doc-contents ">

      <p>The initialization method of the wrapper model.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>learning_rate</code></td>
        <td><code>float</code></td>
        <td><p>the learning rate of optimization. Defaults to 0.3.</p></td>
        <td><code>0.3</code></td>
      </tr>
      <tr>
        <td><code>num_seeds</code></td>
        <td><code>int</code></td>
        <td><p>number of random seeds for the Monte Carlo estimation in the variational inference.
Defaults to 1.</p></td>
        <td><code>1</code></td>
      </tr>
      <tr>
        <td><code>**kwargs</code></td>
        <td></td>
        <td><p>all keyword arguments used for constructing the wrapped BEMB model.</p></td>
        <td><code>{}</code></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>bemb/model/bemb_flex_lightning.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">,</span> <span class="n">num_seeds</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="sd">&quot;&quot;&quot;The initialization method of the wrapper model.</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="sd">        learning_rate (float, optional): the learning rate of optimization. Defaults to 0.3.</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="sd">        num_seeds (int, optional): number of random seeds for the Monte Carlo estimation in the variational inference.</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="sd">            Defaults to 1.</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="sd">        **kwargs: all keyword arguments used for constructing the wrapped BEMB model.</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>    <span class="c1"># use kwargs to pass parameter to BEMB Torch.</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">BEMBFlex</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">num_needs</span> <span class="o">=</span> <span class="n">num_seeds</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
</code></pre></div>
        </details>
    </div>

  </div>




  <div class="doc doc-object doc-method">



<h5 id="bemb.model.bemb_flex_lightning.LitBEMBFlex.configure_optimizers" class="doc doc-heading">
<code class="highlight language-python"><span class="n">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>Choose what optimizers and learning-rate schedulers to use in your optimization.
Normally you'd need one. But in the case of GANs or similar you might have multiple.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td></td>
      <td><p>Any of these 6 options.</p>
<ul>
<li><strong>Single optimizer</strong>.</li>
<li><strong>List or Tuple</strong> of optimizers.</li>
<li><strong>Two lists</strong> - The first list has multiple optimizers, and the second has multiple LR schedulers
  (or multiple <code>lr_scheduler_config</code>).</li>
<li><strong>Dictionary</strong>, with an <code>"optimizer"</code> key, and (optionally) a <code>"lr_scheduler"</code>
  key whose value is a single LR scheduler or <code>lr_scheduler_config</code>.</li>
<li><strong>Tuple of dictionaries</strong> as described above, with an optional <code>"frequency"</code> key.</li>
<li><strong>None</strong> - Fit will run without any optimizer.</li>
</ul></td>
    </tr>
  </tbody>
</table>      <p>The <code>lr_scheduler_config</code> is a dictionary which contains the scheduler and its associated configuration.
The default configuration is shown below.</p>
<p>.. code-block:: python</p>
<div class="highlight"><pre><span></span><code>lr_scheduler_config = {
    # REQUIRED: The scheduler instance
    &quot;scheduler&quot;: lr_scheduler,
    # The unit of the scheduler&#39;s step size, could also be &#39;step&#39;.
    # &#39;epoch&#39; updates the scheduler on epoch end whereas &#39;step&#39;
    # updates it after a optimizer update.
    &quot;interval&quot;: &quot;epoch&quot;,
    # How many epochs/steps should pass between calls to
    # `scheduler.step()`. 1 corresponds to updating the learning
    # rate after every epoch/step.
    &quot;frequency&quot;: 1,
    # Metric to to monitor for schedulers like `ReduceLROnPlateau`
    &quot;monitor&quot;: &quot;val_loss&quot;,
    # If set to `True`, will enforce that the value specified &#39;monitor&#39;
    # is available when the scheduler is updated, thus stopping
    # training if not found. If set to `False`, it will only produce a warning
    &quot;strict&quot;: True,
    # If using the `LearningRateMonitor` callback to monitor the
    # learning rate progress, this keyword can be used to specify
    # a custom logged name
    &quot;name&quot;: None,
}
</code></pre></div>
<p>When there are schedulers in which the <code>.step()</code> method is conditioned on a value, such as the
:class:<code>torch.optim.lr_scheduler.ReduceLROnPlateau</code> scheduler, Lightning requires that the
<code>lr_scheduler_config</code> contains the keyword <code>"monitor"</code> set to the metric name that the scheduler
should be conditioned on.</p>
<p>.. testcode::</p>
<div class="highlight"><pre><span></span><code># The ReduceLROnPlateau scheduler requires a monitor
def configure_optimizers(self):
    optimizer = Adam(...)
    return {
        &quot;optimizer&quot;: optimizer,
        &quot;lr_scheduler&quot;: {
            &quot;scheduler&quot;: ReduceLROnPlateau(optimizer, ...),
            &quot;monitor&quot;: &quot;metric_to_track&quot;,
            &quot;frequency&quot;: &quot;indicates how often the metric is updated&quot;
            # If &quot;monitor&quot; references validation metrics, then &quot;frequency&quot; should be set to a
            # multiple of &quot;trainer.check_val_every_n_epoch&quot;.
        },
    }


# In the case of two optimizers, only one using the ReduceLROnPlateau scheduler
def configure_optimizers(self):
    optimizer1 = Adam(...)
    optimizer2 = SGD(...)
    scheduler1 = ReduceLROnPlateau(optimizer1, ...)
    scheduler2 = LambdaLR(optimizer2, ...)
    return (
        {
            &quot;optimizer&quot;: optimizer1,
            &quot;lr_scheduler&quot;: {
                &quot;scheduler&quot;: scheduler1,
                &quot;monitor&quot;: &quot;metric_to_track&quot;,
            },
        },
        {&quot;optimizer&quot;: optimizer2, &quot;lr_scheduler&quot;: scheduler2},
    )
</code></pre></div>
<p>Metrics can be made available to monitor by simply logging it using
<code>self.log('metric_to_track', metric_val)</code> in your :class:<code>~pytorch_lightning.core.lightning.LightningModule</code>.</p>
<p>!!! note
    The <code>frequency</code> value specified in a dict along with the <code>optimizer</code> key is an int corresponding
    to the number of sequential batches optimized with the specific optimizer.
    It should be given to none or to all of the optimizers.
    There is a difference between passing multiple optimizers in a list,
    and passing multiple optimizers in dictionaries with a frequency of 1:</p>
<div class="highlight"><pre><span></span><code>    - In the former case, all optimizers will operate on the given batch in each optimization step.
    - In the latter, only one optimizer will operate on the given batch at every step.

This is different from the ``frequency`` value specified in the ``lr_scheduler_config`` mentioned above.

.. code-block:: python

    def configure_optimizers(self):
        optimizer_one = torch.optim.SGD(self.model.parameters(), lr=0.01)
        optimizer_two = torch.optim.SGD(self.model.parameters(), lr=0.01)
        return [
            {&quot;optimizer&quot;: optimizer_one, &quot;frequency&quot;: 5},
            {&quot;optimizer&quot;: optimizer_two, &quot;frequency&quot;: 10},
        ]

In this example, the first optimizer will be used for the first 5 steps,
the second optimizer for the next 10 steps and that cycle will continue.
If an LR scheduler is specified for an optimizer using the ``lr_scheduler`` key in the above dict,
the scheduler will only be updated when its optimizer is being used.
</code></pre></div>
<p>Examples::</p>
<div class="highlight"><pre><span></span><code># most cases. no learning rate scheduler
def configure_optimizers(self):
    return Adam(self.parameters(), lr=1e-3)

# multiple optimizer case (e.g.: GAN)
def configure_optimizers(self):
    gen_opt = Adam(self.model_gen.parameters(), lr=0.01)
    dis_opt = Adam(self.model_dis.parameters(), lr=0.02)
    return gen_opt, dis_opt

# example with learning rate schedulers
def configure_optimizers(self):
    gen_opt = Adam(self.model_gen.parameters(), lr=0.01)
    dis_opt = Adam(self.model_dis.parameters(), lr=0.02)
    dis_sch = CosineAnnealing(dis_opt, T_max=10)
    return [gen_opt, dis_opt], [dis_sch]

# example with step-based learning rate schedulers
# each optimizer has its own scheduler
def configure_optimizers(self):
    gen_opt = Adam(self.model_gen.parameters(), lr=0.01)
    dis_opt = Adam(self.model_dis.parameters(), lr=0.02)
    gen_sch = {
        &#39;scheduler&#39;: ExponentialLR(gen_opt, 0.99),
        &#39;interval&#39;: &#39;step&#39;  # called after each training step
    }
    dis_sch = CosineAnnealing(dis_opt, T_max=10) # called every epoch
    return [gen_opt, dis_opt], [gen_sch, dis_sch]

# example with optimizer frequencies
# see training procedure in `Improved Training of Wasserstein GANs`, Algorithm 1
# https://arxiv.org/abs/1704.00028
def configure_optimizers(self):
    gen_opt = Adam(self.model_gen.parameters(), lr=0.01)
    dis_opt = Adam(self.model_dis.parameters(), lr=0.02)
    n_critic = 5
    return (
        {&#39;optimizer&#39;: dis_opt, &#39;frequency&#39;: n_critic},
        {&#39;optimizer&#39;: gen_opt, &#39;frequency&#39;: 1}
    )
</code></pre></div>
<p>!!! note
    Some things to know:</p>
<div class="highlight"><pre><span></span><code>- Lightning calls ``.backward()`` and ``.step()`` on each optimizer and learning rate scheduler as needed.
- If you use 16-bit precision (``precision=16``), Lightning will automatically handle the optimizers.
- If you use multiple optimizers, :meth:`training_step` will have an additional ``optimizer_idx`` parameter.
- If you use :class:`torch.optim.LBFGS`, Lightning handles the closure function automatically for you.
- If you use multiple optimizers, gradients will be calculated only for the parameters of current optimizer
  at each training step.
- If you need to control how often those optimizers step or override the default ``.step()`` schedule,
  override the :meth:`optimizer_step` hook.
</code></pre></div>

        <details class="quote">
          <summary>Source code in <code>bemb/model/bemb_flex_lightning.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="k">return</span> <span class="n">optimizer</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="bemb.model.bemb_flex_lightning.LitBEMBFlex.fit_model" class="doc doc-heading">
<code class="highlight language-python"><span class="n">fit_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset_list</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>A standard pipeline of model training and evaluation.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>dataset_list</code></td>
        <td><code>List[ChoiceDataset]</code></td>
        <td><p>train_dataset, validation_test, and test_dataset in a list of length 3.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>batch_size</code></td>
        <td><code>int</code></td>
        <td><p>batch_size for training and evaluation. Defaults to -1, which indicates full-batch training.</p></td>
        <td><code>-1</code></td>
      </tr>
      <tr>
        <td><code>num_epochs</code></td>
        <td><code>int</code></td>
        <td><p>number of epochs for training. Defaults to 10.</p></td>
        <td><code>10</code></td>
      </tr>
      <tr>
        <td><code>**kwargs</code></td>
        <td></td>
        <td><p>additional keyword argument for the pytorch-lightning Trainer.</p></td>
        <td><code>{}</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>LitBEMBFlex</code></td>
      <td><p>the trained bemb model.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>bemb/model/bemb_flex_lightning.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="nf">fit_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ChoiceDataset</span><span class="p">],</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;LitBEMBFlex&quot;</span><span class="p">:</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="sd">&quot;&quot;&quot;A standard pipeline of model training and evaluation.</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="sd">        dataset_list (List[ChoiceDataset]): train_dataset, validation_test, and test_dataset in a list of length 3.</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="sd">        batch_size (int, optional): batch_size for training and evaluation. Defaults to -1, which indicates full-batch training.</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="sd">        num_epochs (int, optional): number of epochs for training. Defaults to 10.</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="sd">        **kwargs: additional keyword argument for the pytorch-lightning Trainer.</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a><span class="sd">        LitBEMBFlex: the trained bemb model.</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>    <span class="k">def</span> <span class="nf">section_print</span><span class="p">(</span><span class="n">input_text</span><span class="p">):</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>        <span class="sd">&quot;&quot;&quot;Helper function for printing&quot;&quot;&quot;</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;=&#39;</span> <span class="o">*</span> <span class="mi">20</span><span class="p">,</span> <span class="n">input_text</span><span class="p">,</span> <span class="s1">&#39;=&#39;</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>    <span class="c1"># present a summary of the model received.</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>    <span class="n">section_print</span><span class="p">(</span><span class="s1">&#39;model received&#39;</span><span class="p">)</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>    <span class="nb">print</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>    <span class="c1"># present a summary of datasets received.</span>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>    <span class="n">section_print</span><span class="p">(</span><span class="s1">&#39;data set received&#39;</span><span class="p">)</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[Training dataset]&#39;</span><span class="p">,</span> <span class="n">dataset_list</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[Validation dataset]&#39;</span><span class="p">,</span> <span class="n">dataset_list</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[Testing dataset]&#39;</span><span class="p">,</span> <span class="n">dataset_list</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a>    <span class="c1"># create pytorch dataloader objects.</span>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a>    <span class="n">train</span> <span class="o">=</span> <span class="n">create_data_loader</span><span class="p">(</span><span class="n">dataset_list</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">)</span>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a>    <span class="n">validation</span> <span class="o">=</span> <span class="n">create_data_loader</span><span class="p">(</span><span class="n">dataset_list</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">)</span>
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a>    <span class="c1"># WARNING: the test step takes extensive memory cost since it computes likelihood for all items.</span>
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a>    <span class="c1"># we run the test step with a much smaller batch_size.</span>
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a>    <span class="n">test</span> <span class="o">=</span> <span class="n">create_data_loader</span><span class="p">(</span><span class="n">dataset_list</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span> <span class="o">//</span> <span class="mi">10</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">)</span>
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a>
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a>    <span class="n">section_print</span><span class="p">(</span><span class="s1">&#39;train the model&#39;</span><span class="p">)</span>
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a>    <span class="n">trainer</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">gpus</span><span class="o">=</span><span class="mi">1</span> <span class="k">if</span> <span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>  <span class="c1"># use GPU if the model is currently on the GPU.</span>
<a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a>                        <span class="n">max_epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">,</span>
<a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a>                        <span class="n">check_val_every_n_epoch</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a>                        <span class="n">log_every_n_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a>                        <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<a id="__codelineno-0-40" name="__codelineno-0-40" href="#__codelineno-0-40"></a>    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<a id="__codelineno-0-41" name="__codelineno-0-41" href="#__codelineno-0-41"></a>    <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_dataloaders</span><span class="o">=</span><span class="n">train</span><span class="p">,</span> <span class="n">val_dataloaders</span><span class="o">=</span><span class="n">validation</span><span class="p">)</span>
<a id="__codelineno-0-42" name="__codelineno-0-42" href="#__codelineno-0-42"></a>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;time taken: </span><span class="si">{</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<a id="__codelineno-0-43" name="__codelineno-0-43" href="#__codelineno-0-43"></a>
<a id="__codelineno-0-44" name="__codelineno-0-44" href="#__codelineno-0-44"></a>    <span class="n">section_print</span><span class="p">(</span><span class="s1">&#39;test performance&#39;</span><span class="p">)</span>
<a id="__codelineno-0-45" name="__codelineno-0-45" href="#__codelineno-0-45"></a>    <span class="n">trainer</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataloaders</span><span class="o">=</span><span class="n">test</span><span class="p">)</span>
<a id="__codelineno-0-46" name="__codelineno-0-46" href="#__codelineno-0-46"></a>    <span class="k">return</span> <span class="bp">self</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="bemb.model.bemb_flex_lightning.LitBEMBFlex.forward" class="doc doc-heading">
<code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>Calls the forward method of the wrapped BEMB model, please refer to the documentaton of the BEMB class
    for detailed definitions of the arguments.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>args</code></td>
        <td><code>_type_</code></td>
        <td><p>arguments passed to the forward method of the wrapped BEMB model.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>kwargs</code></td>
        <td><code>_type_</code></td>
        <td><p>keyword arguments passed to the forward method of the wrapped BEMB model.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>_type_</code></td>
      <td><p>returns whatever the wrapped BEMB model returns.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>bemb/model/bemb_flex_lightning.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">):</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="sd">&quot;&quot;&quot;Calls the forward method of the wrapped BEMB model, please refer to the documentaton of the BEMB class</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="sd">        for detailed definitions of the arguments.</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="sd">        args (_type_): arguments passed to the forward method of the wrapped BEMB model.</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="sd">        kwargs (_type_): keyword arguments passed to the forward method of the wrapped BEMB model.</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a><span class="sd">        _type_: returns whatever the wrapped BEMB model returns.</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="bemb.model.bemb_flex_lightning.LitBEMBFlex.test_step" class="doc doc-heading">
<code class="highlight language-python"><span class="n">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>Operates on a single batch of data from the test set.
In this step you'd normally generate examples or calculate anything of interest
such as accuracy.</p>
<p>.. code-block:: python</p>
<div class="highlight"><pre><span></span><code># the pseudocode for these calls
test_outs = []
for test_batch in test_data:
    out = test_step(test_batch)
    test_outs.append(out)
test_epoch_end(test_outs)
</code></pre></div>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>batch</code></td>
        <td></td>
        <td><p>The output of your :class:<code>~torch.utils.data.DataLoader</code>.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>batch_idx</code></td>
        <td></td>
        <td><p>The index of this batch.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>dataloader_id</code></td>
        <td></td>
        <td><p>The index of the dataloader that produced this batch.
(only if multiple test dataloaders used).</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td></td>
      <td><p>Any of.</p>
<ul>
<li>Any object or value</li>
<li><code>None</code> - Testing will skip to the next batch</li>
</ul></td>
    </tr>
  </tbody>
</table>      <p>.. code-block:: python</p>
<div class="highlight"><pre><span></span><code># if you have one test dataloader:
def test_step(self, batch, batch_idx):
    ...


# if you have multiple test dataloaders:
def test_step(self, batch, batch_idx, dataloader_idx=0):
    ...
</code></pre></div>
<p>Examples::</p>
<div class="highlight"><pre><span></span><code># CASE 1: A single test dataset
def test_step(self, batch, batch_idx):
    x, y = batch

    # implement your own
    out = self(x)
    loss = self.loss(out, y)

    # log 6 example images
    # or generated text... or whatever
    sample_imgs = x[:6]
    grid = torchvision.utils.make_grid(sample_imgs)
    self.logger.experiment.add_image(&#39;example_images&#39;, grid, 0)

    # calculate acc
    labels_hat = torch.argmax(out, dim=1)
    test_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0)

    # log the outputs!
    self.log_dict({&#39;test_loss&#39;: loss, &#39;test_acc&#39;: test_acc})
</code></pre></div>
<p>If you pass in multiple test dataloaders, :meth:<code>test_step</code> will have an additional argument. We recommend
setting the default value of 0 so that you can quickly switch between single and multiple dataloaders.</p>
<p>.. code-block:: python</p>
<div class="highlight"><pre><span></span><code># CASE 2: multiple test dataloaders
def test_step(self, batch, batch_idx, dataloader_idx=0):
    # dataloader_idx tells you which dataset this is.
    ...
</code></pre></div>
<p>!!! note
    If you don't need to test you don't need to implement this method.</p>
<p>!!! note
    When the :meth:<code>test_step</code> is called, the model has been put in eval mode and
    PyTorch gradients have been disabled. At the end of the test epoch, the model goes back
    to training mode and gradients are enabled.</p>

        <details class="quote">
          <summary>Source code in <code>bemb/model/bemb_flex_lightning.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="c1"># LL = self.model.forward(batch, return_logit=False, all_items=False).mean()</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="c1"># self.log(&#39;test_log_likelihood&#39;, LL)</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="c1"># pred = self.model(batch, return_type=&#39;utility&#39;, return_scope=&#39;item_index&#39;, deterministic=True)</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="c1"># y_pred = torch.sigmoid(pred).cpu().numpy()</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="c1"># y_true = batch.label.cpu().numpy()</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="c1"># performance = {&#39;acc&#39;: metrics.accuracy_score(y_true=y_true, y_pred=(y_pred &gt;= 0.5).astype(int)),</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    <span class="c1">#                &#39;ll&#39;: - metrics.log_loss(y_true=y_true, y_pred=y_pred, eps=1E-5, labels=[0, 1]),</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>    <span class="c1">#             #    &#39;auc&#39;: metrics.roc_auc_score(y_true=y_true, y_score=y_pred),</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    <span class="c1">#             #    &#39;f1&#39;: metrics.f1_score(y_true=y_true, y_pred=(y_pred &gt;= 0.5).astype(int))</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>    <span class="c1">#                }</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>    <span class="c1"># pred = self.model(batch)</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>    <span class="c1"># performance = self.model.get_within_category_accuracy(pred, batch.label)</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_performance_dict</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s1">&#39;test_&#39;</span> <span class="o">+</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">prog_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">))</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="bemb.model.bemb_flex_lightning.LitBEMBFlex.training_step" class="doc doc-heading">
<code class="highlight language-python"><span class="n">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>Here you compute and return the training loss and some additional metrics for e.g.
the progress bar or logger.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>batch</code></td>
        <td></td>
        <td><p>class:<code>~torch.Tensor</code> | (:class:<code>~torch.Tensor</code>, ...) | [:class:<code>~torch.Tensor</code>, ...]):
The output of your :class:<code>~torch.utils.data.DataLoader</code>. A tensor, tuple or list.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>batch_idx</code></td>
        <td><code>``int``</code></td>
        <td><p>Integer displaying index of this batch</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>optimizer_idx</code></td>
        <td><code>``int``</code></td>
        <td><p>When using multiple optimizers, this argument will also be present.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>hiddens</code></td>
        <td><code>``Any``</code></td>
        <td><p>Passed in if
:paramref:<code>~pytorch_lightning.core.lightning.LightningModule.truncated_bptt_steps</code> &gt; 0.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Any of.

- </code></td>
      <td><p>class:<code>~torch.Tensor</code> - The loss tensor
- <code>dict</code> - A dictionary. Can include any keys, but must include the key <code>'loss'</code>
- <code>None</code> - Training will skip to the next batch. This is only for automatic optimization.
    This is not supported for multi-GPU, TPU, IPU, or DeepSpeed.</p></td>
    </tr>
  </tbody>
</table>      <p>In this step you'd normally do the forward pass and calculate the loss for a batch.
You can also do fancier things like multiple forward passes or something model specific.</p>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>def training_step(self, batch, batch_idx):
    x, y, z = batch
    out = self.encoder(x)
    loss = self.loss(out, x)
    return loss
</code></pre></div>
<p>If you define multiple optimizers, this step will be called with an additional
<code>optimizer_idx</code> parameter.</p>
<p>.. code-block:: python</p>
<div class="highlight"><pre><span></span><code># Multiple optimizers (e.g.: GANs)
def training_step(self, batch, batch_idx, optimizer_idx):
    if optimizer_idx == 0:
        # do training_step with encoder
        ...
    if optimizer_idx == 1:
        # do training_step with decoder
        ...
</code></pre></div>
<p>If you add truncated back propagation through time you will also get an additional
argument with the hidden states of the previous step.</p>
<p>.. code-block:: python</p>
<div class="highlight"><pre><span></span><code># Truncated back-propagation through time
def training_step(self, batch, batch_idx, hiddens):
    # hiddens are the hidden states from the previous truncated backprop step
    out, hiddens = self.lstm(data, hiddens)
    loss = ...
    return {&quot;loss&quot;: loss, &quot;hiddens&quot;: hiddens}
</code></pre></div>
<p>!!! note
    The loss value shown in the progress bar is smoothed (averaged) over the last values,
    so it differs from the actual loss returned in train/validation step.</p>

        <details class="quote">
          <summary>Source code in <code>bemb/model/bemb_flex_lightning.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">elbo</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">elbo</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">num_seeds</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_needs</span><span class="p">)</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s1">&#39;train_elbo&#39;</span><span class="p">,</span> <span class="n">elbo</span><span class="p">)</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span> <span class="n">elbo</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="k">return</span> <span class="n">loss</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h5 id="bemb.model.bemb_flex_lightning.LitBEMBFlex.validation_step" class="doc doc-heading">
<code class="highlight language-python"><span class="n">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">)</span></code>


</h5>

    <div class="doc doc-contents ">

      <p>Operates on a single batch of data from the validation set.
In this step you'd might generate examples or calculate anything of interest like accuracy.</p>
<p>.. code-block:: python</p>
<div class="highlight"><pre><span></span><code># the pseudocode for these calls
val_outs = []
for val_batch in val_data:
    out = validation_step(val_batch)
    val_outs.append(out)
validation_epoch_end(val_outs)
</code></pre></div>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>batch</code></td>
        <td></td>
        <td><p>The output of your :class:<code>~torch.utils.data.DataLoader</code>.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>batch_idx</code></td>
        <td></td>
        <td><p>The index of this batch.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>dataloader_idx</code></td>
        <td></td>
        <td><p>The index of the dataloader that produced this batch.
(only if multiple val dataloaders used)</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td></td>
      <td><ul>
<li>Any object or value</li>
<li><code>None</code> - Validation will skip to the next batch</li>
</ul></td>
    </tr>
  </tbody>
</table>      <p>.. code-block:: python</p>
<div class="highlight"><pre><span></span><code># pseudocode of order
val_outs = []
for val_batch in val_data:
    out = validation_step(val_batch)
    if defined(&quot;validation_step_end&quot;):
        out = validation_step_end(out)
    val_outs.append(out)
val_outs = validation_epoch_end(val_outs)
</code></pre></div>
<p>.. code-block:: python</p>
<div class="highlight"><pre><span></span><code># if you have one val dataloader:
def validation_step(self, batch, batch_idx):
    ...


# if you have multiple val dataloaders:
def validation_step(self, batch, batch_idx, dataloader_idx=0):
    ...
</code></pre></div>
<p>Examples::</p>
<div class="highlight"><pre><span></span><code># CASE 1: A single validation dataset
def validation_step(self, batch, batch_idx):
    x, y = batch

    # implement your own
    out = self(x)
    loss = self.loss(out, y)

    # log 6 example images
    # or generated text... or whatever
    sample_imgs = x[:6]
    grid = torchvision.utils.make_grid(sample_imgs)
    self.logger.experiment.add_image(&#39;example_images&#39;, grid, 0)

    # calculate acc
    labels_hat = torch.argmax(out, dim=1)
    val_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0)

    # log the outputs!
    self.log_dict({&#39;val_loss&#39;: loss, &#39;val_acc&#39;: val_acc})
</code></pre></div>
<p>If you pass in multiple val dataloaders, :meth:<code>validation_step</code> will have an additional argument. We recommend
setting the default value of 0 so that you can quickly switch between single and multiple dataloaders.</p>
<p>.. code-block:: python</p>
<div class="highlight"><pre><span></span><code># CASE 2: multiple validation dataloaders
def validation_step(self, batch, batch_idx, dataloader_idx=0):
    # dataloader_idx tells you which dataset this is.
    ...
</code></pre></div>
<p>!!! note
    If you don't need to validate you don't need to implement this method.</p>
<p>!!! note
    When the :meth:<code>validation_step</code> is called, the model has been put in eval mode
    and PyTorch gradients have been disabled. At the end of validation,
    the model goes back to training mode and gradients are enabled.</p>

        <details class="quote">
          <summary>Source code in <code>bemb/model/bemb_flex_lightning.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="c1"># LL = self.model.forward(batch, return_type=&#39;log_prob&#39;, return_scope=&#39;item_index&#39;, deterministic=True).mean()</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="c1"># self.log(&#39;val_log_likelihood&#39;, LL, prog_bar=True)</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="c1"># pred = self.model(batch)</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="c1"># performance = self.model.get_within_category_accuracy(pred, batch.label)</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="c1"># utility.</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_performance_dict</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s1">&#39;val_&#39;</span> <span class="o">+</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">prog_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">))</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>







  </div>

    </div>

  </div>




  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="bemb.utils" class="doc doc-heading">
        <code>utils</code>


  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h2>

    <div class="doc doc-contents ">




  <div class="doc doc-children">










  <div class="doc doc-object doc-module">



<h3 id="bemb.utils.run_helper" class="doc doc-heading">
        <code>run_helper</code>



</h3>

    <div class="doc doc-contents ">

      <p>This script contains a helper function for training and testing the BEMB model.
The helper function here serves as a template for the training procedure, we encourage users to make a copy of this
function and modify it to fully leverage the potential of pytorch lightning (e.g., early stopping and checkpointing).</p>



  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h4 id="bemb.utils.run_helper.run" class="doc doc-heading">
<code class="highlight language-python"><span class="n">run</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataset_list</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>


</h4>

    <div class="doc doc-contents ">

      <p>A standard pipeline of model training and evaluation.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>model</code></td>
        <td><code>LitBEMBFlex</code></td>
        <td><p>the initialized pytorch-lightning wrapper of bemb.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>dataset_list</code></td>
        <td><code>List[ChoiceDataset]</code></td>
        <td><p>train_dataset, validation_test, and test_dataset in a list of length 3.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>batch_size</code></td>
        <td><code>int</code></td>
        <td><p>batch_size for training and evaluation. Defaults to -1, which indicates full-batch training.</p></td>
        <td><code>-1</code></td>
      </tr>
      <tr>
        <td><code>num_epochs</code></td>
        <td><code>int</code></td>
        <td><p>number of epochs for training. Defaults to 10.</p></td>
        <td><code>10</code></td>
      </tr>
      <tr>
        <td><code>**kwargs</code></td>
        <td></td>
        <td><p>additional keyword argument for the pytorch-lightning Trainer.</p></td>
        <td><code>{}</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>LitBEMBFlex</code></td>
      <td><p>the trained bemb model.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>bemb/utils/run_helper.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">LitBEMBFlex</span><span class="p">,</span> <span class="n">dataset_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ChoiceDataset</span><span class="p">],</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">LitBEMBFlex</span><span class="p">:</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="sd">&quot;&quot;&quot;A standard pipeline of model training and evaluation.</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="sd">        model (LitBEMBFlex): the initialized pytorch-lightning wrapper of bemb.</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="sd">        dataset_list (List[ChoiceDataset]): train_dataset, validation_test, and test_dataset in a list of length 3.</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="sd">        batch_size (int, optional): batch_size for training and evaluation. Defaults to -1, which indicates full-batch training.</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="sd">        num_epochs (int, optional): number of epochs for training. Defaults to 10.</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="sd">        **kwargs: additional keyword argument for the pytorch-lightning Trainer.</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a><span class="sd">        LitBEMBFlex: the trained bemb model.</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>    <span class="c1"># present a summary of the model received.</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>    <span class="n">section_print</span><span class="p">(</span><span class="s1">&#39;model received&#39;</span><span class="p">)</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>    <span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>    <span class="c1"># present a summary of datasets received.</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>    <span class="n">section_print</span><span class="p">(</span><span class="s1">&#39;data set received&#39;</span><span class="p">)</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[Training dataset]&#39;</span><span class="p">,</span> <span class="n">dataset_list</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[Validation dataset]&#39;</span><span class="p">,</span> <span class="n">dataset_list</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[Testing dataset]&#39;</span><span class="p">,</span> <span class="n">dataset_list</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>    <span class="c1"># create pytorch dataloader objects.</span>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a>    <span class="n">train</span> <span class="o">=</span> <span class="n">create_data_loader</span><span class="p">(</span><span class="n">dataset_list</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">)</span>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a>    <span class="n">validation</span> <span class="o">=</span> <span class="n">create_data_loader</span><span class="p">(</span><span class="n">dataset_list</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">)</span>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a>    <span class="c1"># WARNING: the test step takes extensive memory cost since it computes likelihood for all items.</span>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a>    <span class="c1"># we run the test step with a much smaller batch_size.</span>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a>    <span class="n">test</span> <span class="o">=</span> <span class="n">create_data_loader</span><span class="p">(</span><span class="n">dataset_list</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span> <span class="o">//</span> <span class="mi">10</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">)</span>
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a>
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a>    <span class="n">section_print</span><span class="p">(</span><span class="s1">&#39;train the model&#39;</span><span class="p">)</span>
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a>    <span class="n">trainer</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">gpus</span><span class="o">=</span><span class="mi">1</span> <span class="k">if</span> <span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">))</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>  <span class="c1"># use GPU if the model is currently on the GPU.</span>
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a>                         <span class="n">max_epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">,</span>
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a>                         <span class="n">check_val_every_n_epoch</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a>                         <span class="n">log_every_n_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a>                         <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a>    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a>    <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_dataloaders</span><span class="o">=</span><span class="n">train</span><span class="p">,</span> <span class="n">val_dataloaders</span><span class="o">=</span><span class="n">validation</span><span class="p">)</span>
<a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;time taken: </span><span class="si">{</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<a id="__codelineno-0-40" name="__codelineno-0-40" href="#__codelineno-0-40"></a>
<a id="__codelineno-0-41" name="__codelineno-0-41" href="#__codelineno-0-41"></a>    <span class="n">section_print</span><span class="p">(</span><span class="s1">&#39;test performance&#39;</span><span class="p">)</span>
<a id="__codelineno-0-42" name="__codelineno-0-42" href="#__codelineno-0-42"></a>    <span class="n">trainer</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataloaders</span><span class="o">=</span><span class="n">test</span><span class="p">)</span>
<a id="__codelineno-0-43" name="__codelineno-0-43" href="#__codelineno-0-43"></a>    <span class="k">return</span> <span class="n">model</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h4 id="bemb.utils.run_helper.section_print" class="doc doc-heading">
<code class="highlight language-python"><span class="n">section_print</span><span class="p">(</span><span class="n">input_text</span><span class="p">)</span></code>


</h4>

    <div class="doc doc-contents ">

      <p>Helper function for printing</p>

        <details class="quote">
          <summary>Source code in <code>bemb/utils/run_helper.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="k">def</span> <span class="nf">section_print</span><span class="p">(</span><span class="n">input_text</span><span class="p">):</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="sd">&quot;&quot;&quot;Helper function for printing&quot;&quot;&quot;</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;=&#39;</span> <span class="o">*</span> <span class="mi">20</span><span class="p">,</span> <span class="n">input_text</span><span class="p">,</span> <span class="s1">&#39;=&#39;</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>




  </div>

    </div>

  </div>




  </div>

    </div>

  </div>




              
            </article>
            
          </div>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
    <nav class="md-footer__inner md-grid" aria-label="Footer" >
      
        
        <a href="../test/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Compatibility Tests" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Compatibility Tests
            </div>
          </div>
        </a>
      
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.ecf98df9.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.9c69f0bc.min.js"></script>
      
        <script src="../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>